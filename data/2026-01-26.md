<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 53]
- [cs.LG](#cs.LG) [Total: 50]
- [cs.RO](#cs.RO) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GR3EN: Generative Relighting for 3D Environments](https://arxiv.org/abs/2601.16272)
*Xiaoyan Xing,Philipp Henzler,Junhwa Hur,Runze Li,Jonathan T. Barron,Pratul P. Srinivasan,Dor Verbin*

Main category: cs.CV

TL;DR: 通过蒸馏视频到视频扩散模型来实现大规模室内场景的可控3D重光照，避免求解困难的逆渲染问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重光照方法因逆渲染问题欠定或病态，难以在复杂真实场景中生成高质量结果；现有扩散模型方法仅限于2D或单个物体的3D重光照。

Method: 将视频到视频重光照扩散模型的输出蒸馏到3D重建中，实现对大规模真实场景的可控重光照。

Result: 在合成与真实数据集上验证，能准确渲染新视角下的新光照条件。

Conclusion: 该方法绕过逆渲染难题，为复杂真实场景提供灵活且高质量的3D重光照解决方案。

Abstract: We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.

</details>


### [2] [Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory](https://arxiv.org/abs/2601.16296)
*Dohun Lee,Chun-Hao Paul Huang,Xuelin Chen,Jong Chul Ye,Duygu Ceylan,Hyeonho Jeong*

Main category: cs.CV

TL;DR: 提出Memory-V2V框架，通过显式记忆提升多轮视频编辑的跨一致性，同时压缩冗余令牌提升30%速度。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑模型在多轮交互中难以保持编辑结果的跨一致性。

Method: 引入外部缓存记忆机制，结合精确检索与动态标记化，并在DiT骨干中嵌入可学习令牌压缩器。

Result: 在视频视角合成与文本驱动长视频编辑任务中，显著提升跨一致性，速度提升30%，性能优于SOTA方法。

Conclusion: Memory-V2V有效解决多轮视频编辑的跨一致性问题，轻量且高效，具备实用价值。

Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V

</details>


### [3] [FeTTL: Federated Template and Task Learning for Multi-Institutional Medical Imaging](https://arxiv.org/abs/2601.16302)
*Abhijeet Parida,Antonia Alomar,Zhifan Jiang,Pooneh Roshanitabrizi,Austin Tapp,Ziyue Xu,Syed Muhammad Anwar,Maria J. Ledesma-Carbayo,Holger R. Roth,Marius George Linguraru*

Main category: cs.CV

TL;DR: FeTTL是一种新的联邦学习框架，通过联合学习全局模板和任务模型来缓解医学影像中的域偏移问题，显著提升多机构数据下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在医学影像中面临数据分布异质性（如扫描协议、设备和人群差异）导致的性能下降问题。

Method: 提出FeTTL框架，联合学习一个全局模板和任务模型，以对齐不同机构的数据分布。

Result: 在视网膜光学盘分割和组织病理转移分类任务上，FeTTL显著优于现有联邦学习基线（p值<0.002）。

Conclusion: FeTTL为联邦学习中的分布偏移提供了系统性、可扩展的解决方案，支持真实多机构环境中的鲁棒部署。

Abstract: Federated learning enables collaborative model training across geographically distributed medical centers while preserving data privacy. However, domain shifts and heterogeneity in data often lead to a degradation in model performance. Medical imaging applications are particularly affected by variations in acquisition protocols, scanner types, and patient populations. To address these issues, we introduce Federated Template and Task Learning (FeTTL), a novel framework designed to harmonize multi-institutional medical imaging data in federated environments. FeTTL learns a global template together with a task model to align data distributions among clients. We evaluated FeTTL on two challenging and diverse multi-institutional medical imaging tasks: retinal fundus optical disc segmentation and histopathological metastasis classification. Experimental results show that FeTTL significantly outperforms the state-of-the-art federated learning baselines (p-values <0.002) for optical disc segmentation and classification of metastases from multi-institutional data. Our experiments further highlight the importance of jointly learning the template and the task. These findings suggest that FeTTL offers a principled and extensible solution for mitigating distribution shifts in federated learning, supporting robust model deployment in real-world, multi-institutional environments.

</details>


### [4] [Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments](https://arxiv.org/abs/2601.16333)
*Aditya K Surikuchi,Raquel Fernández,Sandro Pezzelle*

Main category: cs.CV

TL;DR: 研究视频中重要子事件识别能力，发现现有多模态模型表现接近随机，依赖单一模态，缺乏跨模态协同。


<details>
  <summary>Details</summary>
Motivation: 为实现多模态事件的叙事与摘要，需准确识别视频中的关键子事件，但现有模型在该任务上表现不佳。

Method: 构建基于足球比赛精彩集锦的人类偏好数据集，无额外标注成本，评估多种多模态模型。

Result: 现有模型性能接近随机水平，过度依赖单一模态，未能有效融合多源信息。

Conclusion: 需设计模块化架构处理多模态数据的样本异质性，并开发增强跨模态协同的训练方法。

Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

</details>


### [5] [Coarse-to-Fine Non-rigid Multi-modal Image Registration for Historical Panel Paintings based on Crack Structures](https://arxiv.org/abs/2601.16348)
*Aline Sindel,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 提出一种基于裂纹特征的粗到细非刚性多模态图像配准方法，显著提升历史木板画图像配准精度与效率。


<details>
  <summary>Details</summary>
Motivation: 传统多模态图像配准依赖人工，耗时且精度低，需自动化方法解决分辨率差异、非刚性形变和模态内容差异等挑战。

Method: 利用画作裂纹特征，结合CNN进行关键点检测与描述，GNN进行局部补丁匹配，并通过同源重投影误差过滤，引入多级关键点精炼策略实现粗到细配准。

Result: 在自制高精度多模态数据集上，所提方法在多种分辨率和模态下均优于现有关键点与稠密匹配方法。

Conclusion: 该方法有效解决了历史绘画多模态图像配准难题，为艺术科技分析提供了自动化、高精度的解决方案。

Abstract: Art technological investigations of historical panel paintings rely on acquiring multi-modal image data, including visual light photography, infrared reflectography, ultraviolet fluorescence photography, x-radiography, and macro photography. For a comprehensive analysis, the multi-modal images require pixel-wise alignment, which is still often performed manually. Multi-modal image registration can reduce this laborious manual work, is substantially faster, and enables higher precision. Due to varying image resolutions, huge image sizes, non-rigid distortions, and modality-dependent image content, registration is challenging. Therefore, we propose a coarse-to-fine non-rigid multi-modal registration method efficiently relying on sparse keypoints and thin-plate-splines. Historical paintings exhibit a fine crack pattern, called craquelure, on the paint layer, which is captured by all image systems and is well-suited as a feature for registration. In our one-stage non-rigid registration approach, we employ a convolutional neural network for joint keypoint detection and description based on the craquelure and a graph neural network for descriptor matching in a patch-based manner, and filter matches based on homography reprojection errors in local areas. For coarse-to-fine registration, we introduce a novel multi-level keypoint refinement approach to register mixed-resolution images up to the highest resolution. We created a multi-modal dataset of panel paintings with a high number of keypoint annotations, and a large test set comprising five multi-modal domains and varying image resolutions. The ablation study demonstrates the effectiveness of all modules of our refinement method. Our proposed approaches achieve the best registration results compared to competing keypoint and dense matching methods and refinement methods.

</details>


### [6] [Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models](https://arxiv.org/abs/2601.16378)
*Bridget Leonard,Scott O. Murray*

Main category: cs.CV

TL;DR: 通过引入视角标记，提升多模态语言模型在空间推理任务中的表现，实现更接近人类的视角转换能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在视觉-语言任务中表现良好，但在需要采纳他人视角的空间推理中存在自我中心偏差，缺乏投射性推理能力。

Method: 引入两种视角标记：基于身体关键点的具身线索和抽象表征支持心理旋转，集成到LLaVA-1.5-13B模型中。

Result: 在Isle Bricks V2、COCO、3DSRBench等基准上显著提升准确率，旋转型标记可泛化至非人类代理。

Conclusion: 模型已具备投射性推理的潜在基础，仅缺适当结构；视角标记是一种轻量、通用的增强空间推理机制。

Abstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.

</details>


### [7] [VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection](https://arxiv.org/abs/2601.16381)
*Yuxin Jiang,Yunkang Cao,Yuqi Cheng,Yiheng Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 提出VTFusion框架，通过自适应特征提取和跨模态融合提升少样本异常检测性能，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖自然场景预训练特征，忽视工业领域细粒度语义，且视觉与文本模态融合过于浅层，导致跨模态干扰严重。

Method: 设计自适应图像与文本特征提取器，生成合成异常增强判别力，并引入跨模态交互融合块与多模态引导的分割网络，实现精细像素级异常图生成。

Result: 在MVTec AD和VisA的2-shot场景下，图像级AUROC分别达96.8%和86.2%，在自建工业汽车塑料件数据集上AUPRO达93.5%。

Conclusion: VTFusion有效弥合了预训练模型与工业场景的语义鸿沟，通过深度跨模态融合显著提升少样本异常检测的鲁棒性与实用性。

Abstract: Few-Shot Anomaly Detection (FSAD) has emerged as a critical paradigm for identifying irregularities using scarce normal references. While recent methods have integrated textual semantics to complement visual data, they predominantly rely on features pre-trained on natural scenes, thereby neglecting the granular, domain-specific semantics essential for industrial inspection. Furthermore, prevalent fusion strategies often resort to superficial concatenation, failing to address the inherent semantic misalignment between visual and textual modalities, which compromises robustness against cross-modal interference. To bridge these gaps, this study proposes VTFusion, a vision-text multimodal fusion framework tailored for FSAD. The framework rests on two core designs. First, adaptive feature extractors for both image and text modalities are introduced to learn task-specific representations, bridging the domain gap between pre-trained models and industrial data; this is further augmented by generating diverse synthetic anomalies to enhance feature discriminability. Second, a dedicated multimodal prediction fusion module is developed, comprising a fusion block that facilitates rich cross-modal information exchange and a segmentation network that generates refined pixel-level anomaly maps under multimodal guidance. VTFusion significantly advances FSAD performance, achieving image-level AUROCs of 96.8% and 86.2% in the 2-shot scenario on the MVTec AD and VisA datasets, respectively. Furthermore, VTFusion achieves an AUPRO of 93.5% on a real-world dataset of industrial automotive plastic parts introduced in this paper, further demonstrating its practical applicability in demanding industrial scenarios.

</details>


### [8] [ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation](https://arxiv.org/abs/2601.16394)
*Yihao Wang,Jusheng Zhang,Ziyi Tang,Keze Wang,Meng Yang*

Main category: cs.CV

TL;DR: 提出EBD和VBR模块的新型RES框架，通过熵引导点发现和视觉推理实现更精准的指代分割，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM方法依赖粗框和文本坐标推理，导致提示冗余且难以区分视觉相似干扰物。

Method: 引入熵基点发现（EBD）从粗框中择取高信息量点，并结合视觉基推理（VBR）通过跨模态对齐验证点正确性，构建粗到细的分割流程。

Result: 在RefCOCO、RefCOCO+、RefCOCOg和ReasonSeg四个基准上均达到新SOTA性能。

Conclusion: EBD与VBR有效克服文本推理局限，实现低提示、高精度的语义接地分割。

Abstract: Referring Expression Segmentation (RES) is a core vision-language segmentation task that enables pixel-level understanding of targets via free-form linguistic expressions, supporting critical applications such as human-robot interaction and augmented reality. Despite the progress of Multimodal Large Language Model (MLLM)-based approaches, existing RES methods still suffer from two key limitations: first, the coarse bounding boxes from MLLMs lead to redundant or non-discriminative point prompts; second, the prevalent reliance on textual coordinate reasoning is unreliable, as it fails to distinguish targets from visually similar distractors. To address these issues, we propose \textbf{\model}, a novel RES framework integrating \textbf{E}ntropy-\textbf{B}ased Point \textbf{D}iscovery (\textbf{EBD}) and \textbf{V}ision-\textbf{B}ased \textbf{R}easoning (\textbf{VBR}). Specifically, EBD identifies high-information candidate points by modeling spatial uncertainty within coarse bounding boxes, treating point selection as an information maximization process. VBR verifies point correctness through joint visual-semantic alignment, abandoning text-only coordinate inference for more robust validation. Built on these components, \model implements a coarse-to-fine workflow: bounding box initialization, entropy-guided point discovery, vision-based validation, and mask decoding. Extensive evaluations on four benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg) demonstrate that \model achieves new state-of-the-art performance across all four benchmarks, highlighting its effectiveness in generating accurate and semantically grounded segmentation masks with minimal prompts.

</details>


### [9] [A Cosine Network for Image Super-Resolution](https://arxiv.org/abs/2601.16413)
*Chunwei Tian,Chengyuan Zhang,Bob Zhang,Zhiwu Li,C. L. Philip Chen,David Zhang*

Main category: cs.CV

TL;DR: 提出CSRNet，通过异构块和余弦退火优化图像超分辨率


<details>
  <summary>Details</summary>
Motivation: 传统方法在保留结构信息方面效果有限，需提升超分辨率性能

Method: 设计奇偶异构块提取互补结构信息，结合线性与非线性信息，采用余弦退火优化训练

Result: CSRNet在图像超分辨率任务中达到与当前最优方法相当的性能

Conclusion: 异构架构与余弦退火策略有效提升结构信息保留能力与模型鲁棒性

Abstract: Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.

</details>


### [10] [DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target](https://arxiv.org/abs/2601.16428)
*Shuying Li,Qiang Ma,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 提出DCCS-Det模型，通过双流显著性增强和潜在语义提取模块，提升红外小目标检测的准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在局部-全局特征联合建模和特征冗余方面表现不足，导致目标-背景区分差和目标表征质量下降。

Method: 引入双流显著性增强（DSE）块和潜在感知语义提取与聚合（LaSEA）模块，结合方向感知上下文聚合与跨尺度特征提取，增强特征判别力并抑制噪声。

Result: 在多个数据集上达到最优检测精度，同时保持高效性，消融实验验证了DSE和LaSEA模块的有效性。

Conclusion: DCCS-Det显著提升了复杂背景下红外小目标的检测性能，为红外目标检测提供了新思路。

Abstract: Infrared small target detection (IRSTD) is critical for applications like remote sensing and surveillance, which aims to identify small, low-contrast targets against complex backgrounds. However, existing methods often struggle with inadequate joint modeling of local-global features (harming target-background discrimination) or feature redundancy and semantic dilution (degrading target representation quality). To tackle these issues, we propose DCCS-Det (Directional Context and Cross-Scale Aware Detector for Infrared Small Target), a novel detector that incorporates a Dual-stream Saliency Enhancement (DSE) block and a Latent-aware Semantic Extraction and Aggregation (LaSEA) module. The DSE block integrates localized perception with direction-aware context aggregation to help capture long-range spatial dependencies and local details. On this basis, the LaSEA module mitigates feature degradation via cross-scale feature extraction and random pooling sampling strategies, enhancing discriminative features and suppressing noise. Extensive experiments show that DCCS-Det achieves state-of-the-art detection accuracy with competitive efficiency across multiple datasets. Ablation studies further validate the contributions of DSE and LaSEA in improving target perception and feature representation under complex scenarios. \href{https://huggingface.co/InPeerReview/InfraredSmallTargetDetection-IRSTD.DCCS}{DCCS-Det Official Code is Available Here!}

</details>


### [11] [AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose](https://arxiv.org/abs/2601.16429)
*Jongmin Yu,Hyeontaek Oh,Zhongtian Sun,Angelica I Aviles-Rivero,Moongu Jeon,Jinhong Yang*

Main category: cs.CV

TL;DR: AlphaFace通过视觉-语言模型和对比损失，在保持实时性能的同时提升极端姿态下的人脸交换质量


<details>
  <summary>Details</summary>
Motivation: 现有人脸交换方法在极端姿态下质量下降，几何特征增加计算负担，扩散模型不适用于实时场景

Method: 利用开源视觉语言模型和CLIP嵌入，引入视觉与文本语义对比损失

Result: 在FF++、MPIE和LPFF数据集上超越现有方法，尤其在姿态挑战场景表现优异

Conclusion: AlphaFace实现了高保真身份保持与属性精确还原，同时满足实时性需求

Abstract: Existing face-swapping methods often deliver competitive results in constrained settings but exhibit substantial quality degradation when handling extreme facial poses. To improve facial pose robustness, explicit geometric features are applied, but this approach remains problematic since it introduces additional dependencies and increases computational cost. Diffusion-based methods have achieved remarkable results; however, they are impractical for real-time processing. We introduce AlphaFace, which leverages an open-source vision-language model and CLIP image and text embeddings to apply novel visual and textual semantic contrastive losses. AlphaFace enables stronger identity representation and more precise attribute preservation, all while maintaining real-time performance. Comprehensive experiments across FF++, MPIE, and LPFF demonstrate that AlphaFace surpasses state-of-the-art methods in pose-challenging cases. The project is publicly available on `https://github.com/andrewyu90/Alphaface_Official.git'.

</details>


### [12] [MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection](https://arxiv.org/abs/2601.16434)
*Shuying Li,Qiang Ma,San Zhang,Wuwei Wang,Chuang Yang*

Main category: cs.CV

TL;DR: 提出MDAFNet网络，通过多尺度边缘差分和自适应频域增强模块提升红外小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在深层网络中目标边缘信息逐渐丢失，传统卷积难以区分频率成分，导致低频背景干扰和高频噪声误检。

Method: 引入MSDE模块补偿下采样中的边缘信息损失，结合DAFE模块在空域与频域自适应增强高频目标并抑制噪声。

Result: 在多个数据集上实验表明MDAFNet检测性能显著优于现有方法。

Conclusion: MDAFNet有效解决了红外小目标检测中的边缘退化与频率混淆问题，提升了检测精度与鲁棒性。

Abstract: Infrared small target detection (IRSTD) plays a crucial role in numerous military and civilian applications. However, existing methods often face the gradual degradation of target edge pixels as the number of network layers increases, and traditional convolution struggles to differentiate between frequency components during feature extraction, leading to low-frequency backgrounds interfering with high-frequency targets and high-frequency noise triggering false detections. To address these limitations, we propose MDAFNet (Multi-scale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection), which integrates the Multi-Scale Differential Edge (MSDE) module and Dual-Domain Adaptive Feature Enhancement (DAFE) module. The MSDE module, through a multi-scale edge extraction and enhancement mechanism, effectively compensates for the cumulative loss of target edge information during downsampling. The DAFE module combines frequency domain processing mechanisms with simulated frequency decomposition and fusion mechanisms in the spatial domain to effectively improve the network's capability to adaptively enhance high-frequency targets and selectively suppress high-frequency noise. Experimental results on multiple datasets demonstrate the superior detection performance of MDAFNet.

</details>


### [13] [Masked Face Recognition under Different Backbones](https://arxiv.org/abs/2601.16440)
*Bo Zhang,Ming Zhang,Kun Wu,Lei Bian,Yi Lin*

Main category: cs.CV

TL;DR: 本文修正了2025年论文中的表格和数据，并评估了多种主干网络在戴口罩场景下的人脸识别性能，发现r100_mask_v2和ViT系列表现最佳。


<details>
  <summary>Details</summary>
Motivation: 后疫情时代大量乘客戴口罩，传统人脸识别模型性能下降，亟需评估不同主干网络在遮挡场景下的适应性。

Method: 通过大量对比实验，评估r100、r50、r34_mask_v1及ViT-Small/Tiny等主干网络在有无口罩场景下的识别准确率。

Result: 无口罩时r100表现最佳（>98%）；有口罩时r100_mask_v2准确率达90.07%，ViT-Small/Tiny表现突出，优于传统模型。

Conclusion: 推荐在口罩场景部署r100_mask_v2或ViT系列模型，传统模型需针对性优化。

Abstract: Erratum to the paper (Zhang et al., 2025): corrections to Table IV and the data in Page 3, Section A. In the post-pandemic era, a high proportion of civil aviation passengers wear masks during security checks, posing significant challenges to traditional face recognition models. The backbone network serves as the core component of face recognition models. In standard tests, r100 series models excelled (98%+ accuracy at 0.01% FAR in face comparison, high top1/top5 in search). r50 ranked second, r34_mask_v1 lagged. In masked tests, r100_mask_v2 led (90.07% accuracy), r50_mask_v3 performed best among r50 but trailed r100. Vit-Small/Tiny showed strong masked performance with gains in effectiveness. Through extensive comparative experiments, this paper conducts a comprehensive evaluation of several core backbone networks, aiming to reveal the impacts of different models on face recognition with and without masks, and provide specific deployment recommendations.

</details>


### [14] [Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding](https://arxiv.org/abs/2601.16449)
*Xiaojiang Peng,Jingyi Chen,Zebang Cheng,Bao Peng,Fengyi Wu,Yifei Dong,Shuyuan Tu,Qiyu Hu,Huiting Huang,Yuxiang Lin,Jun-Yan He,Kai Wang,Zheng Lian,Zhi-Qi Cheng*

Main category: cs.CV

TL;DR: 提出Emotion-LLaMAv2与MMEVerse基准，通过端到端多视角编码、卷积注意力预融合和感知到认知课程调优，提升多模态情感推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在情感推理上表现有限，缺乏大规模高质量标注数据与标准化评估基准。

Method: 1. 端到端多视角编码替代人脸检测；2. Conv Attention预融合模块实现局部与全局特征交互；3. 基于LLaMA2的感知到认知课程调优策略。

Result: 构建MMEVerse基准，整合12个数据集，生成13万训练和3.6万测试样本，覆盖18个评估任务，显著提升情感识别与推理性能。

Conclusion: Emotion-LLaMAv2与MMEVerse为多模态情感计算提供了端到端框架与标准化评估体系，推动该领域发展。

Abstract: Understanding human emotions from multimodal signals poses a significant challenge in affective computing and human-robot interaction. While multimodal large language models (MLLMs) have excelled in general vision-language tasks, their capabilities in emotional reasoning remain limited. The field currently suffers from a scarcity of large-scale datasets with high-quality, descriptive emotion annotations and lacks standardized benchmarks for evaluation. Our preliminary framework, Emotion-LLaMA, pioneered instruction-tuned multimodal learning for emotion reasoning but was restricted by explicit face detectors, implicit fusion strategies, and low-quality training data with limited scale. To address these limitations, we present Emotion-LLaMAv2 and the MMEVerse benchmark, establishing an end-to-end pipeline together with a standardized evaluation setting for emotion recognition and reasoning. Emotion-LLaMAv2 introduces three key advances. First, an end-to-end multiview encoder eliminates external face detection and captures nuanced emotional cues via richer spatial and temporal multiview tokens. Second, a Conv Attention pre-fusion module is designed to enable simultaneous local and global multimodal feature interactions external to the LLM backbone. Third, a perception-to-cognition curriculum instruction tuning scheme within the LLaMA2 backbone unifies emotion recognition and free-form emotion reasoning. To support large-scale training and reproducible evaluation, MMEVerse aggregates twelve publicly available emotion datasets, including IEMOCAP, MELD, DFEW, and MAFW, into a unified multimodal instruction format. The data are re-annotated via a multi-agent pipeline involving Qwen2 Audio, Qwen2.5 VL, and GPT 4o, producing 130k training clips and 36k testing clips across 18 evaluation benchmarks.

</details>


### [15] [VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology](https://arxiv.org/abs/2601.16451)
*Peixian Liang,Songhao Li,Shunsuke Koga,Yutong Li,Zahra Alipour,Yucheng Tang,Daguang Xu,Zhi Huang*

Main category: cs.CV

TL;DR: VISTA-PATH 是一个交互式、类感知的病理分割基础模型，通过结合视觉上下文、语义描述和专家反馈，实现精准的多类病理分割，并显著提升临床意义的组织分析。


<details>
  <summary>Details</summary>
Motivation: 现有分割基础模型将病理图像分割视为静态视觉预测任务，缺乏对病理特异性和临床解释性的支持，难以处理异质结构和融入专家反馈。

Method: VISTA-PATH 联合条件化视觉上下文、语义组织描述和可选的空间提示，构建交互式分割框架，并基于包含160万+图像-掩码-文本三元组的VISTA-PATH Data数据集进行训练，支持动态人机反馈优化。

Result: VISTA-PATH 在多个外部基准上超越现有模型，支持通过稀疏标注反馈优化全切片分割，并通过提出的肿瘤互作评分（TIS）显著关联患者生存率。

Conclusion: VISTA-PATH 将病理图像分割从静态预测提升为交互式、临床可解释的表示方法，成为数字病理学的优选基础模型。

Abstract: Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.

</details>


### [16] [Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos](https://arxiv.org/abs/2601.16471)
*Meng Cao,Haoran Tang,Haoze Zhao,Mingfei Han,Ruyang Liu,Qiang Sun,Xiaojun Chang,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: 利用游戏视频中的物理异常作为监督信号，构建PhysGame数据集和GameBench基准，显著提升多模态模型的物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有物理推理数据集要么标注成本高，要么缺乏真实性和多样性，亟需一种可扩展的监督来源。

Method: 提出利用游戏视频中的物理异常（glitches）作为监督信号，构建包含14万+QA对的PhysGame数据集，并设计元信息引导的QA生成策略，同时构建专家标注的GameBench基准。

Result: PhysGame提升Qwen2.5VL在PhysBench上2.5%、MVBench上1.9%的性能，GameBench上绝对提升3.7%，显著增强物理异常检测与跨域泛化能力。

Conclusion: 游戏异常提供了一种可扩展、高效的物理世界理解新路径，推动多模态AI向人类水平的物理推理迈进。

Abstract: Understanding the physical world, including object dynamics, material properties, and causal interactions, remains a core challenge in artificial intelligence. Although recent multi-modal large language models (MLLMs) have demonstrated impressive general reasoning capabilities, they still fall short of achieving human-level understanding of physical principles. Existing datasets for physical reasoning either rely on real-world videos, which incur high annotation costs, or on synthetic simulations, which suffer from limited realism and diversity. In this paper, we propose a novel paradigm that leverages glitches in gameplay videos, referring to visual anomalies that violate predefined physical laws, as a rich and scalable supervision source for physical world understanding. We introduce PhysGame, an meta information guided instruction-tuning dataset containing 140,057 glitch-centric question-answer pairs across five physical domains and sixteen fine-grained categories. To ensure data accuracy, we design a prompting strategy that utilizes gameplay metadata such as titles and descriptions to guide high-quality QA generation. Complementing PhysGame, we construct GameBench, an expert-annotated benchmark with 880 glitch-identified gameplay videos designed to evaluate physical reasoning capabilities. Extensive experiments show that PhysGame significantly enhances both Game2Real transferability, improving the real world physical reasoning performance of Qwen2.5VL by 2.5% on PhysBench, and Game2General transferability, yielding a 1.9% gain on the MVBench benchmark. Moreover, PhysGame-tuned models achieve a 3.7% absolute improvement on GameBench, demonstrating enhanced robustness in detecting physical implausibilities. These results indicate that learning from gameplay anomalies offers a scalable and effective pathway toward advancing physical world understanding in multimodal intelligence.

</details>


### [17] [GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss](https://arxiv.org/abs/2601.16885)
*Yangfan Xu,Lilian Zhang,Xiaofeng He,Pengdong Wu,Wenqi Wu,Jun Mao*

Main category: cs.CV

TL;DR: 提出一种自监督VGGT框架，利用序列几何约束在无标签数据上训练，显著提升大尺度定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有VGGT模型依赖标注数据，难以适应无标签与未知场景，需探索自监督学习方法。

Method: 将成对关系扩展为序列级几何约束，通过多源帧投影到目标帧实现时序特征一致性，并联合优化光度与几何一致性损失。

Result: 模型在数百次迭代内收敛，在大尺度定位任务中表现显著提升，无需硬标签。

Conclusion: 所提自监督框架有效利用多视图几何信息，提升模型在无标签场景下的泛化能力。

Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.

</details>


### [18] [Multi-View Consistent Wound Segmentation With Neural Fields](https://arxiv.org/abs/2601.16487)
*Remi Chierchia,Léo Lebrat,David Ahmedt-Aristizabal,Yulia Arzhaeva,Olivier Salvado,Clinton Fookes,Rodrigo Santa Cruz*

Main category: cs.CV

TL;DR: 本文评估了WoundNeRF方法，利用NeRF SDF从2D图像中实现鲁棒的伤口分割，优于现有视觉Transformer和传统算法。


<details>
  <summary>Details</summary>
Motivation: 伤口护理面临经济与物流负担，现有2D分割方法难以精确追踪愈合进程，亟需更准确的3D重建技术。

Method: 提出WoundNeRF，一种基于NeRF SDF的方法，通过自动生成的标注来估计伤口的3D分割。

Result: WoundNeRF在分割精度上优于前沿的Vision Transformer和传统光栅化算法。

Conclusion: WoundNeRF展示了从2D图像重建多视角一致3D伤口结构的潜力，将开源代码推动该领域发展。

Abstract: Wound care is often challenged by the economic and logistical burdens that consistently afflict patients and hospitals worldwide. In recent decades, healthcare professionals have sought support from computer vision and machine learning algorithms. In particular, wound segmentation has gained interest due to its ability to provide professionals with fast, automatic tissue assessment from standard RGB images. Some approaches have extended segmentation to 3D, enabling more complete and precise healing progress tracking. However, inferring multi-view consistent 3D structures from 2D images remains a challenge. In this paper, we evaluate WoundNeRF, a NeRF SDF-based method for estimating robust wound segmentations from automatically generated annotations. We demonstrate the potential of this paradigm in recovering accurate segmentations by comparing it against state-of-the-art Vision Transformer networks and conventional rasterisation-based algorithms. The code will be released to facilitate further development in this promising paradigm.

</details>


### [19] [AnyView: Synthesizing Any Novel View in Dynamic Scenes](https://arxiv.org/abs/2601.16982)
*Basile Van Hoorick,Dian Chen,Shun Iwase,Pavel Tokmakov,Muhammad Zubair Irshad,Igor Vasiljevic,Swati Gupta,Fangzhou Cheng,Sergey Zakharov,Vitor Campagnolo Guizilini*

Main category: cs.CV

TL;DR: AnyView 是一个基于扩散模型的视频生成框架，能在极少几何假设下实现动态视角合成，显著提升多视角与时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型在高度动态真实场景中难以保持多视角和时空一致性。

Method: 利用单目（2D）、多视角静态（3D）和多视角动态（4D）数据训练通用时空隐式表征，支持任意相机位置与轨迹的零样本视频生成。

Result: 在标准基准上表现与SOTA相当，并在新提出的AnyViewBench（极端动态视角合成）上显著优于基线方法。

Conclusion: AnyView 能在无视角重叠的极端情况下生成真实、一致的视频，证明了其强大的泛化能力。

Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/

</details>


### [20] [Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification](https://arxiv.org/abs/2601.16498)
*Chen Long,Dian Chen,Ruifei Ding,Zhe Chen,Zhen Dong,Bisheng Yang*

Main category: cs.CV

TL;DR: 提出EKDC-Net，通过外部专家知识引导校准分类决策，在少样本和类别相似场景下显著提升树种分类精度，同时发布大规模CU-Tree102数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视长尾分布和高类间相似性问题，难以区分少样本或易混淆树种类别。

Method: 引入外部专家知识，设计LPKEM提取判别性特征，并通过UDCM基于不确定性动态校准模型决策，结合新构建的CU-Tree102数据集进行训练与验证。

Result: 在三个基准数据集上达到SOTA性能，仅增加0.08M参数，分类准确率提升6.42%，精确率提升11.46%。

Conclusion: EKDC-Net作为轻量级插件模块，有效利用专家知识提升小样本树种分类能力，CU-Tree102数据集填补了领域数据稀缺空白。

Abstract: Accurate fine-grained tree species classification is critical for forest inventory and biodiversity monitoring. Existing methods predominantly focus on designing complex architectures to fit local data distributions. However, they often overlook the long-tailed distributions and high inter-class similarity inherent in limited data, thereby struggling to distinguish between few-shot or confusing categories. In the process of knowledge dissemination in the human world, individuals will actively seek expert assistance to transcend the limitations of local thinking. Inspired by this, we introduce an external "Domain Expert" and propose an Expert Knowledge-Guided Classification Decision Calibration Network (EKDC-Net) to overcome these challenges. Our framework addresses two core issues: expert knowledge extraction and utilization. Specifically, we first develop a Local Prior Guided Knowledge Extraction Module (LPKEM). By leveraging Class Activation Map (CAM) analysis, LPKEM guides the domain expert to focus exclusively on discriminative features essential for classification. Subsequently, to effectively integrate this knowledge, we design an Uncertainty-Guided Decision Calibration Module (UDCM). This module dynamically corrects the local model's decisions by considering both overall category uncertainty and instance-level prediction uncertainty. Furthermore, we present a large-scale classification dataset covering 102 tree species, named CU-Tree102 to address the issue of scarce diversity in current benchmarks. Experiments on three benchmark datasets demonstrate that our approach achieves state-of-the-art performance. Crucially, as a lightweight plug-and-play module, EKDC-Net improves backbone accuracy by 6.42% and precision by 11.46% using only 0.08M additional learnable parameters. The dataset, code, and pre-trained models are available at https://github.com/WHU-USI3DV/TreeCLS.

</details>


### [21] [SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer](https://arxiv.org/abs/2601.16515)
*Tongcheng Fang,Hanling Zhang,Ruiqi Xie,Zhuo Han,Xin Tao,Tianchen Zhao,Pengfei Wan,Wenbo Ding,Wanli Ouyang,Xuefei Ning,Yu Wang*

Main category: cs.CV

TL;DR: 提出SALAD方法，在稀疏注意力旁并行引入轻量线性注意力分支，通过输入依赖的门控机制平衡两者，实现90%稀疏度和1.72倍推理加速，同时保持生成质量，且微调高效。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频生成中表现优异，但全注意力机制因二次复杂度导致计算延迟高，现有稀疏注意力方法在稀疏度与训练开销之间存在权衡。

Method: 在稀疏注意力旁并行添加轻量线性注意力分支，并引入输入依赖的门控机制动态平衡两个分支，实现高效推理。

Result: 达到90%稀疏度，推理速度提升1.72倍，生成质量与全注意力基线相当，仅需2000个视频样本和1600步训练即可微调。

Conclusion: SALAD在不牺牲生成质量的前提下，显著降低计算开销，且微调效率高，为视频生成中的高效注意力机制提供了新方案。

Abstract: Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.

</details>


### [22] [TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning](https://arxiv.org/abs/2601.16520)
*Daixian Liu,Jiayi Kuang,Yinghui Li,Yangning Li,Di Yin,Haoyu Cao,Xing Sun,Ying Shen,Hai-Tao Zheng,Liang Lin,Philip S. Yu*

Main category: cs.CV

TL;DR: 提出TangramPuzzle基准，通过几何精确的拼图任务评估多模态大模型的空间推理能力，发现模型忽视几何约束而仅匹配轮廓。


<details>
  <summary>Details</summary>
Motivation: 现有基准任务简单、评估模糊，缺乏对精确空间组合推理的严谨评测。

Method: 设计基于七巧板的几何基准TangramPuzzle，引入符号几何框架TCE，定义轮廓预测与端到端代码生成两个任务。

Result: 主流MLLMs在任务中优先匹配轮廓，忽略几何约束，导致部件变形或失真。

Conclusion: 当前MLLMs在精确空间推理上存在显著缺陷，需更严格的几何基准推动改进。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual recognition and semantic understanding. Nevertheless, their ability to perform precise compositional spatial reasoning remains largely unexplored. Existing benchmarks often involve relatively simple tasks and rely on semantic approximations or coarse relative positioning, while their evaluation metrics are typically limited and lack rigorous mathematical formulations. To bridge this gap, we introduce TangramPuzzle, a geometry-grounded benchmark designed to evaluate compositional spatial reasoning through the lens of the classic Tangram game. We propose the Tangram Construction Expression (TCE), a symbolic geometric framework that grounds tangram assemblies in exact, machine-verifiable coordinate specifications, to mitigate the ambiguity of visual approximation. We design two complementary tasks: Outline Prediction, which demands inferring global shapes from local components, and End-to-End Code Generation, which requires solving inverse geometric assembly problems. We conduct extensive evaluation experiments on advanced open-source and proprietary models, revealing an interesting insight: MLLMs tend to prioritize matching the target silhouette while neglecting geometric constraints, leading to distortions or deformations of the pieces.

</details>


### [23] [AnchoredDream: Zero-Shot 360° Indoor Scene Generation from a Single View via Geometric Grounding](https://arxiv.org/abs/2601.16532)
*Runmao Yao,Junsheng Zhou,Zhen Dong,Yu-Shen Liu*

Main category: cs.CV

TL;DR: 提出AnchoredDream，通过几何与外观协同增强实现单图像零样本360°室内场景生成，显著提升一致性和几何合理性。


<details>
  <summary>Details</summary>
Motivation: 单图像生成完整360°场景因视角变化大而难以保持外观一致性和几何合理性，现有方法受限。

Method: 利用外观引导几何生成，结合warp-and-inpaint、warp-and-refine、后优化和新型Grouting Block模块，实现几何锚定的渐进式场景生成。

Result: 在零样本条件下，AnchoredDream在外观一致性和几何合理性上大幅超越现有方法。

Conclusion: 几何锚定是实现高质量零样本单视图场景生成的关键，具有广泛应用潜力。

Abstract: Single-view indoor scene generation plays a crucial role in a range of real-world applications. However, generating a complete 360° scene from a single image remains a highly ill-posed and challenging problem. Recent approaches have made progress by leveraging diffusion models and depth estimation networks, yet they still struggle to maintain appearance consistency and geometric plausibility under large viewpoint changes, limiting their effectiveness in full-scene generation. To address this, we propose AnchoredDream, a novel zero-shot pipeline that anchors 360° scene generation on high-fidelity geometry via an appearance-geometry mutual boosting mechanism. Given a single-view image, our method first performs appearance-guided geometry generation to construct a reliable 3D scene layout. Then, we progressively generate the complete scene through a series of modules: warp-and-inpaint, warp-and-refine, post-optimization, and a novel Grouting Block, which ensures seamless transitions between the input view and generated regions. Extensive experiments demonstrate that AnchoredDream outperforms existing methods by a large margin in both appearance consistency and geometric plausibility--all in a zero-shot manner. Our results highlight the potential of geometric grounding for high-quality, zero-shot single-view scene generation.

</details>


### [24] [OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding](https://arxiv.org/abs/2601.16538)
*Zixian Liu,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出OnlineSI框架，通过有限空间记忆和融合3D点云与语义信息，实现MLLM在视频流中持续提升空间理解能力，支持真实环境部署。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视MLLM在动态环境中的持续学习能力，且难以部署于实体系统。

Method: 维护有限空间记忆以稳定计算开销，融合3D点云与语义信息增强物体定位，引入Fuzzy F1-Score评估模糊场景下的性能。

Result: 在两个代表性数据集上验证了方法有效性，显著提升空间理解能力。

Conclusion: OnlineSI为MLLM在真实世界实体系统中的应用奠定了基础。

Abstract: In recent years, researchers have increasingly been interested in how to enable Multimodal Large Language Models (MLLM) to possess spatial understanding and reasoning capabilities. However, most existing methods overlook the importance of the ability to continuously work in an ever-changing world, and lack the possibility of deployment on embodied systems in real-world environments. In this work, we introduce OnlineSI, a framework that can continuously improve its spatial understanding of its surroundings given a video stream. Our core idea is to maintain a finite spatial memory to retain past observations, ensuring the computation required for each inference does not increase as the input accumulates. We further integrate 3D point cloud information with semantic information, helping MLLM to better locate and identify objects in the scene. To evaluate our method, we introduce the Fuzzy $F_1$-Score to mitigate ambiguity, and test our method on two representative datasets. Experiments demonstrate the effectiveness of our method, paving the way towards real-world embodied systems.

</details>


### [25] [Semi-Supervised Hierarchical Open-Set Classification](https://arxiv.org/abs/2601.16541)
*Erik Wallin,Fredrik Kahl,Lars Hammarstrand*

Main category: cs.CV

TL;DR: 提出一种基于伪标签的师生框架，提升半监督层次开放集分类性能，仅用20个标签样本即可媲美全监督效果。


<details>
  <summary>Details</summary>
Motivation: 利用大规模未标注数据（含未知类别）改善层次开放集分类性能，解决现有方法依赖大量标注数据的问题。

Method: 提出师生框架，引入子树伪标签和年龄门控机制，增强伪标签可靠性并抑制过自信。

Result: 在iNaturalist19上，仅用20个标签/类，性能超越自监督预训练+监督微调，接近全监督效果。

Conclusion: 该框架有效利用无标签数据，显著降低对标注数据的依赖，为半监督层次开放集分类提供新范式。

Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.

</details>


### [26] [HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.16573)
*Shuying Li,Yuchen Wang,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 提出HA2F框架，通过双模块协同提升遥感变化检测精度与效率，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法因局部特征提取或全局处理导致时序特征匹配偏差，且对辐射与几何噪声敏感。

Method: 提出HA2F框架，包含动态层次特征校准模块（DHFCM）和噪声自适应特征细化模块（NAFRM），分别解决特征对齐偏差与噪声干扰问题。

Result: 在LEVIR-CD、WHU-CD和SYSU-CD数据集上达到SOTA性能，兼具高精度与高效率，消融实验验证模块有效性。

Conclusion: HA2F通过双模块协同显著提升遥感变化检测性能，为多学科应用提供可靠工具。

Abstract: Remote sensing change detection (RSCD) aims to identify the spatio-temporal changes of land cover, providing critical support for multi-disciplinary applications (e.g., environmental monitoring, disaster assessment, and climate change studies). Existing methods focus either on extracting features from localized patches, or pursue processing entire images holistically, which leads to the cross temporal feature matching deviation and exhibiting sensitivity to radiometric and geometric noise. Following the above issues, we propose a dual-module collaboration guided hierarchical adaptive aggregation framework, namely HA2F, which consists of dynamic hierarchical feature calibration module (DHFCM) and noise-adaptive feature refinement module (NAFRM). The former dynamically fuses adjacent-level features through perceptual feature selection, suppressing irrelevant discrepancies to address multi-temporal feature alignment deviations. The NAFRM utilizes the dual feature selection mechanism to highlight the change sensitive regions and generate spatial masks, suppressing the interference of irrelevant regions or shadows. Extensive experiments verify the effectiveness of the proposed HA2F, which achieves state-of-the-art performance on LEVIR-CD, WHU-CD, and SYSU-CD datasets, surpassing existing comparative methods in terms of both precision metrics and computational efficiency. In addition, ablation experiments show that DHFCM and NAFRM are effective. \href{https://huggingface.co/InPeerReview/RemoteSensingChangeDetection-RSCD.HA2F}{HA2F Official Code is Available Here!}

</details>


### [27] [X-Aligner: Composed Visual Retrieval without the Bells and Whistles](https://arxiv.org/abs/2601.16582)
*Yuqian Zheng,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出一种基于VLM的新型Composed Video Retrieval框架，通过X-Aligner模块实现多模态渐进对齐，在Webvid-CoVR上达到SOTA性能并展现强零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoVR方法仅单阶段融合多模态输入，性能提升有限，亟需更强的表示能力与更精细的对齐机制。

Method: 引入X-Aligner跨注意力模块，逐步融合视觉与文本输入，并利用视觉查询的标题作为额外输入；采用两阶段训练策略保留预训练VLM表示，基于BLIP系列架构在Webvid-CoVR上训练。

Result: 在Webvid-CoVR-Test上取得63.93%的Recall@1，显著超越基线，并在CIRCO和Fashion-IQ上展现优异零样本泛化能力。

Conclusion: 所提框架有效利用VLM的表示能力与两阶段训练策略，实现了CoVR任务的SOTA性能与跨任务泛化能力。

Abstract: Composed Video Retrieval (CoVR) facilitates video retrieval by combining visual and textual queries. However, existing CoVR frameworks typically fuse multimodal inputs in a single stage, achieving only marginal gains over initial baseline. To address this, we propose a novel CoVR framework that leverages the representational power of Vision Language Models (VLMs). Our framework incorporates a novel cross-attention module X-Aligner, composed of cross-attention layers that progressively fuse visual and textual inputs and align their multimodal representation with that of the target video. To further enhance the representation of the multimodal query, we incorporate the caption of the visual query as an additional input. The framework is trained in two stages to preserve the pretrained VLM representation. In the first stage, only the newly introduced module is trained, while in the second stage, the textual query encoder is also fine-tuned. We implement our framework on top of BLIP-family architecture, namely BLIP and BLIP-2, and train it on the Webvid-CoVR data set. In addition to in-domain evaluation on Webvid-CoVR-Test, we perform zero-shot evaluations on the Composed Image Retrieval (CIR) data sets CIRCO and Fashion-IQ. Our framework achieves state-of-the-art performance on CoVR obtaining a Recall@1 of 63.93% on Webvid-CoVR-Test, and demonstrates strong zero-shot generalization on CIR tasks.

</details>


### [28] [A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling](https://arxiv.org/abs/2601.16608)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出一种轻量级融合自监督对比学习与量子增强特征建模的医学图像分类框架，在资源受限下实现高性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析受限于标注数据稀缺、计算资源有限和模型泛化能力不足。

Method: 采用MobileNetV2作为轻量骨干网络，通过SimCLR风格自监督预训练，嵌入参数化量子电路（PQC）构建经典-量子混合架构，并在少量标注数据上微调。

Result: 仅用2-3百万参数，性能超越无自监督和量子增强的经典基线，Accuracy、AUC和F1-score均提升，特征可视化显示判别力与稳定性增强。

Conclusion: 该框架为资源受限场景下的高性能医学AI提供实用且前瞻性的解决方案。

Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.

</details>


### [29] [Boundary and Position Information Mining for Aerial Small Object Detection](https://arxiv.org/abs/2601.16617)
*Rongxin Huang,Guangfeng Lin,Wenbo Zhou,Zhirong Li,Wenhuan Wu*

Main category: cs.CV

TL;DR: 提出BPIM框架提升小目标检测性能，融合边界、位置和尺度信息，显著优于Yolov5-P2且计算开销可控。


<details>
  <summary>Details</summary>
Motivation: 无人机图像中小目标检测面临尺度不平衡和边缘模糊的挑战，传统方法难以准确捕捉目标边界与位置信息。

Method: 设计BPIM框架，包含PIG、BIG、CSF、TFF和AWF五个模块，通过注意力机制与跨尺度融合策略整合边界、位置和尺度特征。

Result: 在VisDrone2021、DOTA1.0和WiderPerson数据集上，BPIM性能优于基线Yolov5-P2，达到与SOTA方法相当的精度且计算负载相近。

Conclusion: BPIM有效提升小目标检测的上下文判别力与感知能力，为无人机视觉任务提供高效解决方案。

Abstract: Unmanned Aerial Vehicle (UAV) applications have become increasingly prevalent in aerial photography and object recognition. However, there are major challenges to accurately capturing small targets in object detection due to the imbalanced scale and the blurred edges. To address these issues, boundary and position information mining (BPIM) framework is proposed for capturing object edge and location cues. The proposed BPIM includes position information guidance (PIG) module for obtaining location information, boundary information guidance (BIG) module for extracting object edge, cross scale fusion (CSF) module for gradually assembling the shallow layer image feature, three feature fusion (TFF) module for progressively combining position and boundary information, and adaptive weight fusion (AWF) module for flexibly merging the deep layer semantic feature. Therefore, BPIM can integrate boundary, position, and scale information in image for small object detection using attention mechanisms and cross-scale feature fusion strategies. Furthermore, BPIM not only improves the discrimination of the contextual feature by adaptive weight fusion with boundary, but also enhances small object perceptions by cross-scale position fusion. On the VisDrone2021, DOTA1.0, and WiderPerson datasets, experimental results show the better performances of BPIM compared to the baseline Yolov5-P2, and obtains the promising performance in the state-of-the-art methods with comparable computation load.

</details>


### [30] [SCHIGAND: A Synthetic Facial Generation Mode Pipeline](https://arxiv.org/abs/2601.16627)
*Ananya Kadali,Sunnie Jehan-Morrison,Orasiki Wellington,Barney Evans,Precious Durojaiye,Richard Guest*

Main category: cs.CV

TL;DR: SCHIGAND是一种新型合成人脸生成方法，能在保护身份的同时生成高真实度和多样性的面部数据，可用于生物识别系统测试。


<details>
  <summary>Details</summary>
Motivation: 由于隐私法规、数据稀缺和伦理问题，真实人脸数据的获取受限，现有生成模型难以平衡真实性、多样性和身份保持。

Method: SCHIGAND整合StyleCLIP、HyperStyle、InterfaceGAN和扩散模型，实现高真实度、可控制且身份保留的合成人脸生成。

Result: 通过ArcFace评估，SCHIGAND生成的数据在图像质量与多样性上表现优异，可媲美真实数据。

Conclusion: SCHIGAND有望补充甚至替代真实数据，推动隐私合规且可扩展的合成人脸数据生成。

Abstract: The growing demand for diverse and high-quality facial datasets for training and testing biometric systems is challenged by privacy regulations, data scarcity, and ethical concerns. Synthetic facial images offer a potential solution, yet existing generative models often struggle to balance realism, diversity, and identity preservation. This paper presents SCHIGAND, a novel synthetic face generation pipeline integrating StyleCLIP, HyperStyle, InterfaceGAN, and Diffusion models to produce highly realistic and controllable facial datasets. SCHIGAND enhances identity preservation while generating realistic intra-class variations and maintaining inter-class distinctiveness, making it suitable for biometric testing. The generated datasets were evaluated using ArcFace, a leading facial verification model, to assess their effectiveness in comparison to real-world facial datasets. Experimental results demonstrate that SCHIGAND achieves a balance between image quality and diversity, addressing key limitations of prior generative models. This research highlights the potential of SCHIGAND to supplement and, in some cases, replace real data for facial biometric applications, paving the way for privacy-compliant and scalable solutions in synthetic dataset generation.

</details>


### [31] [Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss](https://arxiv.org/abs/2601.16645)
*Minsu Gong,Nuri Ryu,Jungseul Ok,Sunghyun Cho*

Main category: cs.CV

TL;DR: 提出一种无需训练的结构保持损失（SPL），提升潜扩散模型在图像编辑中边缘结构的保真度


<details>
  <summary>Details</summary>
Motivation: 现有潜扩散模型在图像编辑中难以保留像素级边缘结构，影响写实风格迁移和色调调整等任务效果

Method: 引入结构保持损失（SPL），利用局部线性模型量化输入与编辑图像的结构差异，结合掩码策略、颜色保持损失和后处理步骤优化编辑结果

Result: SPL显著提升结构保真度，在潜扩散图像编辑任务中达到SOTA性能

Conclusion: 该方法无需训练，有效解决了潜扩散模型的结构失真问题，代码将开源

Abstract: Recent advances in image editing leverage latent diffusion models (LDMs) for versatile, text-prompt-driven edits across diverse tasks. Yet, maintaining pixel-level edge structures-crucial for tasks such as photorealistic style transfer or image tone adjustment-remains as a challenge for latent-diffusion-based editing. To overcome this limitation, we propose a novel Structure Preservation Loss (SPL) that leverages local linear models to quantify structural differences between input and edited images. Our training-free approach integrates SPL directly into the diffusion model's generative process to ensure structural fidelity. This core mechanism is complemented by a post-processing step to mitigate LDM decoding distortions, a masking strategy for precise edit localization, and a color preservation loss to preserve hues in unedited areas. Experiments confirm SPL enhances structural fidelity, delivering state-of-the-art performance in latent-diffusion-based image editing. Our code will be publicly released at https://github.com/gongms00/SPL.

</details>


### [32] [Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training](https://arxiv.org/abs/2601.16652)
*Aurora Pia Ghiardelli,Guangzhi Tang,Tao Sun*

Main category: cs.CV

TL;DR: 提出基于脉冲神经网络的三维脑肿瘤分割框架，实现高可靠性和低功耗，FLOPs降低87%


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在医学图像分割中计算成本高、功耗大，难以部署于医疗物联网和床旁系统

Method: 采用矢状面、冠状面和轴向面的多视角脉冲神经网络集成，结合前向时间传播（FPTT）降低训练计算开销，并提供像素级不确定性估计

Result: 在BraTS 2017和2023数据集上实现竞争力的分割精度、良好校准的不确定性，并减少87%的FLOPs

Conclusion: 脉冲神经网络在医疗AI中具备高效、低功耗潜力，适用于资源受限的床旁诊断系统

Abstract: We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.

</details>


### [33] [ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction](https://arxiv.org/abs/2601.16672)
*Ming Li,Hui Shan,Kai Zheng,Chentao Shen,Siyu Liu,Yanwei Fu,Zhen Chen,Xiangru Huang*

Main category: cs.CV

TL;DR: ReWeaver 从稀疏多视角图像中重建具有精确拓扑结构的3D服装和缝合图案，显著提升物理仿真与机器人操作的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖非结构化表示（如3D高斯溅射），难以准确重建服装拓扑与缝合结构，导致无法用于高保真物理仿真。

Method: ReWeaver 从多视角RGB图像中预测2D UV空间和3D空间中的缝线与面板及其连接关系，构建结构化的2D-3D服装表示，并基于新构建的大规模数据集GCD-TS进行训练。

Result: 在拓扑准确性、几何对齐和缝线-面板一致性上显著优于现有方法，仅需4个视角即可实现高质量重建。

Conclusion: ReWeaver 为数字人、虚拟试衣和机器人操作提供了可仿真、高精度的结构化服装重建解决方案。

Abstract: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats, struggling to provide accurate reconstructions of garment topology and sewing structures. As a result, the reconstructed outputs are often unsuitable for high-fidelity physical simulation. We propose ReWeaver, a novel framework for topology-accurate 3D garment and sewing pattern reconstruction from sparse multi-view RGB images. Given as few as four input views, ReWeaver predicts seams and panels as well as their connectivities in both the 2D UV space and the 3D space. The predicted seams and panels align precisely with the multi-view images, yielding structured 2D--3D garment representations suitable for 3D perception, high-fidelity physical simulation, and robotic manipulation. To enable effective training, we construct a large-scale dataset GCD-TS, comprising multi-view RGB images, 3D garment geometries, textured human body meshes and annotated sewing patterns. The dataset contains over 100,000 synthetic samples covering a wide range of complex geometries and topologies. Extensive experiments show that ReWeaver consistently outperforms existing methods in terms of topology accuracy, geometry alignment and seam-panel consistency.

</details>


### [34] [Affinity Contrastive Learning for Skeleton-based Human Activity Understanding](https://arxiv.org/abs/2601.16694)
*Hongda Liu,Yunfan Liu,Min Ren,Lin Sui,Yunlong Wang,Zhenan Sun*

Main category: cs.CV

TL;DR: 提出ACLNet，通过亲和力对比学习提升骨架动作识别性能，引入超类和动态温度调度优化对比信号。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法忽视类间结构相似性与异常正样本影响，导致特征判别力不足。

Method: 设计亲和力度量构建动作超类，引入动态温度调度和基于边缘的对比策略，增强正负样本分离。

Result: 在NTU RGB+D 60/120、Kinetics-Skeleton等六个数据集上显著提升动作识别、步态识别和行人重识别性能。

Conclusion: ACLNet通过建模类间亲和关系有效提升骨架动作理解的特征判别能力，具有广泛适用性。

Abstract: In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.

</details>


### [35] [CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR](https://arxiv.org/abs/2601.16713)
*Sana Al-azzawi,Elisa Barney,Marcus Liwicki*

Main category: cs.CV

TL;DR: 提出CER-HV框架提升阿拉伯文字手写识别数据质量，显著降低标签错误，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语系手写文本识别性能落后于拉丁语系，主要受限于数据集标签噪声问题，现有数据集存在转录、分段、方向和非文本内容错误

Method: 提出CER-HV框架，结合基于CRNN的CER噪声检测器（采用早停避免过拟合）与人工验证环节，高效识别并清洗高噪声样本

Result: 在Muharaf和PHTI数据集上以90%和80-86%精度发现错误；CRNN在5/6数据集上达SOTA，CER最低达8.26%；CER-HV使噪声数据集CER下降1.0-1.8%

Conclusion: 数据质量是阿拉伯语系HTR的关键瓶颈，CER-HV框架通用有效，可推广至其他文字系统，为未来研究提供新基准与清洗方法

Abstract: Handwritten text recognition (HTR) for Arabic-script languages still lags behind Latin-script HTR, despite recent advances in model architectures, datasets, and benchmarks. We show that data quality is a significant limiting factor in many published datasets and propose CER-HV (CER-based Ranking with Human Verification) as a framework to detect and clean label errors. CER-HV combines a CER-based noise detector, built on a carefully configured Convolutional Recurrent Neural Network (CRNN) with early stopping to avoid overfitting noisy samples, and a human-in-the-loop (HITL) step that verifies high-ranking samples. The framework reveals that several existing datasets contain previously underreported problems, including transcription, segmentation, orientation, and non-text content errors. These have been identified with up to 90 percent precision in the Muharaf and 80-86 percent in the PHTI datasets.
  We also show that our CRNN achieves state-of-the-art performance across five of the six evaluated datasets, reaching 8.45 percent Character Error Rate (CER) on KHATT (Arabic), 8.26 percent on PHTI (Pashto), 10.66 percent on Ajami, and 10.11 percent on Muharaf (Arabic), all without any data cleaning. We establish a new baseline of 11.3 percent CER on the PHTD (Persian) dataset. Applying CER-HV improves the evaluation CER by 0.3-0.6 percent on the cleaner datasets and 1.0-1.8 percent on the noisier ones. Although our experiments focus on documents written in an Arabic-script language, including Arabic, Persian, Urdu, Ajami, and Pashto, the framework is general and can be applied to other text recognition datasets.

</details>


### [36] [Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis](https://arxiv.org/abs/2601.16733)
*Yann Le Gall,Nicolas Burlet,Mathieu Simon,Fabien Novella,Samantha Dugelay,Jean-Philippe Malkasse*

Main category: cs.CV

TL;DR: 利用子孔径滤波和固定焦点阴影增强从圆柱合成孔径声呐（CSAS）数据中恢复阴影信息，以提升目标分析与三维重建效果。


<details>
  <summary>Details</summary>
Motivation: CSAS虽提供360°高分辨率图像，但丢失了目标阴影信息，而阴影对目标形状识别和减少虚警至关重要。

Method: 采用子孔径滤波获取多视角图像，结合固定焦点阴影增强（FFSE）提取清晰阴影，并通过空间雕刻法进行三维重建，辅以交互式可视化界面。

Result: 成功从CSAS数据中恢复阴影，显著提升目标分析精度与三维重建效果。

Conclusion: 阴影信息在CSAS中具有重要价值，可有效增强目标识别与三维建模能力。

Abstract: Circular Synthetic Aperture Sonar (CSAS) provides a 360° azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction.

</details>


### [37] [A Step to Decouple Optimization in 3DGS](https://arxiv.org/abs/2601.16736)
*Renjie Ding,Yaonan Wang,Min Liu,Jialin Zhu,Jiazheng Wang,Jiahao Zhao,Wenting Shen,Feixiang He,Xiang Che*

Main category: cs.CV

TL;DR: 通过解耦3D高斯泼溅（3DGS）优化中的耦合问题，提出AdamW-GS方法，提升优化效率与表示效果。


<details>
  <summary>Details</summary>
Motivation: 3DGS优化中存在更新步耦合和梯度耦合两个被忽视的问题，导致状态重缩放、无效正则化和计算开销大。

Method: 将优化过程解耦为稀疏Adam、重新状态正则化和解耦属性正则化，并基于实验重新组合为AdamW-GS。

Result: 在3DGS和3DGS-MCMC框架下实验验证，AdamW-GS在优化效率和表示效果上均优于原方法。

Conclusion: 解耦与再耦合优化策略可显著提升3DGS性能，AdamW-GS是更优的优化器设计。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time novel view synthesis. As an explicit representation optimized through gradient propagation among primitives, optimization widely accepted in deep neural networks (DNNs) is actually adopted in 3DGS, such as synchronous weight updating and Adam with the adaptive gradient. However, considering the physical significance and specific design in 3DGS, there are two overlooked details in the optimization of 3DGS: (i) update step coupling, which induces optimizer state rescaling and costly attribute updates outside the viewpoints, and (ii) gradient coupling in the moment, which may lead to under- or over-effective regularization. Nevertheless, such a complex coupling is under-explored. After revisiting the optimization of 3DGS, we take a step to decouple it and recompose the process into: Sparse Adam, Re-State Regularization and Decoupled Attribute Regularization. Taking a large number of experiments under the 3DGS and 3DGS-MCMC frameworks, our work provides a deeper understanding of these components. Finally, based on the empirical analysis, we re-design the optimization and propose AdamW-GS by re-coupling the beneficial components, under which better optimization efficiency and representation effectiveness are achieved simultaneously.

</details>


### [38] [Automated Road Crack Localization to Guide Highway Maintenance](https://arxiv.org/abs/2601.16737)
*Steffen Knoblauch,Ram Kumar Muthusamy,Pedram Ghamisi,Alexander Zipf*

Main category: cs.CV

TL;DR: 利用开源数据（航空影像和OpenStreetMap）微调YOLOv11模型，实现高速公路裂缝定位，并提出瑞士相对裂缝密度指数（RHCD）以指导养护决策。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致路面应力增加，维护成本上升，亟需高效精准的养护策略。

Method: 整合航空影像与OpenStreetMap，微调YOLOv11进行裂缝检测，构建瑞士RHCD指数评估全国路况。

Result: 裂缝分类F1-score分别为0.84（裂缝）和0.97（无裂缝）；RHCD与地表温度（r=-0.05）和交通量（r=0.17）相关性弱，但在城市中心和交叉口显著升高。

Conclusion: 开源数据可有效支持公共基础设施养护，RHCD指数为精准决策提供了新工具。

Abstract: Highway networks are crucial for economic prosperity. Climate change-induced temperature fluctuations are exacerbating stress on road pavements, resulting in elevated maintenance costs. This underscores the need for targeted and efficient maintenance strategies. This study investigates the potential of open-source data to guide highway infrastructure maintenance. The proposed framework integrates airborne imagery and OpenStreetMap (OSM) to fine-tune YOLOv11 for highway crack localization. To demonstrate the framework's real-world applicability, a Swiss Relative Highway Crack Density (RHCD) index was calculated to inform nationwide highway maintenance. The crack classification model achieved an F1-score of $0.84$ for the positive class (crack) and $0.97$ for the negative class (no crack). The Swiss RHCD index exhibited weak correlations with Long-term Land Surface Temperature Amplitudes (LT-LST-A) (Pearson's $r\ = -0.05$) and Traffic Volume (TV) (Pearson's $r\ = 0.17$), underlining the added value of this novel index for guiding maintenance over other data. Significantly high RHCD values were observed near urban centers and intersections, providing contextual validation for the predictions. These findings highlight the value of open-source data sharing to drive innovation, ultimately enabling more efficient solutions in the public sector.

</details>


### [39] [Curated endoscopic retrograde cholangiopancreatography images dataset](https://arxiv.org/abs/2601.16759)
*Alda João Andrade,Mónica Martins,André Ferreira,Tarcísio Araújo,Luís Lopes,Victor Alves*

Main category: cs.CV

TL;DR: 本研究发布了一个大规模、人工标注的ERCP图像数据集，以促进人工智能在胆胰疾病诊断中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于公开ERCP数据集稀缺，限制了人工智能在该领域的应用，因此需要构建高质量、大规模的标注数据集。

Method: 收集了来自1602名患者的19,018张原始图像和19,317张处理后图像，其中5,519张由三位经验丰富的胃肠病专家手动标注和审核。

Result: 构建了一个经过严格标注的ERCP图像数据集，并通过分类实验验证了其可用性和有效性。

Conclusion: 该数据集可作为ERCP自动分析与诊断的基准数据集，推动AI在胆胰疾病诊疗中的发展。

Abstract: Endoscopic Retrograde Cholangiopancreatography (ERCP) is a key procedure in the diagnosis and treatment of biliary and pancreatic diseases. Artificial intelligence has been pointed as one solution to automatize diagnosis. However, public ERCP datasets are scarce, which limits the use of such approach. Therefore, this study aims to help fill this gap by providing a large and curated dataset. The collection is composed of 19.018 raw images and 19.317 processed from 1.602 patients. 5.519 images are labeled, which provides a ready to use dataset. All images were manually inspected and annotated by two gastroenterologist with more than 5 years of experience and reviewed by another gastroenterologist with more than 20 years of experience, all with more than 400 ERCP procedures annually. The utility and validity of the dataset is proven by a classification experiment. This collection aims to provide or contribute for a benchmark in automatic ERCP analysis and diagnosis of biliary and pancreatic diseases.

</details>


### [40] [Flow Matching for Probabilistic Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.16763)
*Cuong Le,Pavló Melnyk,Bastian Wandt,Mårten Wadenbäck*

Main category: cs.CV

TL;DR: 提出FMPose，基于流匹配的概率3D人体姿态估计方法，优于现有方法


<details>
  <summary>Details</summary>
Motivation: 单目摄像头下3D姿态恢复存在深度模糊问题，传统方法产生错误但高置信度的估计

Method: 采用流匹配生成模型，通过连续正则化流实现从简单源分布到 plausible 3D 姿态分布的最优传输，结合图卷积网络建模2D关键点条件

Result: 在Human3.6M、MPI-INF-3DHP和3DPW三个基准上显著超越现有SOTA方法，生成更快更准

Conclusion: FMPose通过概率建模和最优传输有效缓解深度模糊，实现高效精确的3D姿态估计

Abstract: Recovering 3D human poses from a monocular camera view is a highly ill-posed problem due to the depth ambiguity. Earlier studies on 3D human pose lifting from 2D often contain incorrect-yet-overconfident 3D estimations. To mitigate the problem, emerging probabilistic approaches treat the 3D estimations as a distribution, taking into account the uncertainty measurement of the poses. Falling in a similar category, we proposed FMPose, a probabilistic 3D human pose estimation method based on the flow matching generative approach. Conditioned on the 2D cues, the flow matching scheme learns the optimal transport from a simple source distribution to the plausible 3D human pose distribution via continuous normalizing flows. The 2D lifting condition is modeled via graph convolutional networks, leveraging the learnable connections between human body joints as the graph structure for feature aggregation. Compared to diffusion-based methods, the FMPose with optimal transport produces faster and more accurate 3D pose generations. Experimental results show major improvements of our FMPose over current state-of-the-art methods on three common benchmarks for 3D human pose estimation, namely Human3.6M, MPI-INF-3DHP and 3DPW.

</details>


### [41] [AutoRegressive Generation with B-rep Holistic Token Sequence Representation](https://arxiv.org/abs/2601.16771)
*Jiahao Li,Yunpeng Bai,Yongkang Dai,Hao Guo,Hongping Gan,Yilei Shi*

Main category: cs.CV

TL;DR: BrepARG首次将B-rep的几何与拓扑编码为统一的序列标记，实现基于Transformer的自回归生成，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统图表示方法分离几何与拓扑，无法适用序列生成模型（如Transformer），限制了B-rep生成能力。

Method: BrepARG将B-rep编码为三类标记：几何与位置标记、面索引标记，分层构建统一序列，并用因果掩码Transformer进行自回归学习。

Result: BrepARG在B-rep生成任务上达到当前最优性能，验证了序列化表示的可行性。

Conclusion: BrepARG为B-rep生成开辟了新方向，标志着几何建模从图结构向序列建模的重要转变。

Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.

</details>


### [42] [CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts](https://arxiv.org/abs/2601.16773)
*Shuai Huang,Xuhan Lin,Yuwu Lu*

Main category: cs.CV

TL;DR: 提出CASP方法，通过CLS注意力引导和特征混合提升少样本增量学习性能，无需微调且参数开销低。


<details>
  <summary>Details</summary>
Motivation: 现有提示方法在极端少样本增量学习中泛化能力不足，需更好利用预训练知识共享特征表示。

Method: 引入CLS令牌注意力引导提示（CASP），对查询、键、值投影添加类别共享偏置，并结合注意力扰动与流形令牌混合增强泛化。

Result: 在CUB200、CIFAR100和ImageNet-R上超越SOTA方法，无需增量阶段微调，显著降低参数量。

Conclusion: CASP有效利用预训练模型的注意力机制，实现高效、低开销的少样本增量学习。

Abstract: Few-shot class-incremental learning (FSCIL) presents a core challenge in continual learning, requiring models to rapidly adapt to new classes with very limited samples while mitigating catastrophic forgetting. Recent prompt-based methods, which integrate pretrained backbones with task-specific prompts, have made notable progress. However, under extreme few-shot incremental settings, the model's ability to transfer and generalize becomes critical, and it is thus essential to leverage pretrained knowledge to learn feature representations that can be shared across future categories during the base session. Inspired by the mechanism of the CLS token, which is similar to human attention and progressively filters out task-irrelevant information, we propose the CLS Token Attention Steering Prompts (CASP). This approach introduces class-shared trainable bias parameters into the query, key, and value projections of the CLS token to explicitly modulate the self-attention weights. To further enhance generalization, we also design an attention perturbation strategy and perform Manifold Token Mixup in the shallow feature space, synthesizing potential new class features to improve generalization and reserve the representation capacity for upcoming tasks. Experiments on the CUB200, CIFAR100, and ImageNet-R datasets demonstrate that CASP outperforms state-of-the-art methods in both standard and fine-grained FSCIL settings without requiring fine-tuning during incremental phases and while significantly reducing the parameter overhead.

</details>


### [43] [SLD: Segmentation-Based Landmark Detection for Spinal Ligaments](https://arxiv.org/abs/2601.16782)
*Lara Blomenkamp,Ivanna Kramer,Sabine Bauer,Theresa Schöche*

Main category: cs.CV

TL;DR: 提出了一种基于形状分割和领域规则的脊柱韧带附着点自动检测方法，精度高且泛化性强。


<details>
  <summary>Details</summary>
Motivation: 现有自动检测方法在特定脊柱区域适用性差或精度不足，影响脊柱生物力学模型的可靠性。

Method: 先对3D椎骨进行基于形状的分割，再应用领域特定规则识别不同类型韧带附着点。

Result: 在两个独立患者数据集上验证，平均绝对误差（MAE）为0.7 mm，均方根误差（RMSE）为1.1 mm。

Conclusion: 该方法显著优于现有技术，可广泛应用于全脊柱区域的高精度韧带附着点检测。

Abstract: In biomechanical modeling, the representation of ligament attachments is crucial for a realistic simulation of the forces acting between the vertebrae. These forces are typically modeled as vectors connecting ligament landmarks on adjacent vertebrae, making precise identification of these landmarks a key requirement for constructing reliable spine models. Existing automated detection methods are either limited to specific spinal regions or lack sufficient accuracy. This work presents a novel approach for detecting spinal ligament landmarks, which first performs shape-based segmentation of 3D vertebrae and subsequently applies domain-specific rules to identify different types of attachment points. The proposed method outperforms existing approaches by achieving high accuracy and demonstrating strong generalization across all spinal regions. Validation on two independent spinal datasets from multiple patients yielded a mean absolute error (MAE) of 0.7 mm and a root mean square error (RMSE) of 1.1 mm.

</details>


### [44] [REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion](https://arxiv.org/abs/2601.16788)
*Xuewei Li,Xinghan Bao,Zhimin Chen,Xi Li*

Main category: cs.CV

TL;DR: 提出REL-SF4PASS方法，利用圆柱坐标深度表示和动态多模态融合，显著提升全景语义分割性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分挖掘全景图像几何信息，依赖RGB或简单深度格式，导致几何表达不足和投影失真。

Method: 引入REL深度表示（校正深度、仰角、方位角）和SMMF多模态融合策略，适配全景图像不同区域，增强几何表达并减少ERP投影失真。

Result: 在Stanford2D3D数据集上平均mIoU提升2.35%，3D扰动下性能方差降低约70%。

Conclusion: REL-SF4PASS有效提升全景语义分割的精度与鲁棒性，为几何感知建模提供了新思路。

Abstract: As an important and challenging problem in computer vision, Panoramic Semantic Segmentation (PASS) aims to give complete scene perception based on an ultra-wide angle of view. Most PASS methods often focus on spherical geometry with RGB input or using the depth information in original or HHA format, which does not make full use of panoramic image geometry. To address these shortcomings, we propose REL-SF4PASS with our REL depth representation based on cylindrical coordinate and Spherical-dynamic Multi-Modal Fusion SMMF. REL is made up of Rectified Depth, Elevation-Gained Vertical Inclination Angle, and Lateral Orientation Angle, which fully represents 3D space in cylindrical coordinate style and the surface normal direction. SMMF aims to ensure the diversity of fusion for different panoramic image regions and reduce the breakage of cylinder side surface expansion in ERP projection, which uses different fusion strategies to match the different regions in panoramic images. Experimental results show that REL-SF4PASS considerably improves performance and robustness on popular benchmark, Stanford2D3D Panoramic datasets. It gains 2.35% average mIoU improvement on all 3 folds and reduces the performance variance by approximately 70% when facing 3D disturbance.

</details>


### [45] [Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors](https://arxiv.org/abs/2601.16811)
*Chen-Ying Chien,Po-Chih Kuo*

Main category: cs.CV

TL;DR: 使用CNN-LSTM融合视觉特征与眼动数据，提升住宅室内美学评价预测精度，眼动数据作为训练时的特权信息显著增强主观维度评估。


<details>
  <summary>Details</summary>
Motivation: 由于审美感知的主观性和视觉响应的复杂性，现有方法难以准确预测室内空间的美学体验。

Method: 提出双分支CNN-LSTM模型，融合224个室内视频与28名参与者的眼动追踪数据，评估15个美学维度。

Result: 在客观维度（如光线）上准确率达72.2%，主观维度（如放松感）达66.8%，优于现有视频基线模型；仅用视觉输入时仍保持相近性能。

Conclusion: 眼动数据作为训练阶段的特权信息，能有效提升美学评估模型性能，尤其在主观维度上，为室内设计提供更实用的评估工具。

Abstract: Understanding how people perceive and evaluate interior spaces is essential for designing environments that promote well-being. However, predicting aesthetic experiences remains difficult due to the subjective nature of perception and the complexity of visual responses. This study introduces a dual-branch CNN-LSTM framework that fuses visual features with eye-tracking signals to predict aesthetic evaluations of residential interiors. We collected a dataset of 224 interior design videos paired with synchronized gaze data from 28 participants who rated 15 aesthetic dimensions. The proposed model attains 72.2% accuracy on objective dimensions (e.g., light) and 66.8% on subjective dimensions (e.g., relaxation), outperforming state-of-the-art video baselines and showing clear gains on subjective evaluation tasks. Notably, models trained with eye-tracking retain comparable performance when deployed with visual input alone. Ablation experiments further reveal that pupil responses contribute most to objective assessments, while the combination of gaze and visual cues enhances subjective evaluations. These findings highlight the value of incorporating eye-tracking as privileged information during training, enabling more practical tools for aesthetic assessment in interior design.

</details>


### [46] [ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models](https://arxiv.org/abs/2601.16836)
*Chenxi Ruan,Yu Xiao,Yihan Hou,Guosheng Hu,Wei Zeng*

Main category: cs.CV

TL;DR: 提出ColorConceptBench基准，揭示现有文本到图像模型在隐式颜色概念关联上的严重不足，且无法通过常规方法改善。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型对隐式颜色概念的语义关联能力不足，缺乏系统性评估工具。

Method: 构建包含6,369个人类标注的ColorConceptBench基准，评估模型对1,281个隐式颜色概念的 probabilistic 色彩分布生成能力。

Result: 七种主流T2I模型均表现不佳，对抽象语义不敏感，且扩大模型规模或增强引导无法有效提升性能。

Conclusion: 实现人类水平的颜色语义理解需要根本性的模型学习与表征范式变革，而非单纯增加模型规模。

Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.

</details>


### [47] [No Validation, No Problem: Predicting Model Performance from a Single Gradient](https://arxiv.org/abs/2601.16874)
*Fangzheng Wu,Brian Summa*

Main category: cs.CV

TL;DR: 提出一种无需验证集的检查点选择信号，基于分类器头梯度的Frobenius范数，可在无需标签的情况下高效选择最优检查点并实现早停。


<details>
  <summary>Details</summary>
Motivation: 传统检查点选择依赖验证集，成本高且不适用于无标签场景，需要一种轻量、无标签的替代方案。

Method: 使用单次前向-反向传播中分类器头梯度的Frobenius范数作为代理信号，通过尾窗口内最小化该值选择检查点，并提出头尺度或特征尺度归一化策略适配不同模型。

Result: 在ImageNet、COCO和扩散模型上均表现优异，接近Oracle性能，开销小于0.1%训练时间，且无需验证标签。

Conclusion: 该方法为无验证集场景提供了高效、通用、轻量的检查点选择与早停机制，适用于CNN、Transformer和扩散模型。

Abstract: We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.

</details>


### [48] [Evaluating Large Vision-language Models for Surgical Tool Detection](https://arxiv.org/abs/2601.16895)
*Nakul Poudel,Richard Simon,Cristian A. Linte*

Main category: cs.CV

TL;DR: 研究评估了大视觉语言模型在手术工具检测任务中的表现，发现Qwen2.5在零样本和微调设置下均表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统多为单模态，难以全面理解手术流程，亟需能融合多模态信息的通用手术AI系统。

Method: 在GraSP数据集上评估了Qwen2.5、LLaVA1.5和InternVL3.5三种VLMs，采用零样本和LoRA微调两种设置，并与Grounding DINO对比。

Result: Qwen2.5在零样本和微调下均表现最佳，零样本泛化能力强于Grounding DINO，微调性能相当；Qwen2.5识别更优，Grounding DINO定位更准。

Conclusion: VLMs在手术工具检测中展现出巨大潜力，Qwen2.5是当前最有效的模型，未来可进一步优化多模态融合以提升定位能力。

Abstract: Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.

</details>


### [49] [LoL: Longer than Longer, Scaling Video Generation to Hour](https://arxiv.org/abs/2601.16914)
*Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 提出一种无需训练的多头RoPE抖动方法，有效抑制长视频生成中的sink-collapse问题，实现长达12小时的实时流式视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成模型因RoPE与注意力机制冲突导致sink-collapse，表现为内容反复回退到锚帧、场景突变和循环运动。

Method: 引入轻量级、无需训练的多头RoPE抖动机制，打破头间注意力同质化，缓解长时程崩溃。

Result: 成功抑制sink-collapse，保持生成质量，实现长达12小时的连续流式视频生成，为目前公开最长结果之一。

Conclusion: 该方法为长视频生成提供了高效解决方案，首次实现高质量、实时、无限长度的视频流生成。

Abstract: Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.

</details>


### [50] [Reward-Forcing: Autoregressive Video Generation with Reward Feedback](https://arxiv.org/abs/2601.16933)
*Jingran Zhang,Ning Li,Yuanhao Ban,Andrew Bai,Justin Cui*

Main category: cs.CV

TL;DR: 使用奖励信号引导自回归视频生成，无需强教师模型，性能媲美甚至超越双向模型


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成模型依赖教师模型，导致性能受限且质量低于双向模型

Method: 引入奖励信号指导生成过程，简化训练并保持高视觉保真度和时间一致性

Result: 在VBench上得分84.92，媲美最优自回归方法且无需复杂蒸馏，部分情况超越双向模型

Conclusion: 奖励引导的自回归生成是一种高效、可扩展且性能优越的替代方案

Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.

</details>


### [51] [Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment](https://arxiv.org/abs/2601.16954)
*Ba-Thinh Lam,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Quang-Khai Bui-Tran,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出一种混合域半监督医学图像分割框架，通过复制粘贴机制和聚类MMD块实现域不变表示，仅用少量标注数据即可超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割依赖大量专家标注和一致数据分布，但现实中标注稀缺且数据来自多设备/中心，存在未知域偏移，现有方法假设单域转移或已知域标签，难以实用。

Method: 引入复制粘贴机制（CPM）跨域迁移信息区域，结合聚类最大均值差异（CMMD）块对齐无标签特征与标注锚点，嵌入师生框架实现域不变分割。

Result: 在Fundus和M&Ms基准上，该方法在极少量标注和多未知域下显著优于现有半监督与域适应方法。

Conclusion: 该框架为混合域半监督医学图像分割提供了有效解决方案，具备实际部署潜力。

Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.

</details>


### [52] [VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents](https://arxiv.org/abs/2601.16973)
*Zirui Wang,Junyi Zhang,Jiaxin Ge,Long Lian,Letian Fu,Lisa Dunlap,Ken Goldberg,XuDong Wang,Ion Stoica,David M. Chan,Sewon Min,Joseph E. Gonzalez*

Main category: cs.CV

TL;DR: VisGym 提出17个环境评估视觉语言模型在多步视觉交互中的表现，发现现有模型表现差，但可通过监督微调改善。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在长时序视觉交互中感知、记忆与行动的整合能力不足，缺乏系统性评估工具。

Method: 构建VisGym评测套件，包含17个多样化环境，支持控制难度、输入表示、规划时长和反馈，并提供多步求解器生成监督数据进行微调。

Result: 前沿模型在简单和困难设置下成功率分别为46.6%和26.0%，长上下文反而降低性能，视觉化任务比文本符号任务更难，但目标观察、文本反馈和探索性演示能显著提升表现。

Conclusion: 现有VLM在多步视觉决策中存在明显缺陷，需改进上下文利用与交互学习机制，VisGym为未来研究提供了可靠基准与改进路径。

Abstract: Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.

</details>


### [53] [SyncLight: Controllable and Consistent Multi-View Relighting](https://arxiv.org/abs/2601.16981)
*David Serrano-Lozano,Anand Bhattad,Luis Herranz,Jean-François Lalonde,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: SyncLight是首个在多个未标定视角下实现一致参数化重光照的方法，仅需单参考编辑即可同步多视角光照变化。


<details>
  <summary>Details</summary>
Motivation: 现有生成式方法难以满足多摄像头直播、立体电影和虚拟制作中对光照一致性的严格要求。

Method: 提出一种多视角扩散变换器，使用潜在桥接匹配方法训练，仅用图像对即可在单次推理中同步重光照，无需相机位姿信息。

Result: 在大规模合成与真实多视角数据集上训练后，SyncLight可零样本泛化至任意视角数量，实现高保真光照传播。

Conclusion: SyncLight为多视角采集系统提供了实用的重光照工作流，突破了多视角光照一致性的技术瓶颈。

Abstract: We present SyncLight, the first method to enable consistent, parametric relighting across multiple uncalibrated views of a static scene. While single-view relighting has advanced significantly, existing generative approaches struggle to maintain the rigorous lighting consistency essential for multi-camera broadcasts, stereoscopic cinema, and virtual production. SyncLight addresses this by enabling precise control over light intensity and color across a multi-view capture of a scene, conditioned on a single reference edit. Our method leverages a multi-view diffusion transformer trained using a latent bridge matching formulation, achieving high-fidelity relighting of the entire image set in a single inference step. To facilitate training, we introduce a large-scale hybrid dataset comprising diverse synthetic environments -- curated from existing sources and newly designed scenes -- alongside high-fidelity, real-world multi-view captures under calibrated illumination. Surprisingly, though trained only on image pairs, SyncLight generalizes zero-shot to an arbitrary number of viewpoints, effectively propagating lighting changes across all views, without requiring camera pose information. SyncLight enables practical relighting workflows for multi-view capture systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [54] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 本文扩展了得分匹配框架，提出基于离散得分函数的叶节点判别准则，实现从离散观测数据中准确推断因果顺序，并显著提升现有因果发现方法的准确率。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据中学习有向无环图（DAG）结构长期存在挑战，现有方法多针对连续数据，缺乏有效的离散数据因果发现方法。

Method: 扩展得分匹配框架，提出基于离散得分函数的叶节点判别准则，通过叶节点检测确定拓扑序，再进行边剪枝恢复图结构。

Result: 在模拟和真实数据实验中，该方法能准确推断因果顺序，并显著提升多数现有因果发现基线模型的准确性。

Conclusion: 所提方法为离散数据的因果发现提供了有效新途径，其识别的因果顺序可广泛提升其他方法性能。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [55] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用Fitbit可穿戴设备的心率和睡眠数据，机器学习模型可有效筛查大学生的焦虑、抑郁和压力，F1分数最高达0.79。


<details>
  <summary>Details</summary>
Motivation: 大学生压力大，焦虑抑郁高发，现有研究在心理量表、生理模态和时间序列参数上局限较大，亟需更全面的筛查方法。

Method: 收集StudentMEH Fitbit数据集，利用多种生理模态（如心率、睡眠）训练机器学习模型，评估对焦虑、抑郁和压力的筛查性能。

Result: 心率对压力筛查F1=0.77，心率对焦虑F1=0.79，睡眠对抑郁F1=0.78，表明生理数据具有良好筛查潜力。

Conclusion: 可穿戴设备支持持续心理健康监测，需针对不同心理疾病优化数据聚合方式与模态选择。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [56] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出一种基于数据低维线性投影的新型高斯过程训练目标（投影似然），在精度和计算效率上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程训练计算成本高，稀疏近似方法存在信息损失，亟需更高效且准确的替代方案。

Method: 引入投影似然（PL），通过单位球面上的随机投影降低数据维度，并推导其信息损失的闭式表达。

Result: PL在多种优化器、核函数和中等规模数据集上，显著优于精确GP和变分自由能稀疏GP方法。

Conclusion: 投影似然是一种高效且准确的高斯过程训练框架，适用于中等规模数据的可扩展建模。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [57] [Analyzing Neural Network Information Flow Using Differential Geometry](https://arxiv.org/abs/2601.16366)
*Shuhang Tan,Jayson Sia,Paul Bogdan,Radoslav Ivanov*

Main category: cs.LG

TL;DR: 本文用图论中的Ollivier-Ricci曲率分析神经网络数据流，提出神经曲率（NC）方法，通过修剪负曲率边显著提升剪枝效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于信息论的神经网络数据流分析方法局限明显，亟需新视角以更精准识别关键连接。

Method: 构建神经网络诱导图，引入基于Ollivier-Ricci曲率的神经曲率（NC），根据激活模式计算边曲率，并用负/正曲率边区分重要性。

Result: 移除负曲率边导致性能急剧下降，正曲率边影响微弱；在MNIST、CIFAR-10、CIFAR-100上优于主流剪枝方法，能识别更多冗余边。

Conclusion: 神经曲率是一种有效且新颖的神经网络结构重要性评估工具，为模型分析与压缩提供新范式。

Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.

</details>


### [58] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单循环一阶Actor-Critic算法，通过熵正则化实现无嵌套循环的双层优化，理论收敛且实验有效。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化与强化学习方法依赖二阶信息、强正则化或低效嵌套采样，亟需更高效稳定的解法。

Method: 采用惩罚重公式化，引入衰减熵正则化于下层RL，实现无偏超梯度估计，并基于Polyak-Lojasiewicz条件分析残差以保证收敛。

Result: 理论证明算法在有限时间与样本下收敛至原问题稳定点，实验在GridWorld和RLHF文本生成中验证有效性。

Conclusion: 所提方法突破嵌套结构限制，实现高效、无偏、可收敛的双层RL优化，为RLHF等应用提供新范式。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [59] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 本文在线性奖励模型下，基于算法稳定性理论，为RLHF提供了泛化边界分析，证明在特征覆盖条件下泛化误差为O(n^{-1/2})，并适用于梯度上升算法。


<details>
  <summary>Details</summary>
Motivation: 尽管RLHF在实践中效果显著，但其在高维设置下的理论泛化性质尚未被充分探索。

Method: 基于算法稳定性框架，在线性奖励模型下分析RLHF的泛化性能，并引入特征覆盖条件。

Result: 证明了策略模型的经验最优解具有O(n^{-1/2})的泛化边界，且结果可推广至梯度上升（GA）和随机梯度上升（SGA）。

Conclusion: 本文为RLHF后LLMs的实证泛化表现提供了新的理论支持。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [60] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一种两阶段框架，通过推理增强预测和置信度校正，有效解决罕见事件预测中的类别不平衡问题，显著提升精度并降低干预成本。


<details>
  <summary>Details</summary>
Motivation: 罕见事件预测在医疗、金融等领域至关重要，但传统模型因类别不平衡偏向多数类，导致召回率低、校准差、实用性不足。

Method: LPCORP采用两阶段方法：先用推理模型从文本输入生成增强预测，再用轻量逻辑回归分类器基于置信度进行选择性校正，无需重采样。

Result: 在真实医疗与客服数据集上，LPCORP在不改变样本数量的前提下平衡数据分布，显著提升精度，且预防性干预成本降低超50%。

Conclusion: LPCORP为罕见事件预测提供了一种高效、低成本的解决方案，无需重采样即可突破传统模型性能瓶颈。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [61] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 通过使用正态近似和Berry-Esseen误差控制，改进了VC定理的收敛速率估计，新增了$(\varepsilon\sqrt{n})^{-1}$因子。


<details>
  <summary>Details</summary>
Motivation: 传统VC定理使用Hoeffding不等式，但其收敛速率估计较保守，需更精确的概率分析。

Method: 用正态近似替代Hoeffding不等式，并引入Berry-Esseen误差界进行控制。

Result: 得到了更精细的中偏差收敛估计，指数项中新增$(\varepsilon\sqrt{n})^{-1}$因子。

Conclusion: 该方法提升了VC定理的精度，尤其在$\varepsilon\sqrt{n}$较大时效果显著。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [62] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0 是一个简化临床AI研究的开源工具包，支持7行代码完成建模，提升可复现性与可访问性。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基线复现困难、计算成本高和领域专业知识门槛高等障碍。

Method: 构建统一框架，整合15+数据集、20+临床任务、25+模型、5+可解释方法和不确定性量化，支持多模态数据与多种医疗编码标准，优化计算效率。

Result: 实现最高39倍加速、20倍内存降低，支持从16GB笔记本到生产系统，拥有400+开源社区成员并提供多语言支持。

Conclusion: PyHealth 2.0 建立了开放、可复现、易访问的临床AI研究基础，显著降低技术与专业壁垒。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [63] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 本文比较了KL散度和Wasserstein距离在贝叶斯实验设计中的表现，指出KL收敛更快，Wasserstein在模型误差下更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计中选择合适的效用函数是长期难题，KL散度常用但Wasserstein距离被提出作为替代，需系统评估其优劣。

Method: 通过一个玩具示例和经典源反演问题，对比KL散度与Wasserstein距离在信息增益评估和序列实验设计中的表现。

Result: Wasserstein距离在非信息先验下可能产生虚假奖励；KL散度在无模型误差时收敛更快，Wasserstein在存在模型误差时结果更鲁棒。

Conclusion: 应根据是否存模型误差选择效用函数：无误差用KL，有误差用Wasserstein，为实际应用提供指导。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [64] [Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction](https://arxiv.org/abs/2601.16426)
*Shuang Wu,Meijie Wang,Lun Yu*

Main category: cs.LG

TL;DR: 本文通过A20/E17分子图特征和PNA骨架，在Bemis-Murcko骨架划分下对蒸气压和气味阈值进行建模，并提出安全多任务学习方法以优化主任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在气味相关性质预测中缺乏对分布外泛化能力的评估，且多任务学习易损害主任务性能。

Method: 采用A20/E17分子图特征，比较GINE与PNA骨架；提出安全多任务学习策略，以蒸气压为主任务、气味阈值为辅助任务，结合延迟激活、梯度裁剪和小权重。

Result: PNA在蒸气压任务上达到Val MSE≈0.21，A20/E17结合鲁棒训练在气味阈值任务上达到Val MSE≈0.60-0.61；安全多任务方法显著提升蒸气压泛化性能。

Conclusion: 该方法有效提升分布外泛化能力，安全多任务策略避免任务干扰，为气味性质建模提供可复现的基准框架。

Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.

</details>


### [65] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: 提出Endless Terminals自动生成终端任务的流水线，通过简单PPO训练显著提升模型在终端任务上的表现


<details>
  <summary>Details</summary>
Motivation: 当前终端基准用于评估而非训练，缺乏可扩展的训练环境，限制了自改进代理的发展

Method: 构建四阶段自动化流水线：生成任务描述、构建容器化环境、生成完成测试、筛选可解性，产生3255个无标注终端任务，使用纯PPO与二元奖励训练模型

Result: Llama-3.2-3B、Qwen2.5-7B和Qwen3-8B-openthinker-sft在自建测试集上表现大幅提升，且在Human-curated基准如TerminalBench 2.0上也超越复杂代理方法

Conclusion: 当环境规模足够时，简单的强化学习方法也能取得显著效果，无需复杂代理架构

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [66] [Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network](https://arxiv.org/abs/2601.16446)
*George Awiakye-Marfo,Elijah Agbosu,Victoria Mawuena Barns,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 提出BrownianReLU激活函数，通过布朗运动提升LSTM在金融时序数据中的梯度稳定性和预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数如ReLU在噪声和非平稳金融时序中存在梯度不稳定和死亡神经元问题。

Method: 引入基于布朗运动的随机激活函数BrownianReLU，利用蒙特卡洛模拟实现负输入的平滑自适应响应。

Result: 在Apple、GCB、标普500和LendingClub数据上，BrownianReLU显著降低MSE、提高R²，分类任务中优化了准确率与敏感度权衡。

Conclusion: BrownianReLU有效提升金融时序建模的稳定性与泛化能力，为深度学习在金融领域的应用提供新激活机制。

Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.

</details>


### [67] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 浮点Transformer能表示非置换等变函数，且在序列长度受限时能表示所有置换等变函数，但长序列下能力受限，加性位置编码反而有害。


<details>
  <summary>Details</summary>
Motivation: 现有理论基于实数精确运算，而实际Transformer使用浮点数和近似运算，其表达能力尚未被系统研究。

Method: 分析浮点Transformer在有限精度下的表示能力，证明其对置换等变与非等变函数的表达边界，并评估位置编码影响。

Result: 浮点Transformer可表示非置换等变函数；序列长度受限时可表示所有置换等变函数，长度过大时不能；加性位置编码降低表达能力。

Conclusion: 浮点实现的精度限制显著改变Transformer的理论表达性质，加性位置编码并非总是有益，需重新评估其设计。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [68] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 研究发现对抗鲁棒性与分布鲁棒性存在权衡，但特征可分性可缓解该权衡，甚至在某些情况下提升分布鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有工作表明对抗训练会增强模型对虚假特征的依赖，损害分布鲁棒性，尤其是对少数子群体的性能，亟需深入理解二者关系。

Method: 通过理论分析对抗训练在扰动数据上的行为，提出可计算的替代方法，并研究不同偏置数据下ℓ∞扰动对特征可分性与鲁棒性的影响。

Result: 发现ℓ∞扰动在中等偏置数据上可提升分布鲁棒性；当简洁性偏差促使模型依赖核心特征时，即使数据高度倾斜，分布鲁棒性仍可提升。

Conclusion: 特征可分性是理解对抗与分布鲁棒性权衡的关键因素，忽视它可能导致对鲁棒性的错误结论。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [69] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: 提出R-NCE自监督学习方法，利用结构MRI数据发现更有效的阿尔茨海默病生物标志物，优于传统方法并具有生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 传统MRI分析依赖手工特征，性能有限，亟需更强大的自监督学习方法挖掘潜在生物标志物。

Method: 引入Residual Noise Contrastive Estimation (R-NCE)，结合FreeSurfer特征并最大化增强不变信息。

Result: R-NCE在疾病分类、转化预测和淀粉样蛋白状态预测上均优于传统方法和现有SSL方法，且R-NCE-BAG具高遗传力并关联MAPT和IRAG1基因。

Conclusion: R-NCE能发现更具生物学意义和临床潜力的阿尔茨海默病生物标志物，为早期诊断提供新途径。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [70] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MGCPL算法和CAME策略，实现对分类数据多粒度嵌套聚类的自动探索，具有线性时间复杂度和高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 分类数据的离散距离空间难以定义，传统聚类方法难以处理其多粒度嵌套聚类结构。

Method: 设计多粒度竞争惩罚学习（MGCPL）算法，结合基于MGCPL编码的聚类聚合策略（CAME），对数据进行分阶段编码与聚类。

Result: 提出的MCDC方法能自动发现嵌套聚类结构，在多个真实数据集上优于现有方法，且具有线性时间复杂度和良好的可扩展性。

Conclusion: MCDC在分类数据聚类中表现优异，适用于大规模数据预划分和分布式计算加速。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [71] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出BoostFGL框架，通过客户端与服务器端三重机制提升联邦图学习中的公平性，在保持性能的同时显著改善弱势节点组的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽整体准确率高，但忽视了弱势节点组的性能严重下降，公平性问题源于标签偏差、拓扑混淆和聚合稀释。

Method: BoostFGL包含三重机制：客户端节点提升、客户端拓扑提升和服务器端模型提升，分别强化弱势节点信号、优化传播结构、可靠聚合硬客户端更新。

Result: 在9个数据集上实验显示，BoostFGL将整体F1提升8.43%，显著改善公平性且保持竞争力。

Conclusion: BoostFGL有效缓解联邦图学习中的公平性偏差，为去中心化图学习提供可扩展的公平性解决方案。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [72] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出一种自适应图模型，通过HNSW图与预计算投票机制，在不牺牲精度的前提下显著加速kNN推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统近似最近邻方法在加速kNN推理时往往降低分类精度，且无法自适应选择最优邻居数k。

Method: 结合分层可导航小世界（HNSW）图与预计算投票机制，将邻居选择与加权计算转移至训练阶段，利用高层快速导航、低层编码自适应决策边界。

Result: 在六个数据集上对比八种基线方法，实现实时推理速度，且分类精度无损失。

Conclusion: 该框架为基于图的非参数学习建立了新范式，解决了kNN长期存在的推理瓶颈问题。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [73] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: Transformer的浅层模型在核区域下分析，展示其宽度随样本量对数增长，优化误差与序列长度无关，但内存随序列增长。


<details>
  <summary>Details</summary>
Motivation: 解释Transformer为何表现优异，尤其在非凸优化背景下，对比循环架构的序列长度敏感性问题。

Method: 分析带$m$个独立头的浅层Transformer，使用投影梯度下降在核区域下进行理论推导。

Result: 宽度仅需对数依赖样本量，优化误差与序列长度$T$无关，但内存随$T$增长；数值实验验证了理论缩放规律。

Conclusion: Transformer在序列建模中避免了循环架构的指数误差增长，代价是内存开销，理论与实验一致支持其高效性。

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [74] [Rethinking Large Language Models For Irregular Time Series Classification In Critical Care](https://arxiv.org/abs/2601.16516)
*Feixiang Zheng,Yu Wu,Cecilia Mascolo,Ting Dang*

Main category: cs.LG

TL;DR: LLMs在ICU不规则时间序列上表现与传统模型相当，但训练开销大且少样本性能差，编码器设计比对齐策略更重要。


<details>
  <summary>Details</summary>
Motivation: LLMs在时间序列建模中潜力巨大，但在高缺失率的ICU数据上效果未被系统评估，亟需明确关键组件的影响。

Method: 构建系统性测试平台，评估不同LLM方法在ICU基准数据集上的编码器与多模态对齐策略，对比监督与自监督基线。

Result: 显式建模不规则性的编码器提升12.8% AUPRC，对齐策略最佳仅提升2.9%；LLMs训练慢10倍，少样本下表现更差。

Conclusion: LLMs在ICU时序建模中具潜力，但当前效率低、数据需求高，编码器设计是关键，需进一步优化以实用化。

Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.

</details>


### [75] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: DANCE是一种新的文本属性图联邦学习框架，通过循环压缩和证据保留提升效率、性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有TAG-FGL方法面临LLM计算开销大、压缩非自适应、缺乏可解释性三大问题。

Method: DANCE引入轮次更新的图压缩与证据包机制，动态优化压缩结果并保留文本来源追溯信息。

Result: 在8个数据集上，DANCE在8%压缩率下准确率提升2.33%，token使用减少33.42%。

Conclusion: DANCE有效解决了TAG-FGL中的效率、性能与可解释性权衡问题，为实际部署提供新范式。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [76] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 提出SARE方法，通过几何稳定化解决多模态LLM中的对象幻觉问题，显著提升去遗忘效果与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有去遗忘方法仅表面抑制幻觉，模型易在微调后复发，因陷入尖锐极小值，缺乏几何稳定性。

Method: 将去遗忘建模为定向最小-最大优化问题，引入Targeted-SAM机制，主动平滑幻觉概念附近的损失景观。

Result: SARE在消除幻觉上显著优于基线，同时保留生成质量，并在重学习与参数更新后仍保持稳定抑制。

Conclusion: 几何稳定化是解决幻觉复发的关键，SARE为多模态LLM的可靠去遗忘提供了新范式。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [77] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频率键冲突并非Engram式条件内存的主要瓶颈，反而可能起到正则化作用；提升查找精度未必改善训练效果，门控信用分配才是关键限制。


<details>
  <summary>Details</summary>
Motivation: 探究高频率键冲突是否为Engram式条件内存的瓶颈，并分析其对训练动态的影响。

Method: 提出Engram-Nine，使用最小完美哈希函数（MPHF）构建无冲突热点层，保留原多头哈希查找作为冷层；采用路由分层评估分解每词损失。

Result: 无冲突设计未持续降低验证损失；发现“热点到冷点优势反转”现象，无冲突配置反转更早；门控过早偏好热点位置并持续至后期，导致高损失位置获得更高权重。

Conclusion: 键冲突并非需要消除的缺陷，而是隐式正则化机制；模型主要瓶颈在于门控的信用分配错误，而非索引精度。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [78] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: 通过引入Ollivier-Ricci曲率和Jaccard相似性改进UMAP，提升流形结构建模能力，减少拓扑撕裂与结构坍塌。


<details>
  <summary>Details</summary>
Motivation: UMAP因局部欧氏距离假设难以捕捉内在流形几何，导致拓扑撕裂和结构坍塌，且对k近邻图敏感。

Method: 提出JORC-UMAP，结合Ollivier-Ricci曲率强化几何瓶颈处的边，用Jaccard相似性保证邻域一致性。

Result: 在合成与真实数据集上，JORC-UMAP在SVM准确率和三元组保留分数上优于UMAP及其他降维方法，且保持计算效率。

Conclusion: JORC-UMAP是一种几何感知的UMAP增强方法，能更忠实地还原数据流形结构。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [79] [Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability](https://arxiv.org/abs/2601.16563)
*Vasileios Sevetlidis,George Pavlidis*

Main category: cs.LG

TL;DR: 提出用过程张量表征神经训练，引入基于反向可区分性的记忆 witness，实证证明SGD具有非马尔可夫记忆，并可用于优化器与数据顺序评估。


<details>
  <summary>Details</summary>
Motivation: 传统SGD被理想化为马尔可夫过程，但实际训练中存在状态记忆效应，缺乏可测量的诊断工具。

Method: 将训练建模为过程张量，通过两步干预比较输出分布差异（TV/JS/Hellinger距离），定义反向流Δ_BF作为非马尔可夫性指标。

Result: Δ_BF恒为正且置信区间紧致，受动量、批次重叠和微步数增强，重置优化器状态后消失，证明确实存在优化器与数据状态记忆。

Conclusion: 该框架提供一种无侵入、可计算的诊断工具，将‘数据顺序重要’转化为可检验算子，为比较优化器、课程安排提供统一评估平台。

Abstract: This work proposes neural training as a \emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $Δ_{\mathrm{BF}} = D_2 - D_1>0$ (with $D\in\{\mathrm{TV}, \mathrm{JS}, \mathrm{H}\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. "Data order matters" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.

</details>


### [80] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出一种无需训练的kNN-ICL框架，利用少量样例通过大语言模型预测初创企业成功率，超越传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 早期初创企业数据稀缺，传统机器学习因缺乏标注数据效果有限，亟需不依赖大量数据的预测方法。

Method: 提出kNN-ICL框架，基于相似性从少量标注案例中选择最近邻作为上下文示例，利用大语言模型进行推理预测。

Result: 在Crunchbase真实数据上，kNN-ICL准确率高于监督学习基线和普通上下文学习，仅用50个示例即可达到高平衡准确率。

Conclusion: 上下文学习可作为数据稀缺环境下风投决策的有效工具。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [81] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 首次公开整合芬兰铁路运营与气象数据的大型数据集，支持列车延误预测与天气影响分析


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏运营与气象信息的融合，尤其在北欧地区，亟需结合天气因素研究铁路可靠性

Method: 整合Digitraffic铁路运营数据与209个气象站观测数据，通过Haversine距离时空对齐，构建28个特征，采用空间插补、循环编码和鲁棒缩放预处理

Result: 涵盖3850万条观测，冬季延误率超25%，中部和北部铁路廊道延误集中；XGBoost基线模型MAE为2.73分钟

Conclusion: 该数据集为铁路延误预测、天气影响评估和基础设施脆弱性分析提供了高质量、可复用的机器学习资源

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [82] [E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory](https://arxiv.org/abs/2601.16622)
*Lin Huang,Chengxiang Huang,Ziang Wang,Yiyue Du,Chu Wang,Haocheng Lu,Yunyang Li,Xiaoli Liu,Arthur Jiang,Jia Zhang*

Main category: cs.LG

TL;DR: E2Former-V2通过代数稀疏和硬件感知设计，大幅提升EGNN的推理速度，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统EGNN因在每条边上显式构建几何特征或密集张量积而存在可扩展性瓶颈。

Method: 提出EAAS（等变轴对齐稀疏化）将密集张量收缩转为稀疏重索引，并设计基于Triton内核的在线等变注意力机制，消除边张量并优化SRAM使用。

Result: 在SPICE和OMol25数据集上，E2Former-V2保持与主流模型相当的预测性能，推理速度提升20倍。

Conclusion: 该工作证明了大型等变Transformer可在普通GPU上高效训练，推动了3D分子建模的实用化。

Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.

</details>


### [83] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: 提出DPAD框架，通过双原型动态解耦时序模式，提升预测模型的上下文感知能力


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以动态解耦复杂时序模式，导致学习静态平均表示，缺乏上下文适应性

Method: 构建动态双原型库（DDP）：通用模式库捕获趋势/季节性，稀有模式库记忆关键事件；设计双路径上下文路由（DPC）机制，结合解耦引导损失（DGLoss）优化原型分工

Result: DPAD作为模型无关模块，显著提升主流预测模型在多类真实数据集上的性能与可靠性

Conclusion: DPAD有效实现时序模式的动态解耦与上下文自适应，为时序预测提供通用增强范式

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [84] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出概率安全反事实解释（PSCE），在模型更新时保证解释的置信度与鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释在模型频繁更新时易失效，缺乏对不确定性与变化的保障

Method: 基于贝叶斯原理，构建满足δ-安全与ε-鲁棒性的优化框架，引入不确定性约束

Result: PSCE生成的解释更可信、更具区分性，且在模型变化下具有可证明的鲁棒性

Conclusion: PSCE为动态环境下的反事实解释提供了形式化概率保证，显著优于现有方法

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [85] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态专家知识集成多种因果发现算法的灵活模型平均方法，实验证明其在噪声和清洁数据上均有效，尤其评估了LLM作为专家的临床因果发现能力。


<details>
  <summary>Details</summary>
Motivation: 因果发现算法众多且无明显最优选择，且现实场景常违反算法假设，需依赖专家知识；现有方法缺乏灵活整合专家与算法的机制。

Method: 提出一种动态请求专家知识的模型平均方法，集成多样化的因果发现算法，利用LLM等非完美专家提供辅助信息。

Result: 在清洁与噪声数据上验证了方法的有效性，分析了专家正确率对性能的影响，并评估了LLM在临床因果发现中的实际能力。

Conclusion: 该方法为临床场景中因果发现提供了实用框架，证明动态专家集成优于单一算法，LLM可作为可行的非完美专家资源。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [86] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种序列惩罚法处理学习任务中的严格约束，实验验证其在图像处理中的可行性。


<details>
  <summary>Details</summary>
Motivation: 许多学习任务中的样本处理要求应作为严格约束而非任意罚项形式化，现有方法难以有效处理此类约束。

Method: 采用序列惩罚法，将约束融入优化问题，并证明其在深度学习场景下的收敛性。

Result: 实验表明该方法在图像处理任务中有效且实用。

Conclusion: 序列惩罚法为处理学习中的严格约束提供了可行且有理论保障的解决方案。

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [87] [Uncertainty propagation through trained multi-layer perceptrons: Exact analytical results](https://arxiv.org/abs/2601.16830)
*Andrew Thompson,Miles McCrory*

Main category: cs.LG

TL;DR: 推导了单隐藏层ReLU激活MLP在高斯输入下的输出均值与方差的精确表达式。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖级数展开近似不确定性传播，缺乏精确性。

Method: 基于数学分析，直接推导高斯输入下MLP输出的均值与方差解析表达式。

Result: 得到了无需级数展开的精确均值与方差公式。

Conclusion: 该方法实现了对MLP不确定性传播的精确量化，优于传统近似方法。

Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.

</details>


### [88] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 引入Attentive Neural Processes提升GEDI生物质制图的不确定性校准能力，超越传统机器学习方法


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林、XGBoost）在异质景观中无法正确估计不确定性，因混淆了集成方差与 aleatoric 不确定性且忽略空间上下文

Method: 提出Attentive Neural Processes（ANPs），一种概率元学习框架，结合局部观测集和地理空间基础模型嵌入，自适应学习空间协方差函数

Result: 在五大生物群落中验证，ANPs在保持高精度的同时实现近理想校准的不确定性估计，并通过少量样本实现跨区域迁移

Conclusion: ANPs为大尺度地球观测提供了一种可扩展且理论严谨的替代方案，优于传统集成方差方法

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [89] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 人类与LLM协作改进FunSearch算法，突破组合优化领域长期未解的下界问题


<details>
  <summary>Details</summary>
Motivation: 解决理论计算机科学中组合优化问题的长期瓶颈，特别是现有启发式算法在对抗性实例上的性能局限

Method: 基于FunSearch算法生成的初步结果，通过人类专家迭代优化，构建更优的对抗性实例

Result: 在分层k中位数聚类、背包问题、装箱问题及Lovász汽油问题推广上取得最新下界突破，部分问题十年无显著进展

Conclusion: LLM可提供关键初始模式，但人类专家的数学洞察力是实现严谨突破的核心，证明LLM是数学与计算机科学研究的强力协作工具

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [90] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 本文研究黑盒访问下Transformer序列模型的学习问题，提出高效算法精确学习单头注意力参数，并分析噪声鲁棒性与多头注意力的不可辨识性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖白盒访问，而实际场景常仅能观测输出，亟需仅通过查询输出学习Transformer参数的黑盒学习方法。

Method: 对单头注意力提出$O(d^2)$查询的确定性算法，并基于压缩感知提出$O(rd)$查询的随机算法；分析噪声下的$\varepsilon$精度估计；证明多头注意力参数不可辨识。

Result: 单头注意力可精确学习，噪声下仍可多项式查询估计；多头注意力在无额外假设下参数不可唯一确定。

Conclusion: 黑盒学习单头Transformer可行且高效，但多头注意力需结构假设才能实现可学习性。

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [91] [Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks](https://arxiv.org/abs/2601.16880)
*Bethan Evans,Jared Tanner*

Main category: cs.LG

TL;DR: 推导了DNN输出变化所需的最小范数权重扰动，揭示了其与层敏感性及压缩阈值的关系，并应用于后门攻击的可证明防御。


<details>
  <summary>Details</summary>
Motivation: 理解DNN输出变化所需的最小权重扰动，以评估模型鲁棒性并防御后门攻击。

Method: 推导单层精确公式，对比多层Lipschitz常数鲁棒性保证，并应用于低秩压缩下的后门激活分析。

Result: 单层公式与Lipschitz保证具有相同数量级，低秩压缩可激活潜伏后门且保持精度，确立了后门攻击失败的压缩阈值。

Conclusion: 反向传播的边缘决定了层敏感性，提供了与期望输出偏移一致的最小参数更新的可证明保证。

Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.

</details>


### [92] [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)
*Shijun Zhang,Zuowei Shen,Yuesheng Xu*

Main category: cs.LG

TL;DR: 提出多级深度学习（MGDL）框架，通过分等级训练残差块实现稳定且可解释的误差精炼，并首次理论证明其收敛性。


<details>
  <summary>Details</summary>
Motivation: 深度网络优化困难，而浅层网络有凸重构与全局保证，Motivation是结合二者优势，提升深度网络训练稳定性。

Method: 逐级训练：冻结已学层级，每新增残差块仅拟合剩余误差，基于算子理论构建MGDL框架。

Result: 证明任意连续目标函数下，固定宽度的MGDL-ReLU模型其残差逐级严格递减并一致收敛于零。

Conclusion: MGDL是首个在深度网络中通过分级训练获得严格收敛保证的理论框架，兼具稳定性与可解释性。

Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.

</details>


### [93] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM 是首个统一处理联邦学习中函数约束、通信压缩、本地更新和部分客户端参与的框架，无需对偶变量，具有理论收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习框架难以同时应对函数约束、通信瓶颈、本地更新和部分客户端参与四大挑战，缺乏理论完备的统一解决方案。

Method: 基于切换梯度法，提出无投影、仅原始变量的更新机制，结合双向误差反馈处理压缩噪声，并引入软切换版本稳定边界更新，理论分析收敛至 O(1/√T)。

Result: 理论证明平均迭代点达到最优收敛速率，并给出高概率界解耦采样噪声；实验在 Neyman-Pearson 分类和 CMDP 任务上验证有效性。

Conclusion: FedSGM 首次实现四项关键挑战的统一建模，为约束联邦学习建立了理论与实践基础。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [94] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: TESSERA嵌入方法在塞内加尔花生盆地的作物分类中表现最优，准确率比次优方法高28%。


<details>
  <summary>Details</summary>
Motivation: 现有卫星方法不适用于小农地区，需开发更有效的作物类型制图方法。

Method: 基于TESSERA和AlphaEarth的地理空间基础模型嵌入方法，结合四维评估标准（性能、合理性、可迁移性、可访问性）。

Result: TESSERA方法在四项标准中表现最佳，某次时间迁移实验中准确率提升28%。

Conclusion: TESSERA嵌入是适用于小农地区作物制图的有效方法。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [95] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: 提出GRIP框架，通过几何约束阻止MoE模型中路由器的表面操纵，实现知识直接删除，提升卸载效果与模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在MoE架构中仅通过重定向路由器规避专家，未真正删除知识，导致效用下降与虚假遗忘。

Method: GRIP通过将路由器梯度投影到专家特定零空间，解耦路由稳定性与参数僵化，强制遗忘优化直接修改专家参数。

Result: GRIP在大规模MoE模型上实现超过95%的路由稳定性，兼容多种遗忘算法，显著提升遗忘质量而不损失效用。

Conclusion: GRIP作为无侵入式适配器，成功将密集模型的遗忘方法迁移至MoE架构，为MoE安全遗忘提供通用解决方案。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [96] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 提出TAC指标指导奖励函数调优，并设计Soft-TAC作为可微损失函数，从人类偏好中学习奖励模型，提升RL性能与效率。


<details>
  <summary>Details</summary>
Motivation: 人工设计奖励函数耗时且易出错，需更高效的奖励调优与学习方法。

Method: 引入Trajectory Alignment Coefficient (TAC)评估奖励函数与专家偏好的一致性，并提出Soft-TAC作为其可微近似，用于训练奖励模型。

Result: 使用TAC辅助调优显著提升奖励函数性能并降低认知负荷；Soft-TAC训练的模型在Gran Turismo 7中产生更具区分性的策略行为。

Conclusion: TAC既可作为实用调优工具，也可作为奖励学习目标，在复杂任务中有效提升奖励函数设计效率与质量。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [97] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 通过单调校准恢复余弦相似度的绝对值可解释性，不改变排序性能


<details>
  <summary>Details</summary>
Motivation: 原始余弦相似度因各向异性导致分数集中于高相似度区间，丧失定量解释能力

Method: 使用基于人类相似性判断的保序回归构建单调变换

Result: 实现近乎完美的校准，保持98%的排名相关性和局部稳定性

Conclusion: 该方法不替代余弦相似度，而是通过顺序保持的重参数化，使所有基于排序的结构保持不变

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [98] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多组学习在组可实现设定下样本复杂度优于未知设定，即使组族无限但VC维有限；通过经验风险最小化实现，但计算不可行，提出非适当学习替代方案。


<details>
  <summary>Details</summary>
Motivation: 解决多组学习中样本复杂度在组可实现设定下的理论改进问题，特别是当组族无限但VC维有限时。

Method: 采用组可实现概念类的经验风险最小化，同时提出基于非适当学习的计算可行替代方法。

Result: 在组可实现设定下获得更优样本复杂度，但标准方法计算不可行，非适当学习方法可作为有效替代。

Conclusion: 组可实现设定显著降低样本复杂度，尽管计算上困难，非适当学习为实际应用提供了可行路径。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [99] [Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles](https://arxiv.org/abs/2601.16936)
*Anton Zamyatin,Patrick Indri,Sagar Malhotra,Thomas Gärtner*

Main category: cs.LG

TL;DR: BatchEnsemble虽旨在高效提供类似集成的不确定性估计，但实际表现接近单模型，未能实现真正的集成效果。


<details>
  <summary>Details</summary>
Motivation: 在资源受限和低延迟场景下，需要高效获取不确定性估计，而Deep Ensembles计算成本高，BatchEnsemble被提出以降低参数和内存开销。

Method: 通过在共享基础网络上应用学习的秩-1扰动，实现类似集成的不确定性估计。

Result: 在CIFAR10/10C/SVHN上，BatchEnsemble在准确性、校准和OOD检测方面均低于Deep Ensembles，且接近单模型基线；MNIST实验显示其成员在函数和参数空间上几乎相同。

Conclusion: BatchEnsemble本质上更像一个单模型，而非真正的集成，其多样性不足，无法有效提升不确定性估计性能。

Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.

</details>


### [100] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 提出一种基于刚性碎片的3D分子生成方法，显著提升生成效率与表示压缩率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统原子级分子生成效率低、表示冗余，而图生成方法使用片段但未考虑3D结构，亟需结合碎片化与3D几何的生成框架。

Method: 将分子建模为刚性 motif 集合，采用 SE(3) 等变生成模型进行从头3D分子生成。

Result: 在GEOM-Drugs上原子稳定性超越SOTA，生成步数减少2-10倍，分子表示压缩3.5倍。

Conclusion: 基于刚性碎片的3D生成方法在效率、压缩率与性能上均具优势，为分子生成提供了新范式。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [101] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散重构为块状因果模型，实现并行生成与自回归性能的统一，在语言建模中达到SOTA且训练更快。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）虽具并行生成优势，但性能落后于自回归模型（ARMs）且训练效率低。

Method: 提出ARMD架构，将掩码扩散视为块状因果模型，支持单次并行前向计算、渐进排列训练和分块并行生成策略。

Result: 在标准语言建模基准上超越现有扩散模型，训练步骤更少，同时实现并行生成的SOTA性能。

Conclusion: ARMD成功弥合了并行与序列解码间的性能差距，为高效语言建模提供了新范式。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [102] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 使用潜在扩散模型（LDM）生成物联网攻击数据，有效缓解类别不平衡，显著提升入侵检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法在样本保真度、多样性和计算效率之间难以平衡，难以应对物联网入侵检测中的严重类别不平衡问题。

Method: 提出使用潜在扩散模型（LDM）进行攻击数据增强，并在DDoS、Mirai和中间人攻击三种场景下与主流方法对比评估。

Result: LDM生成的数据使IDS的F1分数最高达0.99，生成质量优于基线，采样时间减少约25%，且能更好保留特征依赖性与多样性。

Conclusion: 潜在扩散模型是生成高质量、高效率合成攻击数据的有效方法，可显著提升物联网ML入侵检测系统的性能。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


### [103] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: 提出了一种高效计算的曲率度量临界锐度（λ_c），首次在7B参数规模上验证了损失景观的锐化现象，并引入相对临界锐度指导预训练到微调的过渡。


<details>
  <summary>Details</summary>
Motivation: Hessian锐度（λ_max^H）虽重要但计算昂贵，难以用于大语言模型，亟需高效替代度量。

Method: 引入临界锐度λ_c，仅需少于10次前向传播即可估算，可捕捉渐进锐化与稳定性边缘现象；进一步定义相对临界锐度λ_c^{1→2}分析预训练到微调的曲率变化。

Result: 在OLMo-2模型（最高7B参数）上首次实现大规模锐化现象观测，验证了λ_c与Hessian锐度的强相关性，并通过相对临界锐度优化数据混合策略。

Conclusion: 临界锐度为大规模训练提供了可扩展、实用的曲率分析工具，推动数据组合与训练策略的科学决策。

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [104] [Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators](https://arxiv.org/abs/2601.16242)
*S. Yaqubi,J. Mattila*

Main category: cs.RO

TL;DR: 提出了一种基于螺杆理论的可扩展多体综合框架，用于三维空间中任意数量柔性连杆串联机器人的PDE动力学建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时兼顾柔性连杆的分布式变形与多体系统约束，缺乏统一且可扩展的动力学建模框架。

Method: 采用体坐标系下的对偶螺杆描述运动与变形，通过变分原理推导单个柔性连杆的动力学方程，并利用约束力严格满足完整关节约束，最终构建可扩展的多体系统模型，并转化为半显式指标-1微分代数系统和抽象柯西问题。

Result: 成功建立了能精确捕捉局部与全局动力学的可扩展模型，完整恢复各刚体运动与柔性变形场，并证明了系统的适定性。

Conclusion: 该框架为柔性多体系统提供了数学严谨、计算可行且高度可扩展的PDE动力学建模新范式。

Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.

</details>


### [105] [DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware](https://arxiv.org/abs/2601.16327)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 提出一种基于DMAVA的分布式多车自动泊车系统，实现低延迟协同控制与可扩展仿真。


<details>
  <summary>Details</summary>
Motivation: 现有仿真方法多为集中式或非分布式设计，限制了可扩展性与完全自主控制能力。

Method: 构建两个模块：1）基于状态协调的多车泊车节点，2）集成Unity-YOLOv5的视觉感知模块，通过Zenoh通信层实现多主机低延迟同步。

Result: 在双/三主机配置下实现确定性协调、无冲突泊车，验证了系统可扩展性与协同性能。

Conclusion: 该系统为多车AVP仿真提供了可行框架，并为未来真实场景与硬件在环验证奠定基础。

Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp

</details>


### [106] [DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware](https://arxiv.org/abs/2601.16336)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 提出一种分布式多自动驾驶汽车架构DMAVA，支持多车在物理主机上实时同步仿真，基于ROS 2、Autoware和Zenoh实现去中心化协作。


<details>
  <summary>Details</summary>
Motivation: 现有仿真架构多限于单车操作或依赖集中控制，难以支持多车真实协同仿真。

Method: 采用分布式架构，每车独立运行完整AV栈，通过低延迟数据通信层（ROS 2 + Zenoh）实现同步，集成Unity环境与Autoware Universe。

Result: 在多主机配置下实现稳定定位、可靠跨主机通信和完全同步的闭环控制，并成功应用于多车自动泊车场景。

Conclusion: DMAVA为多车协同自动驾驶仿真提供了可扩展的分布式基础平台，支持未来高级协同 autonomy 的研究。

Abstract: Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture.

</details>


### [107] [GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter](https://arxiv.org/abs/2601.16393)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 提出一种基于地基GNSS的月球导航卫星轨道与钟差估计算法，利用随机克隆UD分解滤波器和延迟状态平滑器，实现高精度定位。


<details>
  <summary>Details</summary>
Motivation: 月球距离下观测条件差，传统方法精度不足，需提升轨道与钟差估计精度以满足未来月球增强导航服务（LANS）要求。

Method: 构建包含相对论耦合、月球时间尺度变换和多种传播延迟（电离层、等离子层、Shapiro效应）的动态与测量模型，采用随机克隆UD分解滤波器与延迟状态平滑器处理时间差分载波相位（TDCP）测量。

Result: 仿真表明，联合无电离层伪距与TDCP测量可实现米级轨道精度和亚毫米/秒速度精度，满足LANS的信号在空间误差要求。

Conclusion: 该框架显著提升月球轨道与钟差估计精度，为未来月球导航系统提供可行技术路径。

Abstract: This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS).

</details>


### [108] [Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture](https://arxiv.org/abs/2601.16405)
*Beining Wu,Zihao Ding,Leo Ostigaard,Jun Huang*

Main category: cs.RO

TL;DR: 提出一种基于SAC强化学习的能量感知覆盖路径规划框架，在农业机器人中实现高覆盖率与能量安全的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有覆盖路径规划方法忽视能量约束，导致在大规模或资源受限环境中操作不完整。

Method: 结合CNN提取空间特征、LSTM捕捉时间动态，并设计联合优化覆盖率、能耗和返站约束的奖励函数，基于SAC算法实现决策。

Result: 在保证能量安全的前提下，覆盖率稳定超过90%，相比RRT、PSO、ACO基线提升13.4%-19.5%，约束 violation 减少59.9%-88.3%。

Conclusion: 所提SAC框架为农业机器人中能量受限的覆盖路径规划提供了高效且可扩展的解决方案。

Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.

</details>


### [109] [RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways](https://arxiv.org/abs/2601.16424)
*Mingi Jeong,Alberto Quattrini Li*

Main category: cs.RO

TL;DR: RENEW是一种用于动态环境中文本自主水面艇的全局路径规划器，结合风险与能量感知策略，提升航行安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法难以同时应对动态环境中的外部干扰（如洋流）和非可航区域的自适应识别，亟需一种兼具安全性和拓扑多样性的新框架。

Method: 采用分层架构：高层通过约束三角剖分实现拓扑路径多样性，低层在安全走廊内进行轨迹优化，并引入风险与能量感知的自适应安全约束。

Result: RENEW是首个联合解决自适应非可航性与路径拓扑多样性问题的框架，基于真实海洋数据验证了其在动态环境中的鲁棒性。

Conclusion: RENEW通过统一的风险-能量感知策略与分层规划，显著提升了ASV在复杂海洋环境中的安全与可靠性。

Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.

</details>


### [110] [Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab](https://arxiv.org/abs/2601.16578)
*Julius Beerwerth,Jianye Xu,Simon Schäfer,Fynn Belderink,Bassam Alrifaee*

Main category: cs.RO

TL;DR: 提出一个可复现的基准，用于评估车联网多智能体强化学习策略的仿真到现实迁移，揭示了架构差异与环境真实度导致的性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有仿真到现实迁移评估缺乏结构化和可复现的基准，难以系统分析多智能体强化学习在真实场景中的泛化能力。

Method: 基于CPM Lab构建集成仿真、高保真数字孪生与物理测试平台的三域统一基准，部署SigmaRL策略进行零样本评估。

Result: 发现性能下降源于控制栈架构差异与环境真实度提升引发的仿真-现实差距，验证了基准的有效性。

Conclusion: 该开源平台为MARL的仿真到现实迁移研究提供了可复现、可扩展的系统性评估工具。

Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.

</details>


### [111] [A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics](https://arxiv.org/abs/2601.16638)
*Philip Tobuschat,Simon Duenser,Markus Bambach,Ivo Aschwanden*

Main category: cs.RO

TL;DR: 提出一种仅需单次简单实验即可统一标定工业机器人几何与非几何误差的静态标定方法，显著提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有工具定位误差补偿方法需针对不同误差源分别设计实验与模型，成本高、效率低。

Method: 通过在运动链中引入虚拟关节建模几何与非几何效应（如弹性变形、热变形、齿轮误差），并采用高斯-牛顿优化与解析梯度进行参数辨识。

Result: 在KUKA KR30机器人上实现26.8μm的平均位置误差，远优于纯几何标定的102.3μm；Fisher信息谱显示参数估计条件良好，模型鲁棒性强。

Conclusion: 该统一标定方法高效、准确且鲁棒，为工业机器人高精度标定提供新范式。

Abstract: Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration.

</details>


### [112] [ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance](https://arxiv.org/abs/2601.16667)
*Zhuohao Li,Yinghao Li,Jian-Jian Jiang,Lang Zhou,Tianyu Zhang,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 提出ReViP框架，通过视觉-本体感受平衡减少机器人操作中的虚假完成问题，显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型过度依赖本体感觉，忽视视觉证据，导致虚假完成；亟需增强视觉 grounding 和鲁棒性。

Method: 引入外部VLM作为任务阶段观察者，提取任务相关视觉线索，通过视觉-本体感受特征线性调制模块动态平衡多模态信息。

Result: 在自建False-Completion基准（基于LIBERO）及LIBERO、RoboTwin 2.0和真实世界任务中，ReViP显著降低虚假完成率并提升成功率。

Conclusion: ReViP通过任务感知的视觉引导有效缓解模态失衡，为鲁棒机器人操作提供了新范式。

Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

</details>


### [113] [Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation](https://arxiv.org/abs/2601.16677)
*Lucía Güitta-López,Lionel Güitta-López,Jaime Boal,Álvaro Jesús López-López*

Main category: cs.RO

TL;DR: 提出一种StyleID-CycleGAN方法，实现虚拟到现实的零样本迁移，工业机器人任务中成功率达95%以上。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在现实世界中样本效率低，传统仿真训练难以直接迁移至真实环境，亟需高效零样本迁移方案。

Method: 采用Style-Identified Cycle Consistent GAN（SICGAN）将虚拟观测转换为类真实图像，构建混合域进行训练，实现无需微调的零样本部署。

Result: 在虚拟环境中训练成功率达90-100%，真实环境部署后准确率超95%，可泛化至不同颜色和形状的物体（如乐高积木、马克杯）。

Conclusion: 该方法有效解决仿真到现实的迁移难题，具备高效、可扩展性，为工业机器人应用提供实用解决方案。

Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.

</details>


### [114] [Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation](https://arxiv.org/abs/2601.16686)
*Ning Liu,Sen Shen,Zheng Li,Matthew D'Souza,Jen Jen Chung,Thomas Braunl*

Main category: cs.RO

TL;DR: ARMS是一种结合强化学习与模型预测控制的混合框架，用于在安全约束下实现人机协作导航，显著提升成功率与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂动态环境中难以同时满足安全约束与高机动性需求，且计算开销大。

Method: 采用PPO训练的强化学习跟随器与基于QP的单步MPC安全滤波器，通过LSTM与空间编码器处理部分可观测状态，并引入自适应神经切换器实现两控制器的软融合。

Result: 在高杂乱环境中成功率达82.5%，优于DWA和纯RL基线7.1%和3.1%，计算延迟降低33%至5.2毫秒，仿真与实测均验证有效性。

Conclusion: ARMS通过自适应切换机制实现了安全、高效的人机协作导航，具备良好的实用性和可扩展性。

Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.

</details>


### [115] [Creating a biologically more accurate spider robot to study active vibration sensing](https://arxiv.org/abs/2601.16691)
*Siyuan Sun,Eugene H. Lin,Nathan Brown,Hsin-Yi Hung,Andrew Gordus,Jochen Mueller,Chen Li*

Main category: cs.RO

TL;DR: 开发了一种更仿生的八足蜘蛛机器人，通过深度屈膝模拟蜘蛛捕猎时的振动感知机制。


<details>
  <summary>Details</summary>
Motivation: 蜘蛛通过腿关节振动感知猎物，但其屈膝行为如何增强感知尚不明确，因在活体动物中测量振动困难。

Method: 设计并制造了具有八腿、四关节、3D打印外骨骼和硅胶调刚度的新型蜘蛛机器人，采用肌腱驱动实现深度屈膝，并在关节处安装加速度计记录振动。

Result: 新机器人复现了前代机器人的关键振动特征，同时显著提升了生物真实性，为研究腿行为如何调制网上传播振动提供了更准确的机器人物理模型。

Conclusion: 该机器人模型为深入理解蜘蛛主动感知机制提供了可靠实验平台。

Abstract: Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web.

</details>


### [116] [A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation](https://arxiv.org/abs/2601.16712)
*Kartik Chari,Raid Dokhan,Anas Homsi,Niklas Kueper,Elsa Andrea Kirchner*

Main category: cs.RO

TL;DR: 使用8通道sEMG特征提取管道，MLP模型在肘部和肩部扭矩预测上达到与TCN相当的精度，适用于数据有限的康复场景。


<details>
  <summary>Details</summary>
Motivation: 准确预测用户关节扭矩是实现个性化外骨骼辅助的关键，但现有方法对数据量要求高，难以适应临床康复中数据稀缺的现实。

Method: 基于8通道sEMG信号设计特征提取管道，结合MLP与TCN神经网络，利用运动捕捉数据与静力平衡假设估计参考扭矩，评估不同负载下的预测性能。

Result: MLP在肘部、前肩、侧肩扭矩预测上分别实现0.963、1.403、1.434 N m的平均RMSE，性能与TCN相当。

Conclusion: 所提特征提取管道使简单MLP在有限数据下即可达到复杂时序模型的性能，提升康复机器人在临床场景中的实用性与部署效率。

Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.

</details>


### [117] [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](https://arxiv.org/abs/2601.16866)
*Lucía Güitta-López,Vincenzo Suriani,Jaime Boal,Álvaro J. López-López,Daniele Nardi*

Main category: cs.RO

TL;DR: 通过结合知识图谱嵌入提升深度强化学习在机器人控制中的学习效率，减少60%训练时间并提升15%准确率


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在机器人控制中因样本需求大导致训练成本高，亟需提高学习效率

Method: 将知识图谱嵌入（KGE）与视觉观测结合，为智能体提供语义上下文信息

Result: 在固定和随机目标环境中，训练时间减少60%，任务准确率提升约15个百分点，未增加计算复杂度

Conclusion: 语义知识能有效降低深度强化学习的样本复杂度，显著提升其在机器人应用中的性能

Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.

</details>


### [118] [A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study](https://arxiv.org/abs/2601.16870)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 提出一种基于对话的多模态数据采集框架，用于自然人机交互下的轮椅与机械臂协同控制，支持模糊性感知的辅助控制学习。


<details>
  <summary>Details</summary>
Motivation: 现有接口缺乏灵活性，且缺乏捕捉自然人机交互（特别是对话中模糊性）的多模态数据集，限制了AI方法在辅助控制中的发展。

Method: 采用对话协议和双房间巫师之境（WoZ）设置，同步采集RGB-D视频、语音、IMU、末端位姿和全身关节状态五种模态数据，共收集53次试验。

Result: 数据集有效捕捉多种语义模糊性，运动平滑性与用户反馈验证了其质量，支持自然对话驱动的交互。

Conclusion: 该框架为大规模数据收集、基准测试和模糊感知辅助控制系统的开发提供了可靠基础。

Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.

</details>
