<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 80]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.LG](#cs.LG) [Total: 71]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench](https://arxiv.org/abs/2510.26865)
*Fenfen Lin,Yesheng Liu,Haiyu Xu,Chen Yue,Zheqi He,Mingxuan Zhao,Miguel Hu Chen,Jiakang Liu,JG Yao,Xi Yang*

Main category: cs.CV

TL;DR: MeasureBench 是一个评估视觉语言模型读取测量仪器能力的基准，发现当前模型在指针定位上存在严重缺陷，尽管文本推理合理但仍导致数值错误。


<details>
  <summary>Details</summary>
Motivation: 人类能轻松读取测量仪器，但当前视觉语言模型在测量阅读任务上表现不佳，尤其是在精确定位指针等空间细节方面。

Method: 构建了 MeasureBench 基准，包含真实与合成图像，并设计了可扩展的合成流水线，可控制指针、刻度、字体、光照等参数生成多样数据；同时尝试了基于合成数据的强化学习。

Result: 主流视觉语言模型在测量阅读任务上表现糟糕，核心失败模式是无法准确定位指针位置，导致严重数值错误；强化学习在合成数据上有初步成效，但在真实图像上效果有限。

Conclusion: 当前视觉语言模型存在精细空间定位能力的不足，MeasureBench 为推动模型在视觉数值理解和空间感知上的进步提供了重要资源。

Abstract: Reading measurement instruments is effortless for humans and requires
relatively little domain expertise, yet it remains surprisingly challenging for
current vision-language models (VLMs) as we find in preliminary evaluation. In
this work, we introduce MeasureBench, a benchmark on visual measurement reading
covering both real-world and synthesized images of various types of
measurements, along with an extensible pipeline for data synthesis. Our
pipeline procedurally generates a specified type of gauge with controllable
visual appearance, enabling scalable variation in key details such as pointers,
scales, fonts, lighting, and clutter. Evaluation on popular proprietary and
open-weight VLMs shows that even the strongest frontier VLMs struggle
measurement reading in general. A consistent failure mode is indicator
localization: models can read digits or labels but misidentify the key
positions of pointers or alignments, leading to big numeric errors despite
plausible textual reasoning. We have also conducted preliminary experiments
with reinforcement learning over synthetic data, and find encouraging results
on in-domain synthetic subset but less promising for real-world images. Our
analysis highlights a fundamental limitation of current VLMs in fine-grained
spatial grounding. We hope this resource can help future advances on visually
grounded numeracy and precise spatial perception of VLMs, bridging the gap
between recognizing numbers and measuring the world.

</details>


### [2] [PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT](https://arxiv.org/abs/2510.26903)
*Rochak Dhakal,Chen Zhao,Zixin Shi,Joyce H. Keyak,Tadashi S. Kaneko,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Weihua Zhou*

Main category: cs.CV

TL;DR: 提出一种基于Transformer的域自适应分割框架，解决多中心QCT骨分割中的域偏移问题


<details>
  <summary>Details</summary>
Motivation: 深度网络在不同机构QCT数据上表现不稳定，因扫描设备、重建参数和人群差异导致域偏移，影响骨强度评估的可靠性

Method: 在3D TransUNet基础上结合对抗对齐（GRL）和统计对齐（MMD），实现跨机构特征不变性与解剖细节保留

Result: 在Tulane和Rochester共1408例QCT数据上验证，有效提升多中心分割准确性与泛化性

Conclusion: 所提方法显著缓解域偏移问题，支持多中心骨质疏松研究与可复现的生物力学分析

Abstract: Quantitative computed tomography (QCT) plays a crucial role in assessing bone
strength and fracture risk by enabling volumetric analysis of bone density
distribution in the proximal femur. However, deploying automated segmentation
models in practice remains difficult because deep networks trained on one
dataset often fail when applied to another. This failure stems from domain
shift, where scanners, reconstruction settings, and patient demographics vary
across institutions, leading to unstable predictions and unreliable
quantitative metrics. Overcoming this barrier is essential for multi-center
osteoporosis research and for ensuring that radiomics and structural finite
element analysis results remain reproducible across sites. In this work, we
developed a domain-adaptive transformer segmentation framework tailored for
multi-institutional QCT. Our model is trained and validated on one of the
largest hip fracture related research cohorts to date, comprising 1,024 QCT
images scans from Tulane University and 384 scans from Rochester, Minnesota for
proximal femur segmentation. To address domain shift, we integrate two
complementary strategies within a 3D TransUNet backbone: adversarial alignment
via Gradient Reversal Layer (GRL), which discourages the network from encoding
site-specific cues, and statistical alignment via Maximum Mean Discrepancy
(MMD), which explicitly reduces distributional mismatches between institutions.
This dual mechanism balances invariance and fine-grained alignment, enabling
scanner-agnostic feature learning while preserving anatomical detail.

</details>


### [3] [DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2510.26921)
*Moonsoo Jeong,Dongbeen Kim,Minseong Kim,Sungkil Lee*

Main category: cs.CV

TL;DR: 提出DC4GS方法，通过方向一致性优化高斯溅射的密度控制，减少原元数量并提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统自适应密度控制依赖位置梯度大小进行原元分裂，易产生冗余，缺乏对局部结构复杂性的捕捉。

Method: 引入方向一致性（DC）机制，利用梯度的角相干性指导分裂与位置选择，避免冗余分裂并优化原元对齐。

Result: 相比传统方法，原元数量减少达30%，重建保真度显著提升。

Conclusion: DC4GS通过方向一致性有效提升3D高斯溅射的效率与精度，为密度控制提供新范式。

Abstract: We present a Directional Consistency (DC)-driven Adaptive Density Control
(ADC) for 3D Gaussian Splatting (DC4GS). Whereas the conventional ADC bases its
primitive splitting on the magnitudes of positional gradients, we further
incorporate the DC of the gradients into ADC, and realize it through the
angular coherence of the gradients. Our DC better captures local structural
complexities in ADC, avoiding redundant splitting. When splitting is required,
we again utilize the DC to define optimal split positions so that
sub-primitives best align with the local structures than the conventional
random placement. As a consequence, our DC4GS greatly reduces the number of
primitives (up to 30% in our experiments) than the existing ADC, and also
enhances reconstruction fidelity greatly.

</details>


### [4] [Scale-Aware Curriculum Learning for Ddata-Efficient Lung Nodule Detection with YOLOv11](https://arxiv.org/abs/2510.26923)
*Yi Luo,Yike Guo,Hamed Hooshangnejad,Kai Ding*

Main category: cs.CV

TL;DR: 提出一种动态适应数据规模的课程学习方法SACL，在数据稀缺时显著提升肺结节检测性能。


<details>
  <summary>Details</summary>
Motivation: 临床环境中标注数据有限，传统静态课程学习失效，亟需适应不同数据规模的训练策略。

Method: SACL引入自适应轮次调度、难样本注入和尺度感知优化三项机制，基于YOLOv11在LUNA25数据集上验证。

Result: 在全数据集上性能与静态课程学习相当；在10%/20%/50%数据下，mAP50分别提升4.6%/3.5%/2.0%。

Conclusion: SACL无需修改网络结构，即可在不同数据规模下实现鲁棒训练，适合标注资源有限的医疗机构部署。

Abstract: Lung nodule detection in chest CT is crucial for early lung cancer diagnosis,
yet existing deep learning approaches face challenges when deployed in clinical
settings with limited annotated data. While curriculum learning has shown
promise in improving model training, traditional static curriculum strategies
fail in data-scarce scenarios. We propose Scale Adaptive Curriculum Learning
(SACL), a novel training strategy that dynamically adjusts curriculum design
based on available data scale. SACL introduces three key mechanisms:(1)
adaptive epoch scheduling, (2) hard sample injection, and (3) scale-aware
optimization. We evaluate SACL on the LUNA25 dataset using YOLOv11 as the base
detector. Experimental results demonstrate that while SACL achieves comparable
performance to static curriculum learning on the full dataset in mAP50, it
shows significant advantages under data-limited conditions with 4.6%, 3.5%, and
2.0% improvements over baseline at 10%, 20%, and 50% of training data
respectively. By enabling robust training across varying data scales without
architectural modifications, SACL provides a practical solution for healthcare
institutions to develop effective lung nodule detection systems despite limited
annotation resources.

</details>


### [5] [SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions](https://arxiv.org/abs/2510.26961)
*Md. Mehedi Hassan,Shafqat Alam,Shahriar Ahmed Seam,Maruf Ahmed*

Main category: cs.CV

TL;DR: 提出统一多流SYNAPSE-Net框架，实现多种脑部病灶的高精度自适应分割，达到多项SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型为专用点解决方案，泛化能力差、性能波动大，临床可靠性不足。

Method: 融合多流CNN编码器、Swin Transformer瓶颈、动态跨模态注意力融合（CMAF）和分层门控解码器，并采用病灶特异性数据增强与难度感知采样策略训练。

Result: 在WMH、ISLES 2022和BraTS 2020三个公开数据集上均达到SOTA，DSC最高达0.8651，HD95最优。

Conclusion: 该统一自适应框架在多种脑部病变分割中表现优异，具备临床应用潜力，代码与模型已开源。

Abstract: Automated segmentation of heterogeneous brain lesions from multi-modal MRI
remains a critical challenge in clinical neuroimaging. Current deep learning
models are typically specialized `point solutions' that lack generalization and
high performance variance, limiting their clinical reliability. To address
these gaps, we propose the Unified Multi-Stream SYNAPSE-Net, an adaptive
framework designed for both generalization and robustness. The framework is
built on a novel hybrid architecture integrating multi-stream CNN encoders, a
Swin Transformer bottleneck for global context, a dynamic cross-modal attention
fusion (CMAF) mechanism, and a hierarchical gated decoder for high-fidelity
mask reconstruction. The architecture is trained with a variance reduction
strategy that combines pathology specific data augmentation and
difficulty-aware sampling method. The model was evaluated on three different
challenging public datasets: the MICCAI 2017 WMH Challenge, the ISLES 2022
Challenge, and the BraTS 2020 Challenge. Our framework attained a
state-of-the-art DSC value of 0.831 with the HD95 value of 3.03 in the WMH
dataset. For ISLES 2022, it achieved the best boundary accuracy with a
statistically significant difference (HD95 value of 9.69). For BraTS 2020, it
reached the highest DSC value for the tumor core region (0.8651). These
experimental findings suggest that our unified adaptive framework achieves
state-of-the-art performance across multiple brain pathologies, providing a
robust and clinically feasible solution for automated segmentation. The source
code and the pre-trained models are available at
https://github.com/mubid-01/SYNAPSE-Net-pre.

</details>


### [6] [Semantic Frame Aggregation-based Transformer for Live Video Comment Generation](https://arxiv.org/abs/2510.26978)
*Anam Fatima,Yi Yu,Janak Kapuriya,Julien Lalanne,Jainendra Shukla*

Main category: cs.CV

TL;DR: 提出一种基于语义帧聚合的Transformer模型SFAT，通过加权重要视频帧和融合弹幕上下文，生成更相关的直播评论，并构建了大规模英文直播评论数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视视频帧与观众对话的语义相关性优先级，导致生成评论缺乏上下文契合度。

Method: SFAT模型结合CLIP的多模态知识，对视频帧进行语义相关性加权，使用交叉注意力机制融合弹幕与视频信息进行评论生成。

Result: 在新构建的438小时、320万条英文直播评论数据集上，SFAT显著优于现有方法。

Conclusion: 语义帧加权与多模态融合能有效提升直播评论的上下文相关性，新数据集推动英文直播评论生成研究。

Abstract: Live commenting on video streams has surged in popularity on platforms like
Twitch, enhancing viewer engagement through dynamic interactions. However,
automatically generating contextually appropriate comments remains a
challenging and exciting task. Video streams can contain a vast amount of data
and extraneous content. Existing approaches tend to overlook an important
aspect of prioritizing video frames that are most relevant to ongoing viewer
interactions. This prioritization is crucial for producing contextually
appropriate comments. To address this gap, we introduce a novel Semantic Frame
Aggregation-based Transformer (SFAT) model for live video comment generation.
This method not only leverages CLIP's visual-text multimodal knowledge to
generate comments but also assigns weights to video frames based on their
semantic relevance to ongoing viewer conversation. It employs an efficient
weighted sum of frames technique to emphasize informative frames while focusing
less on irrelevant ones. Finally, our comment decoder with a cross-attention
mechanism that attends to each modality ensures that the generated comment
reflects contextual cues from both chats and video. Furthermore, to address the
limitations of existing datasets, which predominantly focus on Chinese-language
content with limited video categories, we have constructed a large scale,
diverse, multimodal English video comments dataset. Extracted from Twitch, this
dataset covers 11 video categories, totaling 438 hours and 3.2 million
comments. We demonstrate the effectiveness of our SFAT model by comparing it to
existing methods for generating comments from live video and ongoing dialogue
contexts.

</details>


### [7] [MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation](https://arxiv.org/abs/2510.26996)
*Arghavan Rezvani,Xiangyi Yan,Anthony T. Wu,Kun Han,Pooya Khosravi,Xiaohui Xie*

Main category: cs.CV

TL;DR: 提出MoME模型，结合视觉语言与混合专家方法，提升医学图像分割性能


<details>
  <summary>Details</summary>
Motivation: 传统医学图像分割方法难以有效利用多尺度视觉特征与文本信息，而大型语言模型中的混合专家（MoE）范式在其他领域表现优异，亟需探索其在医学视觉语言任务中的潜力

Method: 设计MoME架构，动态选择专家，融合多尺度视觉特征与文本嵌入，基于10个数据集（含3,410例CT扫描）进行训练与评估

Result: 在多个医学图像分割基准上实现具有竞争力的精度，验证了视觉语言模型与MoE结合的有效性

Conclusion: MoME为医学图像分析提供了一种新颖且鲁棒的架构，证明了融合文本信息与混合专家机制在医疗视觉任务中的可行性与优越性

Abstract: In this study, we propose MoME, a Mixture of Visual Language Medical Experts,
for Medical Image Segmentation. MoME adapts the successful Mixture of Experts
(MoE) paradigm, widely used in Large Language Models (LLMs), for medical
vision-language tasks. The architecture enables dynamic expert selection by
effectively utilizing multi-scale visual features tailored to the intricacies
of medical imagery, enriched with textual embeddings. This work explores a
novel integration of vision-language models for this domain. Utilizing an
assembly of 10 datasets, encompassing 3,410 CT scans, MoME demonstrates strong
performance on a comprehensive medical imaging segmentation benchmark. Our
approach explores the integration of foundation models for medical imaging,
benefiting from the established efficacy of MoE in boosting model performance
by incorporating textual information. Demonstrating competitive precision
across multiple datasets, MoME explores a novel architecture for achieving
robust results in medical image analysis.

</details>


### [8] [Incremental Human-Object Interaction Detection with Invariant Relation Representation Learning](https://arxiv.org/abs/2510.27020)
*Yana Wei,Zeen Chi,Chongyu Wang,Yu Wu,Shipeng Yan,Yongfei Liu,Xuming He*

Main category: cs.CV

TL;DR: 提出一种无样本的增量关系蒸馏框架（IRD），解决开放世界中人-物交互的持续学习问题，有效缓解灾难性遗忘、交互漂移和零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 开放世界中人-物交互动态演化，传统闭集模型难以应对持续变化，需模拟人类渐进学习能力以实现增量HOI检测。

Method: 提出IRD框架，解耦对象与关系学习，引入两种新颖的关系蒸馏损失，学习跨HOI组合的不变关系特征。

Result: 在HICO-DET和V-COCO数据集上优于现有方法，在缓解遗忘、抵御交互漂移和零样本HOI泛化方面表现突出。

Conclusion: IRD框架为开放环境下的增量HOI检测提供了有效解决方案，无需依赖历史样本即可实现稳定持续学习。

Abstract: In open-world environments, human-object interactions (HOIs) evolve
continuously, challenging conventional closed-world HOI detection models.
Inspired by humans' ability to progressively acquire knowledge, we explore
incremental HOI detection (IHOID) to develop agents capable of discerning
human-object relations in such dynamic environments. This setup confronts not
only the common issue of catastrophic forgetting in incremental learning but
also distinct challenges posed by interaction drift and detecting zero-shot HOI
combinations with sequentially arriving data. Therefore, we propose a novel
exemplar-free incremental relation distillation (IRD) framework. IRD decouples
the learning of objects and relations, and introduces two unique distillation
losses for learning invariant relation features across different HOI
combinations that share the same relation. Extensive experiments on HICO-DET
and V-COCO datasets demonstrate the superiority of our method over
state-of-the-art baselines in mitigating forgetting, strengthening robustness
against interaction drift, and generalization on zero-shot HOIs. Code is
available at \href{https://github.com/weiyana/ContinualHOI}{this HTTP URL}

</details>


### [9] [VitalLens 2.0: High-Fidelity rPPG for Heart Rate Variability Estimation from Face Video](https://arxiv.org/abs/2510.27028)
*Philipp V. Rouast*

Main category: cs.CV

TL;DR: VitalLens 2.0通过新架构和更大训练数据显著提升rPPG精度，实现心率、呼吸率和HRV的高精度估计


<details>
  <summary>Details</summary>
Motivation: 现有rPPG方法在估计HRV等细粒度生理指标时精度不足，需更强大的模型和更丰富的数据支持

Method: 采用新型深度学习架构，使用包含1413名独特个体的多样化训练数据，并在422人测试集上评估性能

Result: HR MAE 1.57 bpm，RR MAE 1.08 bpm，HRV-SDNN MAE 10.18 ms，HRV-RMSSD MAE 16.45 ms，达到SOTA性能

Conclusion: VitalLens 2.0在远程生理信号估计上实现重大突破，且已通过API开放给开发者使用

Abstract: This report introduces VitalLens 2.0, a new deep learning model for
estimating physiological signals from face video. This new model demonstrates a
significant leap in accuracy for remote photoplethysmography (rPPG), enabling
the robust estimation of not only heart rate (HR) and respiratory rate (RR) but
also Heart Rate Variability (HRV) metrics. This advance is achieved through a
combination of a new model architecture and a substantial increase in the size
and diversity of our training data, now totaling 1,413 unique individuals. We
evaluate VitalLens 2.0 on a new, combined test set of 422 unique individuals
from four public and private datasets. When averaging results by individual,
VitalLens 2.0 achieves a Mean Absolute Error (MAE) of 1.57 bpm for HR, 1.08 bpm
for RR, 10.18 ms for HRV-SDNN, and 16.45 ms for HRV-RMSSD. These results
represent a new state-of-the-art, significantly outperforming previous methods.
This model is now available to developers via the VitalLens API at
https://rouast.com/api.

</details>


### [10] [AD-SAM: Fine-Tuning the Segment Anything Vision Foundation Model for Autonomous Driving Perception](https://arxiv.org/abs/2510.27047)
*Mario Camarena,Het Patel,Fatemeh Nazari,Evangelos Papalexakis,Mohamadhossein Noruzoliaee,Jia Chen*

Main category: cs.CV

TL;DR: AD-SAM是为自动驾驶优化的Segment Anything模型，通过双编码器和可变形解码器提升语义分割精度，显著超越SAM和DeepLabV3。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型在自动驾驶复杂道路场景中分割精度不足，需针对性优化以提升边界精度、类平衡和数据效率。

Method: 采用双编码器融合ViT-H的全局语义与ResNet-50的局部细节，结合可变形融合模块和多阶段可变形解码器，使用混合损失函数（Focal、Dice、Lovasz-Softmax、Surface）训练。

Result: 在Cityscapes上达68.1 mIoU，在BDD100K上达59.5 mIoU，相较SAM和DeepLabV3提升最高达22.9和19.2 mIoU，具有更强跨域泛化能力（0.87保留率）和数据效率（1000样本下0.607 mIoU）。

Conclusion: 通过架构与优化的针对性改进，基础模型可实现高精度、高效率、可扩展的自动驾驶感知系统。

Abstract: This paper presents the Autonomous Driving Segment Anything Model (AD-SAM), a
fine-tuned vision foundation model for semantic segmentation in autonomous
driving (AD). AD-SAM extends the Segment Anything Model (SAM) with a
dual-encoder and deformable decoder tailored to spatial and geometric
complexity of road scenes. The dual-encoder produces multi-scale fused
representations by combining global semantic context from SAM's pretrained
Vision Transformer (ViT-H) with local spatial detail from a trainable
convolutional deep learning backbone (i.e., ResNet-50). A deformable fusion
module aligns heterogeneous features across scales and object geometries. The
decoder performs progressive multi-stage refinement using deformable attention.
Training is guided by a hybrid loss that integrates Focal, Dice,
Lovasz-Softmax, and Surface losses, improving semantic class balance, boundary
precision, and optimization stability. Experiments on the Cityscapes and
Berkeley DeepDrive 100K (BDD100K) benchmarks show that AD-SAM surpasses SAM,
Generalized SAM (G-SAM), and a deep learning baseline (DeepLabV3) in
segmentation accuracy. It achieves 68.1 mean Intersection over Union (mIoU) on
Cityscapes and 59.5 mIoU on BDD100K, outperforming SAM, G-SAM, and DeepLabV3 by
margins of up to +22.9 and +19.2 mIoU in structured and diverse road scenes,
respectively. AD-SAM demonstrates strong cross-domain generalization with a
0.87 retention score (vs. 0.76 for SAM), and faster, more stable learning
dynamics, converging within 30-40 epochs, enjoying double the learning speed of
benchmark models. It maintains 0.607 mIoU with only 1000 samples, suggesting
data efficiency critical for reducing annotation costs. These results confirm
that targeted architectural and optimization enhancements to foundation models
enable reliable and scalable AD perception.

</details>


### [11] [Hierarchical Transformers for Unsupervised 3D Shape Abstraction](https://arxiv.org/abs/2510.27088)
*Aditya Vora,Lily Goli,Andrea Tagliasacchi,Hao Zhang*

Main category: cs.CV

TL;DR: HiT提出了一种无监督的分层神经场方法，自动学习跨类别的3D形状分层结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于固定层级结构（如二叉树），无法灵活捕捉多样形状中的复杂层级关系。

Method: 引入层级Transformer（HiT），通过压缩码本自动学习父-子关系，无约束地推断多级分层结构。

Result: 在ShapeNet全部55类上实现无监督形状分割，成功提取多粒度层级结构。

Conclusion: HiT能泛化地学习复杂分层，超越传统方法，为3D形状理解提供新范式。

Abstract: We introduce HiT, a novel hierarchical neural field representation for 3D
shapes that learns general hierarchies in a coarse-to-fine manner across
different shape categories in an unsupervised setting. Our key contribution is
a hierarchical transformer (HiT), where each level learns parent-child
relationships of the tree hierarchy using a compressed codebook. This codebook
enables the network to automatically identify common substructures across
potentially diverse shape categories. Unlike previous works that constrain the
task to a fixed hierarchical structure (e.g., binary), we impose no such
restriction, except for limiting the total number of nodes at each tree level.
This flexibility allows our method to infer the hierarchical structure directly
from data, over multiple shape categories, and representing more general and
complex hierarchies than prior approaches. When trained at scale with a
reconstruction loss, our model captures meaningful containment relationships
between parent and child nodes. We demonstrate its effectiveness through an
unsupervised shape segmentation task over all 55 ShapeNet categories, where our
method successfully segments shapes into multiple levels of granularity.

</details>


### [12] [ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding](https://arxiv.org/abs/2510.27128)
*Haonan Wang,Jingyu Lu,Hongrui Li,Xiaomeng Li*

Main category: cs.CV

TL;DR: ZEBRA是一种无需主题特定微调的零样本脑成像重建框架，通过解耦fMRI表征实现跨被试泛化。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖主题特定模型或微调，限制了可扩展性和实际应用。

Method: 利用对抗训练将fMRI表示分解为受试者相关和语义相关成分，隔离主题不变的语义表征。

Result: ZEBRA在多个指标上超越零样本基线，性能接近完全微调模型，无需额外fMRI数据或重训练。

Conclusion: ZEBRA为通用神经解码提供了可扩展且实用的解决方案。

Abstract: Recent advances in neural decoding have enabled the reconstruction of visual
experiences from brain activity, positioning fMRI-to-image reconstruction as a
promising bridge between neuroscience and computer vision. However, current
methods predominantly rely on subject-specific models or require
subject-specific fine-tuning, limiting their scalability and real-world
applicability. In this work, we introduce ZEBRA, the first zero-shot brain
visual decoding framework that eliminates the need for subject-specific
adaptation. ZEBRA is built on the key insight that fMRI representations can be
decomposed into subject-related and semantic-related components. By leveraging
adversarial training, our method explicitly disentangles these components to
isolate subject-invariant, semantic-specific representations. This
disentanglement allows ZEBRA to generalize to unseen subjects without any
additional fMRI data or retraining. Extensive experiments show that ZEBRA
significantly outperforms zero-shot baselines and achieves performance
comparable to fully finetuned models on several metrics. Our work represents a
scalable and practical step toward universal neural decoding. Code and model
weights are available at: https://github.com/xmed-lab/ZEBRA.

</details>


### [13] [WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond](https://arxiv.org/abs/2510.27133)
*Zhicong Sun,Jacqueline Lo,Jinxing Hu*

Main category: cs.CV

TL;DR: 构建了首个用于森林和野火场景的大型合成3DGS-SLAM数据集WildfireX-SLAM，支持无人机航拍与地面视角，涵盖多种环境条件。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS-SLAM方法多限于小规模室内场景，缺乏适用于大规模森林及野火应急的应用数据集，真实数据采集成本高且不可行。

Method: 基于Unreal Engine 5的Electric Dreams项目，构建自动化数据采集管道，生成包含真值位姿、RGB-D影像及多样环境参数（光照、天气、野火状态）的合成数据集。

Result: 发布WildfireX-SLAM数据集，包含5.5k张低空航拍RGB-D图像，覆盖16km²森林区域，并完成首次3DGS-SLAM在该场景下的系统性基准评估。

Conclusion: WildfireX-SLAM填补了森林SLAM数据空白，为野火响应与森林管理提供高保真仿真平台，推动3DGS在户外大规模场景中的研究进展。

Abstract: 3D Gaussian splatting (3DGS) and its subsequent variants have led to
remarkable progress in simultaneous localization and mapping (SLAM). While most
recent 3DGS-based SLAM works focus on small-scale indoor scenes, developing
3DGS-based SLAM methods for large-scale forest scenes holds great potential for
many real-world applications, especially for wildfire emergency response and
forest management. However, this line of research is impeded by the absence of
a comprehensive and high-quality dataset, and collecting such a dataset over
real-world scenes is costly and technically infeasible. To this end, we have
built a large-scale, comprehensive, and high-quality synthetic dataset for SLAM
in wildfire and forest environments. Leveraging the Unreal Engine 5 Electric
Dreams Environment Sample Project, we developed a pipeline to easily collect
aerial and ground views, including ground-truth camera poses and a range of
additional data modalities from unmanned aerial vehicle. Our pipeline also
provides flexible controls on environmental factors such as light, weather, and
types and conditions of wildfire, supporting the need for various tasks
covering forest mapping, wildfire emergency response, and beyond. The resulting
pilot dataset, WildfireX-SLAM, contains 5.5k low-altitude RGB-D aerial images
from a large-scale forest map with a total size of 16 km2. On top of
WildfireX-SLAM, a thorough benchmark is also conducted, which not only reveals
the unique challenges of 3DGS-based SLAM in the forest but also highlights
potential improvements for future works. The dataset and code will be publicly
available. Project page: https://zhicongsun.github.io/wildfirexslam.

</details>


### [14] [E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources](https://arxiv.org/abs/2510.27135)
*Tong Shen,Jingai Yu,Dong Zhou,Dong Li,Emad Barsoum*

Main category: cs.CV

TL;DR: 提出仅3.04亿参数的高效轻量级多模态扩散模型E-MMDiT，在低资源下实现高速图像生成，性能媲美大模型。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型训练成本高、结构臃肿、推理延迟大，难以实际部署，亟需高效轻量解决方案。

Method: 采用高压缩视觉编码器、多路径压缩模块、Position Reinforcement、交替子区域注意力(ASA)和轻量级AdaLN-affine模块，显著减少token数量与计算开销。

Result: 在25M公开数据、8块MI300X GPU上训练1.5天，512px生成达GenEval 0.66，结合GRPO后升至0.72。

Conclusion: E-MMDiT为开源社区提供了高效、可复现的轻量级生成基线，推动生成式AI的普惠化。

Abstract: Diffusion models have shown strong capabilities in generating high-quality
images from text prompts. However, these models often require large-scale
training data and significant computational resources to train, or suffer from
heavy structure with high latency. To this end, we propose Efficient Multimodal
Diffusion Transformer (E-MMDiT), an efficient and lightweight multimodal
diffusion model with only 304M parameters for fast image synthesis requiring
low training resources. We provide an easily reproducible baseline with
competitive results. Our model for 512px generation, trained with only 25M
public data in 1.5 days on a single node of 8 AMD MI300X GPUs, achieves 0.66 on
GenEval and easily reaches to 0.72 with some post-training techniques such as
GRPO. Our design philosophy centers on token reduction as the computational
cost scales significantly with the token count. We adopt a highly compressive
visual tokenizer to produce a more compact representation and propose a novel
multi-path compression module for further compression of tokens. To enhance our
design, we introduce Position Reinforcement, which strengthens positional
information to maintain spatial coherence, and Alternating Subregion Attention
(ASA), which performs attention within subregions to further reduce
computational cost. In addition, we propose AdaLN-affine, an efficient
lightweight module for computing modulation parameters in transformer blocks.
Our code is available at https://github.com/AMD-AGI/Nitro-E and we hope E-MMDiT
serves as a strong and practical baseline for future research and contributes
to democratization of generative AI models.

</details>


### [15] [Improving Cross-view Object Geo-localization: A Dual Attention Approach with Cross-view Interaction and Multi-Scale Spatial Features](https://arxiv.org/abs/2510.27139)
*Xingtao Ling Yingying Zhu*

Main category: cs.CV

TL;DR: 提出CVCAM和MHSAM模块，提升跨视角目标地理定位精度，并构建新数据集G2D


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨视角信息传递和空间关系特征图优化上表现不佳，易受边缘噪声干扰，导致定位不准

Method: 引入跨视角交叉注意力模块CVCAM实现双视角交互学习，结合多头空间注意力模块MHSAM提取多尺度特征，并构建G2D数据集

Result: 在CVOGL和G2D数据集上 surpass 现有SOTA方法，显著提升定位精度

Conclusion: CVCAM与MHSAM有效增强跨视角语义理解与特征表示，G2D填补了地面到无人机定位数据空白

Abstract: Cross-view object geo-localization has recently gained attention due to
potential applications. Existing methods aim to capture spatial dependencies of
query objects between different views through attention mechanisms to obtain
spatial relationship feature maps, which are then used to predict object
locations. Although promising, these approaches fail to effectively transfer
information between views and do not further refine the spatial relationship
feature maps. This results in the model erroneously focusing on irrelevant edge
noise, thereby affecting localization performance. To address these
limitations, we introduce a Cross-view and Cross-attention Module (CVCAM),
which performs multiple iterations of interaction between the two views,
enabling continuous exchange and learning of contextual information about the
query object from both perspectives. This facilitates a deeper understanding of
cross-view relationships while suppressing the edge noise unrelated to the
query object. Furthermore, we integrate a Multi-head Spatial Attention Module
(MHSAM), which employs convolutional kernels of various sizes to extract
multi-scale spatial features from the feature maps containing implicit
correspondences, further enhancing the feature representation of the query
object. Additionally, given the scarcity of datasets for cross-view object
geo-localization, we created a new dataset called G2D for the "Ground-to-Drone"
localization task, enriching existing datasets and filling the gap in
"Ground-to-Drone" localization task. Extensive experiments on the CVOGL and G2D
datasets demonstrate that our proposed method achieves high localization
accuracy, surpassing the current state-of-the-art.

</details>


### [16] [HiGS: Hierarchical Generative Scene Framework for Multi-Step Associative Semantic Spatial Composition](https://arxiv.org/abs/2510.27148)
*Jiacheng Hong,Kunzhen Wu,Mingrui Yu,Yichao Gu,Shengze Xue,Shuangjiu Xiao,Deli Dong*

Main category: cs.CV

TL;DR: 提出HiGS分层生成框架，通过多步语义关联实现可控的3D场景构建，超越单步方法的布局合理性和用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有方法为单步生成，难以平衡场景复杂度与用户输入简洁性，受人类从全局到局部的场景建模认知过程启发。

Method: 提出HiGS分层生成框架，结合PHiSSG进步式层次空间-语义图，动态组织空间关系与语义依赖，支持递归布局优化与对象一一映射。

Result: 在布局合理性、风格一致性与用户偏好上优于单阶段方法，实现细粒度控制与自动补全。

Conclusion: HiGS提供了一种可控制、可扩展的高效3D场景构建范式，实现用户主导与模型自动协同的生成机制。

Abstract: Three-dimensional scene generation holds significant potential in gaming,
film, and virtual reality. However, most existing methods adopt a single-step
generation process, making it difficult to balance scene complexity with
minimal user input. Inspired by the human cognitive process in scene modeling,
which progresses from global to local, focuses on key elements, and completes
the scene through semantic association, we propose HiGS, a hierarchical
generative framework for multi-step associative semantic spatial composition.
HiGS enables users to iteratively expand scenes by selecting key semantic
objects, offering fine-grained control over regions of interest while the model
completes peripheral areas automatically. To support structured and coherent
generation, we introduce the Progressive Hierarchical Spatial-Semantic Graph
(PHiSSG), which dynamically organizes spatial relationships and semantic
dependencies across the evolving scene structure. PHiSSG ensures spatial and
geometric consistency throughout the generation process by maintaining a
one-to-one mapping between graph nodes and generated objects and supporting
recursive layout optimization. Experiments demonstrate that HiGS outperforms
single-stage methods in layout plausibility, style consistency, and user
preference, offering a controllable and extensible paradigm for efficient 3D
scene construction.

</details>


### [17] [AFM-Net: Advanced Fusing Hierarchical CNN Visual Priors with Global Sequence Modeling for Remote Sensing Image Scene Classification](https://arxiv.org/abs/2510.27155)
*Yuanhao Tang,Xuechao Zou,Zhengpei Hu,Junliang Xing,Chengkun Zhang,Jianqiang Huang*

Main category: cs.CV

TL;DR: AFM-Net通过CNN与Mamba结合，高效融合局部与全局特征，在遥感图像分类中实现高精度与高效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法中CNN擅长局部纹理建模，Transformer擅长全局上下文捕捉，但其高计算成本限制了融合效率。

Method: 提出AFM-Net，包含CNN分支提取层次视觉先验，Mamba分支进行高效全局建模，并通过层次融合机制实现跨层级特征交互，最后用混合专家分类器进行细粒度识别。

Result: 在AID、NWPU-RESISC45和UC Merced数据集上分别达到93.72%、95.54%和96.92%的准确率，超越现有方法。

Conclusion: AFM-Net通过高效融合架构平衡了精度与计算效率，为遥感图像场景分类提供了新思路。

Abstract: Remote sensing image scene classification remains a challenging task,
primarily due to the complex spatial structures and multi-scale characteristics
of ground objects. Existing approaches see CNNs excel at modeling local
textures, while Transformers excel at capturing global context. However,
efficiently integrating them remains a bottleneck due to the high computational
cost of Transformers. To tackle this, we propose AFM-Net, a novel Advanced
Hierarchical Fusing framework that achieves effective local and global
co-representation through two pathways: a CNN branch for extracting
hierarchical visual priors, and a Mamba branch for efficient global sequence
modeling. The core innovation of AFM-Net lies in its Hierarchical Fusion
Mechanism, which progressively aggregates multi-scale features from both
pathways, enabling dynamic cross-level feature interaction and contextual
reconstruction to produce highly discriminative representations. These fused
features are then adaptively routed through a Mixture-of-Experts classifier
module, which dispatches them to the most suitable experts for fine-grained
scene recognition. Experiments on AID, NWPU-RESISC45, and UC Merced show that
AFM-Net obtains 93.72, 95.54, and 96.92 percent accuracy, surpassing
state-of-the-art methods with balanced performance and efficiency. Code is
available at https://github.com/tangyuanhao-qhu/AFM-Net.

</details>


### [18] [How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring](https://arxiv.org/abs/2510.27158)
*Yanfan Zhu,Juming Xiong,Ruining Deng,Yu Wang,Yaohong Wang,Shilin Zhao,Mengmeng Yin,Yuqing Liu,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 本研究尝试用深度学习模型模拟Banff分级，发现虽可部分匹配专家评分，但中间表示存在依赖缺失、幻觉和歧义，限制了可解释性与可靠性。


<details>
  <summary>Details</summary>
Motivation: Banff分类标准具有半定量性、复杂性和观察者间差异大，亟需计算化复制以提升病理评估的一致性与效率。

Method: 将Banff指标（如g、ptc、v）分解为结构与炎症组分，利用现有分割与检测模型，通过基于专家规则的启发式映射计算评分，并与专家标注对比评估。

Result: 部分评分可匹配专家结果，但中间表示常有结构遗漏、幻觉和检测模糊；即使最终分数一致，可解释性仍严重不足。

Conclusion: 当前AI框架难以真正复现专家级分级，需建立模块化评估体系与计算化的Banff标准，以指导移植病理AI模型的未来发展。

Abstract: The Banff Classification provides the global standard for evaluating renal
transplant biopsies, yet its semi-quantitative nature, complex criteria, and
inter-observer variability present significant challenges for computational
replication. In this study, we explore the feasibility of approximating Banff
lesion scores using existing deep learning models through a modular, rule-based
framework. We decompose each Banff indicator - such as glomerulitis (g),
peritubular capillaritis (ptc), and intimal arteritis (v) - into its
constituent structural and inflammatory components, and assess whether current
segmentation and detection tools can support their computation. Model outputs
are mapped to Banff scores using heuristic rules aligned with expert
guidelines, and evaluated against expert-annotated ground truths. Our findings
highlight both partial successes and critical failure modes, including
structural omission, hallucination, and detection ambiguity. Even when final
scores match expert annotations, inconsistencies in intermediate
representations often undermine interpretability. These results reveal the
limitations of current AI pipelines in replicating computational expert-level
grading, and emphasize the importance of modular evaluation and computational
Banff grading standard in guiding future model development for transplant
pathology.

</details>


### [19] [Generating Accurate and Detailed Captions for High-Resolution Images](https://arxiv.org/abs/2510.27164)
*Hankyeol Lee,Gawon Seo,Kyounggyu Lee,Dogun Kim,Kyungwoo Song,Jiyoung Jung*

Main category: cs.CV

TL;DR: 通过结合VLM、LLM和目标检测系统，提升高分辨率图像的caption质量并减少幻觉


<details>
  <summary>Details</summary>
Motivation: VLMs在低分辨率图像上预训练，无法准确捕捉高分辨率图像中的细节和重要对象

Method: 多阶段管道：VLM生成初始caption，LLM预测共现对象，目标检测验证并进行区域特异性caption优化

Result: 在高分辨率图像数据集上，生成的caption更详细、更可靠，且幻觉显著减少

Conclusion: 该管道有效融合多模态模型优势，显著提升高分辨率图像描述的准确性和细节丰富度

Abstract: Vision-language models (VLMs) often struggle to generate accurate and
detailed captions for high-resolution images since they are typically
pre-trained on low-resolution inputs (e.g., 224x224 or 336x336 pixels).
Downscaling high-resolution images to these dimensions may result in the loss
of visual details and the omission of important objects. To address this
limitation, we propose a novel pipeline that integrates vision-language models,
large language models (LLMs), and object detection systems to enhance caption
quality. Our proposed pipeline refines captions through a novel, multi-stage
process. Given a high-resolution image, an initial caption is first generated
using a VLM, and key objects in the image are then identified by an LLM. The
LLM predicts additional objects likely to co-occur with the identified key
objects, and these predictions are verified by object detection systems. Newly
detected objects not mentioned in the initial caption undergo focused,
region-specific captioning to ensure they are incorporated. This process
enriches caption detail while reducing hallucinations by removing references to
undetected objects. We evaluate the enhanced captions using pairwise comparison
and quantitative scoring from large multimodal models, along with a benchmark
for hallucination detection. Experiments on a curated dataset of
high-resolution images demonstrate that our pipeline produces more detailed and
reliable image captions while effectively minimizing hallucinations.

</details>


### [20] [M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar](https://arxiv.org/abs/2510.27166)
*Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: 提出M^3Detection框架，通过多帧多模态特征融合实现高精度3D检测，显著提升恶劣天气下摄像头与4D雷达的联合感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有相机-雷达融合方法多限于单帧输入，场景信息不全且受图像降质和雷达稀疏性影响；多帧融合虽信息更丰富，但面临特征融合鲁棒性差与计算开销大两大挑战。

Method: 设计M^3Detection框架，利用基线检测器中间特征与追踪器轨迹作为参考，构造全局-局部双向特征聚合模块，并引入轨迹级时空推理模块，实现跨帧跨模态的高效特征融合。

Result: 在VoD和TJ4DRadSet数据集上达到SOTA的3D检测性能，验证了多帧多模态融合的有效性。

Conclusion: M^3Detection通过高效多级融合策略，解决了多帧雷达-视觉融合中的特征对齐与计算效率问题，为低成本高鲁棒性3D感知提供了新方案。

Abstract: Recent advances in 4D imaging radar have enabled robust perception in adverse
weather, while camera sensors provide dense semantic information. Fusing the
these complementary modalities has great potential for cost-effective 3D
perception. However, most existing camera-radar fusion methods are limited to
single-frame inputs, capturing only a partial view of the scene. The incomplete
scene information, compounded by image degradation and 4D radar sparsity,
hinders overall detection performance. In contrast, multi-frame fusion offers
richer spatiotemporal information but faces two challenges: achieving robust
and effective object feature fusion across frames and modalities, and
mitigating the computational cost of redundant feature extraction.
Consequently, we propose M^3Detection, a unified multi-frame 3D object
detection framework that performs multi-level feature fusion on multi-modal
data from camera and 4D imaging radar. Our framework leverages intermediate
features from the baseline detector and employs the tracker to produce
reference trajectories, improving computational efficiency and providing richer
information for second-stage. In the second stage, we design a global-level
inter-object feature aggregation module guided by radar information to align
global features across candidate proposals and a local-level inter-grid feature
aggregation module that expands local features along the reference trajectories
to enhance fine-grained object representation. The aggregated features are then
processed by a trajectory-level multi-frame spatiotemporal reasoning module to
encode cross-frame interactions and enhance temporal representation. Extensive
experiments on the VoD and TJ4DRadSet datasets demonstrate that M^3Detection
achieves state-of-the-art 3D detection performance, validating its
effectiveness in multi-frame detection with camera-4D imaging radar fusion.

</details>


### [21] [DANCER: Dance ANimation via Condition Enhancement and Rendering with diffusion model](https://arxiv.org/abs/2510.27169)
*Yucheng Xing,Jinxing Yin,Xiaodong Liu*

Main category: cs.CV

TL;DR: 提出DANCER框架，基于稳定视频扩散模型实现单人舞蹈视频生成，通过外观增强和姿态渲染模块提升生成质量，同时构建TikTok-3K数据集进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在人体舞蹈等高自由度动作生成上面临连续性与细节保真度挑战，需更精准地利用参考图像和运动序列信息。

Method: 设计外观增强模块（AEM）强化参考图像细节，引入姿态渲染模块（PRM）从多域提取姿态条件，并基于TikTok-3K数据集训练稳定视频扩散模型。

Result: 在真实数据集上实验表明，DANCER在舞蹈视频生成质量与连贯性上超越SOTA方法。

Conclusion: DANCER有效提升了人体舞蹈视频的生成效果，提出的模块与数据集为未来视频生成研究提供了新方向。

Abstract: Recently, diffusion models have shown their impressive ability in visual
generation tasks. Besides static images, more and more research attentions have
been drawn to the generation of realistic videos. The video generation not only
has a higher requirement for the quality, but also brings a challenge in
ensuring the video continuity. Among all the video generation tasks,
human-involved contents, such as human dancing, are even more difficult to
generate due to the high degrees of freedom associated with human motions. In
this paper, we propose a novel framework, named as DANCER (Dance ANimation via
Condition Enhancement and Rendering with Diffusion Model), for realistic
single-person dance synthesis based on the most recent stable video diffusion
model. As the video generation is generally guided by a reference image and a
video sequence, we introduce two important modules into our framework to fully
benefit from the two inputs. More specifically, we design an Appearance
Enhancement Module (AEM) to focus more on the details of the reference image
during the generation, and extend the motion guidance through a Pose Rendering
Module (PRM) to capture pose conditions from extra domains. To further improve
the generation capability of our model, we also collect a large amount of video
data from Internet, and generate a novel datasetTikTok-3K to enhance the model
training. The effectiveness of the proposed model has been evaluated through
extensive experiments on real-world datasets, where the performance of our
model is superior to that of the state-of-the-art methods. All the data and
codes will be released upon acceptance.

</details>


### [22] [H2-Cache: A Novel Hierarchical Dual-Stage Cache for High-Performance Acceleration of Generative Diffusion Models](https://arxiv.org/abs/2510.27171)
*Mingyu Sung,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.CV

TL;DR: H2-Cache通过分层缓存机制在不牺牲图像质量的前提下，将扩散模型推理速度提升达5.08倍。


<details>
  <summary>Details</summary>
Motivation: 扩散模型因迭代去噪计算代价高，实际部署受阻；现有缓存方法在加速与保真度之间难以平衡。

Method: 提出H2-Cache，基于去噪过程的结构定义与细节优化两阶段分离，采用双阈值缓存机制，并引入轻量级 pooled feature summarization (PFS) 实现高效相似性估计。

Result: 在Flux架构上实现最高5.08倍加速，图像质量与基线几乎一致，显著优于现有缓存方法。

Conclusion: H2-Cache有效解决速度与质量的权衡难题，为高保真扩散模型的实际应用提供了可行方案。

Abstract: Diffusion models have emerged as state-of-the-art in image generation, but
their practical deployment is hindered by the significant computational cost of
their iterative denoising process. While existing caching techniques can
accelerate inference, they often create a challenging trade-off between speed
and fidelity, suffering from quality degradation and high computational
overhead. To address these limitations, we introduce H2-Cache, a novel
hierarchical caching mechanism designed for modern generative diffusion model
architectures. Our method is founded on the key insight that the denoising
process can be functionally separated into a structure-defining stage and a
detail-refining stage. H2-cache leverages this by employing a dual-threshold
system, using independent thresholds to selectively cache each stage. To ensure
the efficiency of our dual-check approach, we introduce pooled feature
summarization (PFS), a lightweight technique for robust and fast similarity
estimation. Extensive experiments on the Flux architecture demonstrate that
H2-cache achieves significant acceleration (up to 5.08x) while maintaining
image quality nearly identical to the baseline, quantitatively and
qualitatively outperforming existing caching methods. Our work presents a
robust and practical solution that effectively resolves the speed-quality
dilemma, significantly lowering the barrier for the real-world application of
high-fidelity diffusion models. Source code is available at
https://github.com/Bluear7878/H2-cache-A-Hierarchical-Dual-Stage-Cache.

</details>


### [23] [SilhouetteTell: Practical Video Identification Leveraging Blurred Recordings of Video Subtitles](https://arxiv.org/abs/2510.27179)
*Guanchong Huang,Song Fang*

Main category: cs.CV

TL;DR: 提出一种名为SilhouetteTell的新型视频识别攻击方法，通过分析字幕轮廓的时空特征来推断用户观看的视频内容，可在40米外通过智能手机实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 视频观看历史可能泄露用户的隐私信息如兴趣、宗教、政治倾向等，现有方法依赖网络流量分析，存在局限性，亟需新方法应对。

Method: 利用字幕轮廓的时空特征（空间形态与时间间隔）构建特征向量，匹配视频字幕文件，实现对在线和离线视频的识别。

Result: 在商用智能手机上实验验证，SilhouetteTell能高效推断视频标题和片段，识别精度高，有效距离可达40米。

Conclusion: 字幕轮廓可作为隐蔽的指纹信号，SilhouetteTell证明了视觉隐私威胁的新维度，需引起重视并防范。

Abstract: Video identification attacks pose a significant privacy threat that can
reveal videos that victims watch, which may disclose their hobbies, religious
beliefs, political leanings, sexual orientation, and health status. Also, video
watching history can be used for user profiling or advertising and may result
in cyberbullying, discrimination, or blackmail. Existing extensive video
inference techniques usually depend on analyzing network traffic generated by
streaming online videos. In this work, we observe that the content of a
subtitle determines its silhouette displayed on the screen, and identifying
each subtitle silhouette also derives the temporal difference between two
consecutive subtitles. We then propose SilhouetteTell, a novel video
identification attack that combines the spatial and time domain information
into a spatiotemporal feature of subtitle silhouettes. SilhouetteTell explores
the spatiotemporal correlation between recorded subtitle silhouettes of a video
and its subtitle file. It can infer both online and offline videos.
Comprehensive experiments on off-the-shelf smartphones confirm the high
efficacy of SilhouetteTell for inferring video titles and clips under various
settings, including from a distance of up to 40 meters.

</details>


### [24] [Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model](https://arxiv.org/abs/2510.27607)
*John Won,Kyungmin Lee,Huiwon Jang,Dongyoung Kim,Jinwoo Shin*

Main category: cs.CV

TL;DR: DUST是一种双流扩散模型，通过解耦视觉与动作模态提升视觉语言动作模型的机器人策略学习性能，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型难以联合预测下一状态观测与动作序列，因模态间本质差异导致建模困难。

Method: 提出双流扩散架构，独立噪声扰动与解耦流匹配损失，支持异步采样与测试时扩展，无需统一潜在空间。

Result: 在RoboCasa、GR-1模拟环境中提升6%，测试时扩展额外增益2-5%；在Franka机器人上成功率达13%提升，BridgeV2预训练显著迁移性能。

Conclusion: DUST通过模态解耦有效提升VLA性能，兼具训练效率与测试扩展性，为大规模VLA预训练提供新路径。

Abstract: Recently, augmenting Vision-Language-Action models (VLAs) with world modeling
has shown promise in improving robotic policy learning. However, it remains
challenging to jointly predict next-state observations and action sequences
because of the inherent difference between the two modalities. To address this,
we propose DUal-STream diffusion (DUST), a world-model augmented VLA framework
that handles the modality conflict and enhances the performance of VLAs across
diverse tasks. Specifically, we propose a multimodal diffusion transformer
architecture that explicitly maintains separate modality streams while still
enabling cross-modal knowledge sharing. In addition, we introduce independent
noise perturbations for each modality and a decoupled flow-matching loss. This
design enables the model to learn the joint distribution in a bidirectional
manner while avoiding the need for a unified latent space. Based on the
decoupling of modalities during training, we also introduce a joint sampling
method that supports test-time scaling, where action and vision tokens evolve
asynchronously at different rates. Through experiments on simulated benchmarks
such as RoboCasa and GR-1, DUST achieves up to 6% gains over baseline methods,
while our test-time scaling approach provides an additional 2-5% boost. On
real-world tasks with the Franka Research 3, DUST improves success rates by
13%, confirming its effectiveness beyond simulation. Furthermore, pre-training
on action-free videos from BridgeV2 yields significant transfer gains on
RoboCasa, underscoring DUST's potential for large-scale VLA pretraining.

</details>


### [25] [Dual-level Progressive Hardness-Aware Reweighting for Cross-View Geo-Localization](https://arxiv.org/abs/2510.27181)
*Guozheng Zheng,Jian Guan,Mingjie Xie,Xuanjia Zhao,Congyi Fan,Shiheng Zhang,Pengming Feng*

Main category: cs.CV

TL;DR: 提出一种双层级渐进硬度感知重加权策略（DPHR），提升无人机与卫星图像跨视图地理定位的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因静态权重分配对分布变化敏感，易过早强调困难负样本，导致梯度噪声大、收敛不稳定。

Method: 采用样本级RDA模块评估相对难度并细粒度加权负样本，结合批级PALW机制，根据训练进度动态调整损失权重，逐步增强难样本挖掘。

Result: 在University-1652和SUES-200基准上超越现有SOTA方法，表现更优且更鲁棒。

Conclusion: DPHR通过双层级动态重加权有效缓解跨视图定位中的困难负样本问题，提升模型训练稳定性和性能。

Abstract: Cross-view geo-localization (CVGL) between drone and satellite imagery
remains challenging due to severe viewpoint gaps and the presence of hard
negatives, which are visually similar but geographically mismatched samples.
Existing mining or reweighting strategies often use static weighting, which is
sensitive to distribution shifts and prone to overemphasizing difficult samples
too early, leading to noisy gradients and unstable convergence. In this paper,
we present a Dual-level Progressive Hardness-aware Reweighting (DPHR) strategy.
At the sample level, a Ratio-based Difficulty-Aware (RDA) module evaluates
relative difficulty and assigns fine-grained weights to negatives. At the batch
level, a Progressive Adaptive Loss Weighting (PALW) mechanism exploits a
training-progress signal to attenuate noisy gradients during early optimization
and progressively enhance hard-negative mining as training matures. Experiments
on the University-1652 and SUES-200 benchmarks demonstrate the effectiveness
and robustness of the proposed DPHR, achieving consistent improvements over
state-of-the-art methods.

</details>


### [26] [Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications](https://arxiv.org/abs/2510.27186)
*Zixuan Hu,Yongxian Wei,Li Shen,Zhenyi Wang,Lei Li,Chun Yuan,Dacheng Tao*

Main category: cs.CV

TL;DR: 提出一种稀疏模型反演方法，通过仅重构语义前景来加速高分辨率ViT的模型反演，提升效率达3.79倍，同时保持或提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集反演方法在处理高分辨率ViT时效率低下，因冗余反演噪声背景和虚假相关性（幻觉现象）。

Method: 提出稀疏模型反演策略，选择性反演语义前景，跳过噪声背景与虚假相关性，作为即插即用模块无需修改损失函数。

Result: 实现最高3.79倍的加速，且在无数据量化和知识迁移任务中性能相当或更好。

Conclusion: 稀疏反演策略有效解决效率与幻觉问题，为高分辨率模型反演提供了实用且高效的解决方案。

Abstract: Model inversion, which aims to reconstruct the original training data from
pre-trained discriminative models, is especially useful when the original
training data is unavailable due to privacy, usage rights, or size constraints.
However, existing dense inversion methods attempt to reconstruct the entire
image area, making them extremely inefficient when inverting high-resolution
images from large-scale Vision Transformers (ViTs). We further identify two
underlying causes of this inefficiency: the redundant inversion of noisy
backgrounds and the unintended inversion of spurious correlations--a phenomenon
we term "hallucination" in model inversion. To address these limitations, we
propose a novel sparse model inversion strategy, as a plug-and-play extension
to speed up existing dense inversion methods with no need for modifying their
original loss functions. Specifically, we selectively invert semantic
foregrounds while stopping the inversion of noisy backgrounds and potential
spurious correlations. Through both theoretical and empirical studies, we
validate the efficacy of our approach in achieving significant inversion
acceleration (up to 3.79 faster) while maintaining comparable or even enhanced
downstream performance in data-free model quantization and data-free knowledge
transfer. Code is available at https://github.com/Egg-Hu/SMI.

</details>


### [27] [Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions](https://arxiv.org/abs/2510.27195)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出多模态交互真实性评估（MIVA）任务，基于狼人杀游戏构建新数据集，揭示当前MLLMs在识别真假语句上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着AI融入人类生活，提升其社会智力尤其是识破欺骗的能力至关重要，但现有模型在动态多人群聊中的多模态欺骗检测上能力未被充分量化。

Method: 构建含同步视频、文本及真值标签的MIVA数据集，并基准评估主流多模态大语言模型。

Result: 即使GPT-4o等先进模型在MIVA任务上表现仍不理想，难以有效结合视觉社交线索判断真假，表现出过度保守的对齐偏差。

Conclusion: 当前MLLMs在多模态社交推理上存在显著短板，亟需发展更敏锐、可信赖的AI新方法。

Abstract: As AI systems become increasingly integrated into human lives, endowing them
with robust social intelligence has emerged as a critical frontier. A key
aspect of this intelligence is discerning truth from deception, a ubiquitous
element of human interaction that is conveyed through a complex interplay of
verbal language and non-verbal visual cues. However, automatic deception
detection in dynamic, multi-party conversations remains a significant
challenge. The recent rise of powerful Multimodal Large Language Models
(MLLMs), with their impressive abilities in visual and textual understanding,
makes them natural candidates for this task. Consequently, their capabilities
in this crucial domain are mostly unquantified. To address this gap, we
introduce a new task, Multimodal Interactive Veracity Assessment (MIVA), and
present a novel multimodal dataset derived from the social deduction game
Werewolf. This dataset provides synchronized video, text, with verifiable
ground-truth labels for every statement. We establish a comprehensive benchmark
evaluating state-of-the-art MLLMs, revealing a significant performance gap:
even powerful models like GPT-4o struggle to distinguish truth from falsehood
reliably. Our analysis of failure modes indicates that these models fail to
ground language in visual social cues effectively and may be overly
conservative in their alignment, highlighting the urgent need for novel
approaches to building more perceptive and trustworthy AI systems.

</details>


### [28] [Multi-Modal Feature Fusion for Spatial Morphology Analysis of Traditional Villages via Hierarchical Graph Neural Networks](https://arxiv.org/abs/2510.27208)
*Jiaxin Zhang,Zehong Zhu,Junye Deng,Yunqin Li,and Bowen Wang*

Main category: cs.CV

TL;DR: 提出一种分层图神经网络（HGNN）模型，融合多源数据分析村庄空间形态，显著提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 城镇化导致村庄空间特征消失与景观同质化，现有研究依赖单学科定性分析，缺乏数据与数字基础设施支持。

Method: 设计HGNN模型，包含输入节点与通信节点、静态与动态边，结合GCN与GAT，采用双阶段特征更新、关系池化与17类联合训练策略。

Result: 在多模态融合与分类任务中性能显著优于现有方法，联合训练使均值准确率/F1从0.71/0.83提升至0.82/0.90，地块任务提升6%。

Conclusion: 该方法为探索村庄空间模式与生成逻辑提供了科学依据。

Abstract: Villages areas hold significant importance in the study of human-land
relationships. However, with the advancement of urbanization, the gradual
disappearance of spatial characteristics and the homogenization of landscapes
have emerged as prominent issues. Existing studies primarily adopt a
single-disciplinary perspective to analyze villages spatial morphology and its
influencing factors, relying heavily on qualitative analysis methods. These
efforts are often constrained by the lack of digital infrastructure and
insufficient data. To address the current research limitations, this paper
proposes a Hierarchical Graph Neural Network (HGNN) model that integrates
multi-source data to conduct an in-depth analysis of villages spatial
morphology. The framework includes two types of nodes-input nodes and
communication nodes-and two types of edges-static input edges and dynamic
communication edges. By combining Graph Convolutional Networks (GCN) and Graph
Attention Networks (GAT), the proposed model efficiently integrates multimodal
features under a two-stage feature update mechanism. Additionally, based on
existing principles for classifying villages spatial morphology, the paper
introduces a relational pooling mechanism and implements a joint training
strategy across 17 subtypes. Experimental results demonstrate that this method
achieves significant performance improvements over existing approaches in
multimodal fusion and classification tasks. Additionally, the proposed joint
optimization of all sub-types lifts mean accuracy/F1 from 0.71/0.83
(independent models) to 0.82/0.90, driven by a 6% gain for parcel tasks. Our
method provides scientific evidence for exploring villages spatial patterns and
generative logic.

</details>


### [29] [Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness](https://arxiv.org/abs/2510.27213)
*Ren Tasai,Guang Li,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama*

Main category: cs.CV

TL;DR: 提出一种隐私保护的持续自监督学习框架，通过隐式重放和特征蒸馏提升多窗CT图像的特征学习能力


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断面临标注数据稀缺和领域漂移（如CT窗设置差异）挑战，传统方法因隐私限制难以重用历史数据

Method: 引入基于潜在重放的持续预训练机制，结合Wasserstein距离知识蒸馏（WKD）与批次知识集成（BKE）进行特征蒸馏

Result: 在双窗设置的胸部CT数据上验证，性能优于现有方法

Conclusion: 该方法有效缓解持续学习中的灾难性遗忘问题，同时保障数据隐私，提升模型泛化能力

Abstract: We propose a novel continual self-supervised learning (CSSL) framework for
simultaneously learning diverse features from multi-window-obtained chest
computed tomography (CT) images and ensuring data privacy. Achieving a robust
and highly generalizable model in medical image diagnosis is challenging,
mainly because of issues, such as the scarcity of large-scale, accurately
annotated datasets and domain shifts inherent to dynamic healthcare
environments. Specifically, in chest CT, these domain shifts often arise from
differences in window settings, which are optimized for distinct clinical
purposes. Previous CSSL frameworks often mitigated domain shift by reusing past
data, a typically impractical approach owing to privacy constraints. Our
approach addresses these challenges by effectively capturing the relationship
between previously learned knowledge and new information across different
training stages through continual pretraining on unlabeled images.
Specifically, by incorporating a latent replay-based mechanism into CSSL, our
method mitigates catastrophic forgetting due to domain shifts during continual
pretraining while ensuring data privacy. Additionally, we introduce a feature
distillation technique that integrates Wasserstein distance-based knowledge
distillation (WKD) and batch-knowledge ensemble (BKE), enhancing the ability of
the model to learn meaningful, domain-shift-robust representations. Finally, we
validate our approach using chest CT images obtained across two different
window settings, demonstrating superior performance compared with other
approaches.

</details>


### [30] [SpecAware: A Spectral-Content Aware Foundation Model for Unifying Multi-Sensor Learning in Hyperspectral Remote Sensing Mapping](https://arxiv.org/abs/2510.27219)
*Renjie Ji,Xue Wang,Chao Niu,Wen Zhang,Yong Mei,Kun Tan*

Main category: cs.CV

TL;DR: 提出SpecAware模型，结合传感器元属性与超光谱内容，实现多传感器联合预训练，提升地物分类与检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱基础模型忽略传感器元属性，难以适应多传感器数据，限制迁移能力。

Method: 设计SpecAware模型，包含元内容感知模块与超网络嵌入模块，动态生成条件编码参数，实现跨传感器的光谱-空间特征建模。

Result: 在六个数据集上超越现有方法，显著提升地物分割、变化检测与场景分类性能。

Conclusion: SpecAware首次实现融合传感器元信息的统一高光谱基础模型，为多传感器HLSI分析提供新范式。

Abstract: Hyperspectral imaging (HSI) is a vital tool for fine-grained land-use and
land-cover (LULC) mapping. However, the inherent heterogeneity of HSI data has
long posed a major barrier to developing generalized models via joint training.
Although HSI foundation models have shown promise for different downstream
tasks, the existing approaches typically overlook the critical guiding role of
sensor meta-attributes, and struggle with multi-sensor training, limiting their
transferability. To address these challenges, we propose SpecAware, which is a
novel hyperspectral spectral-content aware foundation model for unifying
multi-sensor learning for HSI mapping. We also constructed the Hyper-400K
dataset to facilitate this research, which is a new large-scale, high-quality
benchmark dataset with over 400k image patches from diverse airborne AVIRIS
sensors. The core of SpecAware is a two-step hypernetwork-driven encoding
process for HSI data. Firstly, we designed a meta-content aware module to
generate a unique conditional input for each HSI patch, tailored to each
spectral band of every sample by fusing the sensor meta-attributes and its own
image content. Secondly, we designed the HyperEmbedding module, where a
sample-conditioned hypernetwork dynamically generates a pair of matrix factors
for channel-wise encoding, consisting of adaptive spatial pattern extraction
and latent semantic feature re-projection. Thus, SpecAware gains the ability to
perceive and interpret spatial-spectral features across diverse scenes and
sensors. This, in turn, allows SpecAware to adaptively process a variable
number of spectral channels, establishing a unified framework for joint
pre-training. Extensive experiments on six datasets demonstrate that SpecAware
can learn superior feature representations, excelling in land-cover semantic
segmentation classification, change detection, and scene classification.

</details>


### [31] [Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery](https://arxiv.org/abs/2510.27224)
*Mahmoud El Hussieni,Bahadır K. Güntürk,Hasan F. Ateş,Oğuz Hanoğlu*

Main category: cs.CV

TL;DR: YOLOv11在卫星图像中实现建筑物实例分割与高度分类，性能优于此前模型，适合大规模城市映射。


<details>
  <summary>Details</summary>
Motivation: 精确的建筑物实例分割与高度分类对城市规划、3D建模和基础设施监测至关重要，现有方法在复杂场景和类别不平衡问题上表现不足。

Method: 采用YOLOv11模型，基于DFC2023 Track 2数据集（12.5万栋建筑）进行联合建筑物提取与五级高度分类，使用mAP、精确率、召回率和F1分数评估性能。

Result: YOLOv11实现60.4% mAP@50和38.3% mAP@50-95，在处理遮挡、复杂形状和高密度建筑方面表现优异，且推理速度更快。

Conclusion: YOLOv11在精度与效率上均优于传统多任务框架，为遥感与地理空间智能中的城市语义重建提供了新方案。

Abstract: Accurate building instance segmentation and height classification are
critical for urban planning, 3D city modeling, and infrastructure monitoring.
This paper presents a detailed analysis of YOLOv11, the recent advancement in
the YOLO series of deep learning models, focusing on its application to joint
building extraction and discrete height classification from satellite imagery.
YOLOv11 builds on the strengths of earlier YOLO models by introducing a more
efficient architecture that better combines features at different scales,
improves object localization accuracy, and enhances performance in complex
urban scenes. Using the DFC2023 Track 2 dataset -- which includes over 125,000
annotated buildings across 12 cities -- we evaluate YOLOv11's performance using
metrics such as precision, recall, F1 score, and mean average precision (mAP).
Our findings demonstrate that YOLOv11 achieves strong instance segmentation
performance with 60.4\% mAP@50 and 38.3\% mAP@50--95 while maintaining robust
classification accuracy across five predefined height tiers. The model excels
in handling occlusions, complex building shapes, and class imbalance,
particularly for rare high-rise structures. Comparative analysis confirms that
YOLOv11 outperforms earlier multitask frameworks in both detection accuracy and
inference speed, making it well-suited for real-time, large-scale urban
mapping. This research highlights YOLOv11's potential to advance semantic urban
reconstruction through streamlined categorical height modeling, offering
actionable insights for future developments in remote sensing and geospatial
intelligence.

</details>


### [32] [MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts](https://arxiv.org/abs/2510.27234)
*Jingnan Gao,Zhe Wang,Xianze Fang,Xingyu Ren,Zhuo Chen,Shengqi Liu,Yuhao Cheng,Jiangjing Lyu,Xiaokang Yang,Yichao Yan*

Main category: cs.CV

TL;DR: MoRE是一种基于混合专家架构的密集3D视觉基础模型，通过动态路由和置信度深度优化，在多个3D几何任务上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 3D几何重建模型扩展面临几何监督复杂和数据多样性的挑战，现有方法难以兼顾可扩展性与适应性。

Method: 提出MoRE模型，采用Mixture-of-Experts架构实现特征动态路由，结合置信度深度优化模块和全局对齐的稠密语义特征，并设计专用损失函数提升多任务学习鲁棒性。

Result: 在多个基准测试中实现SOTA性能，无需额外计算即可高效支持下游应用。

Conclusion: MoRE成功解决了3D模型扩展的瓶颈，通过专家稀疏激活与几何优化实现了高效、鲁棒的多任务3D理解。

Abstract: Recent advances in language and vision have demonstrated that scaling up
model capacity consistently improves performance across diverse tasks. In 3D
visual geometry reconstruction, large-scale training has likewise proven
effective for learning versatile representations. However, further scaling of
3D models is challenging due to the complexity of geometric supervision and the
diversity of 3D data. To overcome these limitations, we propose MoRE, a dense
3D visual foundation model based on a Mixture-of-Experts (MoE) architecture
that dynamically routes features to task-specific experts, allowing them to
specialize in complementary data aspects and enhance both scalability and
adaptability. Aiming to improve robustness under real-world conditions, MoRE
incorporates a confidence-based depth refinement module that stabilizes and
refines geometric estimation. In addition, it integrates dense semantic
features with globally aligned 3D backbone representations for high-fidelity
surface normal prediction. MoRE is further optimized with tailored loss
functions to ensure robust learning across diverse inputs and multiple
geometric tasks. Extensive experiments demonstrate that MoRE achieves
state-of-the-art performance across multiple benchmarks and supports effective
downstream applications without extra computation.

</details>


### [33] [Object-IR: Leveraging Object Consistency and Mesh Deformation for Self-Supervised Image Retargeting](https://arxiv.org/abs/2510.27236)
*Tianli Liao,Ran Wang,Siqing Zhang,Lei Li,Guangen Liu,Chenyang Zhao,Heling Cao,Peng Li*

Main category: cs.CV

TL;DR: Object-IR提出一种自监督的图像重定向方法，通过网格变形保持语义对象外观和几何一致性，实现高效高质量重定向。


<details>
  <summary>Details</summary>
Motivation: 现有图像重定向方法在保留语义重要区域几何结构方面仍存在难以解决的失真问题。

Method: 将图像重定向建模为基于学习的网格变形优化问题，使用CNN预测网格运动，结合对象一致性损失、几何保持损失和边界损失进行自监督训练。

Result: 在RetargetMe基准上达到SOTA性能，视觉质量与定量指标均优于现有方法，推理速度快（1024x683分辨率下0.009秒）。

Conclusion: Object-IR通过自监督学习有效避免了对标注数据的依赖，实现了高效、低失真的图像重定向，具备实用价值。

Abstract: Eliminating geometric distortion in semantically important regions remains an
intractable challenge in image retargeting. This paper presents Object-IR, a
self-supervised architecture that reformulates image retargeting as a
learning-based mesh warping optimization problem, where the mesh deformation is
guided by object appearance consistency and geometric-preserving constraints.
Given an input image and a target aspect ratio, we initialize a uniform rigid
mesh at the output resolution and use a convolutional neural network to predict
the motion of each mesh grid and obtain the deformed mesh. The retargeted
result is generated by warping the input image according to the rigid mesh in
the input image and the deformed mesh in the output resolution. To mitigate
geometric distortion, we design a comprehensive objective function
incorporating a) object-consistent loss to ensure that the important semantic
objects retain their appearance, b) geometric-preserving loss to constrain
simple scale transform of the important meshes, and c) boundary loss to enforce
a clean rectangular output. Notably, our self-supervised paradigm eliminates
the need for manually annotated retargeting datasets by deriving supervision
directly from the input's geometric and semantic properties. Extensive
evaluations on the RetargetMe benchmark demonstrate that our Object-IR achieves
state-of-the-art performance, outperforming existing methods in quantitative
metrics and subjective visual quality assessments. The framework efficiently
processes arbitrary input resolutions (average inference time: 0.009s for
1024x683 resolution) while maintaining real-time performance on consumer-grade
GPUs. The source code will soon be available at
https://github.com/tlliao/Object-IR.

</details>


### [34] [Fusion of Heterogeneous Pathology Foundation Models for Whole Slide Image Analysis](https://arxiv.org/abs/2510.27237)
*Zhidong Yang,Xiuhui Shi,Wei Ba,Zhigang Song,Haijing Luan,Taiyuan Hu,Senlin Lin,Jiguang Wang,Shaohua Kevin Zhou,Rui Yan*

Main category: cs.CV

TL;DR: 提出FuseCPath框架，融合异构病理基础模型，提升WSI分析性能


<details>
  <summary>Details</summary>
Motivation: 现有病理基础模型因训练数据和网络结构差异导致特征异构，影响下游任务性能

Method: 1) 多视角聚类筛选判别性补丁；2) 聚类级重嵌入融合补丁级特征；3)协作式知识蒸馏融合幻灯片级特征

Result: 在TCGA的肺癌、膀胱癌和结直肠癌数据集上，FuseCPath在多个任务上达到SOTA性能

Conclusion: FuseCPath有效融合异构病理模型，显著提升病理图像分析的泛化与准确率

Abstract: Whole slide image (WSI) analysis has emerged as an increasingly essential
technique in computational pathology. Recent advances in the pathological
foundation models (FMs) have demonstrated significant advantages in deriving
meaningful patch-level or slide-level feature representations from WSIs.
However, current pathological FMs have exhibited substantial heterogeneity
caused by diverse private training datasets and different network
architectures. This heterogeneity introduces performance variability when we
utilize the extracted features from different FMs in the downstream tasks. To
fully explore the advantage of multiple FMs effectively, in this work, we
propose a novel framework for the fusion of heterogeneous pathological FMs,
called FuseCPath, yielding a model with a superior ensemble performance. The
main contributions of our framework can be summarized as follows: (i) To
guarantee the representativeness of the training patches, we propose a
multi-view clustering-based method to filter out the discriminative patches via
multiple FMs' embeddings. (ii) To effectively fuse the heterogeneous
patch-level FMs, we devise a cluster-level re-embedding strategy to online
capture patch-level local features. (iii) To effectively fuse the heterogeneous
slide-level FMs, we devise a collaborative distillation strategy to explore the
connections between slide-level FMs. Extensive experiments conducted on lung
cancer, bladder cancer, and colorectal cancer datasets from The Cancer Genome
Atlas (TCGA) have demonstrated that the proposed FuseCPath achieves
state-of-the-art performance across multiple tasks on these public datasets.

</details>


### [35] [Trans-defense: Transformer-based Denoiser for Adversarial Defense with Spatial-Frequency Domain Representation](https://arxiv.org/abs/2510.27245)
*Alik Pramanick,Mayank Bansal,Utkarsh Srivastava,Suklav Ghosh,Arijit Sur*

Main category: cs.CV

TL;DR: 提出一种结合空间与频域的两阶段训练方法，通过小波变换和Transformer提升对抗攻击下的图像分类鲁棒性


<details>
  <summary>Details</summary>
Motivation: 深度神经网络易受对抗攻击，限制其在安全关键系统中的应用

Method: 两阶段训练：先训练结合DWT与Transformer的频域-空间联合去噪网络，再用去噪后图像重新训练分类器

Result: 在MNIST、CIFAR-10和Fashion-MNIST上显著提升分类准确率，优于传统去噪和对抗训练方法

Conclusion: 频域信息对对抗防御至关重要，所提方法有效提升模型鲁棒性且代码公开

Abstract: In recent times, deep neural networks (DNNs) have been successfully adopted
for various applications. Despite their notable achievements, it has become
evident that DNNs are vulnerable to sophisticated adversarial attacks,
restricting their applications in security-critical systems. In this paper, we
present two-phase training methods to tackle the attack: first, training the
denoising network, and second, the deep classifier model. We propose a novel
denoising strategy that integrates both spatial and frequency domain approaches
to defend against adversarial attacks on images. Our analysis reveals that
high-frequency components of attacked images are more severely corrupted
compared to their lower-frequency counterparts. To address this, we leverage
Discrete Wavelet Transform (DWT) for frequency analysis and develop a denoising
network that combines spatial image features with wavelets through a
transformer layer. Next, we retrain the classifier using the denoised images,
which enhances the classifier's robustness against adversarial attacks.
Experimental results across the MNIST, CIFAR-10, and Fashion-MNIST datasets
reveal that the proposed method remarkably elevates classification accuracy,
substantially exceeding the performance by utilizing a denoising network and
adversarial training approaches. The code is available at
https://github.com/Mayank94/Trans-Defense.

</details>


### [36] [C-LEAD: Contrastive Learning for Enhanced Adversarial Defense](https://arxiv.org/abs/2510.27249)
*Suklav Ghosh,Sonal Kumar,Arijit Sur*

Main category: cs.CV

TL;DR: 利用对比学习提升深度神经网络对抗攻击的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 深度神经网络易受对抗攻击影响，亟需提升其鲁棒性以支持实际部署

Method: 提出一种基于对比损失的新方法，通过同时训练干净图像和对抗扰动图像，优化模型参数与扰动以学习鲁棒表征

Result: 实验表明该方法在多种对抗扰动下显著提升了模型鲁棒性

Conclusion: 对比损失有助于提取更具信息量和抗攻击性的特征，为深度学习对抗鲁棒性研究提供了新方向

Abstract: Deep neural networks (DNNs) have achieved remarkable success in computer
vision tasks such as image classification, segmentation, and object detection.
However, they are vulnerable to adversarial attacks, which can cause incorrect
predictions with small perturbations in input images. Addressing this issue is
crucial for deploying robust deep-learning systems. This paper presents a novel
approach that utilizes contrastive learning for adversarial defense, a
previously unexplored area. Our method leverages the contrastive loss function
to enhance the robustness of classification models by training them with both
clean and adversarially perturbed images. By optimizing the model's parameters
alongside the perturbations, our approach enables the network to learn robust
representations that are less susceptible to adversarial attacks. Experimental
results show significant improvements in the model's robustness against various
types of adversarial perturbations. This suggests that contrastive loss helps
extract more informative and resilient features, contributing to the field of
adversarial robustness in deep learning.

</details>


### [37] [Enhancing Spatio-Temporal Zero-shot Action Recognition with Language-driven Description Attributes](https://arxiv.org/abs/2510.27255)
*Yehna Kim andYoung-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 提出一种利用网络描述和大语言模型提取关键词的零样本动作识别方法，提升语义歧义问题的处理能力


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖动作类别进行语义关联，但多义词导致语义模糊，影响识别效果

Method: 通过网络爬取描述文本，使用大语言模型提取关键词，并引入时空交互模块对齐视频内容与属性描述

Result: 在UCF-101、HMDB-51和Kinetics-600上分别达到81.0%、53.1%和68.9%的零样本准确率

Conclusion: 该方法有效缓解语义歧义，无需人工标注，显著提升跨数据集的零样本动作识别性能

Abstract: Vision-Language Models (VLMs) have demonstrated impressive capabilities in
zero-shot action recognition by learning to associate video embeddings with
class embeddings. However, a significant challenge arises when relying solely
on action classes to provide semantic context, particularly due to the presence
of multi-semantic words, which can introduce ambiguity in understanding the
intended concepts of actions. To address this issue, we propose an innovative
approach that harnesses web-crawled descriptions, leveraging a large-language
model to extract relevant keywords. This method reduces the need for human
annotators and eliminates the laborious manual process of attribute data
creation. Additionally, we introduce a spatio-temporal interaction module
designed to focus on objects and action units, facilitating alignment between
description attributes and video content. In our zero-shot experiments, our
model achieves impressive results, attaining accuracies of 81.0%, 53.1%, and
68.9% on UCF-101, HMDB-51, and Kinetics-600, respectively, underscoring the
model's adaptability and effectiveness across various downstream tasks.

</details>


### [38] [RegionRAG: Region-level Retrieval-Augumented Generation for Visually-Rich Documents](https://arxiv.org/abs/2510.27261)
*Yinglu Li,Zhiying Lu,Zhihang Liu,Chuanbin Liu,Hongtao Xie*

Main category: cs.CV

TL;DR: 提出RegionRAG，将多模态RAG的检索单元从文档级提升到区域级，提升效率与准确率


<details>
  <summary>Details</summary>
Motivation: 现有方法以文档为检索单位，引入大量无关视觉内容，分散模型注意力并降低性能

Method: 训练时采用混合监督策略定位相关图像块，推理时动态聚合语义区域，使生成器仅关注关键视觉内容

Result: 在六个基准上达到SOTA，R@1提升10.02%，问答准确率提升3.56%，视觉token使用量减少28.58%

Conclusion: 区域级检索显著优于文档级，为多模态RAG提供了更高效精准的新范式

Abstract: Multi-modal Retrieval-Augmented Generation (RAG) has become a critical method
for empowering LLMs by leveraging candidate visual documents. However, current
methods consider the entire document as the basic retrieval unit, introducing
substantial irrelevant visual content in two ways: 1) Relevant documents often
contain large regions unrelated to the query, diluting the focus on salient
information; 2) Retrieving multiple documents to increase recall further
introduces redundant and irrelevant documents. These redundant contexts
distract the model's attention and further degrade the performance. To address
this challenge, we propose \modelname, a novel framework that shifts the
retrieval paradigm from the document level to the region level. During
training, we design a hybrid supervision strategy from both labeled data and
unlabeled data to pinpoint relevant patches. During inference, we propose a
dynamic pipeline that intelligently groups salient patches into complete
semantic regions. By delegating the task of identifying relevant regions to the
retriever, \modelname enables the generator to focus solely on concise visual
content relevant to queries, improving both efficiency and accuracy.
Experiments on six benchmarks demonstrate that RegionRAG achieves
state-of-the-art performance. Improves retrieval accuracy by 10.02\% in R@1 on
average and increases question answering accuracy by 3.56\% while using only
71.42\% visual tokens compared to prior methods. The code will be available at
https://github.com/Aeryn666/RegionRAG.

</details>


### [39] [T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis](https://arxiv.org/abs/2510.27265)
*Raza Imam,Hu Wang,Dwarikanath Mahapatra,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 提出T^3框架，通过样本级动态合并医学视觉语言模型，在不使用反向传播的情况下提升模型在模态变化下的准确性和鲁棒性，并引入批量版本T^3_B降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有预训练模型缺乏模态特异性，而微调模型在模态偏移时表现不佳，传统模型合并方法在医学多模态场景中效果不一致且静态插值限制了可靠性。

Method: T^3利用Jensen-Shannon散度计算样本级合并系数，动态结合通用模型鲁棒性和专家模型精度；T^3_B进一步扩展为批量级合并以降低推理成本。

Result: 在四类医学模态的跨评估协议中，T^3达到新SOTA，显著提升Top-1准确率并减少错误，同时保持高效推理。

Conclusion: T^3为临床环境中自适应医学视觉语言模型的部署提供了高效、可靠的解决方案，未来有望推动医疗AI的实用化。

Abstract: In medical imaging, vision-language models face a critical duality:
pretrained networks offer broad robustness but lack subtle, modality-specific
characteristics, while fine-tuned expert models achieve high in-distribution
accuracy yet falter under modality shift. Existing model-merging techniques,
designed for natural-image benchmarks, are simple and efficient but fail to
deliver consistent gains across diverse medical modalities; their static
interpolation limits reliability in varied clinical tasks. To address this, we
introduce Test-Time Task adaptive merging (T^3), a backpropagation-free
framework that computes per-sample interpolation coefficients via the
Jensen-Shannon divergence between the two models' output distributions. T^3
dynamically preserves local precision when models agree and defers to
generalist robustness under drift. To overcome the inference costs of
sample-wise merging, we further propose a batch-wise extension, T^3_B, that
computes a merging coefficient across a batch of samples, dramatically reducing
computational bottleneck. Recognizing the lack of a standardized
medical-merging benchmark, we present a rigorous cross-evaluation protocol
spanning in-domain, base-to-novel, and corruptions across four modalities.
Empirically, T^3 sets new state-of-the-art in Top-1 accuracy and error
reduction, outperforming strong baselines while maintaining efficiency, paving
the way for adaptive MVLM deployment in clinical settings. Our code is
available at https://github.com/Razaimam45/TCube.

</details>


### [40] [HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration](https://arxiv.org/abs/2510.27266)
*Shaojie Zhang,Pei Fu,Ruoceng Zhang,Jiahui Yang,Anan Du,Xiuwen Xi,Shaokang Wang,Ying Huang,Bin Qin,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: HyperClick 提出一种新框架，通过不确定性校准提升GUI接地的可靠性，减少模型过自信。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理模型缺乏自认知能力，导致过自信和不可靠预测，在动态GUI任务中单次错误即导致失败。

Method: 提出HyperClick框架，采用双奖励机制：正确动作的二元奖励 + 基于截断高斯的空间置信建模，使用Brier分数校准。

Result: 在七个挑战基准上达到SOTA性能，同时实现良好的置信校准，显著降低过自信。

Conclusion: HyperClick通过显式置信校准与自省机制，提升GUI自动化任务的可靠性。

Abstract: Autonomous Graphical User Interface (GUI) agents rely on accurate GUI
grounding, which maps language instructions to on-screen coordinates, to
execute user commands. However, current models, whether trained via supervised
fine-tuning (SFT) or reinforcement fine-tuning (RFT), lack self-awareness of
their capability boundaries, leading to overconfidence and unreliable
predictions. We first systematically evaluate probabilistic and verbalized
confidence in general and GUI-specific models, revealing a misalignment between
confidence and actual accuracy, which is particularly critical in dynamic GUI
automation tasks, where single errors can cause task failure. To address this,
we propose HyperClick, a novel framework that enhances reliable GUI grounding
through uncertainty calibration. HyperClick introduces a dual reward mechanism,
combining a binary reward for correct actions with a truncated Gaussian-based
spatial confidence modeling, calibrated using the Brier score. This approach
jointly optimizes grounding accuracy and confidence reliability, fostering
introspective self-criticism. Extensive experiments on seven challenge
benchmarks show that HyperClick achieves state-of-the-art performance while
providing well-calibrated confidence. By enabling explicit confidence
calibration and introspective self-criticism, HyperClick reduces overconfidence
and supports more reliable GUI automation.

</details>


### [41] [FOCUS: Efficient Keyframe Selection for Long Video Understanding](https://arxiv.org/abs/2510.27280)
*Zirui Zhu,Hailun Xu,Yang Luo,Yong Liu,Kanchan Sarkar,Zhenheng Yang,Yang You*

Main category: cs.CV

TL;DR: FOCUS是一种无需训练、与模型无关的关键帧选择方法，可在严格令牌预算下高效选择与查询相关的视频帧，在长视频问答中显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理小时级视频时因令牌预算受限而依赖预过滤，容易遗漏关键信息帧。

Method: 将短视频片段视为多臂赌博机中的臂，利用经验均值与Bernstein置信区间进行组合型纯探索（CPE），分两阶段先识别高价值时段再选最优帧。

Result: 在两个长视频问答基准上，FOCUS仅处理少于2%的帧即可大幅提升准确率，20分钟以上视频在LongVideoBench上准确率提升11.9%。

Conclusion: FOCUS为多模态大模型的长视频理解提供了一种简单、通用且高效的可扩展关键帧选择方案。

Abstract: Multimodal large language models (MLLMs) represent images and video frames as
visual tokens. Scaling from single images to hour-long videos, however,
inflates the token budget far beyond practical limits. Popular pipelines
therefore either uniformly subsample or apply keyframe selection with
retrieval-style scoring using smaller vision-language models. However, these
keyframe selection methods still rely on pre-filtering before selection to
reduce the inference cost and can miss the most informative moments.
  We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a
training-free, model-agnostic keyframe selection module that selects
query-relevant frames under a strict token budget. FOCUS formulates keyframe
selection as a combinatorial pure-exploration (CPE) problem in multi-armed
bandits: it treats short temporal clips as arms, and uses empirical means and
Bernstein confidence radius to identify informative regions while preserving
exploration of uncertain areas. The resulting two-stage
exploration-exploitation procedure reduces from a sequential policy with
theoretical guarantees, first identifying high-value temporal regions, then
selecting top-scoring frames within each region On two long-video
question-answering benchmarks, FOCUS delivers substantial accuracy improvements
while processing less than 2% of video frames. For videos longer than 20
minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating
its effectiveness as a keyframe selection method and providing a simple and
general solution for scalable long-video understanding with MLLMs.

</details>


### [42] [Rethinking Robust Adversarial Concept Erasure in Diffusion Models](https://arxiv.org/abs/2510.27285)
*Qinghong Yin,Yu Tian,Yue Zhang*

Main category: cs.CV

TL;DR: 提出S-GRACE方法，通过语义引导提升扩散模型中概念擦除的效率与精度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法忽视概念空间中的语义特性，导致对抗样本无法有效拟合目标概念空间，造成覆盖不全或干扰其他概念。

Method: S-GRACE引入语义引导，在概念空间中生成更精准的对抗样本，并进行鲁棒的概念擦除训练。

Result: 在多种扩散模型擦除场景中，S-GRACE性能提升26%，更好保留非目标概念，训练时间减少90%。

Conclusion: 语义引导是提升扩散模型概念擦除效果的关键，S-GRACE为高效精准擦除提供了新范式。

Abstract: Concept erasure aims to selectively unlearning undesirable content in
diffusion models (DMs) to reduce the risk of sensitive content generation. As a
novel paradigm in concept erasure, most existing methods employ adversarial
training to identify and suppress target concepts, thus reducing the likelihood
of sensitive outputs. However, these methods often neglect the specificity of
adversarial training in DMs, resulting in only partial mitigation. In this
work, we investigate and quantify this specificity from the perspective of
concept space, i.e., can adversarial samples truly fit the target concept
space? We observe that existing methods neglect the role of conceptual
semantics when generating adversarial samples, resulting in ineffective fitting
of concept spaces. This oversight leads to the following issues: 1) when there
are few adversarial samples, they fail to comprehensively cover the object
concept; 2) conversely, they will disrupt other target concept spaces.
Motivated by the analysis of these findings, we introduce S-GRACE
(Semantics-Guided Robust Adversarial Concept Erasure), which grace leveraging
semantic guidance within the concept space to generate adversarial samples and
perform erasure training. Experiments conducted with seven state-of-the-art
methods and three adversarial prompt generation strategies across various DM
unlearning scenarios demonstrate that S-GRACE significantly improves erasure
performance 26%, better preserves non-target concepts, and reduces training
time by 90%. Our code is available at https://github.com/Qhong-522/S-GRACE.

</details>


### [43] [Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba](https://arxiv.org/abs/2510.27296)
*Wenfeng Huang,Xiangyun Liao,Wei Cao,Wenjing Jia,Weixin Si*

Main category: cs.CV

TL;DR: FGMamba提出了一种轻量级频域感知状态空间模型，用于医学图像超分辨率，在保持低参数量的同时显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在低计算开销下同时建模长程解剖结构和精细频率细节。

Method: 引入Gated Attention增强状态空间模块（GASM）和金字塔频域融合模块（PFFM），结合FFT引导的多分辨率高频细节融合。

Result: 在五种医学成像模态上超越CNN和Transformer方法，PSNR/SSIM更高，参数量小于0.75M。

Conclusion: 频域感知状态空间模型为可扩展、高精度的医学图像增强提供了有效新范式。

Abstract: Medical image super-resolution (SR) is essential for enhancing diagnostic
accuracy while reducing acquisition cost and scanning time. However, modeling
both long-range anatomical structures and fine-grained frequency details with
low computational overhead remains challenging. We propose FGMamba, a novel
frequency-aware gated state-space model that unifies global dependency modeling
and fine-detail enhancement into a lightweight architecture. Our method
introduces two key innovations: a Gated Attention-enhanced State-Space Module
(GASM) that integrates efficient state-space modeling with dual-branch spatial
and channel attention, and a Pyramid Frequency Fusion Module (PFFM) that
captures high-frequency details across multiple resolutions via FFT-guided
fusion. Extensive evaluations across five medical imaging modalities
(Ultrasound, OCT, MRI, CT, and Endoscopic) demonstrate that FGMamba achieves
superior PSNR/SSIM while maintaining a compact parameter footprint ($<$0.75M),
outperforming CNN-based and Transformer-based SOTAs. Our results validate the
effectiveness of frequency-aware state-space modeling for scalable and accurate
medical image enhancement.

</details>


### [44] [CASR-Net: An Image Processing-focused Deep Learning-based Coronary Artery Segmentation and Refinement Network for X-ray Coronary Angiogram](https://arxiv.org/abs/2510.27315)
*Alvee Hassan,Rusab Sarmun,Muhammad E. H. Chowdhury,M. Murugappan,Md. Sakib Abrar Hossain,Sakib Mahmud,Abdulrahman Alqahtani,Sohaib Bassam Zoghoul,Amith Khandakar,Susu M. Zughaier,Somaya Al-Maadeed,Anwarul Hasan*

Main category: cs.CV

TL;DR: 提出CASR-Net三阶段网络，提升冠状动脉分割精度，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 冠状动脉狭窄检测对降低死亡率至关重要，但X光图像质量差影响诊断，需更鲁棒的自动分割方法

Method: 采用CLAHE与改进Ben Graham预处理 + UNet-DenseNet121编码器 + Self-ONN解码器 + 轮廓精炼模块，实现高精度血管连续性保持

Result: 在双数据集5折交叉验证下，IoU达61.43%，DSC为76.10%，clDice为79.36%，超越现有模型

Conclusion: CASR-Net为临床诊断和治疗规划提供了一种鲁棒、高效的自动冠状动脉分割工具

Abstract: Early detection of coronary artery disease (CAD) is critical for reducing
mortality and improving patient treatment planning. While angiographic image
analysis from X-rays is a common and cost-effective method for identifying
cardiac abnormalities, including stenotic coronary arteries, poor image quality
can significantly impede clinical diagnosis. We present the Coronary Artery
Segmentation and Refinement Network (CASR-Net), a three-stage pipeline
comprising image preprocessing, segmentation, and refinement. A novel
multichannel preprocessing strategy combining CLAHE and an improved Ben Graham
method provides incremental gains, increasing Dice Score Coefficient (DSC) by
0.31-0.89% and Intersection over Union (IoU) by 0.40-1.16% compared with using
the techniques individually. The core innovation is a segmentation network
built on a UNet with a DenseNet121 encoder and a Self-organized Operational
Neural Network (Self-ONN) based decoder, which preserves the continuity of
narrow and stenotic vessel branches. A final contour refinement module further
suppresses false positives. Evaluated with 5-fold cross-validation on a
combination of two public datasets that contain both healthy and stenotic
arteries, CASR-Net outperformed several state-of-the-art models, achieving an
IoU of 61.43%, a DSC of 76.10%, and clDice of 79.36%. These results highlight a
robust approach to automated coronary artery segmentation, offering a valuable
tool to support clinicians in diagnosis and treatment planning.

</details>


### [45] [Overcoming Prompts Pool Confusion via Parameterized Prompt for Incremental Object Detection](https://arxiv.org/abs/2510.27316)
*Zijia An,Boyu Diao,Ruiqi Liu,Libo Huang,Chuanguang Yang,Fei Wang,Zhulin An,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出P²IOD方法，通过参数化提示实现增量目标检测中的知识自适应整合，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示池方法假设任务间类别互斥，忽视检测图像中类别共现现象，导致提示混淆与灾难性遗忘。

Method: 引入参数化提示（P²IOD），利用神经网络全局演化特性自适应整合任务知识，并通过提示融合策略约束更新。

Result: 在PASCAL VOC2007和MS COCO数据集上达到SOTA性能，有效缓解灾难性遗忘。

Conclusion: 参数化提示结构能更好适应增量目标检测中的共现场景，是解决提示混淆与知识保留的有效途径。

Abstract: Recent studies have demonstrated that incorporating trainable prompts into
pretrained models enables effective incremental learning. However, the
application of prompts in incremental object detection (IOD) remains
underexplored. Existing prompts pool based approaches assume disjoint class
sets across incremental tasks, which are unsuitable for IOD as they overlook
the inherent co-occurrence phenomenon in detection images. In co-occurring
scenarios, unlabeled objects from previous tasks may appear in current task
images, leading to confusion in prompts pool. In this paper, we hold that
prompt structures should exhibit adaptive consolidation properties across
tasks, with constrained updates to prevent catastrophic forgetting. Motivated
by this, we introduce Parameterized Prompts for Incremental Object Detection
(P$^2$IOD). Leveraging neural networks global evolution properties, P$^2$IOD
employs networks as the parameterized prompts to adaptively consolidate
knowledge across tasks. To constrain prompts structure updates, P$^2$IOD
further engages a parameterized prompts fusion strategy. Extensive experiments
on PASCAL VOC2007 and MS COCO datasets demonstrate that P$^2$IOD's
effectiveness in IOD and achieves the state-of-the-art performance among
existing baselines.

</details>


### [46] [SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction](https://arxiv.org/abs/2510.27318)
*Wenfeng Huang,Xiangyun Liao,Yinling Qian,Hao Liu,Yongming Yang,Wenjing Jia,Qiong Wang*

Main category: cs.CV

TL;DR: 提出SAGS框架，通过自适应高斯溅射解决内镜视频中组织变形重建的混叠问题，显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射方法侧重渲染速度，忽视组织运动引起的混叠与伪影，影响可视化效果。

Method: 引入注意力驱动的动态加权4D变形解码器，结合3D平滑滤波与2D Mip滤波，实现无混叠的自适应高斯溅射。

Result: 在EndoNeRF和SCARED基准上，SAGS在PSNR、SSIM、LPIPS所有指标上均优于现有方法，可视化质量更优。

Conclusion: SAGS有效解决了动态组织重建中的伪影问题，为机器人辅助手术提供了高质量的实时重建方案。

Abstract: Surgical reconstruction of dynamic tissues from endoscopic videos is a
crucial technology in robot-assisted surgery. The development of Neural
Radiance Fields (NeRFs) has greatly advanced deformable tissue reconstruction,
achieving high-quality results from video and image sequences. However,
reconstructing deformable endoscopic scenes remains challenging due to aliasing
and artifacts caused by tissue movement, which can significantly degrade
visualization quality. The introduction of 3D Gaussian Splatting (3DGS) has
improved reconstruction efficiency by enabling a faster rendering pipeline.
Nevertheless, existing 3DGS methods often prioritize rendering speed while
neglecting these critical issues. To address these challenges, we propose SAGS,
a self-adaptive alias-free Gaussian splatting framework. We introduce an
attention-driven, dynamically weighted 4D deformation decoder, leveraging 3D
smoothing filters and 2D Mip filters to mitigate artifacts in deformable tissue
reconstruction and better capture the fine details of tissue movement.
Experimental results on two public benchmarks, EndoNeRF and SCARED, demonstrate
that our method achieves superior performance in all metrics of PSNR, SSIM, and
LPIPS compared to the state of the art while also delivering better
visualization quality.

</details>


### [47] [Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis](https://arxiv.org/abs/2510.27324)
*Weiming Chen,Yijia Wang,Zhihan Zhu,Zhihai He*

Main category: cs.CV

TL;DR: 提出一种结合文本描述与编码潜变量的联合生成方法，在超低比特率下实现高精度视觉场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有图像编码方法在极低带宽下难以兼顾重建质量与视觉分析性能，亟需新方法突破瓶颈。

Method: 融合文本生成与深度图像压缩，利用文本和编码潜变量共同引导校正流模型进行精确图像生成。

Result: 在极低比特率下实现与传统方法相当的重建质量与视觉分析精度，显著降低带宽消耗。

Conclusion: 该方法为低带宽场景下的视觉通信提供了高效可行的解决方案，具有广泛应用前景。

Abstract: We consider the problem of ultra-low bit rate visual communication for remote
vision analysis, human interactions and control in challenging scenarios with
very low communication bandwidth, such as deep space exploration, battlefield
intelligence, and robot navigation in complex environments. In this paper, we
ask the following important question: can we accurately reconstruct the visual
scene using only a very small portion of the bit rate in existing coding
methods while not sacrificing the accuracy of vision analysis and performance
of human interactions? Existing text-to-image generation models offer a new
approach for ultra-low bitrate image description. However, they can only
achieve a semantic-level approximation of the visual scene, which is far
insufficient for the purpose of visual communication and remote vision analysis
and human interactions. To address this important issue, we propose to
seamlessly integrate image generation with deep image compression, using joint
text and coding latent to guide the rectified flow models for precise
generation of the visual scene. The semantic text description and coding latent
are both encoded and transmitted to the decoder at a very small bit rate.
Experimental results demonstrate that our method can achieve the same image
reconstruction quality and vision analysis accuracy as existing methods while
using much less bandwidth. The code will be released upon paper acceptance.

</details>


### [48] [MeisenMeister: A Simple Two Stage Pipeline for Breast Cancer Classification on MRI](https://arxiv.org/abs/2510.27326)
*Benjamin Hamm,Yannick Kirchhoff,Maximilian Rokuss,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: 本文提出了一种针对乳腺MRI的分类方法，以应对高质量分割标签稀缺的挑战，提升乳腺癌早期检测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌筛查中，由于高质量分割标签稀缺，现有方法在乳腺MRI分析上仍面临挑战，亟需鲁棒的分类方法用于大规模筛查。

Method: 通过迭代实验、评估与优化，构建了以性能、鲁棒性和临床相关性为核心的分类模型，并公开了完整实现。

Result: 提交了面向ODELIA乳腺MRI挑战赛的解决方案，未提供具体性能指标，但强调了方法的系统性设计与临床适用性。

Conclusion: 该方法为乳腺MRI的自动分析提供了可行路径，尤其是在数据标签有限的情况下，具有良好的临床应用前景。

Abstract: The ODELIA Breast MRI Challenge 2025 addresses a critical issue in breast
cancer screening: improving early detection through more efficient and accurate
interpretation of breast MRI scans. Even though methods for general-purpose
whole-body lesion segmentation as well as multi-time-point analysis exist,
breast cancer detection remains highly challenging, largely due to the limited
availability of high-quality segmentation labels. Therefore, developing robust
classification-based approaches is crucial for the future of early breast
cancer detection, particularly in applications such as large-scale screening.
In this write-up, we provide a comprehensive overview of our approach to the
challenge. We begin by detailing the underlying concept and foundational
assumptions that guided our work. We then describe the iterative development
process, highlighting the key stages of experimentation, evaluation, and
refinement that shaped the evolution of our solution. Finally, we present the
reasoning and evidence that informed the design choices behind our final
submission, with a focus on performance, robustness, and clinical relevance. We
release our full implementation publicly at
https://github.com/MIC-DKFZ/MeisenMeister

</details>


### [49] [Understanding the Implicit User Intention via Reasoning with Large Language Model for Image Editing](https://arxiv.org/abs/2510.27335)
*Yijia Wang,Yiqing Shen,Weiming Chen,Zhihai He*

Main category: cs.CV

TL;DR: 提出CIELR方法，通过LLM推理将复杂图像编辑指令分解为简单操作，无需联合微调大模型，显著提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法处理复杂编辑指令需联合微调LLM和DM，计算成本高；亟需一种高效且无需微调的复杂图像编辑方法。

Method: 利用基础模型构建图像结构化语义表示，通过迭代更新机制细化视觉表征，将复杂指令分解为可执行的简单编辑动作。

Result: 在SmartEdit数据集上PSNR提升9.955 dB，在自建CIEBench基准上也优于现有方法，证明其在保持一致区域和推理编辑方面的优越性。

Conclusion: CIELR通过语义推理实现高效复杂图像编辑，避免了高成本微调，为推理驱动的图像编辑提供了新范式。

Abstract: Existing image editing methods can handle simple editing instructions very
well. To deal with complex editing instructions, they often need to jointly
fine-tune the large language models (LLMs) and diffusion models (DMs), which
involves very high computational complexity and training cost. To address this
issue, we propose a new method, called \textbf{C}omplex \textbf{I}mage
\textbf{E}diting via \textbf{L}LM \textbf{R}easoning (CIELR), which converts a
complex user instruction into a set of simple and explicit editing actions,
eliminating the need for jointly fine-tuning the large language models and
diffusion models. Specifically, we first construct a structured semantic
representation of the input image using foundation models. Then, we introduce
an iterative update mechanism that can progressively refine this
representation, obtaining a fine-grained visual representation of the image
scene. This allows us to perform complex and flexible image editing tasks.
Extensive experiments on the SmartEdit Reasoning Scenario Set show that our
method surpasses the previous state-of-the-art by 9.955 dB in PSNR, indicating
its superior preservation of regions that should remain consistent. Due to the
limited number of samples of public datasets of complex image editing with
reasoning, we construct a benchmark named CIEBench, containing 86 image
samples, together with a metric specifically for reasoning-based image editing.
CIELR also outperforms previous methods on this benchmark. The code and dataset
are available at
\href{https://github.com/Jia-shao/Reasoning-Editing}{https://github.com/Jia-shao/Reasoning-Editing}.

</details>


### [50] [RzenEmbed: Towards Comprehensive Multimodal Retrieval](https://arxiv.org/abs/2510.27350)
*Weijian Jian,Yajun Zhang,Dawei Liang,Chunyu Xie,Yixiao He,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: RzenEmbed提出了一种统一的多模态嵌入框架，显著提升文本、图像、视频和视觉文档的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP类模型主要关注自然图像，缺乏对视频和视觉文档等关键模态的支持。

Method: 采用两阶段训练策略，引入加权InfoNCE损失，结合困难样本加权、负样本噪声抑制、可学习温度参数和模型平均技术。

Result: 在MMEB基准上达到SOTA，尤其在视频和视觉文档检索任务上显著超越以往方法。

Conclusion: RzenEmbed实现了多模态统一嵌入，提升检索与指令遵循能力，开源模型已发布。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has
extended CLIP-based frameworks to produce powerful, universal embeddings for
retrieval tasks. However, existing methods primarily focus on natural images,
offering limited support for other crucial visual modalities such as videos and
visual documents. To bridge this gap, we introduce RzenEmbed, a unified
framework to learn embeddings across a diverse set of modalities, including
text, images, videos, and visual documents. We employ a novel two-stage
training strategy to learn discriminative representations. The first stage
focuses on foundational text and multimodal retrieval. In the second stage, we
introduce an improved InfoNCE loss, incorporating two key enhancements.
Firstly, a hardness-weighted mechanism guides the model to prioritize
challenging samples by assigning them higher weights within each batch.
Secondly, we implement an approach to mitigate the impact of false negatives
and alleviate data noise. This strategy not only enhances the model's
discriminative power but also improves its instruction-following capabilities.
We further boost performance with learnable temperature parameter and model
souping. RzenEmbed sets a new state-of-the-art on the MMEB benchmark. It not
only achieves the best overall score but also outperforms all prior work on the
challenging video and visual document retrieval tasks. Our models are available
in https://huggingface.co/qihoo360/RzenEmbed.

</details>


### [51] [FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning](https://arxiv.org/abs/2510.27359)
*Kenneth Yang,Wen-Li Wei,Jen-Chun Lin*

Main category: cs.CV

TL;DR: 提出一种无梯度的参数选择方法FPS，显著降低内存占用并加速参数选择，性能媲美SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法存在推理延迟高或内存占用与全微调相当的问题。

Method: 提出Feedforward-based Parameter Selection (FPS)，通过参数幅度与输入激活的乘积在单次前向传播中选择关键参数。

Result: 在24个视觉任务上，FPS性能与SOTA相当，内存减少9倍，选择速度提升2倍。

Conclusion: FPS是一种真正内存高效且实用的参数高效微调方法，突破了传统方法的权衡困境。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key strategy for
adapting large-scale pre-trained models to downstream tasks, but existing
approaches face notable limitations. Addition-based methods, such as Adapters
[1], introduce inference latency and engineering complexity, while
selection-based methods like Gradient-based Parameter Selection (GPS) [2]
require a full backward pass, which results in the same peak memory usage as
full fine-tuning. To address this dilemma, we propose Feedforward-based
Parameter Selection (FPS), a gradient-free method that identifies an optimal
parameter subset in a single forward pass. FPS ranks parameters by the product
of their magnitudes and corresponding input activations, leveraging both
pre-trained knowledge and downstream data. Evaluated on $24$ visual tasks from
FGVC and VTAB-1k, FPS achieves performance comparable to state-of-the-art
methods while reducing peak memory usage by nearly $9 \times$ and accelerating
parameter selection by about $2 \times$, offering a genuinely memory-efficient
and practical solution for fine-tuning large-scale pre-trained models.

</details>


### [52] [Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V](https://arxiv.org/abs/2510.27364)
*Meftun Akarsu,Kerem Catay,Sedat Bin Vedat,Enes Kutay Yarkan,Ilke Senturk,Arda Sar,Dafne Eksioglu*

Main category: cs.CV

TL;DR: 提出一种两阶段微调开源视频扩散模型的实用流程，从少量数据中生成电影级视频，显著提升视觉风格一致性和时序稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统视频生成模型需要大量数据且难以适配特定影视风格，亟需高效、低成本的方法实现电影级视频合成。

Method: 第一阶段使用LoRA微调Wan2.1 I2V-14B模型的交叉注意力层，学习《El Turco》剧集的视觉风格；第二阶段生成风格一致的关键帧并通过视频解码器扩展为720p序列，辅以轻量级并行化加速推理。

Result: 在FVD、CLIP-SIM和LPIPS指标上优于基线模型，专家用户研究证实 cinematic fidelity 和时序稳定性显著提升，训练仅需单GPU数小时。

Conclusion: 该pipeline高效、可复现，支持跨影视风格迁移，为影视生产提供实用工具。

Abstract: We present a practical pipeline for fine-tuning open-source video diffusion
transformers to synthesize cinematic scenes for television and film production
from small datasets. The proposed two-stage process decouples visual style
learning from motion generation. In the first stage, Low-Rank Adaptation (LoRA)
modules are integrated into the cross-attention layers of the Wan2.1 I2V-14B
model to adapt its visual representations using a compact dataset of short
clips from Ay Yapim's historical television film El Turco. This enables
efficient domain transfer within hours on a single GPU. In the second stage,
the fine-tuned model produces stylistically consistent keyframes that preserve
costume, lighting, and color grading, which are then temporally expanded into
coherent 720p sequences through the model's video decoder. We further apply
lightweight parallelization and sequence partitioning strategies to accelerate
inference without quality degradation. Quantitative and qualitative evaluations
using FVD, CLIP-SIM, and LPIPS metrics, supported by a small expert user study,
demonstrate measurable improvements in cinematic fidelity and temporal
stability over the base model. The complete training and inference pipeline is
released to support reproducibility and adaptation across cinematic domains.

</details>


### [53] [Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds](https://arxiv.org/abs/2510.27391)
*Wu Wei,Xiaomeng Fan,Yuwei Wu,Zhi Gao,Pengxiang Li,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出一种跨树对齐方法，通过构建图像与文本的层次特征树并在双曲流形中对齐，提升视觉-语言模型的模态对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本中提取层次特征，而图像仅用单一特征表示，导致模态对齐不对称且次优

Method: 引入语义感知的视觉特征提取框架，使用交叉注意力从Transformer中间层提取粗到细的视觉特征；将图文特征树嵌入不同曲率的双曲流形，并通过KL距离最小化学习中间流形实现对齐

Result: 在多个图像数据集的分类任务中，该方法在few-shot和跨域设置下持续超越强基线

Conclusion: 跨树对齐方法能有效建模异构模态的层次结构，显著提升视觉-语言模型的对齐性能

Abstract: Modality alignment is critical for vision-language models (VLMs) to
effectively integrate information across modalities. However, existing methods
extract hierarchical features from text while representing each image with a
single feature, leading to asymmetric and suboptimal alignment. To address
this, we propose Alignment across Trees, a method that constructs and aligns
tree-like hierarchical features for both image and text modalities.
Specifically, we introduce a semantic-aware visual feature extraction framework
that applies a cross-attention mechanism to visual class tokens from
intermediate Transformer layers, guided by textual cues to extract visual
features with coarse-to-fine semantics. We then embed the feature trees of the
two modalities into hyperbolic manifolds with distinct curvatures to
effectively model their hierarchical structures. To align across the
heterogeneous hyperbolic manifolds with different curvatures, we formulate a KL
distance measure between distributions on heterogeneous manifolds, and learn an
intermediate manifold for manifold alignment by minimizing the distance. We
prove the existence and uniqueness of the optimal intermediate manifold.
Experiments on taxonomic open-set classification tasks across multiple image
datasets demonstrate that our method consistently outperforms strong baselines
under few-shot and cross-domain settings.

</details>


### [54] [A Hybrid Deep Learning and Forensic Approach for Robust Deepfake Detection](https://arxiv.org/abs/2510.27392)
*Sales Aribe Jr*

Main category: cs.CV

TL;DR: 提出一种融合取证特征与深度学习的混合模型，显著提升深伪检测的准确率与鲁棒性，并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 生成式模型导致深伪内容泛滥，现有检测方法要么泛化差，要么可解释性弱，亟需兼顾精度与透明度的解决方案。

Method: 融合噪声残差、JPEG压缩痕迹、频域特征等取证线索与CNN/ViT深度表示，构建混合检测框架。

Result: 在FaceForensics++、Celeb-DF v2、DFDC数据集上F1分数分别达0.96、0.82、0.77，压缩与对抗攻击下仍保持高鲁棒性，可解释性匹配率达82%。

Conclusion: 混合方法平衡了深度学习的适应性与取证特征的可解释性，是构建可信深伪检测系统的关键方向。

Abstract: The rapid evolution of generative adversarial networks (GANs) and diffusion
models has made synthetic media increasingly realistic, raising societal
concerns around misinformation, identity fraud, and digital trust. Existing
deepfake detection methods either rely on deep learning, which suffers from
poor generalization and vulnerability to distortions, or forensic analysis,
which is interpretable but limited against new manipulation techniques. This
study proposes a hybrid framework that fuses forensic features, including noise
residuals, JPEG compression traces, and frequency-domain descriptors, with deep
learning representations from convolutional neural networks (CNNs) and vision
transformers (ViTs). Evaluated on benchmark datasets (FaceForensics++, Celeb-DF
v2, DFDC), the proposed model consistently outperformed single-method baselines
and demonstrated superior performance compared to existing state-of-the-art
hybrid approaches, achieving F1-scores of 0.96, 0.82, and 0.77, respectively.
Robustness tests demonstrated stable performance under compression (F1 = 0.87
at QF = 50), adversarial perturbations (AUC = 0.84), and unseen manipulations
(F1 = 0.79). Importantly, explainability analysis showed that Grad-CAM and
forensic heatmaps overlapped with ground-truth manipulated regions in 82
percent of cases, enhancing transparency and user trust. These findings confirm
that hybrid approaches provide a balanced solution, combining the adaptability
of deep models with the interpretability of forensic cues, to develop resilient
and trustworthy deepfake detection systems.

</details>


### [55] [Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset](https://arxiv.org/abs/2510.27421)
*Aditya Parikh,Sneha Das,Aasa Feragen*

Main category: cs.CV

TL;DR: 研究发现MAMA-MIA乳腺癌肿瘤分割数据集中存在针对年轻患者的固有年龄偏差，即使控制混杂因素后仍存在，且多源数据聚合会放大族群偏差。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学图像分割中的公平性评估被忽视，偏差可能影响特定人群的诊疗质量并随决策流程放大。

Method: 对MAMA-MIA数据集中的自动化分割结果按年龄、种族和数据来源进行公平性审计分析。

Result: 发现显著的年龄偏差（针对年轻患者），且多源数据聚合暴露并加剧了站点特异性种族偏差。

Conclusion: 医学图像分割模型需在数据层面进行细粒度公平性评估，生理因素与数据偏差共同构成关键挑战。

Abstract: Deep learning models aim to improve diagnostic workflows, but fairness
evaluation remains underexplored beyond classification, e.g., in image
segmentation. Unaddressed segmentation bias can lead to disparities in the
quality of care for certain populations, potentially compounded across clinical
decision points and amplified through iterative model development. Here, we
audit the fairness of the automated segmentation labels provided in the breast
cancer tumor segmentation dataset MAMA-MIA. We evaluate automated segmentation
quality across age, ethnicity, and data source. Our analysis reveals an
intrinsic age-related bias against younger patients that continues to persist
even after controlling for confounding factors, such as data source. We
hypothesize that this bias may be linked to physiological factors, a known
challenge for both radiologists and automated systems. Finally, we show how
aggregating data from multiple data sources influences site-specific ethnic
biases, underscoring the necessity of investigating data at a granular level.

</details>


### [56] [Mitigating Semantic Collapse in Partially Relevant Video Retrieval](https://arxiv.org/abs/2510.27432)
*WonJun Moon,MinSeok Jung,Gilhan Park,Tae-Young Kim,Cheol-Ho Cho,Woojin Jun,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出文本相关性保持和跨分支视频对齐方法，解决部分相关视频检索中的语义坍缩问题，显著提升检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法将整个视频视为正样本，忽略视频内多事件的语义差异，导致文本与视频嵌入空间中的语义坍缩，限制检索性能。

Method: 引入文本相关性保持学习（Text Correlation Preservation Learning）和跨分支视频对齐（CBVA），结合顺序守恒标记合并与自适应CBVA，提升视频片段内部一致性与相互区分性。

Result: 在PRVR基准上实验表明，该框架有效抑制语义坍缩，显著提高视频检索准确性。

Conclusion: 所提方法通过解耦多尺度视频表征与保持文本语义关系，从根本上缓解PRVR任务中的语义坍缩问题，实现更精准的局部匹配检索。

Abstract: Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the
content matches a text query. Existing methods treat every annotated text-video
pair as a positive and all others as negatives, ignoring the rich semantic
variation both within a single video and across different videos. Consequently,
embeddings of both queries and their corresponding video-clip segments for
distinct events within the same video collapse together, while embeddings of
semantically similar queries and segments from different videos are driven
apart. This limits retrieval performance when videos contain multiple, diverse
events. This paper addresses the aforementioned problems, termed as semantic
collapse, in both the text and video embedding spaces. We first introduce Text
Correlation Preservation Learning, which preserves the semantic relationships
encoded by the foundation model across text queries. To address collapse in
video embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive
alignment method that disentangles hierarchical video representations across
temporal scales. Subsequently, we introduce order-preserving token merging and
adaptive CBVA to enhance alignment by producing video segments that are
internally coherent yet mutually distinctive. Extensive experiments on PRVR
benchmarks demonstrate that our framework effectively prevents semantic
collapse and substantially improves retrieval accuracy.

</details>


### [57] [DeblurSDI: Blind Image Deblurring Using Self-diffusion](https://arxiv.org/abs/2510.27439)
*Yanlong Yang,Guanxiong Luo*

Main category: cs.CV

TL;DR: 提出DeblurSDI，一种无需训练的自扩散盲去模糊方法，仅用噪声初始化网络，通过迭代优化恢复清晰图像和模糊核。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖手工先验，深度学习方法需大规模预训练，难以适应真实场景的变异性。

Method: 基于自扩散（SDI）的零样本自监督框架，用两个随机初始化网络迭代优化图像与核，结合数据一致性与L1稀疏约束，引入噪声调度机制提升稳定性。

Result: 在严重退化场景下仍能高质量恢复清晰图像与精确模糊核，性能超越现有方法。

Conclusion: DeblurSDI通过实例特定先验学习，实现无需训练的高效盲去模糊，具有强鲁棒性与实用性。

Abstract: Blind image deconvolution is a challenging ill-posed inverse problem, where
both the latent sharp image and the blur kernel are unknown. Traditional
methods often rely on handcrafted priors, while modern deep learning approaches
typically require extensive pre-training on large external datasets, limiting
their adaptability to real-world scenarios. In this work, we propose DeblurSDI,
a zero-shot, self-supervised framework based on self-diffusion (SDI) that
requires no prior training. DeblurSDI formulates blind deconvolution as an
iterative reverse self-diffusion process that starts from pure noise and
progressively refines the solution. At each step, two randomly-initialized
neural networks are optimized continuously to refine the sharp image and the
blur kernel. The optimization is guided by an objective function combining data
consistency with a sparsity-promoting L1-norm for the kernel. A key innovation
is our noise scheduling mechanism, which stabilizes the optimization and
provides remarkable robustness to variations in blur kernel size. These allow
DeblurSDI to dynamically learn an instance-specific prior tailored to the input
image. Extensive experiments demonstrate that DeblurSDI consistently achieves
superior performance, recovering sharp images and accurate kernels even in
highly degraded scenarios.

</details>


### [58] [CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging](https://arxiv.org/abs/2510.27442)
*Aon Safdar,Mohamed Saadeldin*

Main category: cs.CV

TL;DR: CoMViT是一种轻量级Vision Transformer，专为资源受限的医学影像分析设计，在保持高精度的同时大幅减少参数量。


<details>
  <summary>Details</summary>
Motivation: 传统Vision Transformers在医学影像中因计算量大和小数据集过拟合而难以实际应用。

Method: 整合卷积tokenizer、对角掩码、动态温度缩放和池化序列聚合，进行系统性架构优化。

Result: 在12个MedMNIST数据集上性能媲美或优于更深的CNN和ViT，参数仅约4.5M，减少5-20倍且不牺牲准确率。

Conclusion: 通过有原则的ViT重构，可实现高效且可解释的医学影像模型，适用于低资源场景。

Abstract: Vision Transformers (ViTs) have demonstrated strong potential in medical
imaging; however, their high computational demands and tendency to overfit on
small datasets limit their applicability in real-world clinical scenarios. In
this paper, we present CoMViT, a compact and generalizable Vision Transformer
architecture optimized for resource-constrained medical image analysis. CoMViT
integrates a convolutional tokenizer, diagonal masking, dynamic temperature
scaling, and pooling-based sequence aggregation to improve performance and
generalization. Through systematic architectural optimization, CoMViT achieves
robust performance across twelve MedMNIST datasets while maintaining a
lightweight design with only ~4.5M parameters. It matches or outperforms deeper
CNN and ViT variants, offering up to 5-20x parameter reduction without
sacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT
consistently attends to clinically relevant regions despite its compact size.
These results highlight the potential of principled ViT redesign for developing
efficient and interpretable models in low-resource medical imaging settings.

</details>


### [59] [From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration](https://arxiv.org/abs/2510.27452)
*Jianwen Sun,Fanrui Zhang,Yukang Feng,Chuanhao Li,Zizhen Li,Jiaxin Ai,Yifan Chang,Yu Dai,Kaipeng Zhang*

Main category: cs.CV

TL;DR: VisPainter 提出一种多智能体框架，解决科学插图生成中语义结构缺失与编辑低效的问题，结合 VisBench 评估基准实现高质量、可编辑的向量图生成。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型缺乏语义结构，无法编辑；代码生成方法（如TikZ/SVG）操作繁琐，缺乏直观性，难以满足科学创作中对效率、直观与迭代修改的需求。

Method: 提出 VisPainter 多智能体框架，由 Manager、Designer 和 Toolbox 三模块协作生成兼容标准矢量软件的插图，实现元素级可控；并构建 VisBench 七维评估基准，涵盖内容、布局、视觉感知与交互成本四方面。

Result: 验证了框架架构合理性与评估方法可靠性，实现了公平的视觉语言模型排名，量化了角色分工、步骤控制与描述对插图质量的影响。

Conclusion: VisPainter 首次在科学插图生成中实现高效、直观、可迭代的元素级编辑，为AI辅助科学可视化提供了新范式。

Abstract: Scientific illustrations demand both high information density and
post-editability. However, current generative models have two major
limitations: Frist, image generation models output rasterized images lacking
semantic structure, making it impossible to access, edit, or rearrange
independent visual components in the images. Second, code-based generation
methods (TikZ or SVG), although providing element-level control, force users
into the cumbersome cycle of "writing-compiling-reviewing" and lack the
intuitiveness of manipulation. Neither of these two approaches can well meet
the needs for efficiency, intuitiveness, and iterative modification in
scientific creation. To bridge this gap, we introduce VisPainter, a multi-agent
framework for scientific illustration built upon the model context protocol.
VisPainter orchestrates three specialized modules-a Manager, a Designer, and a
Toolbox-to collaboratively produce diagrams compatible with standard vector
graphics software. This modular, role-based design allows each element to be
explicitly represented and manipulated, enabling true element-level control and
any element can be added and modified later. To systematically evaluate the
quality of scientific illustrations, we introduce VisBench, a benchmark with
seven-dimensional evaluation metrics. It assesses high-information-density
scientific illustrations from four aspects: content, layout, visual perception,
and interaction cost. To this end, we conducted extensive ablation experiments
to verify the rationality of our architecture and the reliability of our
evaluation methods. Finally, we evaluated various vision-language models,
presenting fair and credible model rankings along with detailed comparisons of
their respective capabilities. Additionally, we isolated and quantified the
impacts of role division, step control,and description on the quality of
illustrations.

</details>


### [60] [A Multi-tiered Human-in-the-loop Approach for Interactive School Mapping Using Earth Observation and Machine Learning](https://arxiv.org/abs/2510.27460)
*Casper Fibaek,Abi Riley,Kelsey Doerksen,Do-Hyung Kim,Rochelle Schneider*

Main category: cs.CV

TL;DR: 提出一种多层级人机协同框架，用于提升发展中国家学校位置数据的准确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 发展中国家教育设施数据稀缺且更新滞后，亟需高效、低成本的映射方法。

Method: 采用机器学习分析人口密度与地表覆盖，结合高分辨率卫星影像与深度学习模型，逐步筛选候选学校位置，并通过交互界面由人工验证与修正。

Result: 中分辨率影像被证明效果有限而被移除，最终框架在成本与精度间取得平衡，验证了可扩展性。

Conclusion: 该框架为教育资源规划提供了高效、可扩展的解决方案。

Abstract: This paper presents a multi-tiered human-in-the-loop framework for
interactive school mapping designed to improve the accuracy and completeness of
educational facility records, particularly in developing regions where such
data may be scarce and infrequently updated. The first tier involves a machine
learning based analysis of population density, land cover, and existing
infrastructure compared with known school locations. The first tier identifies
potential gaps and "mislabelled" schools. In subsequent tiers,
medium-resolution satellite imagery (Sentinel-2) is investigated to pinpoint
regions with a high likelihood of school presence, followed by the application
of very high-resolution (VHR) imagery and deep learning models to generate
detailed candidate locations for schools within these prioritised areas. The
medium-resolution approach was later removed due to insignificant improvements.
The medium and VHR resolution models build upon global pre-trained steps to
improve generalisation. A key component of the proposed approach is an
interactive interface to allow human operators to iteratively review, validate,
and refine the mapping results. Preliminary evaluations indicate that the
multi-tiered strategy provides a scalable and cost-effective solution for
educational infrastructure mapping to support planning and resource allocation.

</details>


### [61] [Referee: Reference-aware Audiovisual Deepfake Detection](https://arxiv.org/abs/2510.27475)
*Hyemin Boo,Eunsang Lee,Jiyoung Lee*

Main category: cs.CV

TL;DR: 提出一种基于参考信息的视听深度伪造检测方法Referee，利用单样本身份特征实现跨数据集和跨语言的高精度检测。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法难以泛化到未见过的深度伪造内容，亟需更鲁棒的检测机制。

Method: Referee通过匹配参考样本与目标内容的身份相关查询，联合推理视听同步性与身份一致性。

Result: 在FakeAVCeleb、FaceForensics++和KoDF上达到SOTA性能，尤其在跨数据集和跨语言评估中表现优异。

Conclusion: 跨模态身份验证是未来深度伪造检测的关键方向。

Abstract: Since deepfakes generated by advanced generative models have rapidly posed
serious threats, existing audiovisual deepfake detection approaches struggle to
generalize to unseen forgeries. We propose a novel reference-aware audiovisual
deepfake detection method, called Referee. Speaker-specific cues from only
one-shot examples are leveraged to detect manipulations beyond spatiotemporal
artifacts. By matching and aligning identity-related queries from reference and
target content into cross-modal features, Referee jointly reasons about
audiovisual synchrony and identity consistency. Extensive experiments on
FakeAVCeleb, FaceForensics++, and KoDF demonstrate that Referee achieves
state-of-the-art performance on cross-dataset and cross-language evaluation
protocols. Experimental results highlight the importance of cross-modal
identity verification for future deepfake detection. The code is available at
https://github.com/ewha-mmai/referee.

</details>


### [62] [NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding](https://arxiv.org/abs/2510.27481)
*Wei Xu,Cheng Wang,Dingkang Liang,Zongchuang Zhao,Xingyu Jiang,Peng Zhang,Xiang Bai*

Main category: cs.CV

TL;DR: 构建了首个大规模水下多任务指令微调数据集NautData，并提出VFE模块提升水下场景理解性能，基于LLaVA和Qwen2.5-VL构建了NAUTILUS模型，显著提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 水下场景理解需多粒度多任务感知，但缺乏大规模指令微调数据集，且水下图像退化严重制约模型性能。

Method: 构建1.45M图像-文本对的NautData数据集，提出基于水下成像物理先验的VFE模块，集成至LLaVA-1.5和Qwen2.5-VL形成NAUTILUS模型。

Result: VFE模块在多个基准上持续提升性能，NAUTILUS在NautData及公开数据集上表现优越，全面优于基线模型。

Conclusion: NautData与NAUTILUS为水下场景理解提供了新基准，物理先验驱动的特征增强方法显著提升模型鲁棒性，推动该领域发展。

Abstract: Underwater exploration offers critical insights into our planet and attracts
increasing attention for its broader applications in resource exploration,
national security, etc. We study the underwater scene understanding methods,
which aim to achieve automated underwater exploration. The underwater scene
understanding task demands multi-task perceptions from multiple granularities.
However, the absence of large-scale underwater multi-task instruction-tuning
datasets hinders the progress of this research. To bridge this gap, we
construct NautData, a dataset containing 1.45 M image-text pairs supporting
eight underwater scene understanding tasks. It enables the development and
thorough evaluation of the underwater scene understanding models. Underwater
image degradation is a widely recognized challenge that interferes with
underwater tasks. To improve the robustness of underwater scene understanding,
we introduce physical priors derived from underwater imaging models and propose
a plug-and-play vision feature enhancement (VFE) module, which explicitly
restores clear underwater information. We integrate this module into renowned
baselines LLaVA-1.5 and Qwen2.5-VL and build our underwater LMM, NAUTILUS.
Experiments conducted on the NautData and public underwater datasets
demonstrate the effectiveness of the VFE module, consistently improving the
performance of both baselines on the majority of supported tasks, thus ensuring
the superiority of NAUTILUS in the underwater scene understanding area. Data
and models are available at https://github.com/H-EmbodVis/NAUTILUS.

</details>


### [63] [ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.27492)
*Jiawei Gu,Yunzhuo Hao,Huichen Will Wang,Linjie Li,Michael Qizhe Shieh,Yejin Choi,Ranjay Krishna,Yu Cheng*

Main category: cs.CV

TL;DR: ThinkMorph通过互补的文本-图像推理步骤提升多模态推理性能，显著超越基线模型并展现新兴能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理中文本与图像思维常被视为等价，缺乏互补性，阻碍推理效率与深度。

Method: 构建ThinkMorph模型，在2.4万条高质量交错推理轨迹上微调，实现文本与图像步骤协同推进、视觉内容具体操作与语言逻辑连贯。

Result: 在视觉中心基准上平均提升34.7%，泛化至域外任务，媲美更大或专有模型，并展现视觉操作、模式切换与测试时扩展等新兴能力。

Conclusion: 互补式多模态思维是实现统一模型 emergent 多模态智能的关键方向。

Abstract: Multimodal reasoning requires iterative coordination between language and
vision, yet it remains unclear what constitutes a meaningful interleaved chain
of thought. We posit that text and image thoughts should function as
complementary, rather than isomorphic, modalities that mutually advance
reasoning. Guided by this principle, we build ThinkMorph, a unified model
fine-tuned on 24K high-quality interleaved reasoning traces spanning tasks with
varying visual engagement. ThinkMorph learns to generate progressive text-image
reasoning steps that concretely manipulate visual content while maintaining
coherent verbal logic. It delivers large gains on vision-centric benchmarks
(averaging 34.7% over the base model) and generalizes to out-of-domain tasks,
matching or surpassing larger and proprietary VLMs. Beyond performance,
ThinkMorph exhibits emergent multimodal intelligence, including unseen visual
manipulation skills, adaptive switching between reasoning modes, and better
test-time scaling through diversified multimodal thoughts.These findings
suggest promising directions for characterizing the emergent capabilities of
unified models for multimodal reasoning.

</details>


### [64] [Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation](https://arxiv.org/abs/2510.27508)
*Elena Mulero Ayllón,Linlin Shen,Pierangelo Veltri,Fabrizia Gelardi,Arturo Chiti,Paolo Soda,Matteo Tortora*

Main category: cs.CV

TL;DR: 提出轻量级多模态框架vMambaX，通过上下文门控融合PET与CT图像，实现高效精准的肺肿瘤分割。


<details>
  <summary>Details</summary>
Motivation: 准确的肺肿瘤分割对诊断与治疗规划至关重要，但PET与CT模态间的信息融合仍具挑战。

Method: 基于Visual Mamba架构，设计上下文门控跨模态感知模块（CGM），自适应增强模态间特征交互并抑制噪声。

Result: 在PCLT20K数据集上优于基线模型，且计算复杂度更低。

Conclusion: 自适应跨模态门控机制有效提升多模态分割性能，vMambaX是高效可扩展的肺癌分析框架。

Abstract: Accurate lung tumor segmentation is vital for improving diagnosis and
treatment planning, and effectively combining anatomical and functional
information from PET and CT remains a major challenge. In this study, we
propose vMambaX, a lightweight multimodal framework integrating PET and CT scan
images through a Context-Gated Cross-Modal Perception Module (CGM). Built on
the Visual Mamba architecture, vMambaX adaptively enhances inter-modality
feature interaction, emphasizing informative regions while suppressing noise.
Evaluated on the PCLT20K dataset, the model outperforms baseline models while
maintaining lower computational complexity. These results highlight the
effectiveness of adaptive cross-modal gating for multimodal tumor segmentation
and demonstrate the potential of vMambaX as an efficient and scalable framework
for advanced lung cancer analysis. The code is available at
https://github.com/arco-group/vMambaX.

</details>


### [65] [Deep Neural Watermarking for Robust Copyright Protection in 3D Point Clouds](https://arxiv.org/abs/2510.27533)
*Khandoker Ashik Uz Zaman,Mohammad Zahangir Alam,Mohammed N. M. Ali,Mahdi H. Miraz*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的3D点云水印框架，利用SVD和PointNet++实现强鲁棒性的版权保护


<details>
  <summary>Details</summary>
Motivation: 3D点云易受几何与非几何攻击，传统水印方法易被破坏，亟需更鲁棒的版权保护方案

Method: 通过SVD分解点云块的奇异值嵌入二进制水印，并使用PointNet++深度网络提取水印，应对旋转、缩放、噪声、裁剪等攻击

Result: 在ModelNet40数据集上，深度学习方法在70%裁剪攻击下达到0.83位准确率和0.80 IoU，显著优于传统SVD方法（0.58准确率，0.26 IoU）

Conclusion: 该方法在严重几何失真下仍能高效恢复水印，实现高保真版权验证，为3D点云知识产权保护提供了新方案

Abstract: The protection of intellectual property has become critical due to the rapid
growth of three-dimensional content in digital media. Unlike traditional images
or videos, 3D point clouds present unique challenges for copyright enforcement,
as they are especially vulnerable to a range of geometric and non-geometric
attacks that can easily degrade or remove conventional watermark signals. In
this paper, we address these challenges by proposing a robust deep neural
watermarking framework for 3D point cloud copyright protection and ownership
verification. Our approach embeds binary watermarks into the singular values of
3D point cloud blocks using spectral decomposition, i.e. Singular Value
Decomposition (SVD), and leverages the extraction capabilities of Deep Learning
using PointNet++ neural network architecture. The network is trained to
reliably extract watermarks even after the data undergoes various attacks such
as rotation, scaling, noise, cropping and signal distortions. We validated our
method using the publicly available ModelNet40 dataset, demonstrating that deep
learning-based extraction significantly outperforms traditional SVD-based
techniques under challenging conditions. Our experimental evaluation
demonstrates that the deep learning-based extraction approach significantly
outperforms existing SVD-based methods with deep learning achieving bitwise
accuracy up to 0.83 and Intersection over Union (IoU) of 0.80, compared to SVD
achieving a bitwise accuracy of 0.58 and IoU of 0.26 for the Crop (70%) attack,
which is the most severe geometric distortion in our experiment. This
demonstrates our method's ability to achieve superior watermark recovery and
maintain high fidelity even under severe distortions.

</details>


### [66] [MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series](https://arxiv.org/abs/2510.27547)
*Xue Xia,Randall Balestriero,Tao Zhang,Yixin Zhou,Andrew Ding,Dev Saini,Lorenz Hurni*

Main category: cs.CV

TL;DR: MapSAM2是一种基于视觉基础模型的统一框架，将历史地图图像和时间序列视为视频，实现少样本微调下的自动分割与时空链接。


<details>
  <summary>Details</summary>
Motivation: 历史地图因风格多变和标注数据稀缺，自动化分析困难；构建时空数据集耗时耗力，但对建筑 Dating、交通网络演变等研究至关重要。

Method: 将地图图块和时间序列建模为视频，利用内存注意力机制融合上下文信息；提出伪时间序列生成方法，用单年地图模拟时间变换以降低标注成本。

Result: MapSAM2在有限监督下有效学习时序关联，精准分割并链接时间序列中的建筑物，表现优于传统方法。

Conclusion: 该框架为历史地图的自动化分析提供了高效解决方案，将发布数据集和代码以促进未来研究。

Abstract: Historical maps are unique and valuable archives that document geographic
features across different time periods. However, automated analysis of
historical map images remains a significant challenge due to their wide
stylistic variability and the scarcity of annotated training data. Constructing
linked spatio-temporal datasets from historical map time series is even more
time-consuming and labor-intensive, as it requires synthesizing information
from multiple maps. Such datasets are essential for applications such as dating
buildings, analyzing the development of road networks and settlements, studying
environmental changes etc. We present MapSAM2, a unified framework for
automatically segmenting both historical map images and time series. Built on a
visual foundation model, MapSAM2 adapts to diverse segmentation tasks with
few-shot fine-tuning. Our key innovation is to treat both historical map images
and time series as videos. For images, we process a set of tiles as a video,
enabling the memory attention mechanism to incorporate contextual cues from
similar tiles, leading to improved geometric accuracy, particularly for areal
features. For time series, we introduce the annotated Siegfried Building Time
Series Dataset and, to reduce annotation costs, propose generating pseudo time
series from single-year maps by simulating common temporal transformations.
Experimental results show that MapSAM2 learns temporal associations effectively
and can accurately segment and link buildings in time series under limited
supervision or using pseudo videos. We will release both our dataset and code
to support future research.

</details>


### [67] [Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum](https://arxiv.org/abs/2510.27571)
*Zhuoning Guo,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Xiaowen Chu*

Main category: cs.CV

TL;DR: 提出一个评估、数据与建模协同设计的框架，通过新基准UVRB和海量合成数据训练通用视频嵌入模型GVE，实现零样本泛化突破。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准窄化导致模型能力受限，缺乏多维泛化诊断机制，抑制了通用性发展。

Method: 构建UVRB基准（16个数据集）、生成155万高质量配对数据、设计Modality Pyramind课程训练GVE模型。

Result: GVE在UVRB上达到SOTA零样本表现，揭示主流基准无法预测通用能力，部分相关检索是被忽视的重要场景。

Conclusion: 协同设计的框架为突破局限、实现真正通用视频检索提供了可行路径。

Abstract: The prevailing video retrieval paradigm is structurally misaligned, as narrow
benchmarks incentivize correspondingly limited data and single-task training.
Therefore, universal capability is suppressed due to the absence of a
diagnostic evaluation that defines and demands multi-dimensional
generalization. To break this cycle, we introduce a framework built on the
co-design of evaluation, data, and modeling. First, we establish the Universal
Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to
measure performance but also to diagnose critical capability gaps across tasks
and domains. Second, guided by UVRB's diagnostics, we introduce a scalable
synthesis workflow that generates 1.55 million high-quality pairs to populate
the semantic space required for universality. Finally, we devise the Modality
Pyramid, a curriculum that trains our General Video Embedder (GVE) by
explicitly leveraging the latent interconnections within our diverse data.
Extensive experiments show GVE achieves state-of-the-art zero-shot
generalization on UVRB. In particular, our analysis reveals that popular
benchmarks are poor predictors of general ability and that partially relevant
retrieval is a dominant but overlooked scenario. Overall, our co-designed
framework provides a practical path to escape the limited scope and advance
toward truly universal video retrieval.

</details>


### [68] [Image Hashing via Cross-View Code Alignment in the Age of Foundation Models](https://arxiv.org/abs/2510.27584)
*Ilyass Moummad,Kawtar Zaher,Hervé Goëau,Alexis Joly*

Main category: cs.CV

TL;DR: CroVCA提出了一种简单高效的二值哈希方法，仅用单一损失函数和轻量级网络在极短训练时间内实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有哈希方法复杂、训练耗时、依赖多目标或特定学习范式，难以在大规模检索中高效应用。

Method: CroVCA通过跨视图码对齐与编码率最大化，结合轻量级HashCoder网络（MLP+BN），使用单交叉熵损失学习平衡且多样化的二进制码。

Result: 在COCO和ImageNet100等基准上，仅需5个epochs，16位编码下训练时间不足3分钟，达到SOTA性能。

Conclusion: CroVCA简洁、高效、通用，适用于冻结嵌入探针或LoRA微调，显著提升大规模检索的实用性。

Abstract: Efficient large-scale retrieval requires representations that are both
compact and discriminative. Foundation models provide powerful visual and
multimodal embeddings, but nearest neighbor search in these high-dimensional
spaces is computationally expensive. Hashing offers an efficient alternative by
enabling fast Hamming distance search with binary codes, yet existing
approaches often rely on complex pipelines, multi-term objectives, designs
specialized for a single learning paradigm, and long training times. We
introduce CroVCA (Cross-View Code Alignment), a simple and unified principle
for learning binary codes that remain consistent across semantically aligned
views. A single binary cross-entropy loss enforces alignment, while coding-rate
maximization serves as an anti-collapse regularizer to promote balanced and
diverse codes. To implement this, we design HashCoder, a lightweight MLP
hashing network with a final batch normalization layer to enforce balanced
codes. HashCoder can be used as a probing head on frozen embeddings or to adapt
encoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves
state-of-the-art results in just 5 training epochs. At 16 bits, it particularly
well-for instance, unsupervised hashing on COCO completes in under 2 minutes
and supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These
results highlight CroVCA's efficiency, adaptability, and broad applicability.

</details>


### [69] [ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning](https://arxiv.org/abs/2510.27599)
*Samarup Bhattacharya,Anubhab Bhattacharya,Abir Chakraborty*

Main category: cs.CV

TL;DR: 提出ANCHOR框架，结合对比学习与对抗训练，提升模型对抗攻击下的鲁棒性，同时保持高清洁准确率。


<details>
  <summary>Details</summary>
Motivation: 神经网络依赖梯度学习，但易受对抗攻击影响，小扰动即可导致错误预测，现有对抗训练方法在准确率与鲁棒性间存在权衡。

Method: ANCHOR框架采用监督对比学习，引入硬正例挖掘，使原始图像、增强图像与对抗扰动图像在嵌入空间中与同类样本聚类，与异类分离。

Result: 在CIFAR-10上，ANCHOR在PGD-20（ε=0.031）下显著优于标准对抗训练，兼顾清洁准确率与鲁棒准确率。

Conclusion: 结合对抗引导与硬挖掘对比监督，能学习更结构化、鲁棒的表征，缩小准确率与鲁棒性之间的差距。

Abstract: Neural networks have changed the way machines interpret the world. At their
core, they learn by following gradients, adjusting their parameters step by
step until they identify the most discriminant patterns in the data. This
process gives them their strength, yet it also opens the door to a hidden flaw.
The very gradients that help a model learn can also be used to produce small,
imperceptible tweaks that cause the model to completely alter its decision.
Such tweaks are called adversarial attacks. These attacks exploit this
vulnerability by adding tiny, imperceptible changes to images that, while
leaving them identical to the human eye, cause the model to make wrong
predictions. In this work, we propose Adversarially-trained Contrastive
Hard-mining for Optimized Robustness (ANCHOR), a framework that leverages the
power of supervised contrastive learning with explicit hard positive mining to
enable the model to learn representations for images such that the embeddings
for the images, their augmentations, and their perturbed versions cluster
together in the embedding space along with those for other images of the same
class while being separated from images of other classes. This alignment helps
the model focus on stable, meaningful patterns rather than fragile gradient
cues. On CIFAR-10, our approach achieves impressive results for both clean and
robust accuracy under PGD-20 (epsilon = 0.031), outperforming standard
adversarial training methods. Our results indicate that combining adversarial
guidance with hard-mined contrastive supervision helps models learn more
structured and robust representations, narrowing the gap between accuracy and
robustness.

</details>


### [70] [Who Made This? Fake Detection and Source Attribution with Diffusion Features](https://arxiv.org/abs/2510.27602)
*Simone Bonechi,Paolo Andreini,Barbara Toniella Corradini*

Main category: cs.CV

TL;DR: FRIDA利用预训练扩散模型的内部激活特征，无需微调即可实现跨生成器的假图检测与来源归因，达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 生成式扩散模型制造的假图日益逼真，现有监督检测方法泛化差、依赖大量标注数据且需频繁重训练。

Method: FRIDA提取预训练扩散模型的内部激活特征，使用k近邻分类器进行检测，辅以紧凑神经网络进行来源归因。

Result: 无需微调即可实现先进的跨生成器检测与高精度来源归因，揭示扩散特征内含生成器特异性模式。

Conclusion: 扩散模型的内部表征天然蕴含生成器指纹，为合成图像取证提供了轻量、可解释的新范式。

Abstract: The rapid progress of generative diffusion models has enabled the creation of
synthetic images that are increasingly difficult to distinguish from real ones,
raising concerns about authenticity, copyright, and misinformation. Existing
supervised detectors often struggle to generalize across unseen generators,
requiring extensive labeled data and frequent retraining. We introduce FRIDA
(Fake-image Recognition and source Identification via Diffusion-features
Analysis), a lightweight framework that leverages internal activations from a
pre-trained diffusion model for deepfake detection and source generator
attribution. A k-nearest-neighbor classifier applied to diffusion features
achieves state-of-the-art cross-generator performance without fine-tuning,
while a compact neural model enables accurate source attribution. These results
show that diffusion representations inherently encode generator-specific
patterns, providing a simple and interpretable foundation for synthetic image
forensics.

</details>


### [71] [Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2510.27606)
*Yuhong Liu,Beichen Zhang,Yuhang Zang,Yuhang Cao,Long Xing,Xiaoyi Dong,Haodong Duan,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出Self-supervised RL方法Spatial-SSRL，通过五种无需标注的前置任务提升LVLM的时空理解能力，在多个基准上显著超越基线。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM的时空理解能力弱，依赖昂贵标注或受限环境，难以规模化。

Method: 设计五种自监督前置任务：打乱图块重排、翻转图块识别、裁剪图块修复、区域深度排序和相对3D位置预测，直接从RGB/RGDB图像中生成可验证信号。

Result: 在7个图像与视频时空理解基准上，相比Qwen2.5-VL基线，3B和7B模型分别获得4.63%和3.89%的平均精度提升。

Conclusion: 简单内在的自监督信号可实现可扩展的RLVR，为LVLM提供实用的时空智能提升路径。

Abstract: Spatial understanding remains a weakness of Large Vision-Language Models
(LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement
learning with verifiable rewards (RLVR) pipelines depend on costly supervision,
specialized tools, or constrained environments that limit scale. We introduce
Spatial-SSRL, a self-supervised RL paradigm that derives verifiable signals
directly from ordinary RGB or RGB-D images. Spatial-SSRL automatically
formulates five pretext tasks that capture 2D and 3D spatial structure:
shuffled patch reordering, flipped patch recognition, cropped patch inpainting,
regional depth ordering, and relative 3D position prediction. These tasks
provide ground-truth answers that are easy to verify and require no human or
LVLM annotation. Training on our tasks substantially improves spatial reasoning
while preserving general visual capabilities. On seven spatial understanding
benchmarks in both image and video settings, Spatial-SSRL delivers average
accuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our
results show that simple, intrinsic supervision enables RLVR at scale and
provides a practical route to stronger spatial intelligence in LVLMs.

</details>


### [72] [Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation](https://arxiv.org/abs/2510.27632)
*Riccardo Brioschi,Aleksandr Alekseev,Emanuele Nevali,Berkay Döner,Omar El Malki,Blagoj Mitrevski,Leandro Kieliger,Mark Collier,Andrii Maksai,Jesse Berent,Claudiu Musat,Efi Kokiopoulou*

Main category: cs.CV

TL;DR: 提出一种基于用户草图的图形布局生成方法，通过多模态Transformer模型实现，性能优于现有方法并释放20万合成草图数据集。


<details>
  <summary>Details</summary>
Motivation: 现有布局生成方法依赖复杂约束，降低可用性；草图作为直观约束尚未被充分研究。

Method: 采用多模态Transformer，以草图和内容元素为输入生成布局，并提出大规模合成草图生成方法以解决标注数据稀缺问题。

Result: 在PubLayNet、DocLayNet和SlidesVQA三个数据集上超越现有约束方法，同时提升用户体验。

Conclusion: 草图到布局是一个有前景的研究方向，所提方法与开源数据集将推动该领域后续发展。

Abstract: Graphic layout generation is a growing research area focusing on generating
aesthetically pleasing layouts ranging from poster designs to documents. While
recent research has explored ways to incorporate user constraints to guide the
layout generation, these constraints often require complex specifications which
reduce usability. We introduce an innovative approach exploiting user-provided
sketches as intuitive constraints and we demonstrate empirically the
effectiveness of this new guidance method, establishing the sketch-to-layout
problem as a promising research direction, which is currently under-explored.
To tackle the sketch-to-layout problem, we propose a multimodal
transformer-based solution using the sketch and the content assets as inputs to
produce high quality layouts. Since collecting sketch training data from human
annotators to train our model is very costly, we introduce a novel and
efficient method to synthetically generate training sketches at scale. We train
and evaluate our model on three publicly available datasets: PubLayNet,
DocLayNet and SlidesVQA, demonstrating that it outperforms state-of-the-art
constraint-based methods, while offering a more intuitive design experience. In
order to facilitate future sketch-to-layout research, we release O(200k)
synthetically-generated sketches for the public datasets above. The datasets
are available at https://github.com/google-deepmind/sketch_to_layout.

</details>


### [73] [VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images](https://arxiv.org/abs/2510.27646)
*Cesar H. Comin,Wesley N. Galvão*

Main category: cs.CV

TL;DR: 通过生成具有血管几何先验的合成数据，提升模型在少量样本下的分割性能和跨模态泛化能力。


<details>
  <summary>Details</summary>
Motivation: 血栓分割受制于标注数据稀缺与模型跨模态泛化差，CNN易学习纹理特征而非形状特征。

Method: 提出VessShape方法，生成大量包含管状几何结构与多样纹理的合成图像，引导模型学习形状先验。

Result: 预训练模型在仅4-10个标注样本下实现强few-shot性能，并在未见域上展现零样本分割能力。

Conclusion: 引入形状偏置的合成预训练可有效缓解数据稀缺问题，显著提升血管分割模型的泛化性。

Abstract: Semantic segmentation of blood vessels is an important task in medical image
analysis, but its progress is often hindered by the scarcity of large annotated
datasets and the poor generalization of models across different imaging
modalities. A key aspect is the tendency of Convolutional Neural Networks
(CNNs) to learn texture-based features, which limits their performance when
applied to new domains with different visual characteristics. We hypothesize
that leveraging geometric priors of vessel shapes, such as their tubular and
branching nature, can lead to more robust and data-efficient models. To
investigate this, we introduce VessShape, a methodology for generating
large-scale 2D synthetic datasets designed to instill a shape bias in
segmentation models. VessShape images contain procedurally generated tubular
geometries combined with a wide variety of foreground and background textures,
encouraging models to learn shape cues rather than textures. We demonstrate
that a model pre-trained on VessShape images achieves strong few-shot
segmentation performance on two real-world datasets from different domains,
requiring only four to ten samples for fine-tuning. Furthermore, the model
exhibits notable zero-shot capabilities, effectively segmenting vessels in
unseen domains without any target-specific training. Our results indicate that
pre-training with a strong shape bias can be an effective strategy to overcome
data scarcity and improve model generalization in blood vessel segmentation.

</details>


### [74] [NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception](https://arxiv.org/abs/2510.27647)
*Congzhang Shao,Quan Yuan,Guiyang Luo,Yue Hu,Danni Wang,Yilin Liu,Rui Pan,Bo Chen,Jinglin Li*

Main category: cs.CV

TL;DR: 提出NegoCollab方法，通过协商式公共表征缓解异构代理间的领域差距，提升协作感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法将公共表征固定为某一代理的表征，导致与该代理差异大的其他代理难以对齐，影响性能。

Method: 引入协商者动态生成公共表征，配合发送器与接收器实现局部表征与公共表征的互转，并引入结构对齐损失、实用对齐损失和分布对齐损失联合优化。

Result: 有效减少异构代理间的领域差距，提升特征对齐效果与协作性能。

Conclusion: 协商式公共表征能更公平、高效地融合多模态信息，为异构协作感知提供新思路。

Abstract: Collaborative perception improves task performance by expanding the
perception range through information sharing among agents. . Immutable
heterogeneity poses a significant challenge in collaborative perception, as
participating agents may employ different and fixed perception models. This
leads to domain gaps in the intermediate features shared among agents,
consequently degrading collaborative performance. Aligning the features of all
agents to a common representation can eliminate domain gaps with low training
cost. However, in existing methods, the common representation is designated as
the representation of a specific agent, making it difficult for agents with
significant domain discrepancies from this specific agent to achieve proper
alignment. This paper proposes NegoCollab, a heterogeneous collaboration method
based on the negotiated common representation. It introduces a negotiator
during training to derive the common representation from the local
representations of each modality's agent, effectively reducing the inherent
domain gap with the various local representations. In NegoCollab, the mutual
transformation of features between the local representation space and the
common representation space is achieved by a pair of sender and receiver. To
better align local representations to the common representation containing
multimodal information, we introduce structural alignment loss and pragmatic
alignment loss in addition to the distribution alignment loss to supervise the
training. This enables the knowledge in the common representation to be fully
distilled into the sender.

</details>


### [75] [Gaussian Combined Distance: A Generic Metric for Object Detection](https://arxiv.org/abs/2510.27649)
*Ziqian Guan,Xieyi Fu,Pengjun Huang,Hengyuan Zhang,Hubin Du,Yongtao Liu,Yinglin Wang,Qang Ma*

Main category: cs.CV

TL;DR: 提出一种新的高斯联合距离（GCD）替代IoU和Wasserstein距离，提升小目标检测的定位精度与模型收敛速度。


<details>
  <summary>Details</summary>
Motivation: IoU对位置偏差敏感，Wasserstein距离缺乏尺度不变性且优化中心参数缓慢，导致小目标检测性能不佳。

Method: 引入高斯联合距离（GCD），通过分析其梯度证明其具备尺度不变性并支持联合优化。

Result: 在AI-TOD-v2、MS-COCO-2017和Visdrone-2019数据集上，GCD在多种检测器上均达到SOTA性能。

Conclusion: GCD有效解决小目标检测中的定位难题，具备良好泛化能力，可广泛应用于各类目标检测框架。

Abstract: In object detection, a well-defined similarity metric can significantly
enhance model performance. Currently, the IoU-based similarity metric is the
most commonly preferred choice for detectors. However, detectors using IoU as a
similarity metric often perform poorly when detecting small objects because of
their sensitivity to minor positional deviations. To address this issue, recent
studies have proposed the Wasserstein Distance as an alternative to IoU for
measuring the similarity of Gaussian-distributed bounding boxes. However, we
have observed that the Wasserstein Distance lacks scale invariance, which
negatively impacts the model's generalization capability. Additionally, when
used as a loss function, its independent optimization of the center attributes
leads to slow model convergence and unsatisfactory detection precision. To
address these challenges, we introduce the Gaussian Combined Distance (GCD).
Through analytical examination of GCD and its gradient, we demonstrate that GCD
not only possesses scale invariance but also facilitates joint optimization,
which enhances model localization performance. Extensive experiments on the
AI-TOD-v2 dataset for tiny object detection show that GCD, as a bounding box
regression loss function and label assignment metric, achieves state-of-the-art
performance across various detectors. We further validated the generalizability
of GCD on the MS-COCO-2017 and Visdrone-2019 datasets, where it outperforms the
Wasserstein Distance across diverse scales of datasets. Code is available at
https://github.com/MArKkwanGuan/mmdet-GCD.

</details>


### [76] [Deep learning denoising unlocks quantitative insights in operando materials microscopy](https://arxiv.org/abs/2510.27667)
*Samuel Degnan-Morgenstern,Alexander E. Cohen,Rajeev Gopal,Megan Gober,George J. Nelson,Peng Bai,Martin Z. Bazant*

Main category: cs.CV

TL;DR: 深度去噪技术提升多种显微成像的定量分析精度，突破噪声限制


<details>
  <summary>Details</summary>
Motivation: 操作显微镜中的测量噪声限制了分辨率和定量分析能力

Method: 采用无监督深度学习去噪方法，结合偏微分方程约束优化，适用于多模态和多尺度显微成像

Result: 在STXM、光学显微镜和中子放射照相中分别实现纳米级异质性揭示、自动分割分类和噪声减少80%

Conclusion: 深度去噪是一种通用、无模态限制的增强技术，显著提升操作成像的定量能力与应用范围

Abstract: Operando microscopy provides direct insight into the dynamic chemical and
physical processes that govern functional materials, yet measurement noise
limits the effective resolution and undermines quantitative analysis. Here, we
present a general framework for integrating unsupervised deep learning-based
denoising into quantitative microscopy workflows across modalities and length
scales. Using simulated data, we demonstrate that deep denoising preserves
physical fidelity, introduces minimal bias, and reduces uncertainty in model
learning with partial differential equation (PDE)-constrained optimization.
Applied to experiments, denoising reveals nanoscale chemical and structural
heterogeneity in scanning transmission X-ray microscopy (STXM) of lithium iron
phosphate (LFP), enables automated particle segmentation and phase
classification in optical microscopy of graphite electrodes, and reduces
noise-induced variability by nearly 80% in neutron radiography to resolve
heterogeneous lithium transport. Collectively, these results establish deep
denoising as a powerful, modality-agnostic enhancement that advances
quantitative operando imaging and extends the reach of previously noise-limited
techniques.

</details>


### [77] [Vision Transformer for Robust Occluded Person Reidentification in Complex Surveillance Scenes](https://arxiv.org/abs/2510.27677)
*Bo Li,Duyuan Zheng,Xinyang Liu,Qingwen Li,Hong Li,Hongyan Cui,Ge Gao,Chen Liu*

Main category: cs.CV

TL;DR: Sh-ViT是一种轻量级鲁棒的视觉变换器模型，专门用于遮挡行人重识别，通过打乱模块、场景自适应增强和知识蒸馏提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂模块或仅在清晰正面图像上表现良好，面对遮挡、视角畸变和低图像质量的监控场景适应性差。

Method: 在ViT-Base基础上引入三个组件：最终Transformer层的打乱模块、场景自适应数据增强（几何变换、擦除、模糊、色彩调整）和DeiT知识蒸馏。

Result: 在新构建的MyTT数据集上达到83.2% Rank-1和80.1% mAP，在Market1501上达到94.6% Rank-1和87.5% mAP，显著超越CNN、ViT基线及现有SOTA方法。

Conclusion: Sh-ViT无需外部模块即可提升对遮挡和模糊的鲁棒性，为监控场景提供实用高效的行人重识别解决方案。

Abstract: Person re-identification (ReID) in surveillance is challenged by occlusion,
viewpoint distortion, and poor image quality. Most existing methods rely on
complex modules or perform well only on clear frontal images. We propose Sh-ViT
(Shuffling Vision Transformer), a lightweight and robust model for occluded
person ReID. Built on ViT-Base, Sh-ViT introduces three components: First, a
Shuffle module in the final Transformer layer to break spatial correlations and
enhance robustness to occlusion and blur; Second, scenario-adapted augmentation
(geometric transforms, erasing, blur, and color adjustment) to simulate
surveillance conditions; Third, DeiT-based knowledge distillation to improve
learning with limited labels.To support real-world evaluation, we construct the
MyTT dataset, containing over 10,000 pedestrians and 30,000+ images from base
station inspections, with frequent equipment occlusion and camera variations.
Experiments show that Sh-ViT achieves 83.2% Rank-1 and 80.1% mAP on MyTT,
outperforming CNN and ViT baselines, and 94.6% Rank-1 and 87.5% mAP on
Market1501, surpassing state-of-the-art methods.In summary, Sh-ViT improves
robustness to occlusion and blur without external modules, offering a practical
solution for surveillance-based personnel monitoring.

</details>


### [78] [PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting](https://arxiv.org/abs/2510.27680)
*Danyal Maqbool,Changhee Lee,Zachary Huemann,Samuel D. Church,Matthew E. Larson,Scott B. Perlman,Tomas A. Romero,Joshua D. Warner,Meghan Lubner,Xin Tie,Jameson Merkow,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: 提出PETAR-4B模型，首次将视觉语言模型扩展到3D PET/CT影像，实现基于病灶轮廓的临床报告生成


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型多限于2D医学影像，而3D PET/CT具有大体积数据、微小分散病灶和长报告等特点，亟需更精准的3D多模态理解

Method: 构建包含11,000+病灶描述与3D分割的大型数据集，提出PETAR-4B模型，融合PET、CT与病灶轮廓，实现空间感知的报告生成

Result: 自动化与人工评估均表明PETAR显著提升PET/CT报告质量，实现全局语义与局部病灶的协同推理

Conclusion: PETAR推动了3D医学视觉语言模型的发展，为临床影像报告自动化提供了新范式

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
multimodal reasoning, yet most medical applications remain limited to 2D
imaging. In this work, we extend VLMs to 3D positron emission tomography and
computed tomography (PET/CT), a domain characterized by large volumetric data,
small and dispersed lesions, and lengthy radiology reports. We introduce a
large-scale dataset comprising over 11,000 lesion-level descriptions paired
with 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid
rule-based and large language model (LLM) pipeline. Building upon this dataset,
we propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET,
CT, and lesion contours for spatially grounded report generation. PETAR bridges
global contextual reasoning with fine-grained lesion awareness, producing
clinically coherent and localized findings. Comprehensive automated and human
evaluations demonstrate that PETAR substantially improves PET/CT report
generation quality, advancing 3D medical vision-language understanding.

</details>


### [79] [Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](https://arxiv.org/abs/2510.27684)
*Xiangyu Fan,Zesong Qiu,Zhuguanyu Wu,Fanzhou Wang,Zhiqian Lin,Tianxiang Ren,Dahua Lin,Ruihao Gong,Lei Yang*

Main category: cs.CV

TL;DR: 提出Phased DMD方法，通过分阶段和MoE提升多步蒸馏的多样性与容量，解决传统DMD在复杂生成任务中表现不足的问题。


<details>
  <summary>Details</summary>
Motivation: 一阶段蒸馏模型容量有限，多步蒸馏又导致内存和计算开销增大、多样性下降，现有方法难以平衡效率与性能。

Method: 提出Phased DMD，将SNR范围划分为子区间，分阶段进行分布匹配与分数匹配，并引入Mixture-of-Experts增强模型容量。

Result: 在Qwen-Image和Wan2.2等大型模型上蒸馏后，Phased DMD在保留生成能力的同时，显著优于DMD的多样性。

Conclusion: Phased DMD有效解决了多步蒸馏中的多样性损失与计算效率矛盾，为高效生成模型提供了新范式。

Abstract: Distribution Matching Distillation (DMD) distills score-based generative
models into efficient one-step generators, without requiring a one-to-one
correspondence with the sampling trajectories of their teachers. However,
limited model capacity causes one-step distilled models underperform on complex
generative tasks, e.g., synthesizing intricate object motions in text-to-video
generation. Directly extending DMD to multi-step distillation increases memory
usage and computational depth, leading to instability and reduced efficiency.
While prior works propose stochastic gradient truncation as a potential
solution, we observe that it substantially reduces the generation diversity of
multi-step distilled models, bringing it down to the level of their one-step
counterparts. To address these limitations, we propose Phased DMD, a multi-step
distillation framework that bridges the idea of phase-wise distillation with
Mixture-of-Experts (MoE), reducing learning difficulty while enhancing model
capacity. Phased DMD is built upon two key ideas: progressive distribution
matching and score matching within subintervals. First, our model divides the
SNR range into subintervals, progressively refining the model to higher SNR
levels, to better capture complex distributions. Next, to ensure the training
objective within each subinterval is accurate, we have conducted rigorous
mathematical derivations. We validate Phased DMD by distilling state-of-the-art
image and video generation models, including Qwen-Image (20B parameters) and
Wan2.2 (28B parameters). Experimental results demonstrate that Phased DMD
preserves output diversity better than DMD while retaining key generative
capabilities. We will release our code and models.

</details>


### [80] [LifWavNet: Lifting Wavelet-based Network for Non-contact ECG Reconstruction from Radar](https://arxiv.org/abs/2510.27692)
*Soumitra Kundu,Gargi Panda,Saumik Bhattacharya,Aurobinda Routray,Rajlakshmi Guha*

Main category: cs.CV

TL;DR: LifWavNet使用可学习的提升小波网络实现雷达信号到心电图的非接触式重建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统固定小波方法难以自适应提取雷达信号特征，影响心电图重建精度。

Method: 提出LifWavNet，基于多分辨率分析与合成模型，采用可学习的提升小波单元，并引入多分辨率STFT损失函数提升时频一致性。

Result: 在两个公开数据集上，LifWavNet在心电图重建和心率、心率变异性估计上均超越当前最优方法，且中间特征具有可解释性。

Conclusion: LifWavNet是一种鲁棒且可解释的雷达非接触式心电图测量框架。

Abstract: Non-contact electrocardiogram (ECG) reconstruction from radar signals offers
a promising approach for unobtrusive cardiac monitoring. We present LifWavNet,
a lifting wavelet network based on a multi-resolution analysis and synthesis
(MRAS) model for radar-to-ECG reconstruction. Unlike prior models that use
fixed wavelet approaches, LifWavNet employs learnable lifting wavelets with
lifting and inverse lifting units to adaptively capture radar signal features
and synthesize physiologically meaningful ECG waveforms. To improve
reconstruction fidelity, we introduce a multi-resolution short-time Fourier
transform (STFT) loss, that enforces consistency with the ground-truth ECG in
both temporal and spectral domains. Evaluations on two public datasets
demonstrate that LifWavNet outperforms state-of-the-art methods in ECG
reconstruction and downstream vital sign estimation (heart rate and heart rate
variability). Furthermore, intermediate feature visualization highlights the
interpretability of multi-resolution decomposition and synthesis in
radar-to-ECG reconstruction. These results establish LifWavNet as a robust
framework for radar-based non-contact ECG measurement.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [81] [Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction](https://arxiv.org/abs/2510.26837)
*Conor K. Trygstad,Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 首次测量了昆虫尺度软体推进器的瞬时推力，揭示了流固耦合对微机器人推进的高效性。


<details>
  <summary>Details</summary>
Motivation: 尽管这两种推进器已用于微机器人水下运动，但其相关力的特性和大小尚未系统研究。

Method: 采用基于反应力的理论框架，结合自制的微牛级力传感器进行实验测量。

Result: 单尾推进器最大推力0.45 mN，平均2.97 μN；双尾推进器最大推力0.61 mN，平均22.6 μN。

Conclusion: 这些结果是首次对此类昆虫尺度推进器的瞬时推力测量，为微机器人高效推进提供了流固耦合的见解。

Abstract: We present force characterizations of two newly developed insect-scale
propulsors--one single-tailed and one double-tailed--for microrobotic swimmers
that leverage fluid-structure interaction (FSI) to generate thrust. The designs
of these two devices were inspired by anguilliform swimming and are driven by
soft tails excited by high-work-density (HWD) actuators powered by shape-memory
alloy (SMA) wires. While these propulsors have been demonstrated to be suitable
for microrobotic aquatic locomotion and controllable with simple architectures
for trajectory tracking in the two-dimensional (2D) space, the characteristics
and magnitudes of the associated forces have not been studied systematically.
In the research presented here, we adopted a theoretical framework based on the
notion of reactive forces and obtained experimental data for characterization
using a custom-built micro-N-resolution force sensor. We measured maximum and
cycle-averaged force values with multi-test means of respectively 0.45 mN and
2.97 micro-N, for the tested single-tail propulsor. For the dual-tail
propulsor, we measured maximum and cycle-averaged force values with multi-test
means of 0.61 mN and 22.6 micro-N, respectively. These results represent the
first measurements of the instantaneous thrust generated by insect-scale
propulsors of this type and provide insights into FSI for efficient
microrobotic propulsion.

</details>


### [82] [Leveraging Foundation Models for Enhancing Robot Perception and Action](https://arxiv.org/abs/2510.26855)
*Reihaneh Mirjalili*

Main category: cs.RO

TL;DR: 本文探讨如何系统利用基础模型提升机器人在非结构化环境中的定位、交互与操作能力。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化环境中面临定位、交互和操作的挑战，现有方法缺乏语义理解能力。

Method: 围绕四个核心研究方向，构建语义感知的机器人智能框架，系统整合基础模型。

Result: 未提供具体结果，但提出了一种协同的框架方向。

Conclusion: 通过基础模型推动机器人语义感知智能的发展，实现更有效的环境交互与操作。

Abstract: This thesis investigates how foundation models can be systematically
leveraged to enhance robotic capabilities, enabling more effective
localization, interaction, and manipulation in unstructured environments. The
work is structured around four core lines of inquiry, each addressing a
fundamental challenge in robotics while collectively contributing to a cohesive
framework for semantics-aware robotic intelligence.

</details>


### [83] [Design for One, Deploy for Many: Navigating Tree Mazes with Multiple Agents](https://arxiv.org/abs/2510.26900)
*Jahir Argote-Gerald,Genki Miyauchi,Julian Rau,Paul Trodden,Roderich Gross*

Main category: cs.RO

TL;DR: 提出一种分布式多机器人迷宫遍历算法，通过领导切换机制在无环图环境中实现高效协同，优于朴素策略并接近全知识策略性能。


<details>
  <summary>Details</summary>
Motivation: 迷宫环境如洞穴和管道网络中，机器人面临通信受限和拥塞挑战，现有方法依赖全局通信或完整环境知识，难以实用。

Method: 采用分布式领导切换机制：一机器人任首领使用单机器人迷宫求解器，其余机器人跟随首领，首领在必要时转移给邻居，确保路径一致性。

Result: 仿真中最多300机器人验证，相比朴素策略显著降低完成时间和能耗；相比全局通信策略完成时间更优但能耗更高；与全知识策略渐近等效。20个Pi-puck机器人实验证实可行性。

Conclusion: 该算法在无全局通信和环境知识下，实现了高效、可扩展的多机器人迷宫遍历，兼具性能与实用性。

Abstract: Maze-like environments, such as cave and pipe networks, pose unique
challenges for multiple robots to coordinate, including communication
constraints and congestion. To address these challenges, we propose a
distributed multi-agent maze traversal algorithm for environments that can be
represented by acyclic graphs. It uses a leader-switching mechanism where one
agent, assuming a head role, employs any single-agent maze solver while the
other agents each choose an agent to follow. The head role gets transferred to
neighboring agents where necessary, ensuring it follows the same path as a
single agent would. The multi-agent maze traversal algorithm is evaluated in
simulations with groups of up to 300 agents, various maze sizes, and multiple
single-agent maze solvers. It is compared against strategies that are na\"ive,
or assume either global communication or full knowledge of the environment. The
algorithm outperforms the na\"ive strategy in terms of makespan and
sum-of-fuel. It is superior to the global-communication strategy in terms of
makespan but is inferior to it in terms of sum-of-fuel. The findings suggest it
is asymptotically equivalent to the full-knowledge strategy with respect to
either metric. Moreover, real-world experiments with up to 20 Pi-puck robots
confirm the feasibility of the approach.

</details>


### [84] [NaviTrace: Evaluating Embodied Navigation of Vision-Language Models](https://arxiv.org/abs/2510.26909)
*Tim Windecker,Manthan Patel,Moritz Reuss,Richard Schwarzkopf,Cesar Cadena,Rudolf Lioutikov,Marco Hutter,Jonas Frey*

Main category: cs.RO

TL;DR: 提出NaviTrace基准，评估视觉语言模型在机器人导航中的表现，发现其在空间定位上显著落后于人类


<details>
  <summary>Details</summary>
Motivation: 现有导航评估受限于昂贵的真实实验、简化的仿真和有限的基准，亟需一个可扩展且贴近现实的评估方法

Method: 构建包含1000个场景和3000+专家轨迹的视觉问答基准NaviTrace，提出语义感知轨迹评分（融合DTW、终点误差和体态惩罚）

Result: 评估8个SOTA VLMs，揭示其因空间 grounding 和目标定位差而远低于人类性能

Conclusion: NaviTrace为机器人导航提供可复现、可扩展的评估基准，推动VLM在真实导航任务中的发展

Abstract: Vision-language models demonstrate unprecedented performance and
generalization across a wide range of tasks and scenarios. Integrating these
foundation models into robotic navigation systems opens pathways toward
building general-purpose robots. Yet, evaluating these models' navigation
capabilities remains constrained by costly real-world trials, overly simplified
simulations, and limited benchmarks. We introduce NaviTrace, a high-quality
Visual Question Answering benchmark where a model receives an instruction and
embodiment type (human, legged robot, wheeled robot, bicycle) and must output a
2D navigation trace in image space. Across 1000 scenarios and more than 3000
expert traces, we systematically evaluate eight state-of-the-art VLMs using a
newly introduced semantic-aware trace score. This metric combines Dynamic Time
Warping distance, goal endpoint error, and embodiment-conditioned penalties
derived from per-pixel semantics and correlates with human preferences. Our
evaluation reveals consistent gap to human performance caused by poor spatial
grounding and goal localization. NaviTrace establishes a scalable and
reproducible benchmark for real-world robotic navigation. The benchmark and
leaderboard can be found at
https://leggedrobotics.github.io/navitrace_webpage/.

</details>


### [85] [Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence](https://arxiv.org/abs/2510.26915)
*Zachary Ravichandran,Fernando Cladera,Ankit Prabhu,Jason Hughes,Varun Murali,Camillo Taylor,George J. Pappas,Vijay Kumar*

Main category: cs.RO

TL;DR: SPINE-HT框架通过将LLM推理与异构机器人团队能力结合，在非结构化环境中实现自然语言任务的高效执行，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的机器人团队方法依赖结构化环境，难以适应真实世界中无地图、不确定的非结构化场景。

Method: SPINE-HT采用三阶段流程：LLM生成基于机器人能力的地面化子任务，根据能力分配任务，并通过在线反馈动态优化。

Result: 仿真中成功率是现有方法的近两倍；真实实验中，四类机器人组合任务成功率高达87%。

Conclusion: SPINE-HT有效解决了LLM在非结构化环境中的落地难题，为异构机器人团队的动态任务规划提供了新范式。

Abstract: Heterogeneous robot teams operating in realistic settings often must
accomplish complex missions requiring collaboration and adaptation to
information acquired online. Because robot teams frequently operate in
unstructured environments -- uncertain, open-world settings without prior maps
-- subtasks must be grounded in robot capabilities and the physical world.
While heterogeneous teams have typically been designed for fixed
specifications, generative intelligence opens the possibility of teams that can
accomplish a wide range of missions described in natural language. However,
current large language model (LLM)-enabled teaming methods typically assume
well-structured and known environments, limiting deployment in unstructured
environments. We present SPINE-HT, a framework that addresses these limitations
by grounding the reasoning abilities of LLMs in the context of a heterogeneous
robot team through a three-stage process. Given language specifications
describing mission goals and team capabilities, an LLM generates grounded
subtasks which are validated for feasibility. Subtasks are then assigned to
robots based on capabilities such as traversability or perception and refined
given feedback collected during online operation. In simulation experiments
with closed-loop perception and control, our framework achieves nearly twice
the success rate compared to prior LLM-enabled heterogeneous teaming
approaches. In real-world experiments with a Clearpath Jackal, a Clearpath
Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an
87\% success rate in missions requiring reasoning about robot capabilities and
refining subtasks with online feedback. More information is provided at
https://zacravichandran.github.io/SPINE-HT.

</details>


### [86] [RepV: Safety-Separable Latent Spaces for Scalable Neurosymbolic Plan Verification](https://arxiv.org/abs/2510.26935)
*Yunhao Yang,Neel P. Bhatt,Pranay Samineni,Rohan Siva,Zhanyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: RepV是一种神经符号验证器，通过学习安全与不安全计划的线性可分潜在空间，实现对自然语言规则的高效验证，并提供概率性保证以改进规划器。


<details>
  <summary>Details</summary>
Motivation: 现有形式化方法依赖人工编写时序逻辑规范，表达能力有限；深度学习方法虽能处理自然语言约束，但决策过程不透明，易导致严重误判。

Method: RepV从少量由模型检测器标注的计划出发，训练一个轻量级投影器将计划与语言模型生成的推理嵌入低维空间，并固定线性边界进行快速验证，同时提供概率性置信度。

Result: RepV在合规性预测准确性上比基线方法提升最高达15%，仅增加不到0.2M参数，且其优化框架优于传统微调方法。

Conclusion: 安全可分的潜在空间为神经符号计划验证提供了可扩展、即插即用的 primitives，实现高可靠性与高效性。

Abstract: As AI systems migrate to safety-critical domains, verifying that their
actions comply with well-defined rules remains a challenge. Formal methods
provide provable guarantees but demand hand-crafted temporal-logic
specifications, offering limited expressiveness and accessibility. Deep
learning approaches enable evaluation of plans against natural-language
constraints, yet their opaque decision process invites misclassifications with
potentially severe consequences. We introduce RepV, a neurosymbolic verifier
that unifies both views by learning a latent space where safe and unsafe plans
are linearly separable. Starting from a modest seed set of plans labeled by an
off-the-shelf model checker, RepV trains a lightweight projector that embeds
each plan, together with a language model-generated rationale, into a
low-dimensional space; a frozen linear boundary then verifies compliance for
unseen natural-language rules in a single forward pass.
  Beyond binary classification, RepV provides a probabilistic guarantee on the
likelihood of correct verification based on its position in the latent space.
This guarantee enables a guarantee-driven refinement of the planner, improving
rule compliance without human annotations. Empirical evaluations show that RepV
improves compliance prediction accuracy by up to 15% compared to baseline
methods while adding fewer than 0.2M parameters. Furthermore, our refinement
framework outperforms ordinary fine-tuning baselines across various planning
domains. These results show that safety-separable latent spaces offer a
scalable, plug-and-play primitive for reliable neurosymbolic plan verification.
Code and data are available at: https://repv-project.github.io/.

</details>


### [87] [A Hermetic, Transparent Soft Growing Vine Robot System for Pipe Inspection](https://arxiv.org/abs/2510.27010)
*William E. Heap,Yimeng Qin,Kai Hammond,Anish Bayya,Haonon Kong,Allison M. Okamura*

Main category: cs.RO

TL;DR: 设计并验证了一种密封透明的软体藤蔓机器人，用于管道内部无支管的视觉检测与测绘。


<details>
  <summary>Details</summary>
Motivation: 现有软体藤蔓机器人系统复杂且缺乏真实工业环境验证，限制了其在管道检测中的应用。

Method: 提出密封透明的机器人结构，将所有机械与电子元件封装于柔性透明体中，并设计被动自适应传感器封装端部。

Result: 在真实污水管道中成功完成视觉检测与测绘任务，验证了系统的密封性、透明性和实用性。

Conclusion: 该系统为软体藤蔓机器人在管道巡检中的实际部署提供了可靠且简化的解决方案，推动了其工程化应用。

Abstract: Rehabilitation of aging pipes requires accurate condition assessment and
mapping far into the pipe interiors. Soft growing vine robot systems are
particularly promising for navigating confined, sinuous paths such as in pipes,
but are currently limited by complex subsystems and a lack of validation in
real-world industrial settings. In this paper, we introduce the concept and
implementation of a hermetic and transparent vine robot system for visual
condition assessment and mapping within non-branching pipes. This design
encloses all mechanical and electrical components within the vine robot's soft,
airtight, and transparent body, protecting them from environmental interference
while enabling visual sensing. Because this approach requires an enclosed
mechanism for transporting sensors, we developed, modeled, and tested a
passively adapting enclosed tip mount. Finally, we validated the hermetic and
transparent vine robot system concept through a real-world condition assessment
and mapping task in a wastewater pipe. This work advances the use of
soft-growing vine robots in pipe inspection by developing and demonstrating a
robust, streamlined, field-validated system suitable for continued development
and deployment.

</details>


### [88] [A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics](https://arxiv.org/abs/2510.27033)
*Simindokht Jahangard,Mehrzad Mohammadi,Abhinav Dhall,Hamid Rezatofighi*

Main category: cs.RO

TL;DR: 提出一种结合全景图与3D点云的神经符号框架，提升机器人环境中的空间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在细粒度空间推理上表现不足，因依赖图像相关性而非显式建模空间逻辑关系

Method: 结合神经感知模块（检测实体与属性）与符号推理模块（构建场景图），利用全景图像和3D点云数据

Result: 在JRDB-Reasoning数据集上表现更优，准确可靠，且模型轻量，适用于机器人与具身AI

Conclusion: 神经符号框架能有效增强视觉语言模型的空间推理能力，为机器人应用提供可解释、高效的解决方案

Abstract: Visual reasoning, particularly spatial reasoning, is a challenging cognitive
task that requires understanding object relationships and their interactions
within complex environments, especially in robotics domain. Existing
vision_language models (VLMs) excel at perception tasks but struggle with
fine-grained spatial reasoning due to their implicit, correlation-driven
reasoning and reliance solely on images. We propose a novel neuro_symbolic
framework that integrates both panoramic-image and 3D point cloud information,
combining neural perception with symbolic reasoning to explicitly model spatial
and logical relationships. Our framework consists of a perception module for
detecting entities and extracting attributes, and a reasoning module that
constructs a structured scene graph to support precise, interpretable queries.
Evaluated on the JRDB-Reasoning dataset, our approach demonstrates superior
performance and reliability in crowded, human_built environments while
maintaining a lightweight design suitable for robotics and embodied AI
applications.

</details>


### [89] [SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation](https://arxiv.org/abs/2510.27048)
*Eric T. Chang,Peter Ballentine,Zhanpeng He,Do-Gon Kim,Kai Jiang,Hua-Hsuan Liang,Joaquin Palacios,William Wang,Pedro Piacenza,Ioannis Kymissis,Matei Ciocarlie*

Main category: cs.RO

TL;DR: SpikeATac是一种结合PVDF动态传感和电容静态传感的多模态触觉手指，可实现对脆弱物体的精细抓取与操作。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器难以同时捕捉快速动态响应与稳定静态信息，限制了机器人对脆弱物体的精细操作能力。

Method: 设计16单元PVDF+电容混合传感结构，采样率4kHz，结合强化学习与人类反馈优化力控策略。

Result: 成功实现对脆弱物体的稳定抓取和非传统在手操作任务，性能优于单一模态传感器。

Conclusion: SpikeATac为多模态触觉感知提供了新方案，显著提升机器人在接触密集任务中的操控性能。

Abstract: In this work, we introduce SpikeATac, a multimodal tactile finger combining a
taxelized and highly sensitive dynamic response (PVDF) with a static
transduction method (capacitive) for multimodal touch sensing. Named for its
`spiky' response, SpikeATac's 16-taxel PVDF film sampled at 4 kHz provides
fast, sensitive dynamic signals to the very onset and breaking of contact. We
characterize the sensitivity of the different modalities, and show that
SpikeATac provides the ability to stop quickly and delicately when grasping
fragile, deformable objects. Beyond parallel grasping, we show that SpikeATac
can be used in a learning-based framework to achieve new capabilities on a
dexterous multifingered robot hand. We use a learning recipe that combines
reinforcement learning from human feedback with tactile-based rewards to
fine-tune the behavior of a policy to modulate force. Our hardware platform and
learning pipeline together enable a difficult dexterous and contact-rich task
that has not previously been achieved: in-hand manipulation of fragile objects.
Videos are available at
\href{https://roamlab.github.io/spikeatac/}{roamlab.github.io/spikeatac}.

</details>


### [90] [Learning Generalizable Visuomotor Policy through Dynamics-Alignment](https://arxiv.org/abs/2510.27114)
*Dohyeok Lee,Jung Min Lee,Munkyung Kim,Seokhun Ju,Jin Woo Koo,Kyungjae Lee,Dohyeong Kim,TaeHyun Cho,Jungwoo Lee*

Main category: cs.RO

TL;DR: 提出DAP方法，通过策略与动力学模型互馈提升机器人模仿学习的泛化能力，尤其在视觉干扰和光照变化等OOB场景下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法数据依赖性强，视频预测模型虽能学习时空表征，但无法区分控制输入，限制精确操作且需大量预训练数据。

Method: 提出Dynamics-Aligned Flow Matching Policy (DAP)，构建策略与动力学模型互为校正的架构，实现动作生成中的自我修正。

Result: 在真实机器人操控任务中，DAP在泛化性能上超越基线方法，对视觉干扰和光照变化具有强鲁棒性。

Conclusion: DAP通过动力学对齐的流匹配机制，有效提升机器人策略的泛化能力与环境适应性，无需大规模预训练即可实现精准操控。

Abstract: Behavior cloning methods for robot learning suffer from poor generalization
due to limited data support beyond expert demonstrations. Recent approaches
leveraging video prediction models have shown promising results by learning
rich spatiotemporal representations from large-scale datasets. However, these
models learn action-agnostic dynamics that cannot distinguish between different
control inputs, limiting their utility for precise manipulation tasks and
requiring large pretraining datasets. We propose a Dynamics-Aligned Flow
Matching Policy (DAP) that integrates dynamics prediction into policy learning.
Our method introduces a novel architecture where policy and dynamics models
provide mutual corrective feedback during action generation, enabling
self-correction and improved generalization. Empirical validation demonstrates
generalization performance superior to baseline methods on real-world robotic
manipulation tasks, showing particular robustness in OOD scenarios including
visual distractions and lighting variations.

</details>


### [91] [Confined Space Underwater Positioning Using Collaborative Robots](https://arxiv.org/abs/2510.27151)
*Xueliang Cheng,Kanzhong Yao,Andrew West,Ognjen Marjanovic,Barry Lennox,Keir Groves*

Main category: cs.RO

TL;DR: 提出CAP系统，通过协作机器人与传感器融合实现无基础设施的水下精确定位，误差仅70mm。


<details>
  <summary>Details</summary>
Motivation: 现有水下定位系统在受限、复杂环境中因信号干扰、依赖外部设施和特征不足而失效，制约自主任务部署。

Method: 采用‘母船’概念，水面机器人作为移动先导，与水下机器人协作，融合传感器数据实现实时定位。

Result: 在大型水槽实验中，实现70mm平均欧氏距离误差，无需固定设施、校准或环境特征支持。

Conclusion: CAP系统突破了水下定位的技术瓶颈，为无基础设施环境下的可靠自主作业提供了实用解决方案。

Abstract: Positioning of underwater robots in confined and cluttered spaces remains a
key challenge for field operations. Existing systems are mostly designed for
large, open-water environments and struggle in industrial settings due to poor
coverage, reliance on external infrastructure, and the need for feature-rich
surroundings. Multipath effects from continuous sound reflections further
degrade signal quality, reducing accuracy and reliability. Accurate and easily
deployable positioning is essential for repeatable autonomous missions;
however, this requirement has created a technological bottleneck limiting
underwater robotic deployment. This paper presents the Collaborative Aquatic
Positioning (CAP) system, which integrates collaborative robotics and sensor
fusion to overcome these limitations. Inspired by the "mother-ship" concept,
the surface vehicle acts as a mobile leader to assist in positioning a
submerged robot, enabling localization even in GPS-denied and highly
constrained environments. The system is validated in a large test tank through
repeatable autonomous missions using CAP's position estimates for real-time
trajectory control. Experimental results demonstrate a mean Euclidean distance
(MED) error of 70 mm, achieved in real time without requiring fixed
infrastructure, extensive calibration, or environmental features. CAP leverages
advances in mobile robot sensing and leader-follower control to deliver a step
change in accurate, practical, and infrastructure-free underwater localization.

</details>


### [92] [MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking](https://arxiv.org/abs/2510.27178)
*Xuan-Thuan Nguyen,Khac Nam Nguyen,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Hoang Hiep Ly,Tung D. Ta*

Main category: cs.RO

TL;DR: MobiDock通过视觉导航和螺纹锁机制实现双机器人物理连接，提升稳定性和任务效率


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在协同控制与动态稳定性方面存在挑战

Method: 提出模块化可重构移动操作臂系统MobiDock，基于AprilTag视觉导航和螺纹锁机构实现自主对接

Result: 对接后系统在动态稳定性（更低RMS加速度和 jerk）和任务效率（更高角精度、更快完成时间）上显著优于独立协作机器人

Conclusion: 物理重构是简化协同控制、提升复杂任务性能的有效设计原则

Abstract: Multi-robot systems, particularly mobile manipulators, face challenges in
control coordination and dynamic stability when working together. To address
this issue, this study proposes MobiDock, a modular self-reconfigurable mobile
manipulator system that allows two independent robots to physically connect and
form a unified mobile bimanual platform. This process helps transform a complex
multi-robot control problem into the management of a simpler, single system.
The system utilizes an autonomous docking strategy based on computer vision
with AprilTag markers and a new threaded screw-lock mechanism. Experimental
results show that the docked configuration demonstrates better performance in
dynamic stability and operational efficiency compared to two independently
cooperating robots. Specifically, the unified system has lower Root Mean Square
(RMS) Acceleration and Jerk values, higher angular precision, and completes
tasks significantly faster. These findings confirm that physical
reconfiguration is a powerful design principle that simplifies cooperative
control, improving stability and performance for complex tasks in real-world
environments.

</details>


### [93] [Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets](https://arxiv.org/abs/2510.27184)
*Hoang Hiep Ly,Cong-Nhat Nguyen,Doan-Quang Tran,Quoc-Khanh Dang,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Xuan-Thuan Nguyen,Tung D. Ta*

Main category: cs.RO

TL;DR: 提出一种结合刚性外壳与可充气硅胶囊的混合夹爪指，通过调节气压改变表面摩擦力，实现安全抓取多种物体而无需增大夹持力。


<details>
  <summary>Details</summary>
Motivation: 传统夹爪依赖高法向力抓取物体，易损坏脆弱、光滑或重物。

Method: 设计混合夹爪指，采用刚性外壳与可充气硅胶囊结合，通过控制气压调节表面摩擦系数。

Result: 实验表明，气压增加成比例提升摩擦系数，可稳定抓取重物和滑物，并完好抓取鸡蛋、水果、纸杯等易损物。

Conclusion: 该设计通过调节摩擦而非增大夹持力，提供更安全、灵活的抓取方案，显著提升对多样物体的适应能力。

Abstract: Grasping objects with diverse mechanical properties, such as heavy, slippery,
or fragile items, remains a significant challenge in robotics. Conventional
grippers often rely on applying high normal forces, which can cause damage to
objects. To address this limitation, we present a hybrid gripper finger that
combines a rigid structural shell with a soft, inflatable silicone pocket. The
gripper finger can actively modulate its surface friction by controlling the
internal air pressure of the silicone pocket. Results from fundamental
experiments indicate that increasing the internal pressure results in a
proportional increase in the effective coefficient of friction. This enables
the gripper to stably lift heavy and slippery objects without increasing the
gripping force and to handle fragile or deformable objects, such as eggs,
fruits, and paper cups, with minimal damage by increasing friction rather than
applying excessive force. The experimental results demonstrate that the hybrid
gripper finger with adaptable friction provides a robust and safer alternative
to relying solely on high normal forces, thereby enhancing the gripper
flexibility in handling delicate, fragile, and diverse objects.

</details>


### [94] [Vectorized Online POMDP Planning](https://arxiv.org/abs/2510.27191)
*Marcus Hoerger,Muhammad Sudrajat,Hanna Kurniawati*

Main category: cs.RO

TL;DR: 提出了一种名为VOPP的向量化在线POMDP求解器，通过全向量化计算实现无依赖的并行化，比现有方法快20倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有POMDP求解器因动作优化与价值估计之间的依赖关系导致并行化困难，难以充分利用现代硬件的并行计算能力。

Method: VOPP采用新的POMDP形式化方法，解析求解部分优化组件，仅保留期望估计的数值计算，并将所有规划数据结构表示为张量，实现完全向量化的计算步骤。

Result: VOPP在计算近优解时比现有最先进的并行在线求解器效率提升至少20倍，且无并行计算间的依赖与同步瓶颈。

Conclusion: 通过向量化与解析优化结合，VOPP成功实现了高效并行POMDP规划，为实时自主机器人规划提供了新范式。

Abstract: Planning under partial observability is an essential capability of autonomous
robots. The Partially Observable Markov Decision Process (POMDP) provides a
powerful framework for planning under partial observability problems, capturing
the stochastic effects of actions and the limited information available through
noisy observations. POMDP solving could benefit tremendously from massive
parallelization of today's hardware, but parallelizing POMDP solvers has been
challenging. They rely on interleaving numerical optimization over actions with
the estimation of their values, which creates dependencies and synchronization
bottlenecks between parallel processes that can quickly offset the benefits of
parallelization. In this paper, we propose Vectorized Online POMDP Planner
(VOPP), a novel parallel online solver that leverages a recent POMDP
formulation that analytically solves part of the optimization component,
leaving only the estimation of expectations for numerical computation. VOPP
represents all data structures related to planning as a collection of tensors
and implements all planning steps as fully vectorized computations over this
representation. The result is a massively parallel solver with no dependencies
and synchronization bottlenecks between parallel computations. Experimental
results indicate that VOPP is at least 20X more efficient in computing
near-optimal solutions compared to an existing state-of-the-art parallel online
solver.

</details>


### [95] [A Modular and Scalable System Architecture for Heterogeneous UAV Swarms Using ROS 2 and PX4-Autopilot](https://arxiv.org/abs/2510.27327)
*Robert Pommeranz,Kevin Tebbe,Ralf Heynicke,Gerd Scholl*

Main category: cs.RO

TL;DR: 提出一种基于PX4和ROS 2的模块化、可扩展的异构无人机群反无人机系统架构，支持编队飞行与视觉检测，并在仿真与真实场景中验证。


<details>
  <summary>Details</summary>
Motivation: 需要一种灵活且可扩展的架构来应对异构无人机群在反无人机任务中的协同控制与模块集成挑战。

Method: 采用ROS 2节点化设计，独立封装无人机各硬件组件，抽象通信层以支持多种通信技术，集成视觉检测与地面站控制，实现领导跟随与编队飞行功能。

Result: 成功在Gazebo仿真与真实世界实验中验证了架构的可行性与稳定性。

Conclusion: 该架构为异构无人机群系统提供了模块化、可扩展、易集成的解决方案，适用于反无人机等复杂任务。

Abstract: In this paper a modular and scalable architecture for heterogeneous
swarm-based Counter Unmanned Aerial Systems (C-UASs) built on PX4-Autopilot and
Robot Operating System 2 (ROS 2) framework is presented. The proposed
architecture emphasizes seamless integration of hardware components by
introducing independent ROS 2 nodes for each component of a Unmanned Aerial
Vehicle (UAV). Communication between swarm participants is abstracted in
software, allowing the use of various technologies without architectural
changes. Key functionalities are supported, e.g. leader following and formation
flight to maneuver the swarm. The system also allows computer vision algorithms
to be integrated for the detection and tracking of UAVs. Additionally, a ground
station control is integrated for the coordination of swarm operations.
Swarm-based Unmanned Aerial System (UAS) architecture is verified within a
Gazebo simulation environment but also in real-world demonstrations.

</details>


### [96] [Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict](https://arxiv.org/abs/2510.27333)
*Hao Cheng,Yanbo Jiang,Qingyuan Shi,Qingwen Meng,Keyu Chen,Wenhao Yu,Jianqiang Wang,Sifa Zheng*

Main category: cs.RO

TL;DR: 提出改进的紧急指数MEI，更准确量化横向冲突风险，超越ACT和PET指标


<details>
  <summary>Details</summary>
Motivation: 现有安全评估指标主要关注纵向冲突，难以精准量化城市环境中普遍的横向冲突风险

Method: 提出Modified-Emergency Index (MEI)，优化避让时间估计，基于Argoverse-2数据集验证并对比ACT和PET

Result: MEI在量化关键性与捕捉风险演化上优于ACT和PET，验证了其在城市场景中的有效性

Conclusion: MEI是一种有前景的横向冲突评估指标，可提升自动驾驶安全评估框架，代码已开源

Abstract: Effective, reliable, and efficient evaluation of autonomous driving safety is
essential to demonstrate its trustworthiness. Criticality metrics provide an
objective means of assessing safety. However, as existing metrics primarily
target longitudinal conflicts, accurately quantifying the risks of lateral
conflicts - prevalent in urban settings - remains challenging. This paper
proposes the Modified-Emergency Index (MEI), a metric designed to quantify
evasive effort in lateral conflicts. Compared to the original Emergency Index
(EI), MEI refines the estimation of the time available for evasive maneuvers,
enabling more precise risk quantification. We validate MEI on a public lateral
conflict dataset based on Argoverse-2, from which we extract over 1,500
high-quality AV conflict cases, including more than 500 critical events. MEI is
then compared with the well-established ACT and the widely used PET metrics.
Results show that MEI consistently outperforms them in accurately quantifying
criticality and capturing risk evolution. Overall, these findings highlight MEI
as a promising metric for evaluating urban conflicts and enhancing the safety
assessment framework for autonomous driving. The open-source implementation is
available at https://github.com/AutoChengh/MEI.

</details>


### [97] [Towards a Multi-Embodied Grasping Agent](https://arxiv.org/abs/2510.27420)
*Roman Freiberg,Alexander Qualmann,Ngo Anh Vien,Gerhard Neumann*

Main category: cs.RO

TL;DR: 提出一种数据高效、基于流的等变抓取架构，支持多种夹爪类型，仅凭几何信息推断运动学模型，显著提升学习效率与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式学习机器人运动学结构，且因大规模数据获取困难而受限。

Method: 构建基于JAX的流式等变抓取架构，支持场景、夹爪和抓取的批处理，完全从几何信息中推导运动学模型。

Result: 在25,000场景和2000万抓取数据上验证，涵盖人手到平行夹爪等多种类型，实现更平滑学习、更高性能与更快推理。

Conclusion: 该架构有效解决多夹爪通用抓取的数据效率与泛化性问题，为异构机器人抓取提供新范式。

Abstract: Multi-embodiment grasping focuses on developing approaches that exhibit
generalist behavior across diverse gripper designs. Existing methods often
learn the kinematic structure of the robot implicitly and face challenges due
to the difficulty of sourcing the required large-scale data. In this work, we
present a data-efficient, flow-based, equivariant grasp synthesis architecture
that can handle different gripper types with variable degrees of freedom and
successfully exploit the underlying kinematic model, deducing all necessary
information solely from the gripper and scene geometry. Unlike previous
equivariant grasping methods, we translated all modules from the ground up to
JAX and provide a model with batching capabilities over scenes, grippers, and
grasps, resulting in smoother learning, improved performance and faster
inference time. Our dataset encompasses grippers ranging from humanoid hands to
parallel yaw grippers and includes 25,000 scenes and 20 million grasps.

</details>


### [98] [Learning Soft Robotic Dynamics with Active Exploration](https://arxiv.org/abs/2510.27428)
*Hehui Zheng,Bhavya Sukhija,Chenhao Li,Klemens Iten,Andreas Krause,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SoftAE通过不确定性驱动的主动探索，实现软机器人通用动力学建模，显著提升零样本控制性能。


<details>
  <summary>Details</summary>
Motivation: 软机器人动力学复杂，传统数据驱动方法泛化能力差，依赖特定任务演示或低效随机探索。

Method: SoftAE采用概率集成模型估计认知不确定性，主动引导探索未充分覆盖的状态-动作空间，无需任务监督。

Result: 在仿真与实物平台（连续臂、流体鱼、肌肉骨骼腿）上，SoftAE比随机探索和任务特定方法更准确，零样本控制更强，且对噪声、延迟和非线性具有鲁棒性。

Conclusion: 不确定性驱动的主动探索可为多种软机器人形态生成可扩展、可复用的动力学模型，推动弹性机器人实现更自主、高效的控制。

Abstract: Soft robots offer unmatched adaptability and safety in unstructured
environments, yet their compliant, high-dimensional, and nonlinear dynamics
make modeling for control notoriously difficult. Existing data-driven
approaches often fail to generalize, constrained by narrowly focused task
demonstrations or inefficient random exploration. We introduce SoftAE, an
uncertainty-aware active exploration framework that autonomously learns
task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE
employs probabilistic ensemble models to estimate epistemic uncertainty and
actively guides exploration toward underrepresented regions of the state-action
space, achieving efficient coverage of diverse behaviors without task-specific
supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a
continuum arm, an articulated fish in fluid, and a musculoskeletal leg with
hybrid actuation -- and on a pneumatically actuated continuum soft arm in the
real world. Compared with random exploration and task-specific model-based
reinforcement learning, SoftAE produces more accurate dynamics models, enables
superior zero-shot control on unseen tasks, and maintains robustness under
sensing noise, actuation delays, and nonlinear material effects. These results
demonstrate that uncertainty-driven active exploration can yield scalable,
reusable dynamics models across diverse soft robotic morphologies, representing
a step toward more autonomous, adaptable, and data-efficient control in
compliant robots.

</details>


### [99] [Preliminary Prototyping of Avoidance Behaviors Triggered by a User's Physical Approach to a Robot](https://arxiv.org/abs/2510.27436)
*Tomoko Yonezawa,Hirotake Yamazoe,Atsuo Fujino,Daigo Suhara,Takaya Tamamoto,Yuto Nishiguchi*

Main category: cs.RO

TL;DR: 设计机器人在人际距离过近时通过内态厌恶触发回避行为，基于PAD模型的主导性维度实现分级耐受与回避动作。


<details>
  <summary>Details</summary>
Motivation: 人类在社交中会根据关系和情境灵活应对待亲密接触，但机器人缺乏类似拒绝机制，导致交互不适。

Method: 用人际距离建模不适感的累积与衰减，结合PAD情绪模型的主导性轴，设计耐受与越界回避行为，并在机械臂上实现。

Result: 实现了从内部状态到分级耐受动作及回避行为的连贯流程，行为强度随距离动态变化。

Conclusion: 机器人可通过内部厌恶状态模拟人类的社交边界反应，提升交互自然性与接受度。

Abstract: Human-robot interaction frequently involves physical proximity or contact. In
human-human settings, people flexibly accept, reject, or tolerate such
approaches depending on the relationship and context. We explore the design of
a robot's rejective internal state and corresponding avoidance behaviors, such
as withdrawing or pushing away, when a person approaches. We model the
accumulation and decay of discomfort as a function of interpersonal distance,
and implement tolerance (endurance) and limit-exceeding avoidance driven by the
Dominance axis of the PAD affect model. The behaviors and their intensities are
realized on an arm robot. Results illustrate a coherent pipeline from internal
state parameters to graded endurance motions and, once a limit is crossed, to
avoidance actions.

</details>


### [100] [EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities](https://arxiv.org/abs/2510.27545)
*Travis Davies,Yiqi Huang,Alexi Gladstone,Yunxin Liu,Xiang Chen,Heng Ji,Huxian Liu,Luhui Hu*

Main category: cs.RO

TL;DR: EBT-Policy是一种基于能量的新型机器人策略架构，显著优于扩散策略，计算效率更高且具备零样本恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成模型的策略（如扩散策略）存在计算成本高、曝光偏差和推理不稳定等问题，能量模型（EBM）虽能缓解但难以扩展，需探索其在具身智能中的潜力。

Method: 提出EBT-Policy，结合能量基变换器（EBT）架构，通过端到端学习能量地形和平衡动力学实现高效推理。

Result: 在仿真与真实任务中，EBT-Policy性能超越扩散策略，推理步数减少50倍（仅需2步），并实现零样本失败恢复，无需重试训练。

Conclusion: EBT-Policy通过能量标量实现不确定性感知与动态计算分配，为机器人在分布偏移下的鲁棒与泛化行为提供了新路径。

Abstract: Implicit policies parameterized by generative models, such as Diffusion
Policy, have become the standard for policy learning and Vision-Language-Action
(VLA) models in robotics. However, these approaches often suffer from high
computational cost, exposure bias, and unstable inference dynamics, which lead
to divergence under distribution shifts. Energy-Based Models (EBMs) address
these issues by learning energy landscapes end-to-end and modeling equilibrium
dynamics, offering improved robustness and reduced exposure bias. Yet, policies
parameterized by EBMs have historically struggled to scale effectively. Recent
work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs
to high-dimensional spaces, but their potential for solving core challenges in
physically embodied models remains underexplored. We introduce a new
energy-based architecture, EBT-Policy, that solves core issues in robotic and
real-world settings. Across simulated and real-world tasks, EBT-Policy
consistently outperforms diffusion-based policies, while requiring less
training and inference computation. Remarkably, on some tasks it converges
within just two inference steps, a 50x reduction compared to Diffusion Policy's
100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior
models, such as zero-shot recovery from failed action sequences using only
behavior cloning and without explicit retry training. By leveraging its scalar
energy for uncertainty-aware inference and dynamic compute allocation,
EBT-Policy offers a promising path toward robust, generalizable robot behavior
under distribution shifts.

</details>


### [101] [Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs](https://arxiv.org/abs/2510.27558)
*Sushil Samuel Dinesh,Shinkyu Park*

Main category: cs.RO

TL;DR: 使用现成的预训练基础模型构建机器人操作框架，无需领域特定训练


<details>
  <summary>Details</summary>
Motivation: 减少对专用训练数据的依赖，利用通用基础模型提升机器人操作的灵活性和泛化能力

Method: 整合多模态感知基础模型与通用推理模型，通过动态场景图维持环境空间感知

Result: 在桌面操作实验中验证了框架的有效性，展示其直接基于现成基础模型构建机器人系统的潜力

Conclusion: 该框架为机器人操作提供了一种无需微调、基于通用基础模型的可行路径

Abstract: This paper presents a framework that leverages pre-trained foundation models
for robotic manipulation without domain-specific training. The framework
integrates off-the-shelf models, combining multimodal perception from
foundation models with a general-purpose reasoning model capable of robust task
sequencing. Scene graphs, dynamically maintained within the framework, provide
spatial awareness and enable consistent reasoning about the environment. The
framework is evaluated through a series of tabletop robotic manipulation
experiments, and the results highlight its potential for building robotic
manipulation systems directly on top of off-the-shelf foundation models.

</details>


### [102] [Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping](https://arxiv.org/abs/2510.27666)
*Dong Heon Han,Xiaohao Xu,Yuxi Chen,Yusheng Zhou,Xinqi Zhang,Jiaqi Wang,Daniel Bruder,Xiaonan Huang*

Main category: cs.RO

TL;DR: 受章鱼启发，提出一种模块化软体夹爪，通过分布式自感知气动执行器实现整体形态重构，显著提升抓取多样性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统软体夹爪形态固定，局部变形难以模拟生物系统的跨尺度自适应形变能力。

Method: 设计分布式自感知气动模块网络，实现整体拓扑重构与多形态控制，集成本体感知反馈实现形态智能切换。

Result: 扩展抓取包络，支持多种几何与尺度物体（达10倍尺度差异），实现多物体、内部钩挂等新抓取模式。

Conclusion: 该框架低成本、易制造、可扩展，为机器人实现生物级灵巧操作提供了新路径。

Abstract: Biological systems, such as the octopus, exhibit masterful cross-scale
manipulation by adaptively reconfiguring their entire form, a capability that
remains elusive in robotics. Conventional soft grippers, while compliant, are
mostly constrained by a fixed global morphology, and prior shape-morphing
efforts have been largely confined to localized deformations, failing to
replicate this biological dexterity. Inspired by this natural exemplar, we
introduce the paradigm of collaborative, whole-body proprioceptive morphing,
realized in a modular soft gripper architecture. Our design is a distributed
network of modular self-sensing pneumatic actuators that enables the gripper to
intelligently reconfigure its entire topology, achieving multiple morphing
states that are controllable to form diverse polygonal shapes. By integrating
rich proprioceptive feedback from embedded sensors, our system can seamlessly
transition from a precise pinch to a large envelope grasp. We experimentally
demonstrate that this approach expands the grasping envelope and enhances
generalization across diverse object geometries (standard and irregular) and
scales (up to 10$\times$), while also unlocking novel manipulation modalities
such as multi-object and internal hook grasping. This work presents a low-cost,
easy-to-fabricate, and scalable framework that fuses distributed actuation with
integrated sensing, offering a new pathway toward achieving biological levels
of dexterity in robotic manipulation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [103] [Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning](https://arxiv.org/abs/2510.26829)
*Svetlana Churina,Niranjan Chebrolu,Kokil Jaidka*

Main category: cs.LG

TL;DR: 持续预训练中的虚假信息重复曝光会导致大模型产生类似人类的错误信念漂移，即使少量污染数据也可能永久改变模型对事实的内部表征。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注静态预训练中的数据投毒，而持续预训练下模型是否因重复接触虚假陈述而内化错误信念尚未被探索，受人类“错觉真实效应”启发，本文提出此问题。

Method: 提出“Layer of Truth”框架与数据集，通过注入可控污染数据并探查不同检查点、模型规模和问题类型下的中间表征，量化事实信念的转移过程。

Result: 即使极少量虚假信息暴露，也会导致模型对已确立事实的表征发生持久漂移，且不同层和模型尺寸的敏感性存在差异。

Conclusion: 持续更新的大语言模型存在类似人类的错误信念内化风险，亟需在模型更新过程中加强事实完整性监控。

Abstract: Large language models (LLMs) continually evolve through pre-training on
ever-expanding web data, but this adaptive process also exposes them to subtle
forms of misinformation. While prior work has explored data poisoning during
static pre-training, the effects of such manipulations under continual
pre-training remain largely unexplored. Drawing inspiration from the illusory
truth effect in human cognition - where repeated exposure to falsehoods
increases belief in their accuracy - we ask whether LLMs exhibit a similar
vulnerability. We investigate whether repeated exposure to false but
confidently stated facts can shift a model's internal representation away from
the truth.
  We introduce Layer of Truth, a framework and dataset for probing belief
dynamics in continually trained LLMs. By injecting controlled amounts of
poisoned data and probing intermediate representations across checkpoints,
model scales, and question types, we quantify when and how factual beliefs
shift. Our findings reveal that even minimal exposure can induce persistent
representational drift in well-established facts, with susceptibility varying
across layers and model sizes. These results highlight an overlooked
vulnerability of continually updated LLMs: their capacity to internalize
misinformation analogously to humans, underscoring the need for robust
monitoring of factual integrity during model updates.

</details>


### [104] [SmoothGuard: Defending Multimodal Large Language Models with Noise Perturbation and Clustering Aggregation](https://arxiv.org/abs/2510.26830)
*Guangzhi Su,Shuchang Huang,Yutong Ke,Zhuohang Liu,Long Qian,Kaizhu Huang*

Main category: cs.LG

TL;DR: 提出SmoothGuard，通过随机噪声注入和聚类聚合提升多模态大模型对抗攻击的鲁棒性，同时保持性能


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型虽性能优异，但极易受对抗攻击影响，安全性和可靠性成隐患

Method: 在HuggingFace生态中生成对抗图像，提出SmoothGuard框架：对连续模态（如图像、音频）添加高斯噪声，生成多候选输出，基于嵌入聚类筛选并选取多数簇结果

Result: 在POPE、LLaVA-Bench和MM-SafetyBench上验证有效，显著提升对抗鲁棒性，最优噪声范围为0.1-0.2

Conclusion: SmoothGuard是一种轻量级、通用的防御方法，能在不牺牲效用的前提下增强MLLMs的对抗鲁棒性

Abstract: Multimodal large language models (MLLMs) have achieved impressive performance
across diverse tasks by jointly reasoning over textual and visual inputs.
Despite their success, these models remain highly vulnerable to adversarial
manipulations, raising concerns about their safety and reliability in
deployment. In this work, we first generalize an approach for generating
adversarial images within the HuggingFace ecosystem and then introduce
SmoothGuard, a lightweight and model-agnostic defense framework that enhances
the robustness of MLLMs through randomized noise injection and clustering-based
prediction aggregation. Our method perturbs continuous modalities (e.g., images
and audio) with Gaussian noise, generates multiple candidate outputs, and
applies embedding-based clustering to filter out adversarially influenced
predictions. The final answer is selected from the majority cluster, ensuring
stable responses even under malicious perturbations. Extensive experiments on
POPE, LLaVA-Bench (In-the-Wild), and MM-SafetyBench demonstrate that
SmoothGuard improves resilience to adversarial attacks while maintaining
competitive utility. Ablation studies further identify an optimal noise range
(0.1-0.2) that balances robustness and utility.

</details>


### [105] [Accurate Target Privacy Preserving Federated Learning Balancing Fairness and Utility](https://arxiv.org/abs/2510.26841)
*Kangkang Sun,Jun Wu,Minyi Guo,Jianhua Li,Jianwei Huang*

Main category: cs.LG

TL;DR: 提出FedPF算法，在联邦学习中通过零和博弈平衡隐私与公平，发现二者存在根本权衡， moderate公平约束可提升泛化但非单调，实验显示歧视降低42.9%。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中需同时保障隐私与公平，但二者存在内在冲突，现有方法难以兼顾。

Method: 设计差分隐私公平联邦学习算法FedPF，将隐私与公平约束建模为零和博弈，与模型效用竞争。

Result: 理论上揭示隐私增强限制公平检测能力；实验证明公平约束非单调影响性能，歧视减少达42.9%且保持高精度。

Conclusion: 隐私与公平不可兼得，需精细平衡妥协，而非单一优化。

Abstract: Federated Learning (FL) enables collaborative model training without data
sharing, yet participants face a fundamental challenge, e.g., simultaneously
ensuring fairness across demographic groups while protecting sensitive client
data. We introduce a differentially private fair FL algorithm (\textit{FedPF})
that transforms this multi-objective optimization into a zero-sum game where
fairness and privacy constraints compete against model utility. Our theoretical
analysis reveals a surprising inverse relationship, i.e., stricter privacy
protection fundamentally limits the system's ability to detect and correct
demographic biases, creating an inherent tension between privacy and fairness.
Counterintuitively, we prove that moderate fairness constraints initially
improve model generalization before causing performance degradation, where a
non-monotonic relationship that challenges conventional wisdom about
fairness-utility tradeoffs. Experimental validation demonstrates up to 42.9 %
discrimination reduction across three datasets while maintaining competitive
accuracy, but more importantly, reveals that the privacy-fairness tension is
unavoidable, i.e., achieving both objectives simultaneously requires carefully
balanced compromises rather than optimization of either in isolation. The
source code for our proposed algorithm is publicly accessible at
https://github.com/szpsunkk/FedPF.

</details>


### [106] [CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs](https://arxiv.org/abs/2510.26843)
*Zhiyuan Ning,Jiawei Shao,Ruge Xu,Xinfei Guo,Jun Zhang,Chi Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: 提出CAS-Spec方法，通过动态可切换推理加速策略和动态树级联算法，显著提升自推测解码的推理速度，平均加速1.1×至2.3×，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自推测解码方法速度提升有限，而多模型级联因训练成本高难以实用，亟需低成本、高效率的推理加速方案。

Method: 采用动态可切换推理加速（DSIA）构建推测模型，并提出动态树级联（DyTC）算法，根据接受率和延迟预测自适应路由多级草案模型与分配草案长度。

Result: CAS-Spec在多种LLM和数据集上实现平均1.1×–2.3×加速，DyTC较级联和树基基线分别提升47%和48%的速度。

Conclusion: CAS-Spec可轻松集成至现有LLM，具备良好扩展性，为未来自推测解码加速提供新方向。

Abstract: Speculative decoding has become a widely adopted as an effective technique
for lossless inference acceleration when deploying large language models
(LLMs). While on-the-fly self-speculative methods offer seamless integration
and broad utility, they often fall short of the speed gains achieved by methods
relying on specialized training. Cascading a hierarchy of draft models promises
further acceleration and flexibility, but the high cost of training multiple
models has limited its practical application. In this paper, we propose a novel
Cascade Adaptive Self-Speculative Decoding (CAS-Spec) method which constructs
speculative draft models by leveraging dynamically switchable inference
acceleration (DSIA) strategies, including layer sparsity and activation
quantization. Furthermore, traditional vertical and horizontal cascade
algorithms are inefficient when applied to self-speculative decoding methods.
We introduce a Dynamic Tree Cascade (DyTC) algorithm that adaptively routes the
multi-level draft models and assigns the draft lengths, based on the heuristics
of acceptance rates and latency prediction. Our CAS-Spec method achieves
state-of-the-art acceleration compared to existing on-the-fly speculative
decoding methods, with an average speedup from $1.1\times$ to $2.3\times$ over
autoregressive decoding across various LLMs and datasets. DyTC improves the
average speedup by $47$\% and $48$\% over cascade-based baseline and tree-based
baseline algorithms, respectively. CAS-Spec can be easily integrated into most
existing LLMs and holds promising potential for further acceleration as
self-speculative decoding techniques continue to evolve.

</details>


### [107] [BI-DCGAN: A Theoretically Grounded Bayesian Framework for Efficient and Diverse GANs](https://arxiv.org/abs/2510.26892)
*Mahsa Valizadeh,Rui Tuo,James Caverlee*

Main category: cs.LG

TL;DR: BI-DCGAN通过贝叶斯方法提升DCGAN的样本多样性与不确定性感知能力，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统GAN存在模式坍缩问题，难以捕捉完整数据分布，而现实应用需要多样性和不确定性感知。

Method: 提出BI-DCGAN，采用Bayes by Backprop和平均场变分推断学习网络权重分布，首次从协方差矩阵分析理论上证明贝叶斯建模能增强样本多样性。

Result: 实验表明BI-DCGAN在标准基准上比传统DCGAN生成更多样、更鲁棒的结果，且训练效率相当。

Conclusion: BI-DCGAN是一种可扩展的解决方案，适用于要求多样性与不确定性感知且扩散模型资源开销过高的场景。

Abstract: Generative Adversarial Networks (GANs) are proficient at generating synthetic
data but continue to suffer from mode collapse, where the generator produces a
narrow range of outputs that fool the discriminator but fail to capture the
full data distribution. This limitation is particularly problematic, as
generative models are increasingly deployed in real-world applications that
demand both diversity and uncertainty awareness. In response, we introduce
BI-DCGAN, a Bayesian extension of DCGAN that incorporates model uncertainty
into the generative process while maintaining computational efficiency.
BI-DCGAN integrates Bayes by Backprop to learn a distribution over network
weights and employs mean-field variational inference to efficiently approximate
the posterior distribution during GAN training. We establishes the first
theoretical proof, based on covariance matrix analysis, that Bayesian modeling
enhances sample diversity in GANs. We validate this theoretical result through
extensive experiments on standard generative benchmarks, demonstrating that
BI-DCGAN produces more diverse and robust outputs than conventional DCGANs,
while maintaining training efficiency. These findings position BI-DCGAN as a
scalable and timely solution for applications where both diversity and
uncertainty are critical, and where modern alternatives like diffusion models
remain too resource-intensive.

</details>


### [108] [Integrating Ontologies with Large Language Models for Enhanced Control Systems in Chemical Engineering](https://arxiv.org/abs/2510.26898)
*Crystal Su,Kuai Yu,Jingrui Zhang,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 提出一种融合本体论的大型语言模型框架，提升化学工程中生成模型的可解释性与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在化学工程领域缺乏结构化知识支撑，导致推理不透明且事实不可靠，需整合本体论提升其在过程控制与安全分析中的可信度。

Method: 通过数据获取、语义预处理、信息抽取和本体映射构建模板化问答对，结合控制解码与引文门控机制，约束输出为本体关联术语，并设计双维度评估指标。

Result: 实现了语言质量与本体准确性双优的生成结果，提升了模型在工程应用中的可审计性与可靠性。

Conclusion: 符号结构与神经生成的融合为化学工程关键任务提供了透明、可信的LLM应用新范式。

Abstract: This work presents an ontology-integrated large language model (LLM)
framework for chemical engineering that unites structured domain knowledge with
generative reasoning. The proposed pipeline aligns model training and inference
with the COPE ontology through a sequence of data acquisition, semantic
preprocessing, information extraction, and ontology mapping steps, producing
templated question-answer pairs that guide fine-tuning. A control-focused
decoding stage and citation gate enforce syntactic and factual grounding by
constraining outputs to ontology-linked terms, while evaluation metrics
quantify both linguistic quality and ontological accuracy. Feedback and future
extensions, including semantic retrieval and iterative validation, further
enhance the system's interpretability and reliability. This integration of
symbolic structure and neural generation provides a transparent, auditable
approach for applying LLMs to process control, safety analysis, and other
critical engineering contexts.

</details>


### [109] [Discovering EV Charging Site Archetypes Through Few Shot Forecasting: The First U.S.-Wide Study](https://arxiv.org/abs/2510.26910)
*Kshitij Nikhal,Luke Ackerknecht,Benjamin S. Riggan,Phil Stahlfeld*

Main category: cs.LG

TL;DR: 基于大规模充电数据，提出聚类与少样本预测结合的框架，提升未知充电站点需求预测精度，优化基础设施布局与电网韧性。


<details>
  <summary>Details</summary>
Motivation: 现有研究受限于小规模数据、简单的邻近建模和泛化能力差，难以支持电动汽车充电基础设施的精准规划。

Method: 结合聚类与少样本预测，利用大规模充电数据识别充电站点类型（archetype），并为每类构建专家预测模型。

Result: 针对站点类型的专家模型在未知站点上显著优于全局基线模型，实现更准确的需求预测。

Conclusion: 通过预测性能划分站点类型，可为运营商降低成本、优化能源与定价策略、增强电网韧性提供可操作的决策支持。

Abstract: The decarbonization of transportation relies on the widespread adoption of
electric vehicles (EVs), which requires an accurate understanding of charging
behavior to ensure cost-effective, grid-resilient infrastructure. Existing work
is constrained by small-scale datasets, simple proximity-based modeling of
temporal dependencies, and weak generalization to sites with limited
operational history. To overcome these limitations, this work proposes a
framework that integrates clustering with few-shot forecasting to uncover site
archetypes using a novel large-scale dataset of charging demand. The results
demonstrate that archetype-specific expert models outperform global baselines
in forecasting demand at unseen sites. By establishing forecast performance as
a basis for infrastructure segmentation, we generate actionable insights that
enable operators to lower costs, optimize energy and pricing strategies, and
support grid resilience critical to climate goals.

</details>


### [110] [MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models](https://arxiv.org/abs/2510.26937)
*Zimeng Huang,Jinxin Ke,Xiaoxuan Fan,Yufeng Yang,Yang Liu,Liu Zhonghan,Zedi Wang,Junteng Dai,Haoyi Jiang,Yuyu Zhou,Keze Wang,Ziliang Chen*

Main category: cs.LG

TL;DR: 提出MM-OPERA基准，评估大视觉语言模型的关联推理能力，突破现有封闭式评测局限，揭示其在创造性联想上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评测多限于封闭任务，无法捕捉开放场景中人类关键的关联推理能力，而关联是创造性思维与知识整合的核心。

Method: 构建MM-OPERA基准，包含11,497个开放任务实例（RIA与ICA），结合LLM-as-a-Judge策略进行过程奖励驱动的推理评估。

Result: 系统评估了最先进LVLMs在关联推理上的缺陷，揭示了其在多样性、文化、语言等维度上的局限性，验证了评估方法的有效性。

Conclusion: MM-OPERA为构建更接近人类智能的通用AI提供了新方向与评估体系，开源数据集推动未来研究。

Abstract: Large Vision-Language Models (LVLMs) have exhibited remarkable progress.
However, deficiencies remain compared to human intelligence, such as
hallucination and shallow pattern matching. In this work, we aim to evaluate a
fundamental yet underexplored intelligence: association, a cornerstone of human
cognition for creative thinking and knowledge integration. Current benchmarks,
often limited to closed-ended tasks, fail to capture the complexity of
open-ended association reasoning vital for real-world applications. To address
this, we present MM-OPERA, a systematic benchmark with 11,497 instances across
two open-ended tasks: Remote-Item Association (RIA) and In-Context Association
(ICA), aligning association intelligence evaluation with human psychometric
principles. It challenges LVLMs to resemble the spirit of divergent thinking
and convergent associative reasoning through free-form responses and explicit
reasoning paths. We deploy tailored LLM-as-a-Judge strategies to evaluate
open-ended outputs, applying process-reward-informed judgment to dissect
reasoning with precision. Extensive empirical studies on state-of-the-art
LVLMs, including sensitivity analysis of task instances, validity analysis of
LLM-as-a-Judge strategies, and diversity analysis across abilities, domains,
languages, cultures, etc., provide a comprehensive and nuanced understanding of
the limitations of current LVLMs in associative reasoning, paving the way for
more human-like and general-purpose AI. The dataset and code are available at
https://github.com/MM-OPERA-Bench/MM-OPERA.

</details>


### [111] [Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction](https://arxiv.org/abs/2510.26940)
*Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh*

Main category: cs.LG

TL;DR: 本文揭示了移动预测模型中存在的种族和族裔性能偏差，并提出一种轻量级采样方法FGIS以减少公平性差距，同时保持预测精度。


<details>
  <summary>Details</summary>
Motivation: 尽管移动预测模型广泛应用，但其对不同种族和族裔群体的公平性影响未被充分研究，存在系统性性能差距。

Method: 提出Fairness-Guided Incremental Sampling (FGIS)结合Size-Aware K-Means (SAKM)，利用人口普查数据在潜在空间中聚类用户并生成代理种族标签，优先采样以平衡群体表现。

Result: 在MetaPath2Vec和Transformer模型上，FGIS将组间性能差异最大降低40%，且在低数据阶段效果显著，整体精度损失极小。

Conclusion: 移动预测管道存在结构性不平等，通过数据中心的轻量干预可有效提升公平性，尤其适合低资源应用场景。

Abstract: Next location prediction underpins a growing number of mobility, retail, and
public-health applications, yet its societal impacts remain largely unexplored.
In this paper, we audit state-of-the-art mobility prediction models trained on
a large-scale dataset, highlighting hidden disparities based on user
demographics. Drawing from aggregate census data, we compute the difference in
predictive performance on racial and ethnic user groups and show a systematic
disparity resulting from the underlying dataset, resulting in large differences
in accuracy based on location and user groups. To address this, we propose
Fairness-Guided Incremental Sampling (FGIS), a group-aware sampling strategy
designed for incremental data collection settings. Because individual-level
demographic labels are unavailable, we introduce Size-Aware K-Means (SAKM), a
clustering method that partitions users in latent mobility space while
enforcing census-derived group proportions. This yields proxy racial labels for
the four largest groups in the state: Asian, Black, Hispanic, and White. Built
on these labels, our sampling algorithm prioritizes users based on expected
performance gains and current group representation. This method incrementally
constructs training datasets that reduce demographic performance gaps while
preserving overall accuracy. Our method reduces total disparity between groups
by up to 40\% with minimal accuracy trade-offs, as evaluated on a state-of-art
MetaPath2Vec model and a transformer-encoder model. Improvements are most
significant in early sampling stages, highlighting the potential for
fairness-aware strategies to deliver meaningful gains even in low-resource
settings. Our findings expose structural inequities in mobility prediction
pipelines and demonstrate how lightweight, data-centric interventions can
improve fairness with little added complexity, especially for low-data
applications.

</details>


### [112] [Can machines think efficiently?](https://arxiv.org/abs/2510.26954)
*Adam Winchell*

Main category: cs.LG

TL;DR: 提出一种基于能耗约束的新型图灵测试，以评估人工智能的效率与资源代价


<details>
  <summary>Details</summary>
Motivation: 传统图灵测试已过时，AI虽能通过但带来伦理与环境问题，亟需更实际的评估标准

Method: 在原模仿游戏中加入能量消耗作为约束条件，衡量智能系统的资源效率

Result: 新测试提供了可度量、可操作的评估终点，迫使社会权衡AI的时间收益与资源成本

Conclusion: 智能评估应从抽象能力转向效率与可持续性，能耗约束是未来AI评价的关键维度

Abstract: The Turing Test is no longer adequate for distinguishing human and machine
intelligence. With advanced artificial intelligence systems already passing the
original Turing Test and contributing to serious ethical and environmental
concerns, we urgently need to update the test. This work expands upon the
original imitation game by accounting for an additional factor: the energy
spent answering the questions. By adding the constraint of energy, the new test
forces us to evaluate intelligence through the lens of efficiency, connecting
the abstract problem of thinking to the concrete reality of finite resources.
Further, this proposed new test ensures the evaluation of intelligence has a
measurable, practical finish line that the original test lacks. This additional
constraint compels society to weigh the time savings of using artificial
intelligence against its total resource cost.

</details>


### [113] [Predicting Household Water Consumption Using Satellite and Street View Images in Two Indian Cities](https://arxiv.org/abs/2510.26957)
*Qiao Wang,Joseph George*

Main category: cs.LG

TL;DR: 利用公开卫星图像和谷歌街景数据，结合地理空间变量，准确预测印度胡布利-达尔瓦德地区的家庭用水量，接近传统调查方法的精度。


<details>
  <summary>Details</summary>
Motivation: 传统家庭用水调查成本高、耗时长，急需低成本替代方法。

Method: 采用CNN嵌入和谷歌街景语义分割，结合夜光强度和人口密度等地理空间数据，构建序数分类模型进行预测。

Result: GSV语义分割+遥感协变量模型达到0.55准确率，接近调查基准（0.59），在用水高低端预测精准，中产阶级因视觉代理重叠易混淆。

Conclusion: 开放获取的影像与少量地理数据可作为可靠替代方案，用于城市地区家庭用水估计。

Abstract: Monitoring household water use in rapidly urbanizing regions is hampered by
costly, time-intensive enumeration methods and surveys. We investigate whether
publicly available imagery-satellite tiles, Google Street View (GSV)
segmentation-and simple geospatial covariates (nightlight intensity, population
density) can be utilized to predict household water consumption in
Hubballi-Dharwad, India. We compare four approaches: survey features
(benchmark), CNN embeddings (satellite, GSV, combined), and GSV semantic maps
with auxiliary data. Under an ordinal classification framework, GSV
segmentation plus remote-sensing covariates achieves 0.55 accuracy for water
use, approaching survey-based models (0.59 accuracy). Error analysis shows high
precision at extremes of the household water consumption distribution, but
confusion among middle classes is due to overlapping visual proxies. We also
compare and contrast our estimates for household water consumption to that of
household subjective income. Our findings demonstrate that open-access imagery,
coupled with minimal geospatial data, offers a promising alternative to
obtaining reliable household water consumption estimates using surveys in urban
analytics.

</details>


### [114] [Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget](https://arxiv.org/abs/2510.26981)
*Zhichao Hou,Weizhi Gao,Xiaorui Liu*

Main category: cs.LG

TL;DR: 在有限算力下通过细粒度重计算激活值提升对抗攻击效率


<details>
  <summary>Details</summary>
Motivation: 减少迭代次数会显著降低攻击效果，需在固定算力预算下最大化攻击强度

Method: 提出一种跨迭代和层维度的细粒度激活重计算机制

Result: 在同等成本下优于基线方法，结合对抗训练时仅用30%预算达到原效果

Conclusion: 细粒度控制激活重计算可显著提升算力受限下的对抗攻击效率

Abstract: This work tackles a critical challenge in AI safety research under limited
compute: given a fixed computation budget, how can one maximize the strength of
iterative adversarial attacks? Coarsely reducing the number of attack
iterations lowers cost but substantially weakens effectiveness. To fulfill the
attainable attack efficacy within a constrained budget, we propose a
fine-grained control mechanism that selectively recomputes layer activations
across both iteration-wise and layer-wise levels. Extensive experiments show
that our method consistently outperforms existing baselines at equal cost.
Moreover, when integrated into adversarial training, it attains comparable
performance with only 30% of the original budget.

</details>


### [115] [HADSF: Aspect Aware Semantic Control for Explainable Recommendation](https://arxiv.org/abs/2510.26994)
*Zheng Nie,Peijie Sun*

Main category: cs.LG

TL;DR: 提出HADSF框架，通过两阶段语义提取和新指标ADR/OFR，降低LLM幻觉对推荐系统的影响，提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评论提取中缺乏范围控制、忽略幻觉与下游效果的关联、未探索模型规模与质量的权衡。

Method: HADSF框架：先自适应构建语义词表，再基于词表约束提取结构化方面-观点三元组，并引入ADR和OFR评估幻觉。

Result: 在300万条评论上验证，HADSF降低预测误差，小模型性能接近大模型，且揭示幻觉严重性与预测误差呈非单调关系。

Conclusion: HADSF有效提升推荐系统可解释性与效率，支持可重现研究，适用于资源受限场景。

Abstract: Recent advances in large language models (LLMs) promise more effective
information extraction for review-based recommender systems, yet current
methods still (i) mine free-form reviews without scope control, producing
redundant and noisy representations, (ii) lack principled metrics that link LLM
hallucination to downstream effectiveness, and (iii) leave the cost-quality
trade-off across model scales largely unexplored. We address these gaps with
the Hyper-Adaptive Dual-Stage Semantic Framework (HADSF), a two-stage approach
that first induces a compact, corpus-level aspect vocabulary via adaptive
selection and then performs vocabulary-guided, explicitly constrained
extraction of structured aspect-opinion triples. To assess the fidelity of the
resulting representations, we introduce Aspect Drift Rate (ADR) and Opinion
Fidelity Rate (OFR) and empirically uncover a nonmonotonic relationship between
hallucination severity and rating prediction error. Experiments on
approximately 3 million reviews across LLMs spanning 1.5B-70B parameters show
that, when integrated into standard rating predictors, HADSF yields consistent
reductions in prediction error and enables smaller models to achieve
competitive performance in representative deployment scenarios. We release
code, data pipelines, and metric implementations to support reproducible
research on hallucination-aware, LLM-enhanced explainable recommendation. Code
is available at https://github.com/niez233/HADSF

</details>


### [116] [Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules](https://arxiv.org/abs/2510.26997)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 将学习规则视为导航损失景观的策略，通过最优控制理论统一解释多种优化算法的来源与优化性。


<details>
  <summary>Details</summary>
Motivation: 现有学习规则多为假设而来，缺乏理论依据，不清楚为何某些规则更优以及在何种假设下最优。

Method: 将学习规则建模为部分可观测损失景观中的策略问题，通过最优控制框架推导出不同假设下的最优更新规则。

Result: 梯度下降、动量、自然梯度、Adam等经典算法均由此框架自然导出，且持续学习中的权重重置也被解释为对任务不确定性的最优响应。

Conclusion: 该框架为学习规则提供了统一的理论基础，揭示了学习的计算结构，可指导设计更优的自适应优化算法。

Abstract: Learning rules -- prescriptions for updating model parameters to improve
performance -- are typically assumed rather than derived. Why do some learning
rules work better than others, and under what assumptions can a given rule be
considered optimal? We propose a theoretical framework that casts learning
rules as policies for navigating (partially observable) loss landscapes, and
identifies optimal rules as solutions to an associated optimal control problem.
A range of well-known rules emerge naturally within this framework under
different assumptions: gradient descent from short-horizon optimization,
momentum from longer-horizon planning, natural gradients from accounting for
parameter space geometry, non-gradient rules from partial controllability, and
adaptive optimizers like Adam from online Bayesian inference of loss landscape
shape. We further show that continual learning strategies like weight resetting
can be understood as optimal responses to task uncertainty. By unifying these
phenomena under a single objective, our framework clarifies the computational
structure of learning and offers a principled foundation for designing adaptive
algorithms.

</details>


### [117] [A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms](https://arxiv.org/abs/2510.27001)
*Elise Wolf*

Main category: cs.LG

TL;DR: 本文提出一个可重复的评估框架，用于系统比较经典与方差感知型多臂强盗算法，并揭示方差感知算法在高不确定性环境下更具优势。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准化评估条件，多臂强盗算法的性能难以可靠比较，特别是方差感知算法对环境高度敏感。

Method: 设计了一个可重复的评估框架（Bandit Playground），包含8种算法、多维度指标（奖励、 regrets、价值风险等）和交互式界面。

Result: 方差感知算法在臂奖励差异细微的高不确定性环境中表现更优；经典算法在奖励分布分明或经调优时表现相当或更好。

Conclusion: 贡献在于：1）系统评估框架；2）明确了方差感知算法的优势场景。

Abstract: Multi-armed bandit (MAB) problems serve as a fundamental building block for
more complex reinforcement learning algorithms. However, evaluating and
comparing MAB algorithms remains challenging due to the lack of standardized
conditions and replicability. This is particularly problematic for
variance-aware extensions of classical methods like UCB, whose performance can
heavily depend on the underlying environment. In this study, we address how
performance differences between bandit algorithms can be reliably observed, and
under what conditions variance-aware algorithms outperform classical ones. We
present a reproducible evaluation designed to systematically compare eight
classical and variance-aware MAB algorithms. The evaluation framework,
implemented in our Bandit Playground codebase, features clearly defined
experimental setups, multiple performance metrics (reward, regret, reward
distribution, value-at-risk, and action optimality), and an interactive
evaluation interface that supports consistent and transparent analysis. We show
that variance-aware algorithms can offer advantages in settings with high
uncertainty where the difficulty arises from subtle differences between arm
rewards. In contrast, classical algorithms often perform equally well or better
in more separable scenarios or if fine-tuned extensively. Our contributions are
twofold: (1) a framework for systematic evaluation of MAB algorithms, and (2)
insights into the conditions under which variance-aware approaches outperform
their classical counterparts.

</details>


### [118] [Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase](https://arxiv.org/abs/2510.27002)
*Mihir Mahajan,Alfred Nguyen,Franz Srambical,Stefan Bauer*

Main category: cs.LG

TL;DR: Jasmine是一个基于JAX的高效世界建模代码库，支持跨多加速器扩展，显著加快训练速度并确保可复现性。


<details>
  <summary>Details</summary>
Motivation: 现有世界建模的开放训练基础设施不足，难以应对数据稀缺问题，亟需高效、可扩展且可复现的解决方案。

Method: 提出Jasmine，基于JAX实现性能优化，涵盖数据加载、训练和检查点机制，支持分布式sharding配置。

Result: 在CoinRun案例中，训练速度比先前开源实现快一个数量级，且支持大规模数据集与严格基准测试。

Conclusion: Jasmine为世界建模提供了可扩展、可复现的基础设施，推动模型比较与架构分析的标准化。

Abstract: While world models are increasingly positioned as a pathway to overcoming
data scarcity in domains such as robotics, open training infrastructure for
world modeling remains nascent. We introduce Jasmine, a performant JAX-based
world modeling codebase that scales from single hosts to hundreds of
accelerators with minimal code changes. Jasmine achieves an order-of-magnitude
faster reproduction of the CoinRun case study compared to prior open
implementations, enabled by performance optimizations across data loading,
training and checkpointing. The codebase guarantees fully reproducible training
and supports diverse sharding configurations. By pairing Jasmine with curated
large-scale datasets, we establish infrastructure for rigorous benchmarking
pipelines across model families and architectural ablations.

</details>


### [119] [Mixture-of-Transformers Learn Faster: A Theoretical Study on Classification Problems](https://arxiv.org/abs/2510.27004)
*Hongbo Li,Qinhang Wu,Sen Lin,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: 本文提出Mixture-of-Transformers（MoT）框架，首次从理论上统一解释Transformer级别专家特化与学习动态，并证明其收敛速度显著优于单Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 现有Mixture-of-Experts模型缺乏对feed-forward和attention层同时特化的统一理论解释。

Method: 引入MoT框架，每个Transformer块作为专家，由连续训练的门控网络控制，提出三阶段训练算法，分析专家特化与注意力对齐机制。

Result: 专家各自专精不同任务，门控网络精准路由；梯度冲突减少，子任务强凸；收敛速度提升至O(log(ε⁻¹))，远优于O(ε⁻¹)；实验证实有效性。

Conclusion: 首次提供Transformer层级特化的统一理论框架，为高效大模型设计提供理论依据与实践指导。

Abstract: Mixture-of-Experts (MoE) models improve transformer efficiency but lack a
unified theoretical explanation, especially when both feed-forward and
attention layers are allowed to specialize. To this end, we study the
Mixture-of-Transformers (MoT), a tractable theoretical framework in which each
transformer block acts as an expert governed by a continuously trained gating
network. This design allows us to isolate and study the core learning dynamics
of expert specialization and attention alignment. In particular, we develop a
three-stage training algorithm with continuous training of the gating network,
and show that each transformer expert specializes in a distinct class of tasks
and that the gating network accurately routes data samples to the correct
expert. Our analysis shows how expert specialization reduces gradient conflicts
and makes each subtask strongly convex. We prove that the training drives the
expected prediction loss to near zero in $O(\log(\epsilon^{-1}))$ iteration
steps, significantly improving over the $O(\epsilon^{-1})$ rate for a single
transformer. We further validate our theoretical findings through extensive
real-data experiments, demonstrating the practical effectiveness of MoT.
Together, these results offer the first unified theoretical account of
transformer-level specialization and learning dynamics, providing practical
guidance for designing efficient large-scale models.

</details>


### [120] [Enhancing Sentiment Classification with Machine Learning and Combinatorial Fusion](https://arxiv.org/abs/2510.27014)
*Sean Patten,Pin-Yu Chen,Christina Schweikert,D. Frank Hsu*

Main category: cs.LG

TL;DR: 通过组合融合分析（CFA）整合多种机器学习模型，在IMDB数据集上达到97.072%的最高准确率，高效利用计算资源。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖扩大单模型规模，计算成本高，亟需更高效的集成策略。

Method: 采用组合融合分析（CFA），利用排序-得分特征函数量化模型多样性，融合RoBERTa、随机森林、SVM和XGBoost的预测结果。

Result: 在IMDB数据集上实现97.072%的准确率，超越传统集成方法。

Conclusion: CFA通过挖掘模型多样性而非扩大模型规模，实现了更高精度与更低计算开销的平衡。

Abstract: This paper presents a novel approach to sentiment classification using the
application of Combinatorial Fusion Analysis (CFA) to integrate an ensemble of
diverse machine learning models, achieving state-of-the-art accuracy on the
IMDB sentiment analysis dataset of 97.072\%. CFA leverages the concept of
cognitive diversity, which utilizes rank-score characteristic functions to
quantify the dissimilarity between models and strategically combine their
predictions. This is in contrast to the common process of scaling the size of
individual models, and thus is comparatively efficient in computing resource
use. Experimental results also indicate that CFA outperforms traditional
ensemble methods by effectively computing and employing model diversity. The
approach in this paper implements the combination of a transformer-based model
of the RoBERTa architecture with traditional machine learning models, including
Random Forest, SVM, and XGBoost.

</details>


### [121] [Quantitative Bounds for Length Generalization in Transformers](https://arxiv.org/abs/2510.27015)
*Zachary Izzo,Eshaan Nichani,Jason D. Lee*

Main category: cs.LG

TL;DR: 首次量化了Transformer长度泛化所需的训练序列长度阈值，证明在不同设定下泛化依赖于短序列对长序列行为的模拟能力。


<details>
  <summary>Details</summary>
Motivation: 先前研究知道Transformer在训练长度超过某阈值后能实现长度泛化，但不知所需长度具体多大。

Method: 在多种设定下（如ℓ∞与平均误差控制、无限与有限精度注意力、单双层Transformer）分析泛化机制，证明泛化依赖于短序列对长序列行为的可模拟性。

Result: 给出了首个量化训练长度的理论边界，并通过实验验证了这些边界。

Conclusion: 理论加深了对Transformer外推机制的理解，证实复杂任务需要更丰富的训练数据。

Abstract: We study the problem of length generalization (LG) in transformers: the
ability of a model trained on shorter sequences to maintain performance when
evaluated on much longer, previously unseen inputs. Prior work by Huang et al.
(2025) established that transformers eventually achieve length generalization
once the training sequence length exceeds some finite threshold, but left open
the question of how large it must be. In this work, we provide the first
quantitative bounds on the required training length for length generalization
to occur. Motivated by previous empirical and theoretical work, we analyze LG
in several distinct problem settings: $\ell_\infty$ error control vs. average
error control over an input distribution, infinite-precision softmax attention
vs. finite-precision attention (which reduces to an argmax) in the transformer,
and one- vs. two-layer transformers. In all scenarios, we prove that LG occurs
when the internal behavior of the transformer on longer sequences can be
"simulated" by its behavior on shorter sequences seen during training. Our
bounds give qualitative estimates for the length of training data required for
a transformer to generalize, and we verify these insights empirically. These
results sharpen our theoretical understanding of the mechanisms underlying
extrapolation in transformers, and formalize the intuition that richer training
data is required for generalization on more complex tasks.

</details>


### [122] [Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](https://arxiv.org/abs/2510.27044)
*Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: RLVR提升数学推理评估指标，但常依赖表面启发式而非真实推理策略。


<details>
  <summary>Details</summary>
Motivation: 探讨RLVR是否真正提升大语言模型的数学推理能力，而非仅利用捷径。

Method: 在两个组合问题（活动调度和最长递增子序列）上，使用具有唯一最优解的数据集测试多种奖励设计下的RLVR。

Result: RLVR改善评估指标，但多通过强化表面启发式实现，未学习新推理策略。

Conclusion: 当前RLVR泛化能力有限，亟需能区分真实推理与捷径依赖的基准评测。

Abstract: Mathematical reasoning is a central challenge for large language models
(LLMs), requiring not only correct answers but also faithful reasoning
processes. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as
a promising approach for enhancing such capabilities; however, its ability to
foster genuine reasoning remains unclear. We investigate RLVR on two
combinatorial problems with fully verifiable solutions: \emph{Activity
Scheduling} and the \emph{Longest Increasing Subsequence}, using carefully
curated datasets with unique optima. Across multiple reward designs, we find
that RLVR improves evaluation metrics but often by reinforcing superficial
heuristics rather than acquiring new reasoning strategies. These findings
highlight the limits of RLVR generalization, emphasizing the importance of
benchmarks that disentangle genuine mathematical reasoning from shortcut
exploitation and provide faithful measures of progress. Code available at
https://github.com/xashru/rlvr-seq-generalization.

</details>


### [123] [Consistency Training Helps Stop Sycophancy and Jailbreaks](https://arxiv.org/abs/2510.27062)
*Alex Irpan,Alexander Matt Turner,Mark Kurzeja,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 一致性训练通过使模型对提示中无关扰动不变，有效减少模型的迎合行为和越狱攻击，无需依赖静态数据集。


<details>
  <summary>Details</summary>
Motivation: 当前LLM易受提示中无关信息（如诱导性文本或越狱指令）影响，导致事实错误或不当响应，传统训练依赖静态数据集存在滞后与退化问题。

Method: 提出两种一致性训练方法：BCT（基于外部输出的一致性）和ACT（基于内部激活的一致性），通过自监督方式训练模型对提示扰动保持行为稳定。

Result: BCT与ACT均显著降低Gemini 2.5 Flash对无关提示的敏感性，BCT在抑制越狱方面表现更优，且避免了静态数据集带来的能力退化。

Conclusion: 某些对齐问题本质是一致性问题，应从行为稳定性而非最优响应角度重构训练范式，BCT有望简化对齐训练流程。

Abstract: An LLM's factuality and refusal training can be compromised by simple changes
to a prompt. Models often adopt user beliefs (sycophancy) or satisfy
inappropriate requests which are wrapped within special text (jailbreaking). We
explore \emph{consistency training}, a self-supervised paradigm that teaches a
model to be invariant to certain irrelevant cues in the prompt. Instead of
teaching the model what exact response to give on a particular prompt, we aim
to teach the model to behave identically across prompt data augmentations (like
adding leading questions or jailbreak text). We try enforcing this invariance
in two ways: over the model's external outputs (\emph{Bias-augmented
Consistency Training} (BCT) from Chua et al. [2025]) and over its internal
activations (\emph{Activation Consistency Training} (ACT), a method we
introduce). Both methods reduce Gemini 2.5 Flash's susceptibility to irrelevant
cues. Because consistency training uses responses from the model itself as
training data, it avoids issues that arise from stale training data, such as
degrading model capabilities or enforcing outdated response guidelines. While
BCT and ACT reduce sycophancy equally well, BCT does better at jailbreak
reduction. We think that BCT can simplify training pipelines by removing
reliance on static datasets. We argue that some alignment problems are better
viewed not in terms of optimal responses, but rather as consistency issues.

</details>


### [124] [Towards a Measure of Algorithm Similarity](https://arxiv.org/abs/2510.27063)
*Shairoz Sohail,Taher Ali*

Main category: cs.LG

TL;DR: 提出EMOC框架评估算法相似性，构建PACD数据集，支持聚类、去重和LLM生成程序多样性量化。


<details>
  <summary>Details</summary>
Motivation: 现有算法相似性度量方法缺乏一致性，但在代码克隆检测和程序合成等场景中亟需实用且一致的相似性指标。

Method: 引入EMOC框架（评估-内存-操作-复杂度），将算法实现嵌入特征空间，并构建PACD数据集验证其有效性。

Result: EMOC特征能有效聚类算法类型、检测近重复代码、量化LLM生成程序的多样性。

Conclusion: EMOC提供了一种可复现、实用的算法相似性评估方法，推动相关领域研究。

Abstract: Given two algorithms for the same problem, can we determine whether they are
meaningfully different? In full generality, the question is uncomputable, and
empirically it is muddied by competing notions of similarity. Yet, in many
applications (such as clone detection or program synthesis) a pragmatic and
consistent similarity metric is necessary. We review existing equivalence and
similarity notions and introduce EMOC: An
Evaluation-Memory-Operations-Complexity framework that embeds algorithm
implementations into a feature space suitable for downstream tasks. We compile
PACD, a curated dataset of verified Python implementations across three
problems, and show that EMOC features support clustering and classification of
algorithm types, detection of near-duplicates, and quantification of diversity
in LLM-generated programs. Code, data, and utilities for computing EMOC
embeddings are released to facilitate reproducibility and future work on
algorithm similarity.

</details>


### [125] [MLPerf Automotive](https://arxiv.org/abs/2510.27065)
*Radoyeh Shojaei,Predrag Djurdjevic,Mostafa El-Khamy,James Goel,Kasper Mecklenburg,John Owens,Pınar Muyan-Özçelik,Tom St. John,Jinho Suh,Arjun Suresh*

Main category: cs.LG

TL;DR: MLPerf Automotive 是首个用于评估汽车AI加速系统的标准化公共基准，涵盖2D/3D目标检测与语义分割任务。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法满足汽车系统对安全性和实时处理的独特要求，亟需专用评估标准。

Method: 构建包含任务选择、参考模型和提交规则的基准框架，提供延迟与精度指标以实现跨平台可比性。

Result: 完成首轮基准提交，公开代码与数据集，验证了框架在汽车感知任务中的可行性。

Conclusion: MLPerf Automotive 为汽车ML系统提供了标准化评估工具，推动行业性能比较与技术进步。

Abstract: We present MLPerf Automotive, the first standardized public benchmark for
evaluating Machine Learning systems that are deployed for AI acceleration in
automotive systems. Developed through a collaborative partnership between
MLCommons and the Autonomous Vehicle Computing Consortium, this benchmark
addresses the need for standardized performance evaluation methodologies in
automotive machine learning systems. Existing benchmark suites cannot be
utilized for these systems since automotive workloads have unique constraints
including safety and real-time processing that distinguish them from the
domains that previously introduced benchmarks target. Our benchmarking
framework provides latency and accuracy metrics along with evaluation protocols
that enable consistent and reproducible performance comparisons across
different hardware platforms and software implementations. The first iteration
of the benchmark consists of automotive perception tasks in 2D object
detection, 2D semantic segmentation, and 3D object detection. We describe the
methodology behind the benchmark design including the task selection, reference
models, and submission rules. We also discuss the first round of benchmark
submissions and the challenges involved in acquiring the datasets and the
engineering efforts to develop the reference implementations. Our benchmark
code is available at https://github.com/mlcommons/mlperf_automotive.

</details>


### [126] [Towards Understanding Self-play for LLM Reasoning](https://arxiv.org/abs/2510.27072)
*Justin Yang Chae,Md Tanvirul Alam,Nidhi Rastogi*

Main category: cs.LG

TL;DR: 分析自博弈后训练在大语言模型数学推理中的动态机制，对比RLVR与监督微调，揭示其优势与局限。


<details>
  <summary>Details</summary>
Motivation: 尽管自博弈在领域内和跨领域推理上表现良好，但其改进机制尚不清晰，亟需系统性分析。

Method: 通过绝对零推理器框架，研究参数更新稀疏性、token分布熵动态及替代奖励函数，并结合pass@k评估推理性能。

Result: 揭示了自博弈与RLVR、SFT在训练动态上的本质差异，指出其潜在瓶颈与改进方向。

Conclusion: 自博弈虽有效，但存在内在限制，未来需优化奖励设计与探索更高效的自我生成-求解机制。

Abstract: Recent advances in large language model (LLM) reasoning, led by reinforcement
learning with verifiable rewards (RLVR), have inspired self-play post-training,
where models improve by generating and solving their own problems. While
self-play has shown strong in-domain and out-of-domain gains, the mechanisms
behind these improvements remain poorly understood. In this work, we analyze
the training dynamics of self-play through the lens of the Absolute Zero
Reasoner, comparing it against RLVR and supervised fine-tuning (SFT). Our study
examines parameter update sparsity, entropy dynamics of token distributions,
and alternative proposer reward functions. We further connect these dynamics to
reasoning performance using pass@k evaluations. Together, our findings clarify
how self-play differs from other post-training strategies, highlight its
inherent limitations, and point toward future directions for improving LLM math
reasoning through self-play.

</details>


### [127] [Functional embeddings enable Aggregation of multi-area SEEG recordings over subjects and sessions](https://arxiv.org/abs/2510.27090)
*Sina Javadzadeh,Rahil Soroushmojdehi,S. Alireza Seyyed Mousavi,Mehrnaz Asadi,Sumiko Abe,Terence D. Sanger*

Main category: cs.LG

TL;DR: 提出一种无监督学习框架，通过对比编码和Transformer建模跨被试颅内电极的功能特性，实现无需统一电极布局的跨被试神经数据聚合与预训练。


<details>
  <summary>Details</summary>
Motivation: 由于电极数量、位置和覆盖区域在个体间差异大，传统空间归一化方法难以捕捉真实功能相似性，阻碍了颅内神经数据的跨被试聚合。

Method: 使用Siamese对比编码器学习每个电极的主体无关功能嵌入，并通过Transformer对功能标记建模，捕获跨区域关系，支持掩码通道重建。

Result: 学习到的功能空间能准确区分同一被试内区域，形成一致的区域聚类，并零样本迁移到新电极，Transformer可重建掩码通道且无需被试特异性头或监督。

Conclusion: 该框架为无统一任务结构和传感器布局的颅内神经数据提供了可扩展的跨被试聚合与预训练新路径。

Abstract: Aggregating intracranial recordings across subjects is challenging since
electrode count, placement, and covered regions vary widely. Spatial
normalization methods like MNI coordinates offer a shared anatomical reference,
but often fail to capture true functional similarity, particularly when
localization is imprecise; even at matched anatomical coordinates, the targeted
brain region and underlying neural dynamics can differ substantially between
individuals. We propose a scalable representation-learning framework that (i)
learns a subject-agnostic functional identity for each electrode from
multi-region local field potentials using a Siamese encoder with contrastive
objectives, inducing an embedding geometry that is locality-sensitive to
region-specific neural signatures, and (ii) tokenizes these embeddings for a
transformer that models inter-regional relationships with a variable number of
channels. We evaluate this framework on a 20-subject dataset spanning basal
ganglia-thalamic regions collected during flexible rest/movement recording
sessions with heterogeneous electrode layouts. The learned functional space
supports accurate within-subject discrimination and forms clear,
region-consistent clusters; it transfers zero-shot to unseen channels. The
transformer, operating on functional tokens without subject-specific heads or
supervision, captures cross-region dependencies and enables reconstruction of
masked channels, providing a subject-agnostic backbone for downstream decoding.
Together, these results indicate a path toward large-scale, cross-subject
aggregation and pretraining for intracranial neural data where strict task
structure and uniform sensor placement are unavailable.

</details>


### [128] [QiNN-QJ: A Quantum-inspired Neural Network with Quantum Jump for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.27091)
*Yiwei Chen,Kehuan Yan,Yu Pan,Daoyi Dong*

Main category: cs.LG

TL;DR: 提出一种基于量子跃迁的量子启发神经网络QiNN-QJ，通过耗散动力学实现多模态纠缠建模，提升性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有量子启发模型依赖幺正变换，训练不稳定且泛化能力有限。

Method: 将各模态编码为量子纯态，使用可微分的量子跃迁算子模拟耗散动力学，联合学习哈密顿量和林德布拉德算子生成可控纠缠。

Result: 在CMU-MOSI、CMU-MOSEI和CH-SIMS上超越SOTA模型，并通过冯·诺伊曼熵提升可解释性。

Conclusion: 建立了基于量子纠缠的多模态融合理论框架，推动量子启发方法在跨模态关联建模中的应用。

Abstract: Quantum theory provides non-classical principles, such as superposition and
entanglement, that inspires promising paradigms in machine learning. However,
most existing quantum-inspired fusion models rely solely on unitary or
unitary-like transformations to generate quantum entanglement. While
theoretically expressive, such approaches often suffer from training
instability and limited generalizability. In this work, we propose a
Quantum-inspired Neural Network with Quantum Jump (QiNN-QJ) for multimodal
entanglement modelling. Each modality is firstly encoded as a quantum pure
state, after which a differentiable module simulating the QJ operator
transforms the separable product state into the entangled representation. By
jointly learning Hamiltonian and Lindblad operators, QiNN-QJ generates
controllable cross-modal entanglement among modalities with dissipative
dynamics, where structured stochasticity and steady-state attractor properties
serve to stabilize training and constrain entanglement shaping. The resulting
entangled states are projected onto trainable measurement vectors to produce
predictions. In addition to achieving superior performance over the
state-of-the-art models on benchmark datasets, including CMU-MOSI, CMU-MOSEI,
and CH-SIMS, QiNN-QJ facilitates enhanced post-hoc interpretability through
von-Neumann entanglement entropy. This work establishes a principled framework
for entangled multimodal fusion and paves the way for quantum-inspired
approaches in modelling complex cross-modal correlations.

</details>


### [129] [Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle](https://arxiv.org/abs/2510.27097)
*Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer*

Main category: cs.LG

TL;DR: 提出一种贝叶斯模型，利用单细胞参考数据解卷积批量RNA-seq数据，揭示子宫内膜周期中细胞类型比例和特异性基因表达变化


<details>
  <summary>Details</summary>
Motivation: 批量RNA-seq掩盖细胞类型特异性动态，需精准解析异质组织中各细胞类型的表达特征

Method: 构建概率分层贝叶斯模型，结合高分辨率单细胞参考，推断细胞类型比例与细胞特异性基因表达

Result: 成功解析子宫内膜周期中上皮、间质和免疫细胞比例动态变化，识别出与蜕膜化相关的通路基因，模型具有强鲁棒性

Conclusion: 该方法为研究组织异质性提供强有力工具，具有临床应用潜力，未来可整合空间转录组学拓展应用

Abstract: Bulk tissue RNA sequencing of heterogeneous samples provides averaged gene
expression profiles, obscuring cell type-specific dynamics. To address this, we
present a probabilistic hierarchical Bayesian model that deconvolves bulk
RNA-seq data into constituent cell-type expression profiles and proportions,
leveraging a high-resolution single-cell reference. We apply our model to human
endometrial tissue across the menstrual cycle, a context characterized by
dramatic hormone-driven cellular composition changes. Our extended framework
provides a principled inference of cell type proportions and cell-specific gene
expression changes across cycle phases. We demonstrate the model's structure,
priors, and inference strategy in detail, and we validate its performance with
simulations and comparisons to existing methods. The results reveal dynamic
shifts in epithelial, stromal, and immune cell fractions between menstrual
phases, and identify cell-type-specific differential gene expression associated
with endometrial function (e.g., decidualization markers in stromal cells
during the secretory phase). We further conduct robustness tests and show that
our Bayesian approach is resilient to reference mismatches and noise. Finally,
we discuss the biological significance of our findings, potential clinical
implications for fertility and endometrial disorders, and future directions,
including integration of spatial transcriptomics.

</details>


### [130] [Group-Sensitive Offline Contextual Bandits](https://arxiv.org/abs/2510.27123)
*Yihong Guo,Junjie Luo,Guodong Gao,Ritu Agarwal,Anqi Liu*

Main category: cs.LG

TL;DR: 提出一种带组公平约束的离线上下文摆_bandits_策略优化方法，在维持整体性能的同时减少组间奖励差异。


<details>
  <summary>Details</summary>
Motivation: 传统离线策略优化可能放大组间奖励差距，引发公平性问题，尤其在资源有限时。

Method: 引入组间奖励差异约束的离线策略优化框架，采用双重稳健估计器并提供收敛性保证。

Result: 在合成与真实数据集上验证了方法能有效降低奖励差异，同时保持竞争性整体性能。

Conclusion: 该方法为离线上下文摆_bandits_提供了兼顾公平性与效率的优化框架。

Abstract: Offline contextual bandits allow one to learn policies from
historical/offline data without requiring online interaction. However, offline
policy optimization that maximizes overall expected rewards can unintentionally
amplify the reward disparities across groups. As a result, some groups might
benefit more than others from the learned policy, raising concerns about
fairness, especially when the resources are limited. In this paper, we study a
group-sensitive fairness constraint in offline contextual bandits, reducing
group-wise reward disparities that may arise during policy learning. We tackle
the following common-parity requirements: the reward disparity is constrained
within some user-defined threshold or the reward disparity should be minimized
during policy optimization. We propose a constrained offline policy
optimization framework by introducing group-wise reward disparity constraints
into an off-policy gradient-based optimization procedure. To improve the
estimation of the group-wise reward disparity during training, we employ a
doubly robust estimator and further provide a convergence guarantee for policy
optimization. Empirical results in synthetic and real-world datasets
demonstrate that our method effectively reduces reward disparities while
maintaining competitive overall performance.

</details>


### [131] [AI Agents in Drug Discovery](https://arxiv.org/abs/2510.27130)
*Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth*

Main category: cs.LG

TL;DR: AI代理在药物发现中实现自动化推理与实验，显著提升速度与可重复性，本文首次系统介绍其真实应用与影响。


<details>
  <summary>Details</summary>
Motivation: 传统药物发现流程耗时长、重复性差，AI代理通过整合LLM与多工具实现闭环自主研究，有望彻底改变研发范式。

Method: 系统综述了ReAct、Reflection、Supervisor、Swarm等AI代理架构，并应用于文献综述、毒性预测、协议生成、分子合成、药物重定位等环节。

Result: 实际部署显示，AI代理将原本耗时数月的流程压缩至数小时，提高效率与可追溯性，首次实现量化落地影响。

Conclusion: AI代理推动药物发现向自动化、智能化转型，但仍面临数据异构、可靠性、隐私与基准测试等挑战，未来需强化科学支持型技术发展。

Abstract: Artificial intelligence (AI) agents are emerging as transformative tools in
drug discovery, with the ability to autonomously reason, act, and learn through
complicated research workflows. Building on large language models (LLMs)
coupled with perception, computation, action, and memory tools, these agentic
AI systems could integrate diverse biomedical data, execute tasks, carry out
experiments via robotic platforms, and iteratively refine hypotheses in closed
loops. We provide a conceptual and technical overview of agentic AI
architectures, ranging from ReAct and Reflection to Supervisor and Swarm
systems, and illustrate their applications across key stages of drug discovery,
including literature synthesis, toxicity prediction, automated protocol
generation, small-molecule synthesis, drug repurposing, and end-to-end
decision-making. To our knowledge, this represents the first comprehensive work
to present real-world implementations and quantifiable impacts of agentic AI
systems deployed in operational drug discovery settings. Early implementations
demonstrate substantial gains in speed, reproducibility, and scalability,
compressing workflows that once took months into hours while maintaining
scientific traceability. We discuss the current challenges related to data
heterogeneity, system reliability, privacy, and benchmarking, and outline
future directions towards technology in support of science and translation.

</details>


### [132] [Exploring the Utilities of the Rationales from Large Language Models to Enhance Automated Essay Scoring](https://arxiv.org/abs/2510.27131)
*Hong Jiao,Hanna Choi,Haowei Hua*

Main category: cs.LG

TL;DR: 研究比较了基于作文和基于理由的评分方法，发现结合两者优势的集成模型取得了最佳评分准确率（QWK=0.870）。


<details>
  <summary>Details</summary>
Motivation: 提升自动化作文评分的准确性，尤其是在样本不平衡情况下对低分段的识别能力。

Method: 比较了GPT-4.1和GPT-5生成的理由与原始作文在评分中的表现，并构建了多种集成模型进行对比评估。

Result: 作文评分整体表现优于理由评分，但理由评分对零分段识别更准；结合作文与两种理由的集成模型达到最佳QWK=0.870。

Conclusion: 合理融合作文与AI生成理由的集成方法能显著提升自动化评分性能，尤其有助于改善样本不平衡下的低分段预测。

Abstract: This study explored the utilities of rationales generated by GPT-4.1 and
GPT-5 in automated scoring using Prompt 6 essays from the 2012 Kaggle ASAP
data. Essay-based scoring was compared with rationale-based scoring. The study
found in general essay-based scoring performed better than rationale-based
scoring with higher Quadratic Weighted Kappa (QWK). However, rationale-based
scoring led to higher scoring accuracy in terms of F1 scores for score 0 which
had less representation due to class imbalance issues. The ensemble modeling of
essay-based scoring models increased the scoring accuracy at both specific
score levels and across all score levels. The ensemble modeling of essay-based
scoring and each of the rationale-based scoring performed about the same.
Further ensemble of essay-based scoring and both rationale-based scoring
yielded the best scoring accuracy with QWK of 0.870 compared with 0.848
reported in literature.

</details>


### [133] [FairAD: Computationally Efficient Fair Graph Clustering via Algebraic Distance](https://arxiv.org/abs/2510.27136)
*Minh Phu Vuong,Young-Ju Lee,Iván Ojeda-Ruiz,Chul-Ho Lee*

Main category: cs.LG

TL;DR: 提出FairAD方法，高效实现图聚类中的公平性约束，速度较现有方法快40倍。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型对特定群体的不公平行为引发关注，亟需在图聚类中引入公平性约束。

Method: 通过代数距离构建新亲和矩阵，结合图粗化与约束优化，实现公平聚类。

Result: 在模拟和真实数据集上验证，FairAD在保持公平性的同时，速度提升达40倍。

Conclusion: FairAD是高效且实用的公平图聚类方法，显著优于现有算法。

Abstract: Due to the growing concern about unsavory behaviors of machine learning
models toward certain demographic groups, the notion of 'fairness' has recently
drawn much attention from the community, thereby motivating the study of
fairness in graph clustering. Fair graph clustering aims to partition the set
of nodes in a graph into $k$ disjoint clusters such that the proportion of each
protected group within each cluster is consistent with the proportion of that
group in the entire dataset. It is, however, computationally challenging to
incorporate fairness constraints into existing graph clustering algorithms,
particularly for large graphs. To address this problem, we propose FairAD, a
computationally efficient fair graph clustering method. It first constructs a
new affinity matrix based on the notion of algebraic distance such that
fairness constraints are imposed. A graph coarsening process is then performed
on this affinity matrix to find representative nodes that correspond to $k$
clusters. Finally, a constrained minimization problem is solved to obtain the
solution of fair clustering. Experiment results on the modified stochastic
block model and six public datasets show that FairAD can achieve fair
clustering while being up to 40 times faster compared to state-of-the-art fair
graph clustering algorithms.

</details>


### [134] [Relation-Aware Bayesian Optimization of DBMS Configurations Guided by Affinity Scores](https://arxiv.org/abs/2510.27145)
*Sein Kwon,Seulgi Baek,Hyunseo Yang,Youngwan Jo,Sanghyun Park*

Main category: cs.LG

TL;DR: 提出RelTune框架，通过关系图和GNN建模参数依赖，结合混合评分引导的贝叶斯优化，显著提升数据库配置调优效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化调优方法忽略参数间依赖关系，仅优化部分参数，且贝叶斯优化依赖代理模型导致预测不稳定和探索低效。

Method: RelTune用关系图表示参数依赖，学习GNN嵌入编码性能语义，并提出Hybrid-Score-Guided BO（HBO），融合代理预测与亲和评分。

Result: 在多个DBMS和工作负载上，RelTune相比传统BO方法收敛更快、效率更高，达到最优性能。

Conclusion: 建模参数依赖关系和引入亲和评分可显著提升数据库配置优化效果，RelTune为自动化调优提供了新范式。

Abstract: Database Management Systems (DBMSs) are fundamental for managing large-scale
and heterogeneous data, and their performance is critically influenced by
configuration parameters. Effective tuning of these parameters is essential for
adapting to diverse workloads and maximizing throughput while minimizing
latency. Recent research has focused on automated configuration optimization
using machine learning; however, existing approaches still exhibit several key
limitations. Most tuning frameworks disregard the dependencies among
parameters, assuming that each operates independently. This simplification
prevents optimizers from leveraging relational effects across parameters,
limiting their capacity to capture performancesensitive interactions. Moreover,
to reduce the complexity of the high-dimensional search space, prior work often
selects only the top few parameters for optimization, overlooking others that
contribute meaningfully to performance. Bayesian Optimization (BO), the most
common method for automatic tuning, is also constrained by its reliance on
surrogate models, which can lead to unstable predictions and inefficient
exploration. To overcome these limitations, we propose RelTune, a novel
framework that represents parameter dependencies as a Relational Graph and
learns GNN-based latent embeddings that encode performancerelevant semantics.
RelTune further introduces Hybrid-Score-Guided Bayesian Optimization (HBO),
which combines surrogate predictions with an Affinity Score measuring proximity
to previously high-performing configurations. Experimental results on multiple
DBMSs and workloads demonstrate that RelTune achieves faster convergence and
higher optimization efficiency than conventional BO-based methods, achieving
state-of-the-art performance across all evaluated scenarios.

</details>


### [135] [Exploring Landscapes for Better Minima along Valleys](https://arxiv.org/abs/2510.27153)
*Tong Zhao,Jiacheng Li,Yuanchang Zhou,Guangming Tan,Weile Jia*

Main category: cs.LG

TL;DR: 提出一种名为E的适配器，使优化器在达到局部最小值后继续探索损失景观，以找到更低且更平坦的最小值，提升泛化性能，尤其在大批次训练中显著优于Lamb。


<details>
  <summary>Details</summary>
Motivation: 现有优化器在到达局部最小值后停止搜索，但复杂损失景观中难以保证找到最低或泛化最好的点。

Method: 设计适配器E，使优化器沿低损失山谷持续探索，寻找更优局部最小值，并提供凸与非凸场景下的收敛性证明。

Result: 在大批次训练中，ALTO（适配Lamb）平均提升测试准确率2.5%，优于当前最优方法。

Conclusion: 该方法为优化算法设计开辟新方向，通过持续探索提升泛化能力。

Abstract: Finding lower and better-generalizing minima is crucial for deep learning.
However, most existing optimizers stop searching the parameter space once they
reach a local minimum. Given the complex geometric properties of the loss
landscape, it is difficult to guarantee that such a point is the lowest or
provides the best generalization. To address this, we propose an adaptor "E"
for gradient-based optimizers. The adapted optimizer tends to continue
exploring along landscape valleys (areas with low and nearly identical losses)
in order to search for potentially better local minima even after reaching a
local minimum. This approach increases the likelihood of finding a lower and
flatter local minimum, which is often associated with better generalization. We
also provide a proof of convergence for the adapted optimizers in both convex
and non-convex scenarios for completeness. Finally, we demonstrate their
effectiveness in an important but notoriously difficult training scenario,
large-batch training, where Lamb is the benchmark optimizer. Our testing
results show that the adapted Lamb, ALTO, increases the test accuracy
(generalization) of the current state-of-the-art optimizer by an average of
2.5% across a variety of large-batch training tasks. This work potentially
opens a new research direction in the design of optimization algorithms.

</details>


### [136] [Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](https://arxiv.org/abs/2510.27172)
*Zixuan Hu,Li Shen,Zhenyi Wang,Yongxian Wei,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出无攻击模拟的贝叶斯数据调度器（BDS），通过后验推断自适应过滤有害数据，实现更灵活的微调防御。


<details>
  <summary>Details</summary>
Motivation: 现有防御依赖攻击模拟，难以应对未知攻击和多样化的攻击场景，亟需无需模拟的自适应防御方法。

Method: 将有害微调防御建模为贝叶斯推断问题，学习数据安全属性的后验分布，并根据采样权重动态调整训练数据的重要性，辅以神经调度器实现高效迁移。

Result: 在多种攻击与防御设置下，BDS达到领先性能，且无需重新训练即可适应新数据。

Conclusion: BDS突破了传统模拟依赖的局限，实现了数据驱动、自适应、高效的微调安全防御。

Abstract: Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service
for large language models. Existing defense strategies preemptively build
robustness via attack simulation but suffer from fundamental limitations: (i)
the infeasibility of extending attack simulations beyond bounded threat models
due to the inherent difficulty of anticipating unknown attacks, and (ii)
limited adaptability to varying attack settings, as simulation fails to capture
their variability and complexity. To address these challenges, we propose
Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with
no need for attack simulation. BDS formulates harmful fine-tuning defense as a
Bayesian inference problem, learning the posterior distribution of each data
point's safety attribute, conditioned on the fine-tuning and alignment
datasets. The fine-tuning process is then constrained by weighting data with
their safety attributes sampled from the posterior, thus mitigating the
influence of harmful data. By leveraging the post hoc nature of Bayesian
inference, the posterior is conditioned on the fine-tuning dataset, enabling
BDS to tailor its defense to the specific dataset, thereby achieving adaptive
defense. Furthermore, we introduce a neural scheduler based on amortized
Bayesian learning, enabling efficient transfer to new data without retraining.
Comprehensive results across diverse attack and defense settings demonstrate
the state-of-the-art performance of our approach. Code is available at
https://github.com/Egg-Hu/Bayesian-Data-Scheduler.

</details>


### [137] [A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions](https://arxiv.org/abs/2510.27177)
*Junfan Li,Shizhong Liao,Zenglin Xu,Liqiang Nie*

Main category: cs.LG

TL;DR: 本文提出了一个改进的在线稀疏线性回归算法，在兼容性条件下实现了更优的悔界，并扩展至可额外观察属性的场景。


<details>
  <summary>Details</summary>
Motivation: 在线稀疏线性回归是NP难问题，先前算法依赖较强假设（如线性独立、RIP），而兼容性条件更弱但现有方法性能有限，亟需更高效算法。

Method: 基于Dantzig Selector，引入算法相关的协方差估计采样、自适应参数调整及批处理在线牛顿步，并采用新颖的归纳法分析ℓ1误差和非独立随机变量协方差。

Result: 在兼容性条件下显著改进了Ito等人(2017)的悔界，并扩展至可额外观察k0个属性的场景，也优于Kale等人(2017)和Ito等人的结果。

Conclusion: 所提算法在更弱假设下实现理论性能提升，为在线稀疏学习提供了更实用的解决方案。

Abstract: In this paper, we study the problem of online sparse linear regression (OSLR)
where the algorithms are restricted to accessing only $k$ out of $d$ attributes
per instance for prediction, which was proved to be NP-hard. Previous work gave
polynomial-time algorithms assuming the data matrix satisfies the linear
independence of features, the compatibility condition, or the restricted
isometry property. We introduce a new polynomial-time algorithm, which
significantly improves previous regret bounds (Ito et al., 2017) under the
compatibility condition that is weaker than the other two assumptions. The
improvements benefit from a tighter convergence rate of the $\ell_1$-norm error
of our estimators. Our algorithm leverages the well-studied Dantzig Selector,
but importantly with several novel techniques, including an algorithm-dependent
sampling scheme for estimating the covariance matrix, an adaptive parameter
tuning scheme, and a batching online Newton step with careful initializations.
We also give novel and non-trivial analyses, including an induction method for
analyzing the $\ell_1$-norm error, careful analyses on the covariance of
non-independent random variables, and a decomposition on the regret. We further
extend our algorithm to OSLR with additional observations where the algorithms
can observe additional $k_0$ attributes after each prediction, and improve
previous regret bounds (Kale et al., 2017; Ito et al., 2017).

</details>


### [138] [SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference](https://arxiv.org/abs/2510.27182)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.LG

TL;DR: SERFLOW通过结合FaaS和IaaS，根据ML请求的动态退出率实现按阶段资源分配，降低成本超23%。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视VM冷启动、长尾服务时间等现实因素，导致资源浪费与延迟优化不足。

Method: 将ML查询建模为有向无环阶段序列，按各阶段退出率动态分配FaaS与IaaS资源，并结合自适应负载均衡。

Result: 相比传统方法，SERFLOW在动态负载下降低云成本超23%，同时提升效率。

Conclusion: 阶段感知的混合资源调度是优化ML推理成本与性能的关键，FaaS在稀疏请求场景中更具优势。

Abstract: Dynamic offloading of Machine Learning (ML) model partitions across different
resource orchestration services, such as Function-as-a-Service (FaaS) and
Infrastructure-as-a-Service (IaaS), can balance processing and transmission
delays while minimizing costs of adaptive inference applications. However,
prior work often overlooks real-world factors, such as Virtual Machine (VM)
cold starts, requests under long-tail service time distributions, etc. To
tackle these limitations, we model each ML query (request) as traversing an
acyclic sequence of stages, wherein each stage constitutes a contiguous block
of sparse model parameters ending in an internal or final classifier where
requests may exit. Since input-dependent exit rates vary, no single resource
configuration suits all query distributions. IaaS-based VMs become
underutilized when many requests exit early, yet rapidly scaling to handle
request bursts reaching deep layers is impractical. SERFLOW addresses this
challenge by leveraging FaaS-based serverless functions (containers) and using
stage-specific resource provisioning that accounts for the fraction of requests
exiting at each stage. By integrating this provisioning with adaptive load
balancing across VMs and serverless functions based on request ingestion,
SERFLOW reduces cloud costs by over $23\%$ while efficiently adapting to
dynamic workloads.

</details>


### [139] [MDAS-GNN: Multi-Dimensional Spatiotemporal GNN with Spatial Diffusion for Urban Traffic Risk Forecasting](https://arxiv.org/abs/2510.27197)
*Ziyuan Gao*

Main category: cs.LG

TL;DR: MDAS-GNN是一种融合交通、基础设施和环境三维度风险的图神经网络，显著提升城市道路事故预测精度，尤其在长期预测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统事故预测模型忽略道路段间的空间依赖与时间动态，难以应对复杂城市交通网络的风险建模需求。

Method: 提出MDAS-GNN，结合多维注意力空间扩散机制与多头时序注意力，整合交通、基础设施与环境三类风险特征。

Result: 在伦敦、曼彻斯特和伯明翰实测数据上，MDAS-GNN较基线方法误差降低达40%，长期预测性能突出。

Conclusion: 该框架为城市规划与交通工程提供数据驱动的事故预测工具，支持基础设施优化与安全干预决策。

Abstract: Traffic accidents represent a critical public health challenge, claiming over
1.35 million lives annually worldwide. Traditional accident prediction models
treat road segments independently, failing to capture complex spatial
relationships and temporal dependencies in urban transportation networks. This
study develops MDAS-GNN, a Multi-Dimensional Attention-based Spatial-diffusion
Graph Neural Network integrating three core risk dimensions: traffic safety,
infrastructure, and environmental risk. The framework employs feature-specific
spatial diffusion mechanisms and multi-head temporal attention to capture
dependencies across different time horizons. Evaluated on UK Department for
Transport accident data across Central London, South Manchester, and SE
Birmingham, MDASGNN achieves superior performance compared to established
baseline methods. The model maintains consistently low prediction errors across
short, medium, and long-term periods, with particular strength in long-term
forecasting. Ablation studies confirm that integrated multi-dimensional
features outperform singlefeature approaches, reducing prediction errors by up
to 40%. This framework provides civil engineers and urban planners with
advanced predictive capabilities for transportation infrastructure design,
enabling data-driven decisions for road network optimization, infrastructure
resource improvements, and strategic safety interventions in urban development
projects.

</details>


### [140] [Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models](https://arxiv.org/abs/2510.27207)
*Hamed Najafi,Dongsheng Luo,Jason Liu*

Main category: cs.LG

TL;DR: 提出FFCA框架，通过四维特征曲率分析和动态原型分析，揭示模型学习过程中的几何特性，超越静态解释，实现对学习过程的可信追踪。


<details>
  <summary>Details</summary>
Motivation: 现有归因方法仅提供静态单一分数，无法捕捉非线性与特征交互，难以全面解释模型学习过程。

Method: 引入Feature-Function Curvature Analysis (FFCA)，为每个特征生成四维签名（影响、波动性、非线性、交互），并扩展为动态原型分析，追踪训练过程中这些签名的变化。

Result: 首次实证发现模型遵循层次学习模式（先线性后交互），并能诊断模型容量不足与过拟合 onset。

Conclusion: FFCA通过静态与动态结合，将模型解释从简单量化提升为对整个学习过程的几何化、可信分析。

Abstract: Explainable AI (XAI) is critical for building trust in complex machine
learning models, yet mainstream attribution methods often provide an
incomplete, static picture of a model's final state. By collapsing a feature's
role into a single score, they are confounded by non-linearity and
interactions. To address this, we introduce Feature-Function Curvature Analysis
(FFCA), a novel framework that analyzes the geometry of a model's learned
function. FFCA produces a 4-dimensional signature for each feature, quantifying
its: (1) Impact, (2) Volatility, (3) Non-linearity, and (4) Interaction.
Crucially, we extend this framework into Dynamic Archetype Analysis, which
tracks the evolution of these signatures throughout the training process. This
temporal view moves beyond explaining what a model learned to revealing how it
learns. We provide the first direct, empirical evidence of hierarchical
learning, showing that models consistently learn simple linear effects before
complex interactions. Furthermore, this dynamic analysis provides novel,
practical diagnostics for identifying insufficient model capacity and
predicting the onset of overfitting. Our comprehensive experiments demonstrate
that FFCA, through its static and dynamic components, provides the essential
geometric context that transforms model explanation from simple quantification
to a nuanced, trustworthy analysis of the entire learning process.

</details>


### [141] [Soft Task-Aware Routing of Experts for Equivariant Representation Learning](https://arxiv.org/abs/2510.27222)
*Jaebyeong Jeon,Hyeonseo Jang,Jy-yong Sohn,Kibok Lee*

Main category: cs.LG

TL;DR: 提出STAR方法，通过软任务感知路由减少不变与等变表征学习中的冗余，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用独立投影头学习不变与等变表征，忽略两者共享信息，导致特征冗余和模型容量浪费。

Method: 引入Soft Task-Aware Routing (STAR)，将投影头建模为专家，引导其专精于共享或任务特定信息。

Result: 降低不变与等变嵌入的典型相关性，验证冗余减少，在多种迁移学习任务中一致提升性能。

Conclusion: STAR有效提升表征学习效率，为联合学习不变与等变表征提供新范式。

Abstract: Equivariant representation learning aims to capture variations induced by
input transformations in the representation space, whereas invariant
representation learning encodes semantic information by disregarding such
transformations. Recent studies have shown that jointly learning both types of
representations is often beneficial for downstream tasks, typically by
employing separate projection heads. However, this design overlooks information
shared between invariant and equivariant learning, which leads to redundant
feature learning and inefficient use of model capacity. To address this, we
introduce Soft Task-Aware Routing (STAR), a routing strategy for projection
heads that models them as experts. STAR induces the experts to specialize in
capturing either shared or task-specific information, thereby reducing
redundant feature learning. We validate this effect by observing lower
canonical correlations between invariant and equivariant embeddings.
Experimental results show consistent improvements across diverse transfer
learning tasks. The code is available at https://github.com/YonseiML/star.

</details>


### [142] [FedSM: Robust Semantics-Guided Feature Mixup for Bias Reduction in Federated Learning with Long-Tail Data](https://arxiv.org/abs/2510.27240)
*Jingrui Zhang,Yimeng Xu,Shujie Li,Feng Liang,Haihan Duan,Yanjie Dong,Victor C. M. Leung,Xiping Hu*

Main category: cs.LG

TL;DR: FedSM通过语义引导的特征混合和轻量分类器重训练，缓解联邦学习中非IID和长尾数据导致的模型偏差，显著提升准确率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习因非IID和长尾数据分布导致全局模型偏差，现有方法难以有效缓解。

Method: 提出FedSM框架，利用预训练图文模型计算语义相关性，本地生成类别一致的伪特征，并通过概率类别选择增强多样性，仅需轻量分类器重训练。

Result: 在多种长尾数据集上超越SOTA方法，准确率更高，对域偏移鲁棒且计算高效。

Conclusion: FedSM以低开销本地计算有效缓解联邦学习偏差，具备强实用性和泛化能力。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralized clients without sharing private data. However, FL suffers from
biased global models due to non-IID and long-tail data distributions. We
propose \textbf{FedSM}, a novel client-centric framework that mitigates this
bias through semantics-guided feature mixup and lightweight classifier
retraining. FedSM uses a pretrained image-text-aligned model to compute
category-level semantic relevance, guiding the category selection of local
features to mix-up with global prototypes to generate class-consistent
pseudo-features. These features correct classifier bias, especially when data
are heavily skewed. To address the concern of potential domain shift between
the pretrained model and the data, we propose probabilistic category selection,
enhancing feature diversity to effectively mitigate biases. All computations
are performed locally, requiring minimal server overhead. Extensive experiments
on long-tail datasets with various imbalanced levels demonstrate that FedSM
consistently outperforms state-of-the-art methods in accuracy, with high
robustness to domain shift and computational efficiency.

</details>


### [143] [Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation](https://arxiv.org/abs/2510.27253)
*Qiyan Deng,Changqian Zheng,Lianpeng Qiao,Yuping Wang,Chengliang Chai,Lei Cao*

Main category: cs.LG

TL;DR: 提出IWD方法，利用影响函数加权数据实例，提升数据蒸馏质量与模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数据蒸馏方法忽略数据质量，冗余或有害样本会降低模型性能

Method: IWD通过影响函数为每个实例分配自适应权重，优先保留有益数据，抑制有害数据

Result: 集成IWD后，蒸馏数据集质量提升，模型准确率最高提升7.8%

Conclusion: IWD是一种模块化、通用的框架，能显著提升各类数据蒸馏方法的效果

Abstract: Dataset distillation condenses large datasets into synthetic subsets,
achieving performance comparable to training on the full dataset while
substantially reducing storage and computation costs. Most existing dataset
distillation methods assume that all real instances contribute equally to the
process. In practice, real-world datasets contain both informative and
redundant or even harmful instances, and directly distilling the full dataset
without considering data quality can degrade model performance. In this work,
we present Influence-Weighted Distillation IWD, a principled framework that
leverages influence functions to explicitly account for data quality in the
distillation process. IWD assigns adaptive weights to each instance based on
its estimated impact on the distillation objective, prioritizing beneficial
data while downweighting less useful or harmful ones. Owing to its modular
design, IWD can be seamlessly integrated into diverse dataset distillation
frameworks. Our empirical results suggest that integrating IWD tends to improve
the quality of distilled datasets and enhance model performance, with accuracy
gains of up to 7.8%.

</details>


### [144] [ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models](https://arxiv.org/abs/2510.27256)
*Xin Tang,Youfang Han,Fangfei Gou,Wei Zhao,Xin Meng,Yang Yu,Jinguo Zhang,Yuanchun Shi,Yuntao Wang,Tengxiang Zhang*

Main category: cs.LG

TL;DR: 提出ECVL-ROUTER，一种场景感知的视觉语言模型路由框架，动态选择大模型或小模型以平衡延迟、质量和能耗。


<details>
  <summary>Details</summary>
Motivation: 云上大模型响应慢、能耗高，边缘小模型效率高但能力有限，需结合二者优势。

Method: 设计场景感知路由策略与评估指标，构建专用多模态数据集训练路由器，动态分配Query至合适模型。

Result: 超过80%的查询由小模型处理，问题解决率仅下降不到10%。

Conclusion: ECVL-ROUTER有效实现资源高效分配，在保持高性能的同时显著降低能耗与延迟。

Abstract: Vision-Language Models (VLMs) excel in diverse multimodal tasks. However,
user requirements vary across scenarios, which can be categorized into fast
response, high-quality output, and low energy consumption. Relying solely on
large models deployed in the cloud for all queries often leads to high latency
and energy cost, while small models deployed on edge devices are capable of
handling simpler tasks with low latency and energy cost. To fully leverage the
strengths of both large and small models, we propose ECVL-ROUTER, the first
scenario-aware routing framework for VLMs. Our approach introduces a new
routing strategy and evaluation metrics that dynamically select the appropriate
model for each query based on user requirements, maximizing overall utility. We
also construct a multimodal response-quality dataset tailored for router
training and validate the approach through extensive experiments. Results show
that our approach successfully routes over 80\% of queries to the small model
while incurring less than 10\% drop in problem solving probability.

</details>


### [145] [Higher-order Linear Attention](https://arxiv.org/abs/2510.27258)
*Yifan Zhang,Zhen Qin,Quanquan Gu*

Main category: cs.LG

TL;DR: 提出更高阶线性注意力（HLA），在常数时间与空间复杂度下实现类似注意力的高效序列建模，突破传统线性注意力的表达力限制。


<details>
  <summary>Details</summary>
Motivation: 传统缩放点积注意力的二次开销限制了模型处理长序列的能力，而现有线性注意力和SSM因仅限一阶或核近似导致表达力不足。

Method: HLA通过紧凑的前缀充分统计量实现高阶交互，在二阶情况下保持常数状态，使用流式递推与关联扫描实现因果建模与并行训练，支持更高阶扩展。

Result: HLA可在线性时间与常数内存下精确模拟序列递归，无需计算n×n矩阵，同时保持与注意力相当的表达能力，并支持第三阶及以上扩展。

Conclusion: HLA是一种兼具注意力表达力与RNN效率的新型基本模块，为长序列建模提供了可扩展且理论严谨的解决方案。

Abstract: The quadratic cost of scaled dot-product attention is a central obstacle to
scaling autoregressive language models to long contexts. Linear-time attention
and State Space Models (SSMs) provide scalable alternatives but are typically
restricted to first-order or kernel-based approximations, which can limit
expressivity. We introduce Higher-order Linear Attention (HLA), a causal,
streaming mechanism that realizes higher interactions via compact prefix
sufficient statistics. In the second-order case, HLA maintains a constant-size
state and computes per-token outputs in linear time without materializing any
$n \times n$ matrices. We give closed-form streaming identities, a strictly
causal masked variant using two additional summaries, and a chunk-parallel
training scheme based on associative scans that reproduces the activations of a
serial recurrence exactly. We further outline extensions to third and higher
orders. Collectively, these results position HLA as a principled, scalable
building block that combines attention-like, data-dependent mixing with the
efficiency of modern recurrent architectures. Project Page:
https://github.com/yifanzhang-pro/HLA.

</details>


### [146] [ODP-Bench: Benchmarking Out-of-Distribution Performance Prediction](https://arxiv.org/abs/2510.27263)
*Han Yu,Kehan Li,Dongbai Li,Yue He,Xingxuan Zhang,Peng Cui*

Main category: cs.LG

TL;DR: 提出ODP-Bench基准，统一评估OOD性能预测算法，提供预训练模型与丰富数据集，促进公平比较与深入分析。


<details>
  <summary>Details</summary>
Motivation: 现有OOD性能预测研究评估协议不一致，覆盖数据集和分布偏移类型有限，亟需标准化基准。

Method: 构建ODP-Bench基准，整合主流OOD数据集与预测算法，提供预训练模型作为统一测试平台。

Result: 实现算法间公平比较，降低重复训练成本，揭示现有方法的能力边界。

Conclusion: ODP-Bench为OOD性能预测研究提供了标准化、可复现的评估框架，推动领域发展。

Abstract: Recently, there has been gradually more attention paid to Out-of-Distribution
(OOD) performance prediction, whose goal is to predict the performance of
trained models on unlabeled OOD test datasets, so that we could better leverage
and deploy off-the-shelf trained models in risk-sensitive scenarios. Although
progress has been made in this area, evaluation protocols in previous
literature are inconsistent, and most works cover only a limited number of
real-world OOD datasets and types of distribution shifts. To provide convenient
and fair comparisons for various algorithms, we propose Out-of-Distribution
Performance Prediction Benchmark (ODP-Bench), a comprehensive benchmark that
includes most commonly used OOD datasets and existing practical performance
prediction algorithms. We provide our trained models as a testbench for future
researchers, thus guaranteeing the consistency of comparison and avoiding the
burden of repeating the model training process. Furthermore, we also conduct
in-depth experimental analyses to better understand their capability boundary.

</details>


### [147] [HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction](https://arxiv.org/abs/2510.27281)
*Minghui Li,Yuanhang Wang,Peijin Guo,Wei Wan,Shengshan Hu,Shengqing Hu*

Main category: cs.LG

TL;DR: HiF-DTA通过双路径层次网络和多尺度融合，显著提升药物-靶点亲和力预测性能


<details>
  <summary>Details</summary>
Motivation: 现有序列深度学习方法忽略药物和蛋白的全局语义与局部拓扑特征，且药物表示缺乏多尺度原子级到分子级信息

Method: 提出HiF-DTA，采用双路径架构提取全局语义与局部拓扑特征，并通过多尺度双线性注意力模块融合原子、亚结构和分子层级表示

Result: 在Davis、KIBA和Metz数据集上超越现有最优方法，消融实验验证了全局-局部提取与多尺度融合的关键作用

Conclusion: HiF-DTA有效整合多尺度与多特征信息，为计算药物发现提供更精准的DTA预测框架

Abstract: Accurate prediction of Drug-Target Affinity (DTA) is crucial for reducing
experimental costs and accelerating early screening in computational drug
discovery. While sequence-based deep learning methods avoid reliance on costly
3D structures, they still overlook simultaneous modeling of global sequence
semantic features and local topological structural features within drugs and
proteins, and represent drugs as flat sequences without atomic-level,
substructural-level, and molecular-level multi-scale features. We propose
HiF-DTA, a hierarchical network that adopts a dual-pathway strategy to extract
both global sequence semantic and local topological features from drug and
protein sequences, and models drugs multi-scale to learn atomic, substructural,
and molecular representations fused via a multi-scale bilinear attention
module. Experiments on Davis, KIBA, and Metz datasets show HiF-DTA outperforms
state-of-the-art baselines, with ablations confirming the importance of
global-local extraction and multi-scale fusion.

</details>


### [148] [Can LLMs Help You at Work? A Sandbox for Evaluating LLM Agents in Enterprise Environments](https://arxiv.org/abs/2510.27287)
*Harsh Vishwakarma,Ankush Agarwal,Ojas Patil,Chaitanya Devaguptapu,Mahesh Chandran*

Main category: cs.LG

TL;DR: 提出EnterpriseBench基准，评估LLM在企业环境中的表现，发现最先进模型仅完成41.8%任务。


<details>
  <summary>Details</summary>
Motivation: 企业系统数据碎片化、访问控制复杂，现有LLM难以有效处理真实企业任务，亟需评估基准。

Method: 构建EnterpriseBench基准，包含500个跨领域任务，通过组织元数据生成一致性任务，模拟数据碎片与权限层级。

Result: 顶级LLM代理在EnterpriseBench上平均任务完成率仅为41.8%，显示当前模型在企业场景中能力严重不足。

Conclusion: EnterpriseBench为评估企业AI系统提供新标准，揭示LLM在复杂企业环境中仍有巨大改进空间。

Abstract: Enterprise systems are crucial for enhancing productivity and decision-making
among employees and customers. Integrating LLM based systems into enterprise
systems enables intelligent automation, personalized experiences, and efficient
information retrieval, driving operational efficiency and strategic growth.
However, developing and evaluating such systems is challenging due to the
inherent complexity of enterprise environments, where data is fragmented across
multiple sources and governed by sophisticated access controls. We present
EnterpriseBench, a comprehensive benchmark that simulates enterprise settings,
featuring 500 diverse tasks across software engineering, HR, finance, and
administrative domains. Our benchmark uniquely captures key enterprise
characteristics including data source fragmentation, access control
hierarchies, and cross-functional workflows. Additionally, we provide a novel
data generation pipeline that creates internally consistent enterprise tasks
from organizational metadata. Experiments with state-of-the-art LLM agents
demonstrate that even the most capable models achieve only 41.8% task
completion, highlighting significant opportunities for improvement in
enterprise-focused AI systems.

</details>


### [149] [Temporal Cardiovascular Dynamics for Improved PPG-Based Heart Rate Estimation](https://arxiv.org/abs/2510.27297)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 提出一种基于互信息的非线性混沌方法，显著提升真实场景下心率估计精度，最高提升40%。


<details>
  <summary>Details</summary>
Motivation: 心率波动具有复杂非线性chaos特性，传统方法在日常健康监测中表现不佳。

Method: 引入互信息分析心率非线性混沌行为，并与深度学习结合以增强估计性能。

Result: 在四个真实场景数据集上验证，性能比传统方法提升最高40%，减少多传感依赖，无需后处理。

Conclusion: 该方法有效建模心率非线性复杂性，显著提升实时心率估计的准确性和实用性。

Abstract: The oscillations of the human heart rate are inherently complex and
non-linear -- they are best described by mathematical chaos, and they present a
challenge when applied to the practical domain of cardiovascular health
monitoring in everyday life. In this work, we study the non-linear chaotic
behavior of heart rate through mutual information and introduce a novel
approach for enhancing heart rate estimation in real-life conditions. Our
proposed approach not only explains and handles the non-linear temporal
complexity from a mathematical perspective but also improves the deep learning
solutions when combined with them. We validate our proposed method on four
established datasets from real-life scenarios and compare its performance with
existing algorithms thoroughly with extensive ablation experiments. Our results
demonstrate a substantial improvement, up to 40\%, of the proposed approach in
estimating heart rate compared to traditional methods and existing
machine-learning techniques while reducing the reliance on multiple sensing
modalities and eliminating the need for post-processing steps.

</details>


### [150] [Binary Anomaly Detection in Streaming IoT Traffic under Concept Drift](https://arxiv.org/abs/2510.27304)
*Rodrigo Matos Carnier,Laura Lahesoo,Kensuke Fukuda*

Main category: cs.LG

TL;DR: 该研究比较了批处理学习与流式学习在物联网异常检测中的表现，发现流式学习更能应对概念漂移，且基于树的算法如自适应随机森林在效率和准确性上表现优越。


<details>
  <summary>Details</summary>
Motivation: 传统批处理学习模型在处理物联网流量概念漂移时维护成本高、适应性差，亟需更动态的流式学习方法。

Method: 通过混合现有数据集模拟异构物联网流量流，逐样本流式输入，对比批处理与流式学习模型，评估其在二分类异常检测中的性能与计算开销。

Result: 批处理模型无法有效应对概念漂移；现有数据集异构性不足限制模型评估；自适应随机森林F1达0.990且计算成本降低33%，Hoeffding自适应树F1为0.910且成本降低75%。

Conclusion: 流式学习结合树型算法在物联网实时异常检测中更具优势，兼顾高效性与准确性，适合资源受限的在线应用场景。

Abstract: With the growing volume of Internet of Things (IoT) network traffic, machine
learning (ML)-based anomaly detection is more relevant than ever. Traditional
batch learning models face challenges such as high maintenance and poor
adaptability to rapid anomaly changes, known as concept drift. In contrast,
streaming learning integrates online and incremental learning, enabling
seamless updates and concept drift detection to improve robustness. This study
investigates anomaly detection in streaming IoT traffic as binary
classification, comparing batch and streaming learning approaches while
assessing the limitations of current IoT traffic datasets. We simulated
heterogeneous network data streams by carefully mixing existing datasets and
streaming the samples one by one. Our results highlight the failure of batch
models to handle concept drift, but also reveal persisting limitations of
current datasets to expose model limitations due to low traffic heterogeneity.
We also investigated the competitiveness of tree-based ML algorithms,
well-known in batch anomaly detection, and compared it to non-tree-based ones,
confirming the advantages of the former. Adaptive Random Forest achieved
F1-score of 0.990 $\pm$ 0.006 at one-third the computational cost of its batch
counterpart. Hoeffding Adaptive Tree reached F1-score of 0.910 $\pm$ 0.007,
reducing computational cost by four times, making it a viable choice for online
applications despite a slight trade-off in stability.

</details>


### [151] [Un-Attributability: Computing Novelty From Retrieval & Semantic Similarity](https://arxiv.org/abs/2510.27313)
*Philipp Davydov,Ameya Prabhu,Matthias Bethge,Elisa Nguyen,Seong Joon Oh*

Main category: cs.LG

TL;DR: 提出一种基于未可归因性的语义新颖性度量方法，通过检索模型评估语言模型输出是否源自预训练数据，并在SmolLM上发现模型利用更长上下文、领域影响新颖性、指令微调增加新颖性。


<details>
  <summary>Details</summary>
Motivation: 现有训练数据归因方法关注哪些训练样本影响输出，但无法识别完全未被预训练数据覆盖的语义新颖输出。

Method: 采用双阶段检索管道：先用GIST嵌入索引语料库并检索Top-n候选，再用ColBERTv2重排序；若最相似语料项的归因度低于人工参考文本，则判定输出为新颖。

Result: 在SmolLM和SmolLM2上发现：(1) 模型利用比以往更长的预训练上下文；(2) 某些领域系统性促进或抑制新颖性；(3) 指令微调不仅改变风格，还提升输出新颖性。

Conclusion: 未可归因性作为新颖性度量可高效支持预训练尺度分析，发布20TB语料与索引数据以促进可复现与扩展研究。

Abstract: Understanding how language-model outputs relate to the pretraining corpus is
central to studying model behavior. Most training data attribution (TDA)
methods ask which training examples causally influence a given output, often
using leave-one-out tests. We invert the question: which outputs cannot be
attributed to any pretraining example? We introduce un-attributability as an
operational measure of semantic novelty: an output is novel if the pretraining
corpus contains no semantically similar context. We approximate this with a
simple two-stage retrieval pipeline: index the corpus with lightweight GIST
embeddings, retrieve the top-n candidates, then rerank with ColBERTv2. If the
nearest corpus item is less attributable than a human-generated text reference,
we consider the output of the model as novel. We evaluate on SmolLM and SmolLM2
and report three findings: (1) models draw on pretraining data across much
longer spans than previously reported; (2) some domains systematically promote
or suppress novelty; and (3) instruction tuning not only alters style but also
increases novelty. Reframing novelty assessment around un-attributability
enables efficient analysis at pretraining scale. We release ~20 TB of corpus
chunks and index artifacts to support replication and large-scale extension of
our analysis at https://huggingface.co/datasets/stai-tuebingen/faiss-smollm

</details>


### [152] [MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data](https://arxiv.org/abs/2510.27321)
*Yu-Chen Kuo,Yi-Ju Tseng*

Main category: cs.LG

TL;DR: MedM2T是一种时间感知的多模态框架，用于处理医疗数据的异构性和稀疏性，在MIMIC-IV数据集上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 医疗数据具有多模态和异构时间结构，现有模型难以有效建模其复杂性。

Method: MedM2T包含稀疏时间序列编码器、分层时间感知融合机制和双模态注意力机制，结合模态特定预训练编码器进行特征对齐。

Result: 在MIMIC-IV数据集上，MedM2T在CVD预测中达到AUROC 0.947、AUPRC 0.706，死亡率预测AUROC 0.901、AUPRC 0.558，ICU住院时间预测MAE为2.31。

Conclusion: MedM2T在多模态医疗预测任务中表现出强大性能和广泛适用性，是临床预测的有前景工具。

Abstract: The inherent multimodality and heterogeneous temporal structures of medical
data pose significant challenges for modeling. We propose MedM2T, a time-aware
multimodal framework designed to address these complexities. MedM2T integrates:
(i) Sparse Time Series Encoder to flexibly handle irregular and sparse time
series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and
macro-temporal patterns from multiple dense time series, such as ECGs, and
(iii) Bi-Modal Attention to extract cross-modal interactions, which can be
extended to any number of modalities. To mitigate granularity gaps between
modalities, MedM2T uses modality-specific pre-trained encoders and aligns
resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and
MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease
dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality
prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed
state-of-the-art multimodal learning frameworks and existing time series
models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction;
an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean
Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the
robustness and broad applicability of MedM2T, positioning it as a promising
tool in clinical prediction. We provide the implementation of MedM2T at
https://github.com/DHLab-TSENG/MedM2T.

</details>


### [153] [Reasoning Models Sometimes Output Illegible Chains of Thought](https://arxiv.org/abs/2510.27338)
*Arun Jose*

Main category: cs.LG

TL;DR: 面向结果的强化学习导致思维链（CoT）失去可读性，削弱了监控有效性，尽管最终答案准确率高。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习如何影响思维链的可读性与可监控性，以应对潜在恶意行为检测的挑战。

Method: 在14个推理模型上评估CoT可读性，强制使用可读部分测试准确率下降，并分析可读性与性能的关系。

Result: 强化学习使CoT变得不可读，但答案仍准确；可读性差时准确率下降53%，且在难题上更差，无性能-可读性正相关。

Conclusion: 未 Explicit 优化可读性时，面向结果的RL会自然产生不透明推理，威胁基于CoT的监控机制。

Abstract: Language models trained via outcome-based reinforcement learning (RL) to
reason using chain-of-thought (CoT) have shown remarkable performance.
Monitoring such a model's CoT may allow us to understand its intentions and
detect potential malicious behavior. However, to be effective, this requires
that CoTs are legible and faithful. We study CoT legibility across 14 reasoning
models, finding that RL often causes reasoning to become illegible to both
humans and AI monitors, with reasoning models (except Claude) generating
illegible CoTs while returning to perfectly readable final answers. We show
that models use illegible reasoning to reach correct answers (accuracy dropping
by 53\% when forced to use only legible portions), yet find no correlation
between legibility and performance when resampling - suggesting the
relationship is more nuanced. We also find that legibility degrades on harder
questions. We discuss potential hypotheses for these results, including
steganography, training artifacts, and vestigial tokens. These results suggest
that without explicit optimization for legibility, outcome-based RL naturally
produces models with increasingly opaque reasoning processes, potentially
undermining monitoring approaches.

</details>


### [154] [Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity](https://arxiv.org/abs/2510.27378)
*Austin Meek,Eitan Sprejer,Iván Arcuschin,Austin J. Brockmeier,Steven Basart*

Main category: cs.LG

TL;DR: 本文提出一种衡量链式思维（CoT）可监控性的新指标，结合忠实性与冗余性，揭示模型推理的透明度差异。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过输入提示后答案变化来评估CoT忠实性，忽略答案未变但推理缺失关键因素的情况，导致可监控性评估不全面。

Method: 引入冗余性（verbosity）概念，衡量CoT是否包含解决任务所需的所有因素，并与忠实性结合形成综合可监控性评分。

Result: 模型看似忠实，但可能遗漏关键推理因素；不同模型家族的可监控性差异显著。

Conclusion: CoT的可监控性应综合考虑忠实性与冗余性，为安全监控提供更可靠依据，并已开源评估代码。

Abstract: Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.
Since any long, serial reasoning process must pass through this textual trace,
the quality of the CoT is a direct window into what the model is thinking. This
visibility could help us spot unsafe or misaligned behavior (monitorability),
but only if the CoT is transparent about its internal reasoning (faithfulness).
Fully measuring faithfulness is difficult, so researchers often focus on
examining the CoT in cases where the model changes its answer after adding a
cue to the input. This proxy finds some instances of unfaithfulness but loses
information when the model maintains its answer, and does not investigate
aspects of reasoning not tied to the cue. We extend these results to a more
holistic sense of monitorability by introducing verbosity: whether the CoT
lists every factor needed to solve the task. We combine faithfulness and
verbosity into a single monitorability score that shows how well the CoT serves
as the model's external `working memory', a property that many safety schemes
based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning
models on BBH, GPQA, and MMLU. Our results show that models can appear faithful
yet remain hard to monitor when they leave out key factors, and that
monitorability differs sharply across model families. We release our evaluation
code using the Inspect library to support reproducible future work.

</details>


### [155] [FedMuon: Accelerating Federated Learning with Matrix Orthogonalization](https://arxiv.org/abs/2510.27403)
*Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: 提出FedMuon优化器，通过矩阵正交化和全局对齐显著减少联邦学习通信轮次，加速收敛。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习使用元素级优化器（如SGD/Adam），忽略权重矩阵的几何结构，导致病态方向放大、条件数恶化、收敛慢；非IID场景下本地正交化引发客户端漂移。

Method: 引入Muon优化器进行矩阵正交化更新，提出FedMuon：1）动量聚合用于本地初始化；2）局部-全局梯度对齐以减少客户端漂移。

Result: 在IID和非IID设置下均显著减少通信轮次，提升收敛速度与测试精度；理论证明在无异质性假设下实现线性加速收敛。

Conclusion: FedMuon有效解决联邦学习中的通信瓶颈与客户端漂移问题，适用于语言与视觉模型，性能优于主流基线方法。

Abstract: The core bottleneck of Federated Learning (FL) lies in the communication
rounds. That is, how to achieve more effective local updates is crucial for
reducing communication rounds. Existing FL methods still primarily use
element-wise local optimizers (Adam/SGD), neglecting the geometric structure of
the weight matrices. This often leads to the amplification of pathological
directions in the weights during local updates, leading deterioration in the
condition number and slow convergence. Therefore, we introduce the Muon
optimizer in local, which has matrix orthogonalization to optimize
matrix-structured parameters. Experimental results show that, in IID setting,
Local Muon significantly accelerates the convergence of FL and reduces
communication rounds compared to Local SGD and Local AdamW. However, in non-IID
setting, independent matrix orthogonalization based on the local distributions
of each client induces strong client drift. Applying Muon in non-IID FL poses
significant challenges: (1) client preconditioner leading to client drift; (2)
moment reinitialization. To address these challenges, we propose a novel
Federated Muon optimizer (FedMuon), which incorporates two key techniques: (1)
momentum aggregation, where clients use the aggregated momentum for local
initialization; (2) local-global alignment, where the local gradients are
aligned with the global update direction to significantly reduce client drift.
Theoretically, we prove that \texttt{FedMuon} achieves a linear speedup
convergence rate without the heterogeneity assumption, where $S$ is the number
of participating clients per round, $K$ is the number of local iterations, and
$R$ is the total number of communication rounds. Empirically, we validate the
effectiveness of FedMuon on language and vision models. Compared to several
baselines, FedMuon significantly reduces communication rounds and improves test
accuracy.

</details>


### [156] [Atlas-Alignment: Making Interpretability Transferable Across Language Models](https://arxiv.org/abs/2510.27413)
*Bruno Puri,Jim Berend,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.LG

TL;DR: 提出Atlas-Alignment框架，通过轻量级对齐技术将未知潜在空间映射到通用概念图谱，实现跨模型的可解释性与可控性，降低解释成本。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性流程成本高、难扩展，需为每个新模型单独训练稀疏自编码器并手动标注特征。

Method: 利用共享输入和轻量级表征对齐技术，将目标模型的潜在空间对齐到预构建的、带标签的人类可解释概念图谱（Concept Atlas）。

Result: 无需标注数据即可实现语义特征检索与基于概念的生成引导，验证了方法的有效性与鲁棒性。

Conclusion: Atlas-Alignment通过一次性构建高质量概念图谱，大幅降低多模型的可解释性成本，实现高效、可扩展的机制可解释性。

Abstract: Interpretability is crucial for building safe, reliable, and controllable
language models, yet existing interpretability pipelines remain costly and
difficult to scale. Interpreting a new model typically requires costly training
of model-specific sparse autoencoders, manual or semi-automated labeling of SAE
components, and their subsequent validation. We introduce Atlas-Alignment, a
framework for transferring interpretability across language models by aligning
unknown latent spaces to a Concept Atlas - a labeled, human-interpretable
latent space - using only shared inputs and lightweight representational
alignment techniques. Once aligned, this enables two key capabilities in
previously opaque models: (1) semantic feature search and retrieval, and (2)
steering generation along human-interpretable atlas concepts. Through
quantitative and qualitative evaluations, we show that simple representational
alignment methods enable robust semantic retrieval and steerable generation
without the need for labeled concept data. Atlas-Alignment thus amortizes the
cost of explainable AI and mechanistic interpretability: by investing in one
high-quality Concept Atlas, we can make many new models transparent and
controllable at minimal marginal cost.

</details>


### [157] [MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting Post-fire Vegetation Loss](https://arxiv.org/abs/2510.27443)
*Meenu Ravi,Shailik Sarkar,Yanshen Sun,Vaishnavi Singh,Chang-Tien Lu*

Main category: cs.LG

TL;DR: 提出一种名为MVeLMA的多模态机器学习管道，用于预测野火后的植被损失，显著优于现有模型并生成高风险区域置信图。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分探索影响植被损失的多模态因素及其交互作用，且预测模型缺乏可解释性，限制了实际应用。

Method: MVeLMA采用多模态特征集成与堆叠集成架构，结合概率建模进行不确定性估计，预测县级尺度的植被损失。

Result: MVeLMA在预测精度上超越多种SOTA和基线模型，并生成植被损失置信图以识别高风险县区。

Conclusion: 该方法可为灾后救援规划、生态政策制定和野生动物恢复管理提供有力支持。

Abstract: Understanding post-wildfire vegetation loss is critical for developing
effective ecological recovery strategies and is often challenging due to the
extended time and effort required to capture the evolving ecosystem features.
Recent works in this area have not fully explored all the contributing factors,
their modalities, and interactions with each other. Furthermore, most research
in this domain is limited by a lack of interpretability in predictive modeling,
making it less useful in real-world settings. In this work, we propose a novel
end-to-end ML pipeline called MVeLMA (\textbf{M}ultimodal \textbf{Ve}getation
\textbf{L}oss \textbf{M}odeling \textbf{A}rchitecture) to predict county-wise
vegetation loss from fire events. MVeLMA uses a multimodal feature integration
pipeline and a stacked ensemble-based architecture to capture different
modalities while also incorporating uncertainty estimation through
probabilistic modeling. Through comprehensive experiments, we show that our
model outperforms several state-of-the-art (SOTA) and baseline models in
predicting post-wildfire vegetation loss. Furthermore, we generate vegetation
loss confidence maps to identify high-risk counties, thereby helping targeted
recovery efforts. The findings of this work have the potential to inform future
disaster relief planning, ecological policy development, and wildlife recovery
management.

</details>


### [158] [Spectral Neural Graph Sparsification](https://arxiv.org/abs/2510.27474)
*Angelica Liguori,Ettore Ritacco,Pietro Sabatino,Annalisa Socievole*

Main category: cs.LG

TL;DR: 提出谱保留网络，通过自适应演化图结构与特征、正则化谱一致性，实现高效图表示学习并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络依赖固定结构且易过平滑，难以高效处理大规模图数据。

Method: 引入联合图演化层与谱一致性损失，联合优化图拓扑与节点特征，保持谱属性一致。

Result: 在节点层级稀疏化任务中，性能优于现有方法，计算成本更低。

Conclusion: 谱保留网络通过动态结构演化与谱约束，显著提升图学习效率与表现力。

Abstract: Graphs are central to modeling complex systems in domains such as social
networks, molecular chemistry, and neuroscience. While Graph Neural Networks,
particularly Graph Convolutional Networks, have become standard tools for graph
learning, they remain constrained by reliance on fixed structures and
susceptibility to over-smoothing. We propose the Spectral Preservation Network,
a new framework for graph representation learning that generates reduced graphs
serving as faithful proxies of the original, enabling downstream tasks such as
community detection, influence propagation, and information diffusion at a
reduced computational cost. The Spectral Preservation Network introduces two
key components: the Joint Graph Evolution layer and the Spectral Concordance
loss. The former jointly transforms both the graph topology and the node
feature matrix, allowing the structure and attributes to evolve adaptively
across layers and overcoming the rigidity of static neighborhood aggregation.
The latter regularizes these transformations by enforcing consistency in both
the spectral properties of the graph and the feature vectors of the nodes. We
evaluate the effectiveness of Spectral Preservation Network on node-level
sparsification by analyzing well-established metrics and benchmarking against
state-of-the-art methods. The experimental results demonstrate the superior
performance and clear advantages of our approach.

</details>


### [159] [Simplex-to-Euclidean Bijections for Categorical Flow Matching](https://arxiv.org/abs/2510.27480)
*Bernardo Williams,Victor M. Yeom-Song,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 通过Aitchison几何将单纯形映射到欧几里得空间，实现离散数据的连续化建模并精确恢复原分布


<details>
  <summary>Details</summary>
Motivation: 现有方法在单纯形上使用黎曼几何或自定义噪声过程，缺乏在欧几里得空间中保持Aitchison几何结构的高效建模方式

Method: 利用Aitchison几何定义光滑双射，将单纯形映射至欧氏空间，并通过Dirichlet插值实现离散观测的连续化

Result: 在欧氏空间中实现密度建模，同时精确恢复原始离散分布，性能优于传统方法

Conclusion: 该方法结合了欧氏空间的计算优势与Aitchison几何的统计一致性，为分类数据建模提供了新范式

Abstract: We propose a method for learning and sampling from probability distributions
supported on the simplex. Our approach maps the open simplex to Euclidean space
via smooth bijections, leveraging the Aitchison geometry to define the
mappings, and supports modeling categorical data by a Dirichlet interpolation
that dequantizes discrete observations into continuous ones. This enables
density modeling in Euclidean space through the bijection while still allowing
exact recovery of the original discrete distribution. Compared to previous
methods that operate on the simplex using Riemannian geometry or custom noise
processes, our approach works in Euclidean space while respecting the Aitchison
geometry, and achieves competitive performance on both synthetic and real-world
data sets.

</details>


### [160] [Thought Branches: Interpreting LLM Reasoning Requires Resampling](https://arxiv.org/abs/2510.27484)
*Uzay Macar,Paul C. Bogdan,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.LG

TL;DR: 通过重采样分析思维链（CoT）分布，揭示模型推理的因果机制，超越单一样本的局限。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅基于单个CoT，无法准确捕捉模型的因果影响与计算过程，需通过分布视角进行更可靠的分析。

Method: 提出重采样方法，结合因果干预、韧性度量和因果中介分析，系统研究CoT中各步骤的因果作用。

Result: 发现自我保存语句影响微弱，离策略干预效果不稳定，关键规划步骤具有高韧性且影响大，隐性提示有累积因果效应。

Conclusion: 通过重采样分析CoT分布，可实现更可靠、可解释的模型推理因果分析与干预策略。

Abstract: Most work interpreting reasoning models studies only a single
chain-of-thought (CoT), yet these models define distributions over many
possible CoTs. We argue that studying a single sample is inadequate for
understanding causal influence and the underlying computation. Though fully
specifying this distribution is intractable, it can be understood by sampling.
We present case studies using resampling to investigate model decisions. First,
when a model states a reason for its action, does that reason actually cause
the action? In "agentic misalignment" scenarios, we resample specific sentences
to measure their downstream effects. Self-preservation sentences have small
causal impact, suggesting they do not meaningfully drive blackmail. Second, are
artificial edits to CoT sufficient for steering reasoning? These are common in
literature, yet take the model off-policy. Resampling and selecting a
completion with the desired property is a principled on-policy alternative. We
find off-policy interventions yield small and unstable effects compared to
resampling in decision-making tasks. Third, how do we understand the effect of
removing a reasoning step when the model may repeat it post-edit? We introduce
a resilience metric that repeatedly resamples to prevent similar content from
reappearing downstream. Critical planning statements resist removal but have
large effects when eliminated. Fourth, since CoT is sometimes "unfaithful", can
our methods teach us anything in these settings? Adapting causal mediation
analysis, we find that hints that have a causal effect on the output without
being explicitly mentioned exert a subtle and cumulative influence on the CoT
that persists even if the hint is removed. Overall, studying distributions via
resampling enables reliable causal analysis, clearer narratives of model
reasoning, and principled CoT interventions.

</details>


### [161] [FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models](https://arxiv.org/abs/2510.27486)
*Junkang Liu,Fanhua Shang,Kewen Zhu,Hongying Liu,Yuanyuan Liu,Jin Liu*

Main category: cs.LG

TL;DR: 提出FedAdamW，解决联邦学习中AdamW的方差大、客户端漂移和收敛慢问题，理论证明收敛性并实验验证效果


<details>
  <summary>Details</summary>
Motivation: 直接应用AdamW在联邦学习中面临三大挑战：第二矩估计方差大、局部过拟合导致客户端漂移、每轮重置动量减慢收敛

Method: 提出FedAdamW，通过局部校正机制与解耦权重衰减缓解过拟合，聚合第二矩估计均值并避免重置，理论分析收敛性并用PAC-Bayesian解释权重衰减有效性

Result: 理论证明在无同分布假设下实现线性加速收敛，实验上在语言和视觉Transformer模型上显著减少通信轮数并提升测试准确率

Conclusion: FedAdamW是首个专为联邦学习设计的AdamW优化器，有效解决了现有方法的缺陷，具备理论保证与优异实践经验

Abstract: AdamW has become one of the most effective optimizers for training
large-scale models. We have also observed its effectiveness in the context of
federated learning (FL). However, directly applying AdamW in federated learning
settings poses significant challenges: (1) due to data heterogeneity, AdamW
often yields high variance in the second-moment estimate $\boldsymbol{v}$; (2)
the local overfitting of AdamW may cause client drift; and (3) Reinitializing
moment estimates ($\boldsymbol{v}$, $\boldsymbol{m}$) at each round slows down
convergence. To address these challenges, we propose the first
\underline{Fed}erated \underline{AdamW} algorithm, called \texttt{FedAdamW},
for training and fine-tuning various large models. \texttt{FedAdamW} aligns
local updates with the global update using both a \textbf{local correction
mechanism} and decoupled weight decay to mitigate local overfitting.
\texttt{FedAdamW} efficiently aggregates the \texttt{mean} of the second-moment
estimates to reduce their variance and reinitialize them. Theoretically, we
prove that \texttt{FedAdamW} achieves a linear speedup convergence rate of
$\mathcal{O}(\sqrt{(L \Delta \sigma_l^2)/(S K R \epsilon^2)}+(L \Delta)/R)$
without \textbf{heterogeneity assumption}, where $S$ is the number of
participating clients per round, $K$ is the number of local iterations, and $R$
is the total number of communication rounds. We also employ PAC-Bayesian
generalization analysis to explain the effectiveness of decoupled weight decay
in local training. Empirically, we validate the effectiveness of
\texttt{FedAdamW} on language and vision Transformer models. Compared to
several baselines, \texttt{FedAdamW} significantly reduces communication rounds
and improves test accuracy. The code is available in
https://github.com/junkangLiu0/FedAdamW.

</details>


### [162] [InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames](https://arxiv.org/abs/2510.27497)
*Haorui Li,Weitao Du,Yuqiang Li,Hongyu Guo,Shengchao Liu*

Main category: cs.LG

TL;DR: InertialAR通过惯性帧对齐和几何感知注意力，实现了3D分子生成的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在文本和图像中表现优异，但在3D分子生成中面临序列编码不变性与原子-坐标联合建模的挑战

Method: 提出InertialAR：1) 基于惯性帧的标准化token化方法，保证SE(3)与排列不变性；2) 引入几何旋转位置编码(GeoRoPE)增强注意力几何感知；3) 分层自回归预测：先预测原子类型，再通过扩散损失预测3D坐标

Result: 在QM9、GEOM-Drugs和B3LYP数据集上，7/10指标达SOTA；可控生成任务中5项指标全面超越基线

Conclusion: InertialAR首次有效将Transformer用于3D分子生成，解决了关键不变性与建模难题，为多模态生成模型拓展至三维分子空间提供了新范式

Abstract: Transformer-based autoregressive models have emerged as a unifying paradigm
across modalities such as text and images, but their extension to 3D molecule
generation remains underexplored. The gap stems from two fundamental
challenges: (1) tokenizing molecules into a canonical 1D sequence of tokens
that is invariant to both SE(3) transformations and atom index permutations,
and (2) designing an architecture capable of modeling hybrid atom-based tokens
that couple discrete atom types with continuous 3D coordinates. To address
these challenges, we introduce InertialAR. InertialAR devises a canonical
tokenization that aligns molecules to their inertial frames and reorders atoms
to ensure SE(3) and permutation invariance. Moreover, InertialAR equips the
attention mechanism with geometric awareness via geometric rotary positional
encoding (GeoRoPE). In addition, it utilizes a hierarchical autoregressive
paradigm to predict the next atom-based token, predicting the atom type first
and then its 3D coordinates via Diffusion loss. Experimentally, InertialAR
achieves state-of-the-art performance on 7 of the 10 evaluation metrics for
unconditional molecule generation across QM9, GEOM-Drugs, and B3LYP. Moreover,
it significantly outperforms strong baselines in controllable generation for
targeted chemical functionality, attaining state-of-the-art results across all
5 metrics.

</details>


### [163] [DP-FedPGN: Finding Global Flat Minima for Differentially Private Federated Learning via Penalizing Gradient Norm](https://arxiv.org/abs/2510.27504)
*Junkang Liu,Yuxuan Tian,Fanhua Shang,Yuanyuan Liu,Hongying Liu,Junchao Zhou,Daorui Ding*

Main category: cs.LG

TL;DR: 提出DP-FedPGN算法，通过全局梯度模惩罚寻找全局平坦极小值，在保证差分隐私的同时提升联邦学习模型的泛化性能与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有CL-DPFL方法因引入差分隐私导致损失景观尖锐，降低模型泛化能力；SAM虽寻求局部平坦极小值，但无法反映全局平坦性，且未解决数据异构与梯度裁剪误差问题。

Method: 提出DP-FedPGN，引入全局梯度模惩罚项到本地损失函数，以引导模型收敛至全局平坦极小值，结合Rényi DP提供严格隐私保证并分析本地更新敏感性。

Result: 在ResNet和Transformer上于6个视觉与NLP任务中显著优于现有SOTA方法，提升泛化性能，加速收敛，并降低梯度裁剪误差。

Conclusion: DP-FedPGN有效缓解差分隐私带来的性能退化，兼顾隐私保护、泛化能力与收敛效率，且对数据异构具有鲁棒性。

Abstract: To prevent inference attacks in Federated Learning (FL) and reduce the
leakage of sensitive information, Client-level Differentially Private Federated
Learning (CL-DPFL) is widely used. However, current CL-DPFL methods usually
result in sharper loss landscapes, which leads to a decrease in model
generalization after differential privacy protection. By using Sharpness Aware
Minimization (SAM), the current popular federated learning methods are to find
a local flat minimum value to alleviate this problem. However, the local
flatness may not reflect the global flatness in CL-DPFL. Therefore, to address
this issue and seek global flat minima of models, we propose a new CL-DPFL
algorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to
the local loss to find the global flat minimum. Moreover, by using our global
gradient norm penalty, we not only find a flatter global minimum but also
reduce the locally updated norm, which means that we further reduce the error
of gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN
mitigates the performance degradation caused by DP. Meanwhile, the proposed
DP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves
fast convergence. We also use R\'enyi DP to provide strict privacy guarantees
and provide sensitivity analysis for local updates. Finally, we conduct
effectiveness tests on both ResNet and Transformer models, and achieve
significant improvements in six visual and natural language processing tasks
compared to existing state-of-the-art algorithms. The code is available at
https://github.com/junkangLiu0/DP-FedPGN

</details>


### [164] [Learning Sparse Approximate Inverse Preconditioners for Conjugate Gradient Solvers on GPUs](https://arxiv.org/abs/2510.27517)
*Zherui Yang,Zhehao Li,Kangbo Lyu,Yixuan Li,Tao Du,Ligang Liu*

Main category: cs.LG

TL;DR: 提出一种基于GNN的GPU友好型稀疏近似逆（SPAI）预条件子，避免三角求解，加速CG收敛，相比传统方法提速68%-113%。


<details>
  <summary>Details</summary>
Motivation: 传统预条件子依赖固定算法，难以从数据中优化；现有学习方法依赖不完全分解，导致GPU并行性差且GNN难以建模长程依赖。

Method: 使用GNN直接构建SPAI预条件子，规避三角求解，仅需两次矩阵-向量乘法；引入统计学驱动的尺度不变损失函数，匹配CG对条件数的敏感性。

Result: 在PDE和合成数据集上，显著优于对角、IC、传统SPAI及现有学习方法，GPU求解时间减少40%-53%，条件数更优，泛化能力强。

Conclusion: 该方法为GPU环境下的学习型预条件子提供了高效、通用的新范式，具有实用价值与推广前景。

Abstract: The conjugate gradient solver (CG) is a prevalent method for solving
symmetric and positive definite linear systems Ax=b, where effective
preconditioners are crucial for fast convergence. Traditional preconditioners
rely on prescribed algorithms to offer rigorous theoretical guarantees, while
limiting their ability to exploit optimization from data. Existing
learning-based methods often utilize Graph Neural Networks (GNNs) to improve
the performance and speed up the construction. However, their reliance on
incomplete factorization leads to significant challenges: the associated
triangular solve hinders GPU parallelization in practice, and introduces
long-range dependencies which are difficult for GNNs to model. To address these
issues, we propose a learning-based method to generate GPU-friendly
preconditioners, particularly using GNNs to construct Sparse Approximate
Inverse (SPAI) preconditioners, which avoids triangular solves and requires
only two matrix-vector products at each CG step. The locality of matrix-vector
product is compatible with the local propagation mechanism of GNNs. The
flexibility of GNNs also allows our approach to be applied in a wide range of
scenarios. Furthermore, we introduce a statistics-based scale-invariant loss
function. Its design matches CG's property that the convergence rate depends on
the condition number, rather than the absolute scale of A, leading to improved
performance of the learned preconditioner. Evaluations on three PDE-derived
datasets and one synthetic dataset demonstrate that our method outperforms
standard preconditioners (Diagonal, IC, and traditional SPAI) and previous
learning-based preconditioners on GPUs. We reduce solution time on GPUs by
40%-53% (68%-113% faster), along with better condition numbers and superior
generalization performance. Source code available at
https://github.com/Adversarr/LearningSparsePreconditioner4GPU

</details>


### [165] [Leveraging Generic Time Series Foundation Models for EEG Classification](https://arxiv.org/abs/2510.27522)
*Théo Gnassounou,Yessin Moakher,Shifeng Xie,Vasilii Feofanov,Ievgen Redko*

Main category: cs.LG

TL;DR: 通用时间序列基础模型在脑电图任务上表现优异，超越传统EEG专用模型


<details>
  <summary>Details</summary>
Motivation: 探索通用时间序列基础模型在脑电图（EEG）等生物医学信号中的迁移能力，填补该领域研究空白

Method: 在异构真实世界数据和纯合成数据上预训练时间序列分类基础模型，并应用于运动想象分类与睡眠阶段预测任务

Result: 两种预训练方式均显著优于EEGNet和CBraMod，证明跨域预训练模型可有效迁移到EEG任务

Conclusion: 通用时间序列基础模型有潜力成为EEG分析的新范式，脑电信号分析可受益于更广泛的时间序列领域进展

Abstract: Foundation models for time series are emerging as powerful general-purpose
backbones, yet their potential for domain-specific biomedical signals such as
electroencephalography (EEG) remains rather unexplored. In this work, we
investigate the applicability a recently proposed time series classification
foundation model, to a different EEG tasks such as motor imagery classification
and sleep stage prediction. We test two pretraining regimes: (a) pretraining on
heterogeneous real-world time series from multiple domains, and (b) pretraining
on purely synthetic data. We find that both variants yield strong performance,
consistently outperforming EEGNet, a widely used convolutional baseline, and
CBraMod, the most recent EEG-specific foundation model. These results suggest
that generalist time series foundation models, even when pretrained on data of
non-neural origin or on synthetic signals, can transfer effectively to EEG. Our
findings highlight the promise of leveraging cross-domain pretrained models for
brain signal analysis, suggesting that EEG may benefit from advances in the
broader time series literature.

</details>


### [166] [Active transfer learning for structural health monitoring](https://arxiv.org/abs/2510.27525)
*J. Poole,N. Dervilis,K. Worden,P. Gardner,V. Giglioni,R. S. Mills,A. J. Hughes*

Main category: cs.LG

TL;DR: 提出一种基于贝叶斯的域自适应框架，结合主动学习，显著减少结构健康监测中标签数据需求，降低运维成本。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测标签数据昂贵且难获取，现有无监督域自适应方法未考虑在线更新与主动采样，导致数据效率低。

Method: 构建贝叶斯域自适应模型，融合主动学习策略，选择最 informative 样本进行标注，提升标签稀缺场景下的分类性能。

Result: 在多座实验桥梁数据集上验证，联合迁移学习与主动学习显著提高数据效率，减少所需标注数据量。

Conclusion: 该方法可有效降低结构运维中的检测频次与成本，为数据驱动的结构运维提供新路径。

Abstract: Data for training structural health monitoring (SHM) systems are often
expensive and/or impractical to obtain, particularly for labelled data.
Population-based SHM (PBSHM) aims to address this limitation by leveraging data
from multiple structures. However, data from different structures will follow
distinct distributions, potentially leading to large generalisation errors for
models learnt via conventional machine learning methods. To address this issue,
transfer learning -- in the form of domain adaptation (DA) -- can be used to
align the data distributions. Most previous approaches have only considered
\emph{unsupervised} DA, where no labelled target data are available; they do
not consider how to incorporate these technologies in an online framework --
updating as labels are obtained throughout the monitoring campaign. This paper
proposes a Bayesian framework for DA in PBSHM, that can improve unsupervised DA
mappings using a limited quantity of labelled target data. In addition, this
model is integrated into an active sampling strategy to guide inspections to
select the most informative observations to label -- leading to further
reductions in the required labelled data to learn a target classifier. The
effectiveness of this methodology is evaluated on a population of experimental
bridges. Specifically, this population includes data corresponding to several
damage states, as well as, a comprehensive set of environmental conditions. It
is found that combining transfer learning and active learning can improve data
efficiency when learning classification models in label-scarce scenarios. This
result has implications for data-informed operation and maintenance of
structures, suggesting a reduction in inspections over the operational lifetime
of a structure -- and therefore a reduction in operational costs -- can be
achieved.

</details>


### [167] [TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control](https://arxiv.org/abs/2510.27527)
*Yuxiang Chen,Xiaoming Xu,Pengle Zhang,Michael Beyer,Martin Rapp,Jun Zhu,Jianfei Chen*

Main category: cs.LG

TL;DR: TetraJet-v2提出一种端到端的4位全量化训练方法，显著缩小了与全精度训练的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练成本高昂，低精度全量化训练（FQT）虽能提升效率，但在4位精度下实现近无损训练仍具挑战。

Method: 采用NVFP4格式对激活值、权重和梯度进行量化，提出非偏双块量化、OsciReset抑制权重震荡、OutControl保留异常值精度。

Result: 在370M参数模型和200Btokens数据上，TetraJet-v2比现有FP4方法性能平均提升51.3%，逼近全精度表现。

Conclusion: TetraJet-v2有效解决低精度训练中的震荡与异常值问题，为高效LLM训练提供了可行方案。

Abstract: Large Language Models (LLMs) training is prohibitively expensive, driving
interest in low-precision fully-quantized training (FQT). While novel 4-bit
formats like NVFP4 offer substantial efficiency gains, achieving near-lossless
training at such low precision remains challenging. We introduce TetraJet-v2,
an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,
and gradients in all linear layers. We identify two critical issues hindering
low-precision LLM training: weight oscillation and outliers. To address these,
we propose: 1) an unbiased double-block quantization method for NVFP4 linear
layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)
OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently
outperforms prior FP4 training methods on pre-training LLMs across varying
model sizes up to 370M and data sizes up to 200B tokens, reducing the
performance gap to full-precision training by an average of 51.3%.

</details>


### [168] [AstuteRAG-FQA: Task-Aware Retrieval-Augmented Generation Framework for Proprietary Data Challenges in Financial Question Answering](https://arxiv.org/abs/2510.27537)
*Mohammad Zahangir Alam,Khandoker Ashik Uz Zaman,Mahdi H. Miraz*

Main category: cs.LG

TL;DR: AstuteRAG-FQA是一种自适应RAG框架，专为金融问答设计，通过任务感知提示工程和混合检索策略解决金融领域数据受限、隐私与合规挑战。


<details>
  <summary>Details</summary>
Motivation: 现有RAG在金融领域面临数据访问受限、检索精度低、监管约束和敏感信息解读困难等问题，亟需专用框架提升金融问答的准确性与安全性。

Method: 提出AstuteRAG-FQA框架，结合开放与私有金融数据的混合检索、四层任务分类（显式事实、隐式事实、可解释推理、隐藏因果推理）、动态提示工程、差分隐私、数据匿名化、角色访问控制及实时合规监控。

Result: 系统评估了上下文嵌入、小模型增强和目标微调三种数据集成方法，验证了其在不同金融环境中的效率与可行性。

Conclusion: AstuteRAG-FQA显著提升金融问答的精准性与合规性，为敏感领域RAG应用提供了可落地的安全架构范式。

Abstract: Retrieval-Augmented Generation (RAG) shows significant promise in
knowledge-intensive tasks by improving domain specificity, enhancing temporal
relevance, and reducing hallucinations. However, applying RAG to finance
encounters critical challenges: restricted access to proprietary datasets,
limited retrieval accuracy, regulatory constraints, and sensitive data
interpretation. We introduce AstuteRAG-FQA, an adaptive RAG framework tailored
for Financial Question Answering (FQA), leveraging task-aware prompt
engineering to address these challenges. The framework uses a hybrid retrieval
strategy integrating both open-source and proprietary financial data while
maintaining strict security protocols and regulatory compliance. A dynamic
prompt framework adapts in real time to query complexity, improving precision
and contextual relevance. To systematically address diverse financial queries,
we propose a four-tier task classification: explicit factual, implicit factual,
interpretable rationale, and hidden rationale involving implicit causal
reasoning. For each category, we identify key challenges, datasets, and
optimization techniques within the retrieval and generation process. The
framework incorporates multi-layered security mechanisms including differential
privacy, data anonymization, and role-based access controls to protect
sensitive financial information. Additionally, AstuteRAG-FQA implements
real-time compliance monitoring through automated regulatory validation systems
that verify responses against industry standards and legal obligations. We
evaluate three data integration techniques - contextual embedding, small model
augmentation, and targeted fine-tuning - analyzing their efficiency and
feasibility across varied financial environments.

</details>


### [169] [ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling](https://arxiv.org/abs/2510.27610)
*Zhuohan Wang,Ziwei Zhu,Ziniu Li,Congliang Chen,Yizhou Han,Yufeng Lin,Zhihang Lin,Angyang Gu,Xinglin Hu,Ruoyu Sun,Tian Ding*

Main category: cs.LG

TL;DR: 提出ORGEval框架，通过图同构检测评估LLM构建优化模型的能力，超越传统求解器方法，在效率和一致性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 工业优化问题建模需大量人工与领域知识，LLM自动化建模缺乏可靠评估指标，现有求解器方法存在不一致、不可行与高计算成本问题。

Method: ORGEval将优化模型表示为图，利用图同构检测与对称可分解（SD）条件下的Weisfeiler-Lehman测试，实现结构等价性评估，忽略数值扰动。

Result: ORGEval在所有参数配置下达到100%一致性，显著快于求解器方法，并构建Bench4Opt基准，发现DeepSeek-V3和Claude-Opus-4在直接提示下表现最优。

Conclusion: 图结构评估方法有效克服传统方法缺陷，为LLM优化建模提供了可扩展、高效的评价工具，推动该领域评估体系发展。

Abstract: Formulating optimization problems for industrial applications demands
significant manual effort and domain expertise. While Large Language Models
(LLMs) show promise in automating this process, evaluating their performance
remains difficult due to the absence of robust metrics. Existing solver-based
approaches often face inconsistency, infeasibility issues, and high
computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs' capabilities in
formulating linear and mixed-integer linear programs. ORGEval represents
optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the
tested graphs are symmetric decomposable (SD), under which the
Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an
SD detection algorithm to evaluate model equivalence. By focusing on structural
equivalence rather than instance-level configurations, ORGEval is robust to
numerical variations. Experimental results show that our method can
successfully detect model equivalence and produce 100\% consistent results
across random parameter configurations, while significantly outperforming
solver-based methods in runtime, especially on difficult problems. Leveraging
ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs
on optimization modeling. Our results reveal that although optimization
modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even
leading reasoning models.

</details>


### [170] [Panprediction: Optimal Predictions for Any Downstream Task and Loss](https://arxiv.org/abs/2510.27638)
*Sivaraman Balakrishnan,Nika Haghtalab,Daniel Hsu,Brian Lee,Eric Zhao*

Main category: cs.LG

TL;DR: 提出panprediction框架，证明在宽松假设下，同时最小化无限多损失和任务的统计复杂度可等同于单一任务，显著改进了全能预测的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习局限于固定损失和任务，而新兴范式希望模型能适应多种下游损失与任务，亟需统一数学框架。

Method: 形式化panprediction框架，提出确定性和随机性预测器算法，通过步校准（step calibration）实现高效降维。

Result: 确定性预测器样本复杂度为$	ilde{O}(1/\varepsilon^3)$，随机性为$	ilde{O}(1/\varepsilon^2)$，同时改进全能预测的复杂度并匹配已有最优结果。

Conclusion: Panprediction统一了全能预测与多组学习，表明多任务多损失学习在统计上可与单任务单损失同样高效。

Abstract: Supervised learning is classically formulated as training a model to minimize
a fixed loss function over a fixed distribution, or task. However, an emerging
paradigm instead views model training as extracting enough information from
data so that the model can be used to minimize many losses on many downstream
tasks. We formalize a mathematical framework for this paradigm, which we call
panprediction, and study its statistical complexity. Formally, panprediction
generalizes omniprediction and sits upstream from multi-group learning, which
respectively focus on predictions that generalize to many downstream losses or
many downstream tasks, but not both. Concretely, we design algorithms that
learn deterministic and randomized panpredictors with
$\tilde{O}(1/\varepsilon^3)$ and $\tilde{O}(1/\varepsilon^2)$ samples,
respectively. Our results demonstrate that under mild assumptions,
simultaneously minimizing infinitely many losses on infinitely many tasks can
be as statistically easy as minimizing one loss on one task. Along the way, we
improve the best known sample complexity guarantee of deterministic
omniprediction by a factor of $1/\varepsilon$, and match all other known sample
complexity guarantees of omniprediction and multi-group learning. Our key
technical ingredient is a nearly lossless reduction from panprediction to a
statistically efficient notion of calibration, called step calibration.

</details>


### [171] [Imbalanced Classification through the Lens of Spurious Correlations](https://arxiv.org/abs/2510.27650)
*Jakob Hackstein,Sidney Bender*

Main category: cs.LG

TL;DR: 通过可解释AI识别并消除类别不平衡中的Clever Hans效应，提升分类性能


<details>
  <summary>Details</summary>
Motivation: 类别不平衡会放大Clever Hans效应，而现有方法忽视这一问题

Method: 基于反事实解释的可解释AI方法，联合识别并消除不平衡中的Clever Hans效应

Result: 在三个数据集上取得competitive分类性能，并揭示了不平衡下Clever Hans效应的产生机制

Conclusion: 将不平衡问题与Clever Hans效应关联，为可解释AI在不平衡学习中的应用提供了新视角

Abstract: Class imbalance poses a fundamental challenge in machine learning, frequently
leading to unreliable classification performance. While prior methods focus on
data- or loss-reweighting schemes, we view imbalance as a data condition that
amplifies Clever Hans (CH) effects by underspecification of minority classes.
In a counterfactual explanations-based approach, we propose to leverage
Explainable AI to jointly identify and eliminate CH effects emerging under
imbalance. Our method achieves competitive classification performance on three
datasets and demonstrates how CH effects emerge under imbalance, a perspective
largely overlooked by existing approaches.

</details>


### [172] [Information-Theoretic Greedy Layer-wise Training for Traffic Sign Recognition](https://arxiv.org/abs/2510.27651)
*Shuyan Lyu,Zhanzimo Wu,Junliang Du*

Main category: cs.LG

TL;DR: 提出一种基于确定性信息瓶颈和Rényi熵的分层训练方法，无需反向传播即可在CNN上实现与SGD相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统反向传播生物不可信且内存开销大，现有分层训练方法仅在小数据集和简单架构上验证。

Method: 利用确定性信息瓶颈（DIB）和矩阵化Rényi α-熵，每层联合辅助分类器训练，学习最小充分表征。

Result: 在CIFAR-10/100和交通标志识别任务上，性能超越现有分层训练方法，接近SGD效果。

Conclusion: 该方法实现了生物 plausible、低内存、高性能的深度网络分层训练，验证了信息瓶颈原理在训练动态中的核心作用。

Abstract: Modern deep neural networks (DNNs) are typically trained with a global
cross-entropy loss in a supervised end-to-end manner: neurons need to store
their outgoing weights; training alternates between a forward pass
(computation) and a top-down backward pass (learning) which is biologically
implausible. Alternatively, greedy layer-wise training eliminates the need for
cross-entropy loss and backpropagation. By avoiding the computation of
intermediate gradients and the storage of intermediate outputs, it reduces
memory usage and helps mitigate issues such as vanishing or exploding
gradients. However, most existing layer-wise training approaches have been
evaluated only on relatively small datasets with simple deep architectures. In
this paper, we first systematically analyze the training dynamics of popular
convolutional neural networks (CNNs) trained by stochastic gradient descent
(SGD) through an information-theoretic lens. Our findings reveal that networks
converge layer-by-layer from bottom to top and that the flow of information
adheres to a Markov information bottleneck principle. Building on these
observations, we propose a novel layer-wise training approach based on the
recently developed deterministic information bottleneck (DIB) and the
matrix-based R\'enyi's $\alpha$-order entropy functional. Specifically, each
layer is trained jointly with an auxiliary classifier that connects directly to
the output layer, enabling the learning of minimal sufficient task-relevant
representations. We empirically validate the effectiveness of our training
procedure on CIFAR-10 and CIFAR-100 using modern deep CNNs and further
demonstrate its applicability to a practical task involving traffic sign
recognition. Our approach not only outperforms existing layer-wise training
baselines but also achieves performance comparable to SGD.

</details>


### [173] [Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems](https://arxiv.org/abs/2510.27659)
*Alireza Saleh Abadi,Leen-Kiat Soh*

Main category: cs.LG

TL;DR: 本文探讨开放多智能体强化学习中开放性对信用分配问题的影响，发现传统方法因假设环境静态而失效，实证表明开放性导致信用误分配和性能下降。


<details>
  <summary>Details</summary>
Motivation: 传统信用分配方法假设智能体群体、任务和类型静态，难以应对开放系统中智能体进出、任务演化和能力变化的动态特性，亟需新方法。

Method: 通过概念分析引入新的开放性子类，揭示其如何破坏环境静态性假设，并采用代表性时序与结构算法在开放环境中进行实证研究。

Result: 开放性导致信用误分配，表现为损失函数不稳定和系统性能显著下降。

Conclusion: 在开放多智能体系统中，必须重新设计信用分配方法以适应动态环境，传统静态假设已不适用。

Abstract: In the rapidly evolving field of multi-agent reinforcement learning (MARL),
understanding the dynamics of open systems is crucial. Openness in MARL refers
to the dynam-ic nature of agent populations, tasks, and agent types with-in a
system. Specifically, there are three types of openness as reported in (Eck et
al. 2023) [2]: agent openness, where agents can enter or leave the system at
any time; task openness, where new tasks emerge, and existing ones evolve or
disappear; and type openness, where the capabil-ities and behaviors of agents
change over time. This report provides a conceptual and empirical review,
focusing on the interplay between openness and the credit assignment problem
(CAP). CAP involves determining the contribution of individual agents to the
overall system performance, a task that becomes increasingly complex in open
environ-ments. Traditional credit assignment (CA) methods often assume static
agent populations, fixed and pre-defined tasks, and stationary types, making
them inadequate for open systems. We first conduct a conceptual analysis,
in-troducing new sub-categories of openness to detail how events like agent
turnover or task cancellation break the assumptions of environmental
stationarity and fixed team composition that underpin existing CAP methods. We
then present an empirical study using representative temporal and structural
algorithms in an open environment. The results demonstrate that openness
directly causes credit misattribution, evidenced by unstable loss functions and
significant performance degradation.

</details>
