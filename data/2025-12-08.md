<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 85]
- [cs.LG](#cs.LG) [Total: 69]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [AREA3D: Active Reconstruction Agent with Unified Feed-Forward 3D Perception and Vision-Language Guidance](https://arxiv.org/abs/2512.05131)
*Tianling Xu,Shengzhe Gan,Leslie Gu,Yuelei Li,Fangneng Zhan,Hanspeter Pfister*

Main category: cs.CV

TL;DR: AREA3D提出一种基于视觉-语言引导的主动3D重建方法，在稀疏视角下实现最优重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有主动重建方法依赖手工几何启发式规则，导致冗余观测且提升有限。

Method: 结合前馈3D重建模型与视觉-语言模型，解耦视点不确定性建模，引入语义引导以获取信息丰富且多样的视角。

Result: 在场景与物体级基准上实现SOTA重建精度，尤其在稀疏视角下表现突出。

Conclusion: AREA3D通过语义引导与高效不确定性估计，显著提升主动重建效率与质量。

Abstract: Active 3D reconstruction enables an agent to autonomously select viewpoints to efficiently obtain accurate and complete scene geometry, rather than passively reconstructing scenes from pre-collected images. However, existing active reconstruction methods often rely on hand-crafted geometric heuristics, which can lead to redundant observations without substantially improving reconstruction quality. To address this limitation, we propose AREA3D, an active reconstruction agent that leverages feed-forward 3D reconstruction models and vision-language guidance. Our framework decouples view-uncertainty modeling from the underlying feed-forward reconstructor, enabling precise uncertainty estimation without expensive online optimization. In addition, an integrated vision-language model provides high-level semantic guidance, encouraging informative and diverse viewpoints beyond purely geometric cues. Extensive experiments on both scene-level and object-level benchmarks demonstrate that AREA3D achieves state-of-the-art reconstruction accuracy, particularly in the sparse-view regime. Code will be made available at: https://github.com/TianlingXu/AREA3D .

</details>


### [2] [Breaking Scale Anchoring: Frequency Representation Learning for Accurate High-Resolution Inference from Low-Resolution Training](https://arxiv.org/abs/2512.05132)
*Wenshuo Wang,Fan Zhang*

Main category: cs.CV

TL;DR: 提出新问题Scale Anchoring，通过频域表示学习缓解低分辨率数据限制，使超分辨率预测误差随分辨率提升而降低


<details>
  <summary>Details</summary>
Motivation: 现有方法错误地将低分辨率误差稳定视为多分辨率泛化成功，但物理模拟模型应随分辨率提升降低误差；低分辨率数据受Nyquist频率限制无法表征高频信号，导致误差被锚定在低分辨率

Method: 提出架构无关的频率表示学习（FRL），通过分辨率对齐的频域表示和光谱一致性训练，增强高分辨率频段响应稳定性

Result: FRL方法在任务和分辨率范围内显著优于基线，误差随分辨率降低，且计算开销较小

Conclusion: Scale Anchoring是超分辨率时空预测中的新问题，FRL通过频域建模有效解决该问题，为物理感知的深度学习模型提供新方向

Abstract: Zero-Shot Super-Resolution Spatiotemporal Forecasting requires a deep learning model to be trained on low-resolution data and deployed for inference on high-resolution. Existing studies consider maintaining similar error across different resolutions as indicative of successful multi-resolution generalization. However, deep learning models serving as alternatives to numerical solvers should reduce error as resolution increases. The fundamental limitation is, the upper bound of physical law frequencies that low-resolution data can represent is constrained by its Nyquist frequency, making it difficult for models to process signals containing unseen frequency components during high-resolution inference. This results in errors being anchored at low resolution, incorrectly interpreted as successful generalization. We define this fundamental phenomenon as a new problem distinct from existing issues: Scale Anchoring. Therefore, we propose architecture-agnostic Frequency Representation Learning. It alleviates Scale Anchoring through resolution-aligned frequency representations and spectral consistency training: on grids with higher Nyquist frequencies, the frequency response in high-frequency bands of FRL-enhanced variants is more stable. This allows errors to decrease with resolution and significantly outperform baselines within our task and resolution range, while incurring only modest computational overhead.

</details>


### [3] [InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models](https://arxiv.org/abs/2512.05134)
*Zihao Wu*

Main category: cs.CV

TL;DR: InvarDiff通过利用确定性采样中的特征不变性，在不重新训练的情况下实现扩散模型2-3倍加速，且质量几乎无损。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成质量高但采样慢，因需迭代计算，存在大量冗余计算。

Method: 提出InvarDiff，基于多尺度（时间步和层）特征不变性，构建二进制缓存计划矩阵，通过分位数变化度量决定何时复用缓存结果，并引入重采样校正防止漂移。

Result: 在DiT和FLUX上实现2-3倍端到端加速，图像质量指标几乎无下降，视觉效果与完整计算几乎一致。

Conclusion: 特征不变性可有效用于加速扩散模型，InvarDiff为训练免费、高效且高保真的加速方法。

Abstract: Diffusion models deliver high-fidelity synthesis but remain slow due to iterative sampling. We empirically observe there exists feature invariance in deterministic sampling, and present InvarDiff, a training-free acceleration method that exploits the relative temporal invariance across timestep-scale and layer-scale. From a few deterministic runs, we compute a per-timestep, per-layer, per-module binary cache plan matrix and use a re-sampling correction to avoid drift when consecutive caches occur. Using quantile-based change metrics, this matrix specifies which module at which step is reused rather than recomputed. The same invariance criterion is applied at the step scale to enable cross-timestep caching, deciding whether an entire step can reuse cached results. During inference, InvarDiff performs step-first and layer-wise caching guided by this matrix. When applied to DiT and FLUX, our approach reduces redundant compute while preserving fidelity. Experiments show that InvarDiff achieves $2$-$3\times$ end-to-end speed-ups with minimal impact on standard quality metrics. Qualitatively, we observe almost no degradation in visual quality compared with full computations.

</details>


### [4] [Fine-tuning an ECG Foundation Model to Predict Coronary CT Angiography Outcomes](https://arxiv.org/abs/2512.05136)
*Yujie Xiao,Gongzhen Tang,Deyun Zhang,Jun Li,Guangkun Nie,Haoyu Wang,Shun Huang,Tong Liu,Qinghao Zhao,Kangyin Chen,Shenda Hong*

Main category: cs.CV

TL;DR: 开发了一种可解释的AI-ECG模型，用于预测冠状动脉CTA中的严重狭窄，表现稳定且在正常心电图人群中仍有效。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉CTA因设备要求高、辐射和患者配合限制，难以大规模应用，而AI-ECG利用广泛可用的心电图数据提供更便捷的CAD筛查方案。

Method: 构建可解释的AI模型，基于ECG预测四条主要冠状动脉（RCA、LM、LAD、LCX）的严重或完全狭窄，并在内外部验证集评估性能，进行亚组分析和可解释性研究。

Result: 内部验证AUC：RCA 0.794、LM 0.818、LAD 0.744、LCX 0.755；外部验证AUC：RCA 0.749、LM 0.971、LAD 0.667、LCX 0.727；在正常ECG亚组中性能稳定，且可解释性分析揭示了关键心电图波形特征。

Conclusion: AI-ECG模型在无需复杂影像设备条件下，可有效辅助冠状动脉严重狭窄筛查，具备临床实用潜力和机理解释性。

Abstract: Coronary artery disease (CAD) remains a major global health burden. Accurate identification of the culprit vessel and assessment of stenosis severity are essential for guiding individualized therapy. Although coronary CT angiography (CCTA) is the first-line non-invasive modality for CAD diagnosis, its dependence on high-end equipment, radiation exposure, and strict patient cooperation limits large-scale use. With advances in artificial intelligence (AI) and the widespread availability of electrocardiography (ECG), AI-ECG offers a promising alternative for CAD screening. In this study, we developed an interpretable AI-ECG model to predict severe or complete stenosis of the four major coronary arteries on CCTA. On the internal validation set, the model's AUCs for the right coronary artery (RCA), left main coronary artery (LM), left anterior descending artery (LAD), and left circumflex artery (LCX) were 0.794, 0.818, 0.744, and 0.755, respectively; on the external validation set, the AUCs reached 0.749, 0.971, 0.667, and 0.727, respectively. Performance remained stable in a clinically normal-ECG subset, indicating robustness beyond overt ECG abnormalities. Subgroup analyses across demographic and acquisition-time strata further confirmed model stability. Risk stratification based on vessel-specific incidence thresholds showed consistent separation on calibration and cumulative event curves. Interpretability analyses revealed distinct waveform differences between high- and low-risk groups, highlighting key electrophysiological regions contributing to model decisions and offering new insights into the ECG correlates of coronary stenosis.

</details>


### [5] [ChromouVQA: Benchmarking Vision-Language Models under Chromatic Camouflaged Images](https://arxiv.org/abs/2512.05137)
*Yunfei Zhang,Yizhuo He,Yuanxun Shao,Zhengtao Yao,Haoyan Xu,Junhao Dong,Zhen Yao,Zhikang Dong*

Main category: cs.CV

TL;DR: 提出ChromouVQA基准，用于评估视觉语言模型在复杂背景下的图-底分离能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在杂乱背景中难以识别目标，需更精细的图-底分离能力评估。

Method: 构建基于Ishihara色块的多任务基准，包含九类VQA任务，控制颜色对比、形状密度、遮挡等变量。

Result: 人类与模型表现差距显著，尤其在低对比度与复杂几何填充下；提出对比学习方法提升全局形状恢复。

Conclusion: ChromouVQA为可复现评估提供紧凑可控基准，推动模型在复杂场景中的鲁棒性研究。

Abstract: Vision-Language Models (VLMs) have advanced multimodal understanding, yet still struggle when targets are embedded in cluttered backgrounds requiring figure-ground segregation. To address this, we introduce ChromouVQA, a large-scale, multi-task benchmark based on Ishihara-style chromatic camouflaged images. We extend classic dot plates with multiple fill geometries and vary chromatic separation, density, size, occlusion, and rotation, recording full metadata for reproducibility. The benchmark covers nine vision-question-answering tasks, including recognition, counting, comparison, and spatial reasoning. Evaluations of humans and VLMs reveal large gaps, especially under subtle chromatic contrast or disruptive geometric fills. We also propose a model-agnostic contrastive recipe aligning silhouettes with their camouflaged renderings, improving recovery of global shapes. ChromouVQA provides a compact, controlled benchmark for reproducible evaluation and extension. Code and dataset are available at https://github.com/Chromou-VQA-Benchmark/Chromou-VQA.

</details>


### [6] [Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models](https://arxiv.org/abs/2512.05139)
*Yang Xiang,Jingwen Zhong,Yige Yan,Petros Koutrakis,Eric Garshick,Meredith Franklin*

Main category: cs.CV

TL;DR: 使用迁移学习的扩散模型从粗分辨率数据生成高分辨率卫星图像，表现优于传统方法，并保留物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在有限训练数据下实现高精度、物理一致的遥感图像降尺度，亟需更高效且符合物理规律的生成模型。

Method: 采用轻量级U-Net预训练提取粗分辨率数据的时空表征，冻结编码器后作为扩散模型的物理先验输入，结合MERRA-2与G5NR数据进行跨域降尺度。

Result: 在多个区域和季节中R²达0.65–0.94，超越U-Net、VAE等基线模型；通过半变异函数、自相关分析验证了空间变异性与时间自相关性的物理一致性。

Conclusion: 迁移增强的扩散模型可有效实现长期粗分辨率图像的高保真降尺度，为环境暴露评估和长期监测提供可靠工具。

Abstract: We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA's MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km). Our study area included a large area in Asia, which was made computationally tractable by splitting into two subregions and four seasons. We conducted domain similarity analysis using Wasserstein distances confirmed minimal distributional shift between MERRA-2 and G5NR, validating the safety of parameter frozen transfer. Across seasonal regional splits, our model achieved excellent performance (R2 = 0.65 to 0.94), outperforming comparison models including deterministic U-Nets, variational autoencoders, and prior transfer learning baselines. Out of data evaluations using semivariograms, ACF/PACF, and lag-based RMSE/R2 demonstrated that the predicted downscaled images preserved physically consistent spatial variability and temporal autocorrelation, enabling stable autoregressive reconstruction beyond the G5NR record. These results show that transfer enhanced diffusion models provide a robust and physically coherent solution for downscaling a long time series of coarse resolution images with limited training periods. This advancement has significant implications for improving environmental exposure assessment and long term environmental monitoring.

</details>


### [7] [FlowEO: Generative Unsupervised Domain Adaptation for Earth Observation](https://arxiv.org/abs/2512.05140)
*Georges Le Bellier,Nicolas Audebert*

Main category: cs.CV

TL;DR: FlowEO是一种基于流匹配的生成模型框架，用于遥感图像的无监督域自适应，显著提升了跨域分类与分割性能。


<details>
  <summary>Details</summary>
Motivation: 遥感数据异构性强，训练与部署域间分布偏移严重制约预训练模型泛化能力，亟需有效的无监督域自适应方法。

Method: 提出FlowEO，利用流匹配学习语义保持的图像空间映射，实现源域到目标域的分布迁移。

Result: 在四个遥感数据集上验证，FlowEO在SAR到光学、灾害引起的时序与语义偏移等场景中，优于现有图像翻译方法，且图像感知质量相当或更优。

Conclusion: 流匹配驱动的无监督域自适应在遥感领域具有巨大潜力，为跨域环境监测提供了新途径。

Abstract: The increasing availability of Earth observation data offers unprecedented opportunities for large-scale environmental monitoring and analysis. However, these datasets are inherently heterogeneous, stemming from diverse sensors, geographical regions, acquisition times, and atmospheric conditions. Distribution shifts between training and deployment domains severely limit the generalization of pretrained remote sensing models, making unsupervised domain adaptation (UDA) crucial for real-world applications. We introduce FlowEO, a novel framework that leverages generative models for image-space UDA in Earth observation. We leverage flow matching to learn a semantically preserving mapping that transports from the source to the target image distribution. This allows us to tackle challenging domain adaptation configurations for classification and semantic segmentation of Earth observation images. We conduct extensive experiments across four datasets covering adaptation scenarios such as SAR to optical translation and temporal and semantic shifts caused by natural disasters. Experimental results demonstrate that FlowEO outperforms existing image translation approaches for domain adaptation while achieving on-par or better perceptual image quality, highlighting the potential of flow-matching-based UDA for remote sensing.

</details>


### [8] [Self-Improving VLM Judges Without Human Annotations](https://arxiv.org/abs/2512.05145)
*Inna Wanyin Lin,Yushi Hu,Shuyue Stella Li,Scott Geng,Pang Wei Koh,Luke Zettlemoyer,Tim Althoff,Marjan Ghazvininejad*

Main category: cs.CV

TL;DR: 提出一种无需人工标注、仅用自合成数据自我训练视觉语言模型判别器的方法，在多个基准上超越大模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLM判别器依赖昂贵且易过时的人类偏好标注，亟需无需人工干预的自训练方法。

Method: 三阶段迭代框架：生成多模态指令-响应对，生成推理轨迹与判断并过滤低质量样本，用正确判断与推理轨迹训练判别器。

Result: 在VL-RewardBench上将Llama-3.2-11B判别器准确率从0.38提升至0.51，超越GPT-4o、Claude 3.5 Sonnet等更大模型，在通用性、幻觉检测和推理维度表现突出。

Conclusion: 该方法证明了无需人工标注的自判别器可随VLM快速发展而进化，具备未来应用潜力。

Abstract: Effective judges of Vision-Language Models (VLMs) are crucial for model development. Current methods for training VLM judges mainly rely on large-scale human preference annotations. However, such an approach is costly, and the annotations easily become obsolete as models rapidly improve. In this work, we present a framework to self-train a VLM judge model without any human preference annotations, using only self-synthesized data. Our method is iterative and has three stages: (1) generate diverse multimodal instruction-response pairs at varying quality levels, (2) generate reasoning traces and judgments for each pair, removing the ones that do not match our expected quality levels, and (3) training on correct judge answers and their reasoning traces. We evaluate the resulting judge on Multimodal RewardBench and VL-RewardBench across domains: correctness, preference, reasoning, safety, and visual question-answering. Our method improves a Llama-3.2-11B multimodal judge from 0.38 to 0.51 in overall accuracy on VL-RewardBench, often outperforming much larger models including Llama-3.2-90B, GPT-4o, and Claude 3.5 Sonnet, with particularly strong gains in general, hallucination, and reasoning dimensions. The overall strength of these human-annotation-free results suggest the potential for a future self-judge that evolves alongside rapidly improving VLM capabilities.

</details>


### [9] [TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows](https://arxiv.org/abs/2512.05150)
*Zhenglin Cheng,Peng Sun,Jianguo Li,Tao Lin*

Main category: cs.CV

TL;DR: TwinFlow 提出一种无需预训练教师模型和对抗网络的单步生成框架，在文本到图像任务中以1次评估实现媲美100步模型的性能，效率提升100倍。


<details>
  <summary>Details</summary>
Motivation: 现有少步生成方法依赖迭代蒸馏或对抗训练，存在训练不稳定、内存开销大、低步数性能下降等问题，亟需更简洁高效的单步生成方案。

Method: TwinFlow 通过双流结构直接训练单步生成器，跳过预训练教师模型和对抗网络，利用联合优化策略实现高效学习。

Result: 在1-NFE下，GenEval得分达0.83，超越SANA-Sprint和RCGM；在Qwen-Image-20B上训练后，1-NFE性能媲美原100-NFE模型，计算成本降低100倍。

Conclusion: TwinFlow 为大规模高效多模态生成提供了简单、可扩展的新范式，显著降低推理开销而不牺牲质量。

Abstract: Recent advances in large multi-modal generative models have demonstrated impressive capabilities in multi-modal generation, including image and video generation. These models are typically built upon multi-step frameworks like diffusion and flow matching, which inherently limits their inference efficiency (requiring 40-100 Number of Function Evaluations (NFEs)). While various few-step methods aim to accelerate the inference, existing solutions have clear limitations. Prominent distillation-based methods, such as progressive and consistency distillation, either require an iterative distillation procedure or show significant degradation at very few steps (< 4-NFE). Meanwhile, integrating adversarial training into distillation (e.g., DMD/DMD2 and SANA-Sprint) to enhance performance introduces training instability, added complexity, and high GPU memory overhead due to the auxiliary trained models. To this end, we propose TwinFlow, a simple yet effective framework for training 1-step generative models that bypasses the need of fixed pretrained teacher models and avoids standard adversarial networks during training, making it ideal for building large-scale, efficient models. On text-to-image tasks, our method achieves a GenEval score of 0.83 in 1-NFE, outperforming strong baselines like SANA-Sprint (a GAN loss-based framework) and RCGM (a consistency-based framework). Notably, we demonstrate the scalability of TwinFlow by full-parameter training on Qwen-Image-20B and transform it into an efficient few-step generator. With just 1-NFE, our approach matches the performance of the original 100-NFE model on both the GenEval and DPG-Bench benchmarks, reducing computational cost by $100\times$ with minor quality degradation. Project page is available at https://zhenglin-cheng.com/twinflow.

</details>


### [10] [EFDiT: Efficient Fine-grained Image Generation Using Diffusion Transformer Models](https://arxiv.org/abs/2512.05152)
*Kun Wang,Donglin Di,Tonghua Su,Lei Fan*

Main category: cs.CV

TL;DR: 提出分层嵌入器与ProAttention机制，提升细粒度图像生成的语义清晰度与细节质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在细粒度图像生成中存在语义纠缠和细节不足的问题，尤其在大规模分类中表现不佳

Method: 引入分层嵌入器融合超类与子类语义，结合感知阶段的超分辨率增强，以及高效的ProAttention机制

Result: 在公开基准上超越现有微调方法，显著提升生成图像的语义准确性和细节丰富度

Conclusion: 该方法有效缓解细粒度生成中的语义纠缠与细节缺失，为扩散模型在精细图像生成任务中提供新思路

Abstract: Diffusion models are highly regarded for their controllability and the diversity of images they generate. However, class-conditional generation methods based on diffusion models often focus on more common categories. In large-scale fine-grained image generation, issues of semantic information entanglement and insufficient detail in the generated images still persist. This paper attempts to introduce a concept of a tiered embedder in fine-grained image generation, which integrates semantic information from both super and child classes, allowing the diffusion model to better incorporate semantic information and address the issue of semantic entanglement. To address the issue of insufficient detail in fine-grained images, we introduce the concept of super-resolution during the perceptual information generation stage, enhancing the detailed features of fine-grained images through enhancement and degradation models. Furthermore, we propose an efficient ProAttention mechanism that can be effectively implemented in the diffusion model. We evaluate our method through extensive experiments on public benchmarks, demonstrating that our approach outperforms other state-of-the-art fine-tuning methods in terms of performance.

</details>


### [11] [Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning](https://arxiv.org/abs/2512.05172)
*Wentao Wang,Chunyang Liu,Kehua Sheng,Bo Zhang,Yan Wang*

Main category: cs.CV

TL;DR: 提出一种基于视觉语言模型的强化学习框架Semore，通过双路径骨干网络联合提取语义与运动表示，提升决策效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的强化学习方法主要关注策略引导，但骨干网络表示能力有限，难以充分捕捉视觉环境中的语义与动态信息。

Method: Semore框架利用VLM融合常识知识，结合CLIP实现文本-图像对齐，通过双路径骨干分别提取语义与运动特征，并采用独立监督机制实现两者的协同学习与自发交互。

Result: 实验表明，Semore在特征层面借助VLM引导，相比现有方法展现出更高效和自适应的性能。

Conclusion: VLM在特征级引导能显著提升视觉强化学习的表现，Semore为语义与运动表示的联合建模提供了有效新范式。

Abstract: The growing exploration of Large Language Models (LLM) and Vision-Language Models (VLM) has opened avenues for enhancing the effectiveness of reinforcement learning (RL). However, existing LLM-based RL methods often focus on the guidance of control policy and encounter the challenge of limited representations of the backbone networks. To tackle this problem, we introduce Enhanced Semantic Motion Representations (Semore), a new VLM-based framework for visual RL, which can simultaneously extract semantic and motion representations through a dual-path backbone from the RGB flows. Semore utilizes VLM with common-sense knowledge to retrieve key information from observations, while using the pre-trained clip to achieve the text-image alignment, thereby embedding the ground-truth representations into the backbone. To efficiently fuse semantic and motion representations for decision-making, our method adopts a separately supervised approach to simultaneously guide the extraction of semantics and motion, while allowing them to interact spontaneously. Extensive experiments demonstrate that, under the guidance of VLM at the feature level, our method exhibits efficient and adaptive ability compared to state-of-art methods. All codes are released.

</details>


### [12] [Your Latent Mask is Wrong: Pixel-Equivalent Latent Compositing for Diffusion Models](https://arxiv.org/abs/2512.05198)
*Rowan Bradbury,Dazhi Zhong*

Main category: cs.CV

TL;DR: 提出像素等效潜空间合成（PELC）原则，通过DecFormer Transformer实现高精度潜变量融合，显著提升扩散模型内补绘制的质量。


<details>
  <summary>Details</summary>
Motivation: 传统线性插值潜变量方法在掩膜边缘产生严重伪影和全局色彩失真，无法实现像素空间的真正透明合成。

Method: 引入DecFormer，一个770万参数的Transformer，预测通道级混合权重与离流形残差校正，使潜变量融合后解码结果等价于像素空间的alpha合成。

Result: 在FLUX.1系列模型上，边缘错误降低达53%，恢复全局色彩一致性与软边支持，轻量LoRA即可媲美全微调模型。

Conclusion: PELC是通用的像素等效潜空间编辑框架，不仅适用于内补绘制，还可扩展至颜色校正等任务。

Abstract: Latent inpainting in diffusion models still relies almost universally on linearly interpolating VAE latents under a downsampled mask. We propose a key principle for compositing image latents: Pixel-Equivalent Latent Compositing (PELC). An equivalent latent compositor should be the same as compositing in pixel space. This principle enables full-resolution mask control and true soft-edge alpha compositing, even though VAEs compress images 8x spatially. Modern VAEs capture global context beyond patch-aligned local structure, so linear latent blending cannot be pixel-equivalent: it produces large artifacts at mask seams and global degradation and color shifts. We introduce DecFormer, a 7.7M-parameter transformer that predicts per-channel blend weights and an off-manifold residual correction to realize mask-consistent latent fusion. DecFormer is trained so that decoding after fusion matches pixel-space alpha compositing, is plug-compatible with existing diffusion pipelines, requires no backbone finetuning and adds only 0.07% of FLUX.1-Dev's parameters and 3.5% FLOP overhead. On the FLUX.1 family, DecFormer restores global color consistency, soft-mask support, sharp boundaries, and high-fidelity masking, reducing error metrics around edges by up to 53% over standard mask interpolation. Used as an inpainting prior, a lightweight LoRA on FLUX.1-Dev with DecFormer achieves fidelity comparable to FLUX.1-Fill, a fully finetuned inpainting model. While we focus on inpainting, PELC is a general recipe for pixel-equivalent latent editing, as we demonstrate on a complex color-correction task.

</details>


### [13] [DEAR: Dataset for Evaluating the Aesthetics of RenderingDEAR: Dataset for Evaluating the Aesthetics of Rendering](https://arxiv.org/abs/2512.05209)
*Vsevolod Plohotnuk,Artyom Panshin,Nikola Banić,Simone Bianco,Michael Freeman,Egor Ershov*

Main category: cs.CV

TL;DR: 提出首个基于人类主观偏好评估图像渲染美学的基准数据集DEAR，突破传统图像质量评估局限。


<details>
  <summary>Details</summary>
Motivation: 传统图像质量评估主要关注噪声、模糊等技术退化，缺乏对渲染美学这种主观偏好领域的系统性评估数据集。

Method: 基于MIT-Adobe FiveK构建DEAR数据集，通过大规模众包收集13,648名评估者对图像对的25次 pairwise 偏好评分，捕捉细粒度审美偏好。

Result: DEAR是首个系统性反映渲染美学主观判断的数据集，支持风格偏好预测、美学基准测试与个性化建模等新任务。

Conclusion: DEAR填补了图像渲染美学评估的空白，为AI生成图像与摄影编辑提供新的评估范式。

Abstract: Traditional Image Quality Assessment~(IQA) focuses on quantifying technical degradations such as noise, blur, or compression artifacts, using both full-reference and no-reference objective metrics. However, evaluation of rendering aesthetics, a growing domain relevant to photographic editing, content creation, and AI-generated imagery, remains underexplored due to the lack of datasets that reflect the inherently subjective nature of style preference. In this work, a novel benchmark dataset designed to model human aesthetic judgments of image rendering styles is introduced: the Dataset for Evaluating the Aesthetics of Rendering (DEAR). Built upon the MIT-Adobe FiveK dataset, DEAR incorporates pairwise human preference scores collected via large-scale crowdsourcing, with each image pair evaluated by 25 distinct human evaluators with a total of 13,648 of them participating overall. These annotations capture nuanced, context-sensitive aesthetic preferences, enabling the development and evaluation of models that go beyond traditional distortion-based IQA, focusing on a new task: Evaluation of Aesthetics of Rendering (EAR). The data collection pipeline is described, human voting patterns are analyzed, and multiple use cases are outlined, including style preference prediction, aesthetic benchmarking, and personalized aesthetic modeling. To the best of the authors' knowledge, DEAR is the first dataset to systematically address image aesthetics of rendering assessment grounded in subjective human preferences. A subset of 100 images with markup for them is published on HuggingFace (huggingface.co/datasets/vsevolodpl/DEAR).

</details>


### [14] [IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction](https://arxiv.org/abs/2512.05240)
*Dmitrii Torbunov,Onur Okuducu,Yi Huang,Odera Dim,Rebecca Coles,Yonggang Cui,Yihui Ren*

Main category: cs.CV

TL;DR: 提出混合事件相机与稀疏RGB关键帧的低功耗视频捕获方法，通过扩散模型实现高质量视频重建


<details>
  <summary>Details</summary>
Motivation: 传统RGB摄像头功耗高，事件相机虽低功耗但输出非标准视频，需在节能前提下恢复可用RGB视频

Method: 采用IE2Video任务，结合单帧RGB与事件流，对比自回归模型HyperE2VID与基于扩散模型LTX的事件注入方法

Result: 扩散模型LTX较自回归基线提升33%感知质量（LPIPS: 0.283 vs 0.422），在三个事件数据集上验证了跨数据集泛化能力

Conclusion: 混合捕获+扩散重建范式显著降低功耗同时保持视频质量，为边缘视频系统提供高效解决方案

Abstract: Continuous video monitoring in surveillance, robotics, and wearable systems faces a fundamental power constraint: conventional RGB cameras consume substantial energy through fixed-rate capture. Event cameras offer sparse, motion-driven sensing with low power consumption, but produce asynchronous event streams rather than RGB video. We propose a hybrid capture paradigm that records sparse RGB keyframes alongside continuous event streams, then reconstructs full RGB video offline -- reducing capture power consumption while maintaining standard video output for downstream applications. We introduce the Image and Event to Video (IE2Video) task: reconstructing RGB video sequences from a single initial frame and subsequent event camera data. We investigate two architectural strategies: adapting an autoregressive model (HyperE2VID) for RGB generation, and injecting event representations into a pretrained text-to-video diffusion model (LTX) via learned encoders and low-rank adaptation. Our experiments demonstrate that the diffusion-based approach achieves 33\% better perceptual quality than the autoregressive baseline (0.283 vs 0.422 LPIPS). We validate our approach across three event camera datasets (BS-ERGB, HS-ERGB far/close) at varying sequence lengths (32-128 frames), demonstrating robust cross-dataset generalization with strong performance on unseen capture configurations.

</details>


### [15] [Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization](https://arxiv.org/abs/2512.05259)
*Georgios Chatzichristodoulou,Niki Efthymiou,Panagiotis Filntisis,Georgios Pavlakos,Petros Maragos*

Main category: cs.CV

TL;DR: 提出AionHMR框架，实现成人、儿童和婴儿的统一3D人体重建，支持实时、隐私保护的匿名数据发布。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体重建方法在成人上表现良好，但对儿童和婴儿泛化能力差，缺乏适用于多年龄段的统一模型。

Method: 基于SMPL-A人体模型优化，生成儿童和婴儿的伪真值标注，训练专用Transformer模型实现年龄包容的实时3D重建。

Result: 显著提升儿童和婴儿的形状与姿态估计精度，同时保持成人性能，并发布3D-BabyRobot隐私匿名数据集。

Conclusion: AionHMR填补了多年龄层3D人体建模的空白，为隐私友好的儿童行为分析奠定基础。

Abstract: While three-dimensional (3D) shape and pose estimation is a highly researched area that has yielded significant advances, the resulting methods, despite performing well for the adult population, generally fail to generalize effectively to children and infants. This paper addresses this challenge by introducing AionHMR, a comprehensive framework designed to bridge this domain gap. We propose an optimization-based method that extends a top-performing model by incorporating the SMPL-A body model, enabling the concurrent and accurate modeling of adults, children, and infants. Leveraging this approach, we generated pseudo-ground-truth annotations for publicly available child and infant image databases. Using these new training data, we then developed and trained a specialized transformer-based deep learning model capable of real-time 3D age-inclusive human reconstruction. Extensive experiments demonstrate that our methods significantly improve shape and pose estimation for children and infants without compromising accuracy on adults. Importantly, our reconstructed meshes serve as privacy-preserving substitutes for raw images, retaining essential action, pose, and geometry information while enabling anonymized datasets release. As a demonstration, we introduce the 3D-BabyRobot dataset, a collection of action-preserving 3D reconstructions of children interacting with robots. This work bridges a crucial domain gap and establishes a foundation for inclusive, privacy-aware, and age-diverse 3D human modeling.

</details>


### [16] [CARD: Correlation Aware Restoration with Diffusion](https://arxiv.org/abs/2512.05268)
*Niki Nezakati,Arnab Ghosh,Amit Roy-Chowdhury,Vishwanath Saragadam*

Main category: cs.CV

TL;DR: CARD是一种无需训练的扩散模型扩展方法，通过白化相关噪声提升图像恢复效果，并引入新数据集CIN-D评估真实场景下的相关噪声恢复性能。


<details>
  <summary>Details</summary>
Motivation: 现有去噪扩散模型假设噪声为独立同分布高斯噪声，但实际传感器噪声具有空间相关性，限制了其在真实场景中的有效性。

Method: CARD通过白化有噪声观测将相关噪声转化为独立同分布形式，并在DDRM的闭式采样框架下进行噪声白化更新，无需重新训练。

Result: 在合成相关噪声基准和新数据集CIN-D上，CARD在去噪、去模糊和超分辨率任务中均优于现有方法。

Conclusion: 正确建模空间相关噪声对实际图像恢复至关重要，CARD为处理此类噪声提供了高效且有效的解决方案。

Abstract: Denoising diffusion models have achieved state-of-the-art performance in image restoration by modeling the process as sequential denoising steps. However, most approaches assume independent and identically distributed (i.i.d.) Gaussian noise, while real-world sensors often exhibit spatially correlated noise due to readout mechanisms, limiting their practical effectiveness. We introduce Correlation Aware Restoration with Diffusion (CARD), a training-free extension of DDRM that explicitly handles correlated Gaussian noise. CARD first whitens the noisy observation, which converts the noise into an i.i.d. form. Then, the diffusion restoration steps are replaced with noise-whitened updates, which inherits DDRM's closed-form sampling efficiency while now being able to handle correlated noise. To emphasize the importance of addressing correlated noise, we contribute CIN-D, a novel correlated noise dataset captured across diverse illumination conditions to evaluate restoration methods on real rolling-shutter sensor noise. This dataset fills a critical gap in the literature for experimental evaluation with real-world correlated noise. Experiments on standard benchmarks with synthetic correlated noise and on CIN-D demonstrate that CARD consistently outperforms existing methods across denoising, deblurring, and super-resolution tasks.

</details>


### [17] [Inferring Compositional 4D Scenes without Ever Seeing One](https://arxiv.org/abs/2512.05272)
*Ahmet Berke Gokmen,Ajad Chhatkuli,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: COM4D从单目视频中联合重建多对象4D场景，无需4D compositional训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单对象建模且依赖类别特定参数模型，导致场景配置不一致且泛化性差。

Method: 通过解耦的空间与时间注意力机制，仅用2D视频监督学习对象组成与动态，再通过注意力混合机制重建4D场景。

Result: 在无4D compositional数据下，实现多对象4D重建，且在4D对象与3D重建任务上达到SOTA。

Conclusion: COM4D首次实现纯数据驱动的多对象4D场景联合重建，突破了对参数模型和4D数据的依赖。

Abstract: Scenes in the real world are often composed of several static and dynamic objects. Capturing their 4-dimensional structures, composition and spatio-temporal configuration in-the-wild, though extremely interesting, is equally hard. Therefore, existing works often focus on one object at a time, while relying on some category-specific parametric shape model for dynamic objects. This can lead to inconsistent scene configurations, in addition to being limited to the modeled object categories. We propose COM4D (Compositional 4D), a method that consistently and jointly predicts the structure and spatio-temporal configuration of 4D/3D objects using only static multi-object or dynamic single object supervision. We achieve this by a carefully designed training of spatial and temporal attentions on 2D video input. The training is disentangled into learning from object compositions on the one hand, and single object dynamics throughout the video on the other, thus completely avoiding reliance on 4D compositional training data. At inference time, our proposed attention mixing mechanism combines these independently learned attentions, without requiring any 4D composition examples. By alternating between spatial and temporal reasoning, COM4D reconstructs complete and persistent 4D scenes with multiple interacting objects directly from monocular videos. Furthermore, COM4D provides state-of-the-art results in existing separate problems of 4D object and composed 3D reconstruction despite being purely data-driven.

</details>


### [18] [From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model](https://arxiv.org/abs/2512.05277)
*Kevin Cannons,Saeed Ranjbar Alvar,Mohammad Asiful Hossain,Ahmad Rezaei,Mohsen Gholami,Alireza Heidarikhazaei,Zhou Weimin,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 提出首个专注于自动驾驶场景的时序理解基准TAD，提升VLMs对动态动作关系的理解，提出两种无训练方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频时序基准多针对体育、烹饪等场景，缺乏针对自动驾驶 ego-centric 视频的独特时序挑战的专门评估工具。

Method: 构建TAD基准（6000+ QA对，7项任务），评估9种通用与专用模型，并提出Scene-CoT和TCogMap两种无训练方法增强时序理解。

Result: 现有SoTA模型在TAD上表现不佳，所提方法在不训练的情况下使平均准确率提升达17.72%。

Conclusion: TAD填补了自动驾驶时序理解评估的空白，为未来研究提供基准与有效增强方法，代码与数据集已开源。

Abstract: Temporal understanding in autonomous driving (AD) remains a significant challenge, even for recent state-of-the-art (SoTA) Vision-Language Models (VLMs). Prior work has introduced datasets and benchmarks aimed at improving temporal reasoning, but these have emphasized other video content, including sports, cooking, and movies. No existing benchmark focuses exclusively on the unique challenges of temporal understanding in ego-centric AD footage. To fill this gap, the Temporal Understanding in Autonomous Driving (TAD) benchmark is presented, which evaluates VLMs' ability to capture the dynamic relationships between actions in AD. TAD comprises nearly 6,000 question-answer (QA) pairs, spanning 7 human-designed tasks. In addition, an evaluation is performed that consists of 9 closed- and open-source generalist models as well as SoTA AD specialist models. When applied to TAD, current SoTA models demonstrated substandard accuracies, largely due to imperfect fine-grained motion understanding. To improve motion understanding and overall accuracy on TAD, two novel training-free solutions are proposed: Scene-CoT, that leverages Chain-of-Thought (CoT) and TCogMap, which incorporates an ego-centric temporal cognitive map. The proposed approaches are integrated with existing VLMs and improve average accuracy on TAD by up to 17.72%. By introducing TAD, benchmarking multiple SoTA models, and proposing effective enhancements, this work aims to catalyze future research on temporal understanding in AD. The benchmark and evaluation code are available at \href{https://huggingface.co/datasets/vbdai/TAD}{Hugging Face} and \href{https://github.com/vbdi/tad_bench}{Github}, respectively.

</details>


### [19] [SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling](https://arxiv.org/abs/2512.05343)
*Elisabetta Fedele,Francis Engelmann,Ian Huang,Or Litany,Marc Pollefeys,Leonidas Guibas*

Main category: cs.CV

TL;DR: SpaceControl是一种无需训练的测试时方法，可对3D生成进行显式空间控制，支持多种几何输入并保持高视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本或图像的3D生成方法在几何精确性上不足，语言模糊、图像难编辑。

Method: 提出SpaceControl，利用预训练生成模型，接受从简单原语到详细网格的几何输入，无需训练，通过可控参数平衡几何保真度与视觉真实感。

Result: 在几何保真度上超越训练型和优化型基线，同时保持高视觉质量，用户研究验证其有效性。

Conclusion: SpaceControl实现了直观、精确的3D几何控制，支持交互式编辑与实际创作流程部署。

Abstract: Generative methods for 3D assets have recently achieved remarkable progress, yet providing intuitive and precise control over the object geometry remains a key challenge. Existing approaches predominantly rely on text or image prompts, which often fall short in geometric specificity: language can be ambiguous, and images are cumbersome to edit. In this work, we introduce SpaceControl, a training-free test-time method for explicit spatial control of 3D generation. Our approach accepts a wide range of geometric inputs, from coarse primitives to detailed meshes, and integrates seamlessly with modern pre-trained generative models without requiring any additional training. A controllable parameter lets users trade off between geometric fidelity and output realism. Extensive quantitative evaluation and user studies demonstrate that SpaceControl outperforms both training-based and optimization-based baselines in geometric faithfulness while preserving high visual quality. Finally, we present an interactive user interface that enables online editing of superquadrics for direct conversion into textured 3D assets, facilitating practical deployment in creative workflows. Find our project page at https://spacecontrol3d.github.io/

</details>


### [20] [SplatPainter: Interactive Authoring of 3D Gaussians from 2D Edits via Test-Time Training](https://arxiv.org/abs/2512.05354)
*Yang Zheng,Hao Tan,Kai Zhang,Peng Wang,Leonidas Guibas,Gordon Wetzstein,Wang Yifan*

Main category: cs.CV

TL;DR: 提出一种状态感知的前馈模型，实现对3D高斯点云的交互式编辑，支持局部细化、涂刷和全局重着色，速度极快。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散或优化的方法速度慢、破坏原始资产特征，缺乏精细控制能力，难以满足交互式3D编辑需求。

Method: 采用状态感知的前馈模型，直接预测高斯属性更新，并结合测试时训练实现迭代编辑，输入为2D视图。

Result: 支持多种编辑任务（局部细化、涂刷、重着色），保持高保真度，实现交互式速度，且单模型通用。

Conclusion: 该方法为3D内容创作提供了流畅直观的交互编辑新范式，突破了现有技术的效率与精度瓶颈。

Abstract: The rise of 3D Gaussian Splatting has revolutionized photorealistic 3D asset creation, yet a critical gap remains for their interactive refinement and editing. Existing approaches based on diffusion or optimization are ill-suited for this task, as they are often prohibitively slow, destructive to the original asset's identity, or lack the precision for fine-grained control. To address this, we introduce \ourmethod, a state-aware feedforward model that enables continuous editing of 3D Gaussian assets from user-provided 2D view(s). Our method directly predicts updates to the attributes of a compact, feature-rich Gaussian representation and leverages Test-Time Training to create a state-aware, iterative workflow. The versatility of our approach allows a single architecture to perform diverse tasks, including high-fidelity local detail refinement, local paint-over, and consistent global recoloring, all at interactive speeds, paving the way for fluid and intuitive 3D content authoring.

</details>


### [21] [Group Orthogonal Low-Rank Adaptation for RGB-T Tracking](https://arxiv.org/abs/2512.05359)
*Zekai Shao,Yufan Hu,Jingyuan Liu,Bin Fan,Hongmin Liu*

Main category: cs.CV

TL;DR: 提出GOLA框架通过正交约束减少低秩适配中的参数冗余，提升RGB-T跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 低秩适配在RGB-T跟踪中存在显著冗余，限制模型学习多样化知识以应对复杂挑战。

Method: 采用SVD分解量化秩重要性，冻结关键秩，聚类冗余秩并引入组间正交约束，迫使不同组学习互补特征。

Result: GOLA显著减少参数冗余，提升特征表达能力，在四个基准数据集上超越现有方法。

Conclusion: 结构化正交低秩适配有效增强RGB-T跟踪的适应性与性能。

Abstract: Parameter-efficient fine-tuning has emerged as a promising paradigm in RGB-T tracking, enabling downstream task adaptation by freezing pretrained parameters and fine-tuning only a small set of parameters. This set forms a rank space made up of multiple individual ranks, whose expressiveness directly shapes the model's adaptability. However, quantitative analysis reveals low-rank adaptation exhibits significant redundancy in the rank space, with many ranks contributing almost no practical information. This hinders the model's ability to learn more diverse knowledge to address the various challenges in RGB-T tracking. To address this issue, we propose the Group Orthogonal Low-Rank Adaptation (GOLA) framework for RGB-T tracking, which effectively leverages the rank space through structured parameter learning. Specifically, we adopt a rank decomposition partitioning strategy utilizing singular value decomposition to quantify rank importance, freeze crucial ranks to preserve the pretrained priors, and cluster the redundant ranks into groups to prepare for subsequent orthogonal constraints. We further design an inter-group orthogonal constraint strategy. This constraint enforces orthogonality between rank groups, compelling them to learn complementary features that target diverse challenges, thereby alleviating information redundancy. Experimental results demonstrate that GOLA effectively reduces parameter redundancy and enhances feature representation capabilities, significantly outperforming state-of-the-art methods across four benchmark datasets and validating its effectiveness in RGB-T tracking tasks.

</details>


### [22] [PoolNet: Deep Learning for 2D to 3D Video Process Validation](https://arxiv.org/abs/2512.05362)
*Sanchit Kaul,Joseph Luna,Shray Arora*

Main category: cs.CV

TL;DR: 提出PoolNet深度学习框架，高效筛选适合SfM处理的图像数据，显著缩短处理时间。


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法耗时且计算成本高，且大量公开数据因相机姿态不足、遮挡和噪声而不适用。

Method: 引入PoolNet，一种用于帧级和场景级验证的深度学习框架，评估图像数据是否适合SfM处理。

Result: PoolNet能有效区分适合与不适合SfM的场景，并大幅减少SfM数据获取时间。

Conclusion: PoolNet为野外图像数据的SfM预处理提供了高效、可靠的解决方案。

Abstract: Lifting Structure-from-Motion (SfM) information from sequential and non-sequential image data is a time-consuming and computationally expensive task. In addition to this, the majority of publicly available data is unfit for processing due to inadequate camera pose variation, obscuring scene elements, and noisy data. To solve this problem, we introduce PoolNet, a versatile deep learning framework for frame-level and scene-level validation of in-the-wild data. We demonstrate that our model successfully differentiates SfM ready scenes from those unfit for processing while significantly undercutting the amount of time state of the art algorithms take to obtain structure-from-motion data.

</details>


### [23] [ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration](https://arxiv.org/abs/2512.05385)
*Yingjie Xia,Tao Liu,Jinglei Shi,Qingsong Xie,Heng Guo,Jian Yang,Xi Wang*

Main category: cs.CV

TL;DR: 提出ShaRP框架，在不重新训练的情况下通过改进注意力剪枝显著加速VLLM推理，尤其在浅层实现高压缩率下的稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现有注意力剪枝方法在VLLM浅层解码器中因位置编码偏差和信息交互不足导致性能严重下降，亟需更有效的剪枝策略。

Method: ShaRP融合分段感知因果掩码、位置去偏差和令牌去重，优化浅层视觉令牌选择。

Result: 在多个视频理解基准上达到竞争力性能，无需重训练即可在高压缩率下稳定运行。

Conclusion: ShaRP为加速VLLM推理建立新范式，证明改进注意力剪枝在浅层有效可行。

Abstract: Video Large Language Models (VLLMs) face the challenge of high computational load during the pre-filling stage due to the processing of an enormous number of visual tokens. Although attention-based pruning methods are widely used to accelerate inference, trials at early decoder layers often result in significant performance degradation, especially under high compression rates. We argue that while attention-based pruning inherently holds the potential to identify the most relevant visual tokens, its effectiveness in shallow decoder layers is limited by factors such as positional encoding bias and insufficient information interaction. In this paper, we propose an improved attention-based pruning framework, termed ShaRP, that integrates segment-aware causal masking, positional debiasing, and token deduplication for enhanced token selection. It enables effective pruning at shallow layers while maintaining stable performance under high compression rates without retraining. Extensive experiments demonstrate that ShaRP achieves competitive performance across multiple video understanding benchmarks, establishing a new paradigm for accelerating VLLM inference.

</details>


### [24] [LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models](https://arxiv.org/abs/2512.05391)
*Qingqiao Hu,Weimin Lyu,Meilong Xu,Kehan Qi,Xiaoling Hu,Saumya Gupta,Jiawei Zhou,Chao Chen*

Main category: cs.CV

TL;DR: 提出LoC-Path框架，通过减少病理全切片图像中的冗余特征，实现高效且性能相当的多模态语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有模型因处理大量图像块导致计算开销大，而人类专家仅依赖关键区域诊断，存在效率差距。

Method: 引入Sparse Token Merger与MAE预训练重采样器压缩冗余图块，结合Cross-Attention Routing Adapter和Token Importance Scorer高效融合视觉与语言模型。

Result: 性能媲美现有最先进模型，显著降低计算与内存开销。

Conclusion: 通过冗余消除与注意力路由，可实现病理WSI理解的高效建模，无需依赖重型编码器。

Abstract: Whole Slide Image (WSI) understanding is fundamentally challenging due to its gigapixel scale and the extreme sparsity of diagnostically relevant regions. Unlike human experts who primarily rely on key areas to arrive at a diagnosis, existing slide-level multimodal large language models (MLLMs) for pathology rely on heavy slide-level encoders that process thousands of patch features in a brute-force manner, resulting in excessive computational cost. In this work, we revisit the WSI-language modeling paradigm and show that tile-level features exhibit strong global and local redundancy, whereas only a small subset of tiles are truly task-relevant. Motivated by this observation, we introduce an efficient MLLM framework, called LoC-Path, that replaces the expensive slide-level encoder with redundancy-reducing modules. We first design a Sparse Token Merger (STM) and an MAE-pretrained resampler to remove local redundancy and compress globally redundant tile tokens into a compact slide-level representation set. We then propose a Cross-Attention Routing Adapter (CARA) and a Token Importance Scorer (TIS) to integrate the compressed visual representation with the language model in a computation-efficient manner. Extensive experiments demonstrate that our approach achieves performance comparable to existing state-of-the-art whole-slide MLLMs, while requiring significantly lower computation and memory.

</details>


### [25] [Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability](https://arxiv.org/abs/2512.05394)
*Shizhan Liu,Xinran Deng,Zhuoyi Yang,Jiayan Teng,Xiaotao Gu,Jie Tang*

Main category: cs.CV

TL;DR: 提出SSVAE，通过两种轻量正则化方法优化视频VAE潜在空间频谱结构，显著加速文本到视频生成并提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频VAE注重重建保真度，忽视潜在空间结构对扩散训练的影响，导致训练困难。

Method: 提出局部相关性正则化和潜在掩码重建两种轻量、与主干无关的正则化方法，引导潜在空间具有低频偏置和少数主导模式的频谱特性。

Result: SSVAE使文本到视频生成收敛速度提升3倍，视频奖励提升10%，优于开源强基线VAE。

Conclusion: 潜在空间的频谱结构对扩散模型训练至关重要，SSVAE通过结构化设计显著提升效率与质量。

Abstract: Latent diffusion models pair VAEs with diffusion backbones, and the structure of VAE latents strongly influences the difficulty of diffusion training. However, existing video VAEs typically focus on reconstruction fidelity, overlooking latent structure. We present a statistical analysis of video VAE latent spaces and identify two spectral properties essential for diffusion training: a spatio-temporal frequency spectrum biased toward low frequencies, and a channel-wise eigenspectrum dominated by a few modes. To induce these properties, we propose two lightweight, backbone-agnostic regularizers: Local Correlation Regularization and Latent Masked Reconstruction. Experiments show that our Spectral-Structured VAE (SSVAE) achieves a $3\times$ speedup in text-to-video generation convergence and a 10\% gain in video reward, outperforming strong open-source VAEs. The code is available at https://github.com/zai-org/SSVAE.

</details>


### [26] [The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos](https://arxiv.org/abs/2512.05398)
*Zhuoyuan Wu,Xurui Yang,Jiahui Huang,Yue Wang,Jun Gao*

Main category: cs.CV

TL;DR: 提出Dynamic Prior方法，利用视觉语言模型和SAM2无需训练即可准确分割动态物体，显著提升3D结构重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法受动态物体干扰，现有学习方法因缺乏大规模运动分割数据集而效果有限。

Method: 引入Dynamic Prior，结合VLMs的推理能力与SAM2的细粒度分割能力，实现无需任务训练的动态物体识别。

Result: 在合成与真实视频上达到运动分割SOTA，并显著提升相机位姿、深度重建和4D轨迹估计的精度与鲁棒性。

Conclusion: Dynamic Prior为动态场景下的3D理解提供了一种无需训练、通用且高效的解决方案。

Abstract: Estimating accurate camera poses, 3D scene geometry, and object motion from in-the-wild videos is a long-standing challenge for classical structure from motion pipelines due to the presence of dynamic objects. Recent learning-based methods attempt to overcome this challenge by training motion estimators to filter dynamic objects and focus on the static background. However, their performance is largely limited by the availability of large-scale motion segmentation datasets, resulting in inaccurate segmentation and, therefore, inferior structural 3D understanding. In this work, we introduce the Dynamic Prior (\ourmodel) to robustly identify dynamic objects without task-specific training, leveraging the powerful reasoning capabilities of Vision-Language Models (VLMs) and the fine-grained spatial segmentation capacity of SAM2. \ourmodel can be seamlessly integrated into state-of-the-art pipelines for camera pose optimization, depth reconstruction, and 4D trajectory estimation. Extensive experiments on both synthetic and real-world videos demonstrate that \ourmodel not only achieves state-of-the-art performance on motion segmentation, but also significantly improves accuracy and robustness for structural 3D understanding.

</details>


### [27] [Genetic Algorithms For Parameter Optimization for Disparity Map Generation of Radiata Pine Branch Images](https://arxiv.org/abs/2512.05410)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 使用遗传算法自动优化SGBM和WLS参数，提升无人机树枝距离测量精度，同时保持高效处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统立体匹配算法如SGBM+WLS虽快，但依赖人工调参，难以在复杂林业环境中保持高精度。

Method: 提出基于遗传算法的参数优化框架，自动搜索SGBM与WLS的最佳参数组合。

Result: 相比基线配置，均方误差降低42.86%，PSNR提升8.47%，SSIM提升28.52%，且在多种成像条件下泛化性能更优。

Conclusion: 该方法无需人工调参，适用于资源受限的无人机系统，显著提升林业场景中的距离测量精度与鲁棒性。

Abstract: Traditional stereo matching algorithms like Semi-Global Block Matching (SGBM) with Weighted Least Squares (WLS) filtering offer speed advantages over neural networks for UAV applications, generating disparity maps in approximately 0.5 seconds per frame. However, these algorithms require meticulous parameter tuning. We propose a Genetic Algorithm (GA) based parameter optimization framework that systematically searches for optimal parameter configurations for SGBM and WLS, enabling UAVs to measure distances to tree branches with enhanced precision while maintaining processing efficiency. Our contributions include: (1) a novel GA-based parameter optimization framework that eliminates manual tuning; (2) a comprehensive evaluation methodology using multiple image quality metrics; and (3) a practical solution for resource-constrained UAV systems. Experimental results demonstrate that our GA-optimized approach reduces Mean Squared Error by 42.86% while increasing Peak Signal-to-Noise Ratio and Structural Similarity by 8.47% and 28.52%, respectively, compared with baseline configurations. Furthermore, our approach demonstrates superior generalization performance across varied imaging conditions, which is critcal for real-world forestry applications.

</details>


### [28] [YOLO and SGBM Integration for Autonomous Tree Branch Detection and Depth Estimation in Radiata Pine Pruning Applications](https://arxiv.org/abs/2512.05412)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 使用双目摄像头和YOLO+SGBM实现低成本自主无人机修剪松树，提升安全性与效率


<details>
  <summary>Details</summary>
Motivation: 人工修剪辐射松存在高空和地形作业风险，需自动化解决方案

Method: 基于YOLO目标检测与SGBM立体匹配的计算机视觉框架，仅用双目摄像头实现枝干检测与深度估计

Result: YOLO较Mask R-CNN提升至82.0% mAPmask50-95，2米内定位准确，单帧处理时间<1秒

Conclusion: 该系统无需LiDAR，成本低且可行，可显著提升林业作业安全与效率

Abstract: Manual pruning of radiata pine trees poses significant safety risks due to extreme working heights and challenging terrain. This paper presents a computer vision framework that integrates YOLO object detection with Semi-Global Block Matching (SGBM) stereo vision for autonomous drone-based pruning operations. Our system achieves precise branch detection and depth estimation using only stereo camera input, eliminating the need for expensive LiDAR sensors. Experimental evaluation demonstrates YOLO's superior performance over Mask R-CNN, achieving 82.0% mAPmask50-95 for branch segmentation. The integrated system accurately localizes branches within a 2 m operational range, with processing times under one second per frame. These results establish the feasibility of cost-effective autonomous pruning systems that enhance worker safety and operational efficiency in commercial forestry.

</details>


### [29] [Label-Efficient Point Cloud Segmentation with Active Learning](https://arxiv.org/abs/2512.05759)
*Johannes Meyer,Jasper Hoffmann,Felix Schulz,Dominik Merkle,Daniel Buescher,Alexander Reiterer,Joschka Boedecker,Wolfram Burgard*

Main category: cs.CV

TL;DR: 提出一种简单有效的3D点云主动学习方法，使用2D网格分割点云并用网络集成估计不确定性，在多个数据集上达到或超越复杂方法的性能。


<details>
  <summary>Details</summary>
Motivation: 3D点云语义分割标注成本高，现有主动学习方法依赖复杂启发式策略，亟需更简洁高效的方法。

Method: 采用2D网格将点云划分为列状可标注区域，利用网络集成估计预测不确定性以选择最有益的区域进行标注。

Result: 在S3DIS、Toronto-3D和Freiburg城市点云数据集上性能媲美或优于现有复杂方法，且标注面积比标注点数更适合作为评估指标。

Conclusion: 所提方法简单有效，验证了标注面积在点云主动学习中的优越性，为未来研究提供新方向。

Abstract: Semantic segmentation of 3D point cloud data often comes with high annotation costs. Active learning automates the process of selecting which data to annotate, reducing the total amount of annotation needed to achieve satisfactory performance. Recent approaches to active learning for 3D point clouds are often based on sophisticated heuristics for both, splitting point clouds into annotatable regions and selecting the most beneficial for further neural network training. In this work, we propose a novel and easy-to-implement strategy to separate the point cloud into annotatable regions. In our approach, we utilize a 2D grid to subdivide the point cloud into columns. To identify the next data to be annotated, we employ a network ensemble to estimate the uncertainty in the network output. We evaluate our method on the S3DIS dataset, the Toronto-3D dataset, and a large-scale urban 3D point cloud of the city of Freiburg, which we labeled in parts manually. The extensive evaluation shows that our method yields performance on par with, or even better than, complex state-of-the-art methods on all datasets. Furthermore, we provide results suggesting that in the context of point clouds the annotated area can be a more meaningful measure for active learning algorithms than the number of annotated points.

</details>


### [30] [Moving object detection from multi-depth images with an attention-enhanced CNN](https://arxiv.org/abs/2512.05415)
*Masato Shibukawa,Fumi Yoshida,Toshifumi Yanagisawa,Takashi Ito,Hirohisa Kurosaki,Makoto Yoshikawa,Kohki Kamiya,Ji-an Jiang,Wesley Fraser,JJ Kavelaars,Susan Benecchi,Anne Verbiscer,Akira Hatakeyama,Hosei O,Naoya Ozaki*

Main category: cs.CV

TL;DR: 提出一种多输入卷积神经网络结合注意力模块的方法，显著提升太阳系移动物体检测的准确率并减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统依赖人工验证移动物体信号的方法劳动成本高，亟需自动化解决方案。

Method: 采用多输入卷积神经网络，同时处理多帧堆叠图像，并引入卷积块注意力模块以增强空间与通道维度的关键特征提取。

Result: 在约2000张观测图像上实现99%准确率、AUC>0.99，人工工作量减少99%以上。

Conclusion: 该方法显著提升检测性能，实现高效自动化验证，为大规模巡天数据处理提供有力工具。

Abstract: One of the greatest challenges for detecting moving objects in the solar system from wide-field survey data is determining whether a signal indicates a true object or is due to some other source, like noise. Object verification has relied heavily on human eyes, which usually results in significant labor costs. In order to address this limitation and reduce the reliance on manual intervention, we propose a multi-input convolutional neural network integrated with a convolutional block attention module. This method is specifically tailored to enhance the moving object detection system that we have developed and used previously. The current method introduces two innovations. This first one is a multi-input architecture that processes multiple stacked images simultaneously. The second is the incorporation of the convolutional block attention module which enables the model to focus on essential features in both spatial and channel dimensions. These advancements facilitate efficient learning from multiple inputs, leading to more robust detection of moving objects. The performance of the model is evaluated on a dataset consisting of approximately 2,000 observational images. We achieved an accuracy of nearly 99% with AUC (an Area Under the Curve) of >0.99. These metrics indicate that the proposed model achieves excellent classification performance. By adjusting the threshold for object detection, the new model reduces the human workload by more than 99% compared to manual verification.

</details>


### [31] [World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty](https://arxiv.org/abs/2512.05927)
*Zhiting Mei,Tenny Yin,Micah Baker,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.CV

TL;DR: 提出C3方法，通过潜空间校准实现视频生成的亚像素级置信度估计，有效检测幻觉与分布外样本。


<details>
  <summary>Details</summary>
Motivation: 现有可控视频模型无法评估自身置信度，导致生成内容违背物理现实，影响机器人规划等关键应用。

Method: 引入基于严格适当评分规则的潜空间不确定性量化框架，将高分辨率潜空间不确定性映射至RGB像素空间，实现可解释的热力图可视化。

Result: 在Bridge和DROID数据集上实现校准的置信度估计，并有效检测分布外样本，支持高分辨率不确定性可视化。

Conclusion: C3首次实现可控视频模型的稠密、校准、可解释的不确定性估计，显著提升生成安全性与可靠性。

Abstract: Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model's uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.

</details>


### [32] [Performance Evaluation of Deep Learning for Tree Branch Segmentation in Autonomous Forestry Systems](https://arxiv.org/abs/2512.05418)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 在不同分辨率下评估深度学习模型用于无人机林业枝干分割，确定精度与效率的权衡基准。


<details>
  <summary>Details</summary>
Motivation: 无人机自主林业操作需在多变条件下实现快速精确的枝干分割，以保障导航与修剪安全。

Method: 在256x256、512x512、1024x1024三种分辨率下，使用Urban Street Tree Dataset测试22种深度学习配置，采用IoU、Dice、TS-IoU和CPR等指标评估。

Result: U-Net+MiT-B4在256x256和512x512表现最优；U-Net+MiT-B3在1024x1024精度最高，U-Net++边界质量最佳；PSPNet效率最高但精度较低。

Conclusion: 本研究建立了适用于嵌入式林业系统的多分辨率分割精度-效率基准，为实际部署提供指导。

Abstract: UAV-based autonomous forestry operations require rapid and precise tree branch segmentation for safe navigation and automated pruning across varying pixel resolutions and operational conditions. We evaluate different deep learning methods at three resolutions (256x256, 512x512, 1024x1024) using the Urban Street Tree Dataset, employing standard metrics (IoU, Dice) and specialized measures including Thin Structure IoU (TS-IoU) and Connectivity Preservation Rate (CPR). Among 22 configurations tested, U-Net with MiT-B4 backbone achieves strong performance at 256x256. At 512x512, MiT-B4 leads in IoU, Dice, TS-IoU, and Boundary-F1. At 1024x1024, U-Net+MiT-B3 shows the best validation performance for IoU/Dice and precision, while U-Net++ excels in boundary quality. PSPNet provides the most efficient option (2.36/9.43/37.74 GFLOPs) with 25.7/19.6/11.8 percentage point IoU reductions compared to top performers at respective resolutions. These results establish multi-resolution benchmarks for accuracy-efficiency trade-offs in embedded forestry systems. Implementation is available at https://github.com/BennyLinntu/PerformanceTreeBranchSegmentation.

</details>


### [33] [Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition](https://arxiv.org/abs/2512.05936)
*Anne Sielemann,Lena Loercher,Max-Lion Schumacher,Stefan Wolf,Masoud Roschani,Jens Ziehn*

Main category: cs.CV

TL;DR: 提出一种结合数据驱动与分析建模的交通标志合成管道，生成逼真且参数可调的合成数据集Synset Signset Germany，用于提升交通标志识别性能与可解释性研究。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据集缺乏真实磨损效果与物理光照建模，限制了模型在现实场景中的鲁棒性与可解释性评估。

Method: 采用GAN生成纹理磨损效果，结合分析性场景调制实现物理正确的光照与参数化控制，构建包含105500张图像的合成数据集。

Result: 生成的Synset Signset Germany数据集包含211类德国交通标志，提供遮罩、分割图及详细元数据，在真实数据集GTSRB上评估其逼真度优于现有SOTA方法CATERED。

Conclusion: 该方法实现了高逼真度与可参数化合成，为可解释AI与鲁棒性测试提供了新工具，推动交通标志识别系统的可靠评估。

Abstract: In this paper, we present a synthesis pipeline and dataset for training / testing data in the task of traffic sign recognition that combines the advantages of data-driven and analytical modeling: GAN-based texture generation enables data-driven dirt and wear artifacts, rendering unique and realistic traffic sign surfaces, while the analytical scene modulation achieves physically correct lighting and allows detailed parameterization. In particular, the latter opens up applications in the context of explainable AI (XAI) and robustness tests due to the possibility of evaluating the sensitivity to parameter changes, which we demonstrate with experiments. Our resulting synthetic traffic sign recognition dataset Synset Signset Germany contains a total of 105500 images of 211 different German traffic sign classes, including newly published (2020) and thus comparatively rare traffic signs. In addition to a mask and a segmentation image, we also provide extensive metadata including the stochastically selected environment and imaging effect parameters for each image. We evaluate the degree of realism of Synset Signset Germany on the real-world German Traffic Sign Recognition Benchmark (GTSRB) and in comparison to CATERED, a state-of-the-art synthetic traffic sign recognition dataset.

</details>


### [34] [ParaUni: Enhance Generation in Unified Multimodal Model with Reinforcement-driven Hierarchical Parallel Information Interaction](https://arxiv.org/abs/2512.05422)
*Jiangtong Tan,Lin Liu,Jie Huanng,Xiaopeng Zhang,Qi Tian,Feng Zhao*

Main category: cs.CV

TL;DR: ParaUni通过并行提取VLM多层特征并引入层间动态调整机制，显著提升统一多模态模型的生成质量与强化学习奖励对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法因视觉语言模型与扩散模型间表征差异大，难以平衡充分交互与灵活实现。

Method: 提出ParaUni，并行提取VLM多层特征通过层集成模块（LIM）融合，并设计层间动态调整机制（LDAM）优化强化学习中的多奖励对齐。

Result: 实验表明ParaUni利用多层互补特征显著提升生成质量，并在强化学习阶段展现强大的多奖励提升潜力。

Conclusion: ParaUni通过结构化多层特征交互与动态奖励对齐，为统一多模态生成提供了高效且灵活的新范式。

Abstract: Unified multimodal models significantly improve visual generation by combining vision-language models (VLMs) with diffusion models. However, existing methods struggle to fully balance sufficient interaction and flexible implementation due to vast representation difference. Considering abundant and hierarchical information in VLM's layers from low-level details to high-level semantics, we propose \textbf{ParaUni}. It extracts features from variants VLM's layers in a \textbf{Para}llel way for comprehensive information interaction and retains a flexible separation architecture to enhance generation in \textbf{Uni}fied multimodal model. Concretely, visual features from all VLM's layers are fed in parallel into a Layer Integration Module (LIM), which efficiently integrates fine-grained details and semantic abstractions and provides the fused representation as a condition to the diffusion model. To further enhance performance, we reveal that these hierarchical layers respond unequally to different rewards in Reinforcement Learning (RL). Crucially, we design a Layer-wise Dynamic Adjustment Mechanism (LDAM) to facilitate multiple reward improvements that aligns the hierarchical properties of these layers using RL. Extensive experiments show ParaUni leverages complementary multi-layer features to substantially improve generation quality and shows strong potential for multiple reward advances during RL stages. Code is available at https://github.com/JosephTiTan/ParaUni.

</details>


### [35] [Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception](https://arxiv.org/abs/2512.05937)
*Anne Sielemann,Valentin Barner,Stefan Wolf,Masoud Roschani,Jens Ziehn,Juergen Beyerer*

Main category: cs.CV

TL;DR: 通过生成六种合成数据集，量化背景相关性对交通标志识别中分类性能和特征重要性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法难以定量评估背景特征是否为虚假相关，真实数据中相关性难以控制，而合成数据缺乏真实感量化。

Method: 系统生成六种仅在相机变化和背景相关性程度上不同的合成交通标志数据集，隔离分析背景特征对分类性能和显著性的影响。

Result: 量化了在训练域变化下，背景特征何时以及多大程度上获得分类重要性。

Conclusion: 合成数据能有效分离和度量背景相关性的影响，为XAI方法的评估提供了可量化的基准。

Abstract: Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [...] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [...] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [...] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [...].
  Download: synset.de/datasets/synset-signset-ger/background-effect

</details>


### [36] [TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression](https://arxiv.org/abs/2512.05446)
*Cheng-Yuan Ho,He-Bi Yang,Jui-Chiu Chiang,Yu-Lun Liu,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 提出TED-4DGS，一种基于时间激活与嵌入的动态3D高斯泼溅压缩方法，实现最优率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法要么冗余低效，要么缺乏显式时间控制，亟需更紧凑且率失真优化的压缩方案。

Method: 采用稀疏锚点基础的3DGS，引入可学习的时间激活参数与轻量级时间嵌入，结合INR超先验和通道自回归模型进行率失真压缩。

Result: 在多个真实数据集上达到当前最优的率失真性能，是首个针对动态3DGS的率失真优化压缩框架之一。

Conclusion: TED-4DGS有效统一了时空与规范表示的优点，为动态3DGS的高效压缩提供了新范式。

Abstract: Building on the success of 3D Gaussian Splatting (3DGS) in static 3D scene representation, its extension to dynamic scenes, commonly referred to as 4DGS or dynamic 3DGS, has attracted increasing attention. However, designing more compact and efficient deformation schemes together with rate-distortion-optimized compression strategies for dynamic 3DGS representations remains an underexplored area. Prior methods either rely on space-time 4DGS with overspecified, short-lived Gaussian primitives or on canonical 3DGS with deformation that lacks explicit temporal control. To address this, we present TED-4DGS, a temporally activated and embedding-based deformation scheme for rate-distortion-optimized 4DGS compression that unifies the strengths of both families. TED-4DGS is built on a sparse anchor-based 3DGS representation. Each canonical anchor is assigned learnable temporal-activation parameters to specify its appearance and disappearance transitions over time, while a lightweight per-anchor temporal embedding queries a shared deformation bank to produce anchor-specific deformation. For rate-distortion compression, we incorporate an implicit neural representation (INR)-based hyperprior to model anchor attribute distributions, along with a channel-wise autoregressive model to capture intra-anchor correlations. With these novel elements, our scheme achieves state-of-the-art rate-distortion performance on several real-world datasets. To the best of our knowledge, this work represents one of the first attempts to pursue a rate-distortion-optimized compression framework for dynamic 3DGS representations.

</details>


### [37] [University Building Recognition Dataset in Thailand for the mission-oriented IoT sensor system](https://arxiv.org/abs/2512.05468)
*Takara Taniguchi,Yudai Ueda,Atsuya Muramatsu,Kohki Hashimoto,Ryo Yagi,Hideya Ochiai,Chaodit Aswakul*

Main category: cs.CV

TL;DR: 提出WAFL-ViT在边缘设备上进行联邦学习，并构建了针对朱拉隆功大学的CUBR数据集，实验证明其优于自训练方式。


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备性能提升，边缘训练成为趋势，WAFL通过设备间通信实现协作学习，但缺乏针对特定场景的数据集。

Method: 提出WAFL-ViT框架，基于Vision Transformer在边缘设备上实现联邦学习，并构建了CUBR数据集作为泰国朱拉隆功大学的专用数据集。

Result: 在UTBR和CUBR数据集上验证，WAFL训练精度高于自训练方式，CUBR数据集有效支持特定场景任务。

Conclusion: WAFL-ViT结合专用数据集（如CUBR）可显著提升边缘联邦学习性能，为城市建筑识别等任务提供新范式。

Abstract: Many industrial sectors have been using of machine learning at inference mode on edge devices. Future directions show that training on edge devices is promising due to improvements in semiconductor performance. Wireless Ad Hoc Federated Learning (WAFL) has been proposed as a promising approach for collaborative learning with device-to-device communication among edges. In particular, WAFL with Vision Transformer (WAFL-ViT) has been tested on image recognition tasks with the UTokyo Building Recognition Dataset (UTBR). Since WAFL-ViT is a mission-oriented sensor system, it is essential to construct specific datasets by each mission. In our work, we have developed the Chulalongkorn University Building Recognition Dataset (CUBR), which is specialized for Chulalongkorn University as a case study in Thailand. Additionally, our results also demonstrate that training on WAFL scenarios achieves better accuracy than self-training scenarios. Dataset is available in https://github.com/jo2lxq/wafl/.

</details>


### [38] [EmoStyle: Emotion-Driven Image Stylization](https://arxiv.org/abs/2512.05478)
*Jingyuan Yang,Zihuan Bai,Hui Huang*

Main category: cs.CV

TL;DR: 提出EmoStyle框架，实现情感驱动的图像风格化，在保留内容的同时增强情感表达。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格化方法忽视风格所携带的情感影响，缺乏情感与风格的关联建模。

Method: 构建EmoStyleSet数据集，提出情感-内容推理器与风格量化器，实现情感导向的风格编码与生成。

Result: EmoStyle在情感表达与内容保持上表现优异，用户研究证实其有效性，且风格字典可迁移到其他生成任务。

Conclusion: 该工作奠定了情感驱动图像风格化的基础，拓展了AI艺术创作的潜力。

Abstract: Art has long been a profound medium for expressing emotions. While existing image stylization methods effectively transform visual appearance, they often overlook the emotional impact carried by styles. To bridge this gap, we introduce Affective Image Stylization (AIS), a task that applies artistic styles to evoke specific emotions while preserving content. We present EmoStyle, a framework designed to address key challenges in AIS, including the lack of training data and the emotion-style mapping. First, we construct EmoStyleSet, a content-emotion-stylized image triplet dataset derived from ArtEmis to support AIS. We then propose an Emotion-Content Reasoner that adaptively integrates emotional cues with content to learn coherent style queries. Given the discrete nature of artistic styles, we further develop a Style Quantizer that converts continuous style features into emotion-related codebook entries. Extensive qualitative and quantitative evaluations, including user studies, demonstrate that EmoStyle enhances emotional expressiveness while maintaining content consistency. Moreover, the learned emotion-aware style dictionary is adaptable to other generative tasks, highlighting its potential for broader applications. Our work establishes a foundation for emotion-driven image stylization, expanding the creative potential of AI-generated art.

</details>


### [39] [UniFS: Unified Multi-Contrast MRI Reconstruction via Frequency-Spatial Fusion](https://arxiv.org/abs/2512.05481)
*Jialin Li,Yiwei Ren,Kai Pan,Dong Wei,Pujin Cheng,Xian Wu,Xiaoying Tang*

Main category: cs.CV

TL;DR: 提出UniFS模型，无需重训即可通用处理多种k空间欠采样模式的多对比度MR重建


<details>
  <summary>Details</summary>
Motivation: 现有方法需为每种欠采样模式单独训练模型，且忽视频率信息，泛化能力差

Method: 引入跨模态频率融合、自适应掩码提示学习和双分支互补细化模块，实现频率-空间联合建模

Result: 在BraTS和HCP数据集上，对未知欠采样模式均达到SOTA性能

Conclusion: UniFS有效提升泛化性，首次实现无需重训的多模式MR重建，推动临床实用化

Abstract: Recently, Multi-Contrast MR Reconstruction (MCMR) has emerged as a hot research topic that leverages high-quality auxiliary modalities to reconstruct undersampled target modalities of interest. However, existing methods often struggle to generalize across different k-space undersampling patterns, requiring the training of a separate model for each specific pattern, which limits their practical applicability. To address this challenge, we propose UniFS, a Unified Frequency-Spatial Fusion model designed to handle multiple k-space undersampling patterns for MCMR tasks without any need for retraining. UniFS integrates three key modules: a Cross-Modal Frequency Fusion module, an Adaptive Mask-Based Prompt Learning module, and a Dual-Branch Complementary Refinement module. These modules work together to extract domain-invariant features from diverse k-space undersampling patterns while dynamically adapt to their own variations. Another limitation of existing MCMR methods is their tendency to focus solely on spatial information while neglect frequency characteristics, or extract only shallow frequency features, thus failing to fully leverage complementary cross-modal frequency information. To relieve this issue, UniFS introduces an adaptive prompt-guided frequency fusion module for k-space learning, significantly enhancing the model's generalization performance. We evaluate our model on the BraTS and HCP datasets with various k-space undersampling patterns and acceleration factors, including previously unseen patterns, to comprehensively assess UniFS's generalizability. Experimental results across multiple scenarios demonstrate that UniFS achieves state-of-the-art performance. Our code is available at https://github.com/LIKP0/UniFS.

</details>


### [40] [Concept-based Explainable Data Mining with VLM for 3D Detection](https://arxiv.org/abs/2512.05482)
*Mai Tsujimoto*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型挖掘驾驶场景中的稀有物体，提升3D检测性能，仅用少量数据即可显著改善稀有类别如自行车、拖车的检测效果。


<details>
  <summary>Details</summary>
Motivation: 稀有物体在自动驾驶点云检测中难以识别，现有方法未充分挖掘视觉语言模型在3D检测中的数据挖掘潜力。

Method: 构建跨模态框架，融合目标检测、语义特征提取、降维与多维度异常检测（Isolation Forest + t-SNE）及概念过滤，自动识别并标注稀有物体概念。

Result: 在nuScenes数据集上，仅用部分训练数据即显著提升稀有类别检测性能，优于随机采样，大幅降低标注成本。

Conclusion: 该方法为安全关键系统提供了高效、可解释的数据筛选策略，具有重要应用价值。

Abstract: Rare-object detection remains a challenging task in autonomous driving systems, particularly when relying solely on point cloud data. Although Vision-Language Models (VLMs) exhibit strong capabilities in image understanding, their potential to enhance 3D object detection through intelligent data mining has not been fully explored. This paper proposes a novel cross-modal framework that leverages 2D VLMs to identify and mine rare objects from driving scenes, thereby improving 3D object detection performance. Our approach synthesizes complementary techniques such as object detection, semantic feature extraction, dimensionality reduction, and multi-faceted outlier detection into a cohesive, explainable pipeline that systematically identifies rare but critical objects in driving scenes. By combining Isolation Forest and t-SNE-based outlier detection methods with concept-based filtering, the framework effectively identifies semantically meaningful rare objects. A key strength of this approach lies in its ability to extract and annotate targeted rare object concepts such as construction vehicles, motorcycles, and barriers. This substantially reduces the annotation burden and focuses only on the most valuable training samples. Experiments on the nuScenes dataset demonstrate that this concept-guided data mining strategy enhances the performance of 3D object detection models while utilizing only a fraction of the training data, with particularly notable improvements for challenging object categories such as trailers and bicycles compared with the same amount of random data. This finding has substantial implications for the efficient curation of datasets in safety-critical autonomous systems.

</details>


### [41] [WaterWave: Bridging Underwater Image Enhancement into Video Streams via Wavelet-based Temporal Consistency Field](https://arxiv.org/abs/2512.05492)
*Qi Zhu,Jingyi Zhang,Naishan Zheng,Wei Yu,Jinghao Zhang,Deyi Ji,Feng Zhao*

Main category: cs.CV

TL;DR: 提出WaterWave方法，利用小波域时序一致性先验提升水下视频质量，无需配对数据，显著优于现有单帧增强方法，并提升下游追踪任务性能。


<details>
  <summary>Details</summary>
Motivation: 水下视频对获取困难，现有方法直接逐帧应用单图像增强模型导致时序不一致。

Method: 在小波域构建时序一致性场WaterWave，通过渐进滤除不一致成分保留运动细节，并设计水下光流校正模块提升频率表征精度。

Result: 显著提升增强视频质量，在UOSTrack和MAT追踪任务中分别提升19.7%和9.7%的精确率。

Conclusion: WaterWave有效解决水下视频时序不一致问题，为无配对数据场景提供高效增强方案，具备良好下游应用潜力。

Abstract: Underwater video pairs are fairly difficult to obtain due to the complex underwater imaging. In this case, most existing video underwater enhancement methods are performed by directly applying the single-image enhancement model frame by frame, but a natural issue is lacking temporal consistency. To relieve the problem, we rethink the temporal manifold inherent in natural videos and observe a temporal consistency prior in dynamic scenes from the local temporal frequency perspective. Building upon the specific prior and no paired-data condition, we propose an implicit representation manner for enhanced video signals, which is conducted in the wavelet-based temporal consistency field, WaterWave. Specifically, under the constraints of the prior, we progressively filter and attenuate the inconsistent components while preserving motion details and scenes, achieving a natural-flowing video. Furthermore, to represent temporal frequency bands more accurately, an underwater flow correction module is designed to rectify estimated flows considering the transmission in underwater scenes. Extensive experiments demonstrate that WaterWave significantly enhances the quality of videos generated using single-image underwater enhancements. Additionally, our method demonstrates high potential in downstream underwater tracking tasks, such as UOSTrack and MAT, outperforming the original video by a large margin, i.e., 19.7% and 9.7% on precise respectively.

</details>


### [42] [Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.05494)
*Fan Zhang,Zhiwei Gu,Hua Wang*

Main category: cs.CV

TL;DR: 提出一种新型Decoder框架，通过三个模块提升医学图像分割的边缘细节与空间连续性建模能力


<details>
  <summary>Details</summary>
Motivation: 传统Transformer解码器在捕捉边缘细节、局部纹理和空间连续性方面存在局限，影响医学图像分割精度

Method: 引入ACFA（自适应交叉融合注意力）、TFFA（三域特征融合注意力）和SMMM（结构感知多尺度掩码模块）三个模块，分别增强空间响应、融合频域-空域特征、优化编码器-解码器跳跃连接

Result: 在肿瘤分割和器官边界提取等高精度任务中显著提升分割准确率与模型泛化能力

Conclusion: 该框架有效克服传统解码器缺陷，为医学图像分割提供高效实用的解决方案

Abstract: To address the limitations of Transformer decoders in capturing edge details, recognizing local textures and modeling spatial continuity, this paper proposes a novel decoder framework specifically designed for medical image segmentation, comprising three core modules. First, the Adaptive Cross-Fusion Attention (ACFA) module integrates channel feature enhancement with spatial attention mechanisms and introduces learnable guidance in three directions (planar, horizontal, and vertical) to enhance responsiveness to key regions and structural orientations. Second, the Triple Feature Fusion Attention (TFFA) module fuses features from Spatial, Fourier and Wavelet domains, achieving joint frequency-spatial representation that strengthens global dependency and structural modeling while preserving local information such as edges and textures, making it particularly effective in complex and blurred boundary scenarios. Finally, the Structural-aware Multi-scale Masking Module (SMMM) optimizes the skip connections between encoder and decoder by leveraging multi-scale context and structural saliency filtering, effectively reducing feature redundancy and improving semantic interaction quality. Working synergistically, these modules not only address the shortcomings of traditional decoders but also significantly enhance performance in high-precision tasks such as tumor segmentation and organ boundary extraction, improving both segmentation accuracy and model generalization. Experimental results demonstrate that this framework provides an efficient and practical solution for medical image segmentation.

</details>


### [43] [Rethinking Infrared Small Target Detection: A Foundation-Driven Efficient Paradigm](https://arxiv.org/abs/2512.05511)
*Chuang Yu,Jinmiao Zhao,Yunpeng Liu,Yaokun Li,Xiujun Shu,Yuanhao Feng,Bo Wang,Yimian Dai,Xiangyu Yue*

Main category: cs.CV

TL;DR: 首次将视觉基础模型的冻结表征引入红外小目标检测，提出FDEP框架，在不增加推理开销下显著提升精度并构建统一评估指标HSE。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉基础模型在红外小目标检测中的潜力尚未探索，现有方法缺乏高效融合机制与统一评估标准。

Method: 提出FDEP框架，包含SAMF模块实现语义对齐融合，CO-ISD策略实现隐式自蒸馏，以及HSE评估指标统一多维度评价。

Result: 在多个公开数据集上达到SOTA性能，无额外推理开销。

Conclusion: FDEP框架有效利用视觉基础模型的先验知识，为红外小目标检测提供了高效、公平且高性能的新范式。

Abstract: While large-scale visual foundation models (VFMs) exhibit strong generalization across diverse visual domains, their potential for single-frame infrared small target (SIRST) detection remains largely unexplored. To fill this gap, we systematically introduce the frozen representations from VFMs into the SIRST task for the first time and propose a Foundation-Driven Efficient Paradigm (FDEP), which can seamlessly adapt to existing encoder-decoder-based methods and significantly improve accuracy without additional inference overhead. Specifically, a Semantic Alignment Modulation Fusion (SAMF) module is designed to achieve dynamic alignment and deep fusion of the global semantic priors from VFMs with task-specific features. Meanwhile, to avoid the inference time burden introduced by VFMs, we propose a Collaborative Optimization-based Implicit Self-Distillation (CO-ISD) strategy, which enables implicit semantic transfer between the main and lightweight branches through parameter sharing and synchronized backpropagation. In addition, to unify the fragmented evaluation system, we construct a Holistic SIRST Evaluation (HSE) metric that performs multi-threshold integral evaluation at both pixel-level confidence and target-level robustness, providing a stable and comprehensive basis for fair model comparison. Extensive experiments demonstrate that the SIRST detection networks equipped with our FDEP framework achieve state-of-the-art (SOTA) performance on multiple public datasets. Our code is available at https://github.com/YuChuang1205/FDEP-Framework

</details>


### [44] [Know-Show: Benchmarking Video-Language Models on Spatio-Temporal Grounded Reasoning](https://arxiv.org/abs/2512.05513)
*Chinthani Sugandhika,Chen Li,Deepu Rajan,Basura Fernando*

Main category: cs.CV

TL;DR: 提出Know-Show基准和GRAM方法，评估并提升视频语言模型的时空 grounding 推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型在推理时缺乏对时空证据的可靠 grounding，难以展示其知识。

Method: 构建Know-Show基准（5类时空场景，2.5K人工问题），并提出无训练的GRAM插件，通过注意力选择视频标记和时间戳编码增强 grounding。

Result: 主流模型（Qwen、VideoLLaVA、GPT-4o等）在Know-Show上表现显著差于人类，尤其在细粒度手-物交互中表现不佳。

Conclusion: Know-Show为视频语言理解建立了统一评估标准，推动可解释、可靠的多模态推理系统发展。

Abstract: Large Video-Language Models (Video-LMs) have achieved impressive progress in multimodal understanding, yet their reasoning remains weakly grounded in space and time. We present Know-Show, a new benchmark designed to evaluate spatio-temporal grounded reasoning, the ability of a model to reason about actions and their semantics while simultaneously grounding its inferences in visual and temporal evidence. Know-Show unifies reasoning and localization within a single evaluation framework consisting of five complementary scenarios across spatial (person, object, person-object, and hand-object) and temporal dimensions. Built from Charades, Action Genome, and Ego4D with 2.5K human-authored questions, the benchmark exposes significant gaps between current Video-LMs and human reasoning. To bridge this gap, we propose GRAM, a training-free plug-in that augments Video-LMs with fine-grained grounding through attention-based video token selection and explicit timestamp encoding. Extensive experiments across open and closed Video-LMs (Qwen, VideoLLaVA, GPT-4o, and Gemini, etc.) reveal that existing models struggle to "show what they know" and vice versa, especially in fine-grained hand-object interactions. Know-Show establishes a unified standard for assessing grounded reasoning in video-language understanding and provides insights toward developing interpretable and reliable multimodal reasoning systems. We will release the code at https://github.com/LUNAProject22/Know-Show.

</details>


### [45] [DashFusion: Dual-stream Alignment with Hierarchical Bottleneck Fusion for Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.05515)
*Yuhua Wen,Qifei Li,Yingying Zhou,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CV

TL;DR: 提出一种名为DashFusion的双流对齐与分层瓶颈融合框架，显著提升多模态情感分析性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法孤立处理模态对齐与融合，导致性能与效率受限。

Method: 采用双流对齐模块（时序与语义对齐）+ 监督对比学习 + 分层瓶颈融合，通过压缩瓶颈标记实现高效特征整合。

Result: 在CMU-MOSI、CMU-MOSEI和CH-SIMS三个数据集上达到SOTA性能，消融实验验证方法有效性。

Conclusion: DashFusion通过协同对齐与高效融合，为多模态情感分析提供了新范式。

Abstract: Multimodal sentiment analysis (MSA) integrates various modalities, such as text, image, and audio, to provide a more comprehensive understanding of sentiment. However, effective MSA is challenged by alignment and fusion issues. Alignment requires synchronizing both temporal and semantic information across modalities, while fusion involves integrating these aligned features into a unified representation. Existing methods often address alignment or fusion in isolation, leading to limitations in performance and efficiency. To tackle these issues, we propose a novel framework called Dual-stream Alignment with Hierarchical Bottleneck Fusion (DashFusion). Firstly, dual-stream alignment module synchronizes multimodal features through temporal and semantic alignment. Temporal alignment employs cross-modal attention to establish frame-level correspondences among multimodal sequences. Semantic alignment ensures consistency across the feature space through contrastive learning. Secondly, supervised contrastive learning leverages label information to refine the modality features. Finally, hierarchical bottleneck fusion progressively integrates multimodal information through compressed bottleneck tokens, which achieves a balance between performance and computational efficiency. We evaluate DashFusion on three datasets: CMU-MOSI, CMU-MOSEI, and CH-SIMS. Experimental results demonstrate that DashFusion achieves state-of-the-art performance across various metrics, and ablation studies confirm the effectiveness of our alignment and fusion techniques. The codes for our experiments are available at https://github.com/ultramarineX/DashFusion.

</details>


### [46] [VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation](https://arxiv.org/abs/2512.05524)
*Chinthani Sugandhika,Chen Li,Deepu Rajan,Basura Fernando*

Main category: cs.CV

TL;DR: 提出VOST-SGG，利用视觉语言模型增强时空场景图生成，提升关系预测性能


<details>
  <summary>Details</summary>
Motivation: 现有DETR风格模型的可学习查询语义无信息且初始化无关实例，且仅依赖视觉特征进行谓词分类，限制了性能

Method: 引入双源查询初始化策略分离“什么”与“哪里”的注意力，并构建融合视觉、文本和空间信息的多模态特征库，利用VLM提供语义先验

Result: 在Action Genome数据集上达到SOTA性能，验证了VLM辅助语义先验和多模态特征的有效性

Conclusion: 整合VLM的语义常识与多模态特征能显著提升ST-SGG的可解释性与准确性，具有广泛应用前景

Abstract: Spatio-temporal scene graph generation (ST-SGG) aims to model objects and their evolving relationships across video frames, enabling interpretable representations for downstream reasoning tasks such as video captioning and visual question answering. Despite recent advancements in DETR-style single-stage ST-SGG models, they still suffer from several key limitations. First, while these models rely on attention-based learnable queries as a core component, these learnable queries are semantically uninformed and instance-agnostically initialized. Second, these models rely exclusively on unimodal visual features for predicate classification. To address these challenges, we propose VOST-SGG, a VLM-aided one-stage ST-SGG framework that integrates the common sense reasoning capabilities of vision-language models (VLMs) into the ST-SGG pipeline. First, we introduce the dual-source query initialization strategy that disentangles what to attend to from where to attend, enabling semantically grounded what-where reasoning. Furthermore, we propose a multi-modal feature bank that fuses visual, textual, and spatial cues derived from VLMs for improved predicate classification. Extensive experiments on the Action Genome dataset demonstrate that our approach achieves state-of-the-art performance, validating the effectiveness of integrating VLM-aided semantic priors and multi-modal features for ST-SGG. We will release the code at https://github.com/LUNAProject22/VOST.

</details>


### [47] [See in Depth: Training-Free Surgical Scene Segmentation with Monocular Depth Priors](https://arxiv.org/abs/2512.05529)
*Kunyi Yang,Qingyu Wang,Cheng Yuan,Yutong Ban*

Main category: cs.CV

TL;DR: 提出一种无需训练的深度引导手术场景分割方法DepSeg，利用单目深度先验和预训练模型实现高效标注的像素级分割。


<details>
  <summary>Details</summary>
Motivation: 手术场景的像素级分割因密集标注成本高而难以扩展，亟需标注高效的解决方案。

Method: 使用预训练单目深度网络估计深度图，生成深度引导的点提示，由SAM2生成无类别掩码，再通过预训练视觉特征与模板库进行模板匹配分类。

Result: 在CholecSeg8k数据集上，DepSeg相比SAM2自动分割基线（14.7% mIoU）提升至35.9% mIoU，仅用10-20%模板仍保持竞争力。

Conclusion: 深度引导提示与模板分类结合，显著降低标注需求，是一种高效、实用的手术场景分割方法。

Abstract: Pixel-wise segmentation of laparoscopic scenes is essential for computer-assisted surgery but difficult to scale due to the high cost of dense annotations. We propose depth-guided surgical scene segmentation (DepSeg), a training-free framework that utilizes monocular depth as a geometric prior together with pretrained vision foundation models. DepSeg first estimates a relative depth map with a pretrained monocular depth estimation network and proposes depth-guided point prompts, which SAM2 converts into class-agnostic masks. Each mask is then described by a pooled pretrained visual feature and classified via template matching against a template bank built from annotated frames. On the CholecSeg8k dataset, DepSeg improves over a direct SAM2 auto segmentation baseline (35.9% vs. 14.7% mIoU) and maintains competitive performance even when using only 10--20% of the object templates. These results show that depth-guided prompting and template-based classification offer an annotation-efficient segmentation approach.

</details>


### [48] [Ideal Observer for Segmentation of Dead Leaves Images](https://arxiv.org/abs/2512.05539)
*Swantje Mahncke,Malte Ott*

Main category: cs.CV

TL;DR: 本文提出基于死叶模型的贝叶斯理想观察者理论，用于图像像素分割，并给出性能上限以对比人和算法。


<details>
  <summary>Details</summary>
Motivation: 人类视觉环境中的遮挡现象复杂，死叶模型能有效模拟物体层叠遮挡，但缺乏系统的贝叶斯分割理论框架。

Method: 基于已有工作，推导出针对死叶模型的贝叶斯理想观察者，计算像素分区的后验概率，并分析实际应用的可行性因素。

Result: 建立了可计算的后验概率模型，为像素级分割提供理论上的性能上限。

Conclusion: 该模型可作为基准，用于比较人类视觉与视觉算法在有限像素分割任务中的表现。

Abstract: The human visual environment is comprised of different surfaces that are distributed in space. The parts of a scene that are visible at any one time are governed by the occlusion of overlapping objects. In this work we consider "dead leaves" models, which replicate these occlusions when generating images by layering objects on top of each other. A dead leaves model is a generative model comprised of distributions for object position, shape, color and texture. An image is generated from a dead leaves model by sampling objects ("leaves") from these distributions until a stopping criterion is reached, usually when the image is fully covered or until a given number of leaves was sampled. Here, we describe a theoretical approach, based on previous work, to derive a Bayesian ideal observer for the partition of a given set of pixels based on independent dead leaves model distributions. Extending previous work, we provide step-by-step explanations for the computation of the posterior probability as well as describe factors that determine the feasibility of practically applying this computation. The dead leaves image model and the associated ideal observer can be applied to study segmentation decisions in a limited number of pixels, providing a principled upper-bound on performance, to which humans and vision algorithms could be compared.

</details>


### [49] [Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models](https://arxiv.org/abs/2512.05546)
*Weijue Bu,Guan Yuan,Guixian Zhang*

Main category: cs.CV

TL;DR: 提出无需训练的推理时框架CG-VLM，通过感知视觉-文本协同性来精准控制注意力，抑制幻觉，提升多模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅在输出层干预，无法纠正内部推理漂移；启发式头抑制或全局引导向量缺乏理论基础。

Method: 引入Conscious Gaze (CG-VLM)，基于Harsanyi交互构建认知需求传感器，检测视觉 grounding 需求，并通过聚焦共识诱导模块在中间层重定向注意力至视觉token。

Result: 在POPE和CHAIR上对InstructBLIP、LLaVA、Qwen-VL和mPLUG均达到SOTA，且保留通用能力。

Conclusion: 令牌级感知实现精准、上下文感知的干预，无需训练即可有效抑制幻觉，提升视觉语言模型的可靠性。

Abstract: Large Vision-Language Models (VLMs) often exhibit text inertia, where attention drifts from visual evidence toward linguistic priors, resulting in object hallucinations. Existing decoding strategies intervene only at the output logits and thus cannot correct internal reasoning drift, while recent internal-control methods based on heuristic head suppression or global steering vectors lack principled grounding. We introduce Conscious Gaze (CG-VLM), a training-free, inference-time framework that converts game-theoretic interpretability into actionable decoding control. A Cognitive Demand Sensor built on Harsanyi interactions estimates instantaneous vision-text synergy and identifies moments when visual grounding is necessary. Conditioned on this signal, a Focused Consensus Induction module selectively reorients mid-layer attention toward visual tokens before collapse into text priors. CG-VLM achieves state-of-the-art results on POPE and CHAIR across InstructBLIP, LLaVA, Qwen-VL, and mPLUG, while preserving general capabilities, demonstrating that token-level sensing enables precise, context-aware intervention without compromising foundational knowledge.

</details>


### [50] [2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency](https://arxiv.org/abs/2512.05557)
*Xingxi Yin,Yicheng Li,Gong Yan,Chenglin Li,Jian Zhao,Cong Huang,Yue Deng,Yin Zhang*

Main category: cs.CV

TL;DR: 提出2K-Characters-10K-Stories数据集，实现身份一致性与瞬时属性解耦控制的视觉叙事生成


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏身份与瞬时属性的解耦，限制了序列生成的可控性

Method: 引入Human-in-the-Loop管道与解耦控制机制，结合MMLM评估与局部图像编辑确保像素级一致性

Result: 微调模型在视觉叙事生成上达到闭源模型性能水平

Conclusion: 该数据集与方法显著提升可控视觉叙事的序列身份一致性与生成质量

Abstract: Sequential identity consistency under precise transient attribute control remains a long-standing challenge in controllable visual storytelling. Existing datasets lack sufficient fidelity and fail to disentangle stable identities from transient attributes, limiting structured control over pose, expression, and scene composition and thus constraining reliable sequential synthesis. To address this gap, we introduce \textbf{2K-Characters-10K-Stories}, a multi-modal stylized narrative dataset of \textbf{2{,}000} uniquely stylized characters appearing across \textbf{10{,}000} illustration stories. It is the first dataset that pairs large-scale unique identities with explicit, decoupled control signals for sequential identity consistency. We introduce a \textbf{Human-in-the-Loop pipeline (HiL)} that leverages expert-verified character templates and LLM-guided narrative planning to generate highly-aligned structured data. A \textbf{decoupled control} scheme separates persistent identity from transient attributes -- pose and expression -- while a \textbf{Quality-Gated loop} integrating MMLM evaluation, Auto-Prompt Tuning, and Local Image Editing enforces pixel-level consistency. Extensive experiments demonstrate that models fine-tuned on our dataset achieves performance comparable to closed-source models in generating visual narratives.

</details>


### [51] [ProPhy: Progressive Physical Alignment for Dynamic World Simulation](https://arxiv.org/abs/2512.05564)
*Zijun Wang,Panwen Hu,Jing Wang,Terry Jingchen Zhang,Yuhao Cheng,Long Chen,Yiqiang Yan,Zutao Jiang,Hanhui Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出ProPhy框架，通过分阶段物理专家机制提升视频生成的物理一致性


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型对物理提示响应各向同性，缺乏对局部物理线索的细粒度对齐，导致大尺度或复杂动力学场景物理不一致

Method: 采用两阶段Mixture-of-Physics-Experts（MoPE）机制：语义专家从文本提取语义级物理原则，精炼专家捕捉Token级动力学，并引入视觉语言模型的物理推理能力进行对齐

Result: 在物理感知视频生成基准上，ProPhy生成的视频比现有方法更真实、动态且物理一致

Conclusion: ProPhy通过显式物理条件控制和各向异性生成，有效提升了视频生成对物理规律的建模能力

Abstract: Recent advances in video generation have shown remarkable potential for constructing world simulators. However, current models still struggle to produce physically consistent results, particularly when handling large-scale or complex dynamics. This limitation arises primarily because existing approaches respond isotropically to physical prompts and neglect the fine-grained alignment between generated content and localized physical cues. To address these challenges, we propose ProPhy, a Progressive Physical Alignment Framework that enables explicit physics-aware conditioning and anisotropic generation. ProPhy employs a two-stage Mixture-of-Physics-Experts (MoPE) mechanism for discriminative physical prior extraction, where Semantic Experts infer semantic-level physical principles from textual descriptions, and Refinement Experts capture token-level physical dynamics. This mechanism allows the model to learn fine-grained, physics-aware video representations that better reflect underlying physical laws. Furthermore, we introduce a physical alignment strategy that transfers the physical reasoning capabilities of vision-language models (VLMs) into the Refinement Experts, facilitating a more accurate representation of dynamic physical phenomena. Extensive experiments on physics-aware video generation benchmarks demonstrate that ProPhy produces more realistic, dynamic, and physically coherent results than existing state-of-the-art methods.

</details>


### [52] [MedDIFT: Multi-Scale Diffusion-Based Correspondence in 3D Medical Imaging](https://arxiv.org/abs/2512.05571)
*Xingyu Zhang,Anna Reithmeir,Fryderyk Kögl,Rickmer Braren,Julia A. Schnabel,Daniel M. Lang*

Main category: cs.CV

TL;DR: MedDIFT是一种无需训练的3D医学图像配准方法，利用预训练扩散模型的多尺度特征进行体素匹配，精度媲美最优学习方法且优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于局部强度的医学图像配准方法难以捕捉全局语义结构，在低对比度或解剖变异区域易出现误匹配。

Method: MedDIFT使用预训练医学扩散模型的中间层特征作为体素描述符，通过余弦相似性进行匹配，并可选引入局部搜索先验。

Result: 在公开肺部CT数据集上，MedDIFT的配准精度与最优学习方法UniGradICON相当，显著优于传统B样条方法，且无需任务特定训练。

Conclusion: 多层级特征融合和适度扩散噪声能有效提升配准性能，扩散模型的中间表征为无训练医学图像配准提供了新路径。

Abstract: Accurate spatial correspondence between medical images is essential for longitudinal analysis, lesion tracking, and image-guided interventions. Medical image registration methods rely on local intensity-based similarity measures, which fail to capture global semantic structure and often yield mismatches in low-contrast or anatomically variable regions. Recent advances in diffusion models suggest that their intermediate representations encode rich geometric and semantic information. We present MedDIFT, a training-free 3D correspondence framework that leverages multi-scale features from a pretrained latent medical diffusion model as voxel descriptors. MedDIFT fuses diffusion activations into rich voxel-wise descriptors and matches them via cosine similarity, with an optional local-search prior. On a publicly available lung CT dataset, MedDIFT achieves correspondence accuracy comparable to the state-of-the-art learning-based UniGradICON model and surpasses conventional B-spline-based registration, without requiring any task-specific model training. Ablation experiments confirm that multi-level feature fusion and modest diffusion noise improve performance.

</details>


### [53] [Learning High-Fidelity Cloth Animation via Skinning-Free Image Transfer](https://arxiv.org/abs/2512.05593)
*Rong Wang,Wei Mao,Changsheng Lu,Hongdong Li*

Main category: cs.CV

TL;DR: 提出一种无蒙皮的3D服装变形方法，通过分离低频位置与高频法线估计，并利用2D图像转移与多模态融合，显著提升皱纹细节与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有基于蒙皮的方法因缺乏显式监督导致服装变形错位，影响高频皱纹恢复。

Method: 独立估计顶点位置（低频）与法线（高频），将其编码为纹理图像，借助预训练2D模型进行图像迁移，并通过多模态融合恢复3D变形。

Result: 在多种服装类型上显著提升动画质量，恢复更精细的皱纹，且无需手动UV划分，具备良好拓扑泛化性。

Conclusion: 该方法摆脱了对蒙皮的依赖，通过解耦频率模态与2D图像迁移，实现了高保真、高泛化性的3D服装变形。

Abstract: We present a novel method for generating 3D garment deformations from given body poses, which is key to a wide range of applications, including virtual try-on and extended reality. To simplify the cloth dynamics, existing methods mostly rely on linear blend skinning to obtain low-frequency posed garment shape and only regress high-frequency wrinkles. However, due to the lack of explicit skinning supervision, such skinning-based approach often produces misaligned shapes when posing the garment, consequently corrupts the high-frequency signals and fails to recover high-fidelity wrinkles. To tackle this issue, we propose a skinning-free approach by independently estimating posed (i) vertex position for low-frequency posed garment shape, and (ii) vertex normal for high-frequency local wrinkle details. In this way, each frequency modality can be effectively decoupled and directly supervised by the geometry of the deformed garment. To further improve the visual quality of animation, we propose to encode both vertex attributes as rendered texture images, so that 3D garment deformation can be equivalently achieved via 2D image transfer. This enables us to leverage powerful pretrained image models to recover fine-grained visual details in wrinkles, while maintaining superior scalability for garments of diverse topologies without relying on manual UV partition. Finally, we propose a multimodal fusion to incorporate constraints from both frequency modalities and robustly recover deformed 3D garments from transferred images. Extensive experiments show that our method significantly improves animation quality on various garment types and recovers finer wrinkles than state-of-the-art methods.

</details>


### [54] [Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction](https://arxiv.org/abs/2512.05597)
*Ruihong Yin,Xuepeng Shi,Oleksandr Bailo,Marco Manfredi,Theo Gevers*

Main category: cs.CV

TL;DR: Fast SceneScript 提出一种结构化语言模型，通过多令牌预测加速 3D 场景布局估计，无需牺牲精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的感知通用方法虽性能优越，但依赖自回归逐令牌预测，推理速度慢。

Method: 引入多令牌预测（MTP）减少自回归迭代，结合置信度引导解码（CGD）过滤不可靠令牌，并设计参数高效机制降低开销。

Result: 在 ASE 和 Structured3D 基准上，每步可生成最多 9 个令牌，仅增加约 7.5% 参数，保持精度。

Conclusion: Fast SceneScript 实现了 3D 场景布局估计的高效与高精度平衡，为结构化语言模型提供新范式。

Abstract: Recent perception-generalist approaches based on language models have achieved state-of-the-art results across diverse tasks, including 3D scene layout estimation, via unified architecture and interface. However, these approaches rely on autoregressive next-token prediction, which is inherently slow. In this work, we introduce Fast SceneScript, a novel structured language model for accurate and efficient 3D scene layout estimation. Our method employs multi-token prediction (MTP) to reduce the number of autoregressive iterations and significantly accelerate inference. While MTP improves speed, unreliable token predictions can significantly reduce accuracy. To filter out unreliable tokens, we adapt self-speculative decoding (SSD) for structured language models and introduce confidence-guided decoding (CGD) with an improved scoring mechanism for token reliability. Furthermore, we design a parameter-efficient mechanism that reduces the parameter overhead of MTP. Extensive experiments on the ASE and Structured3D benchmarks demonstrate that Fast SceneScript can generate up to 9 tokens per decoder inference step without compromising accuracy, while adding only $\sim7.5\%$ additional parameters.

</details>


### [55] [NormalView: sensor-agnostic tree species classification from backpack and aerial lidar data using geometric projections](https://arxiv.org/abs/2512.05610)
*Juho Korkeala,Jesse Muhojoki,Josef Taher,Klaara Salolahti,Matti Hyyppä,Antero Kukko,Juha Hyyppä*

Main category: cs.CV

TL;DR: NormalView是一种基于投影的深度学习方法，利用几何信息和YOLOv11实现激光扫描点云的树种分类，准确率高达95.5%，且对传感器无依赖。


<details>
  <summary>Details</summary>
Motivation: 现有树种分类方法依赖特定传感器或缺乏泛化能力，亟需一种传感器无关、高精度的点云分类方法。

Method: NormalView将点云局部几何信息编码为法向量二维投影，输入YOLOv11网络进行分类，并评估多光谱强度信息的影响。

Result: 在MLS数据上准确率达95.5%（宏观平均94.8%），在ALS数据上为91.8%（79.1%）；多光谱强度信息提升分类性能，三通道组合最优。

Conclusion: 投影法结合几何信息与先进图像网络可实现高精度、传感器无关的树种分类，方法可推广且数据已公开。

Abstract: Laser scanning has proven to be an invaluable tool in assessing the decomposition of forest environments. Mobile laser scanning (MLS) has shown to be highly promising for extremely accurate, tree level inventory. In this study, we present NormalView, a sensor-agnostic projection-based deep learning method for classifying tree species from point cloud data. NormalView embeds local geometric information into two-dimensional projections, in the form of normal vector estimates, and uses the projections as inputs to an image classification network, YOLOv11. In addition, we inspected the effect of multispectral radiometric intensity information on classification performance. We trained and tested our model on high-density MLS data (7 species, ~5000 pts/m^2), as well as high-density airborne laser scanning (ALS) data (9 species, >1000 pts/m^2). On the MLS data, NormalView achieves an overall accuracy (macro-average accuracy) of 95.5 % (94.8 %), and 91.8 % (79.1 %) on the ALS data. We found that having intensity information from multiple scanners provides benefits in tree species classification, and the best model on the multispectral ALS dataset was a model using intensity information from all three channels of the multispectral ALS. This study demonstrates that projection-based methods, when enhanced with geometric information and coupled with state-of-the-art image classification backbones, can achieve exceptional results. Crucially, these methods are sensor-agnostic, relying only on geometric information. Additionally, we publically release the MLS dataset used in the study.

</details>


### [56] [DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model](https://arxiv.org/abs/2512.05613)
*Pasquale De Marinis,Pieter M. Blok,Uzay Kaymak,Rogier Brussee,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: DistillFSS通过知识蒸馏将支持集信息嵌入模型参数，实现无需支持图像的快速推理，在跨域少样本语义分割中性能优越且效率高。


<details>
  <summary>Details</summary>
Motivation: 传统 episodic 方法在跨域少样本语义分割中因域分布差异大、标签空间不重叠和支持样本稀缺而不可靠且计算开销大。

Method: 提出DistillFSS框架，利用教师-学生蒸馏机制将支持集知识直接嵌入学生网络的专用层，消除测试时对支持图像的依赖。

Result: 在新构建的跨域基准上，DistillFSS在多类和多样本场景下性能媲美或超越SOTA方法，并显著降低计算开销。

Conclusion: DistillFSS通过参数化知识蒸馏实现高效、轻量的跨域少样本分割，支持快速扩展至新类别和大支持集。

Abstract: Cross-Domain Few-Shot Semantic Segmentation (CD-FSS) seeks to segment unknown classes in unseen domains using only a few annotated examples. This setting is inherently challenging: source and target domains exhibit substantial distribution shifts, label spaces are disjoint, and support images are scarce--making standard episodic methods unreliable and computationally demanding at test time. To address these constraints, we propose DistillFSS, a framework that embeds support-set knowledge directly into a model's parameters through a teacher--student distillation process. By internalizing few-shot reasoning into a dedicated layer within the student network, DistillFSS eliminates the need for support images at test time, enabling fast, lightweight inference, while allowing efficient extension to novel classes in unseen domains through rapid teacher-driven specialization. Combined with fine-tuning, the approach scales efficiently to large support sets and significantly reduces computational overhead. To evaluate the framework under realistic conditions, we introduce a new CD-FSS benchmark spanning medical imaging, industrial inspection, and remote sensing, with disjoint label spaces and variable support sizes. Experiments show that DistillFSS matches or surpasses state-of-the-art baselines, particularly in multi-class and multi-shot scenarios, while offering substantial efficiency gains. The code is available at https://github.com/pasqualedem/DistillFSS.

</details>


### [57] [Experts-Guided Unbalanced Optimal Transport for ISP Learning from Unpaired and/or Paired Data](https://arxiv.org/abs/2512.05635)
*Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出一种基于最优传输的无监督ISP训练框架，无需配对数据即可达到甚至超越有监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有学习型ISP管道严重依赖昂贵的配对raw-to-sRGB数据集，数据获取成为主要瓶颈。

Method: 引入基于非平衡最优传输（UOT）的无监督框架，结合专家判别器委员会，用于跨域映射并纠正ISP失效模式。

Result: 在配对和无配对模式下均超越或匹敌现有最优方法，尤其在无配对模式下性能接近甚至优于有监督方法。

Conclusion: 该框架打破了对配对数据的依赖，为ISP学习提供了高效、鲁棒的新范式。

Abstract: Learned Image Signal Processing (ISP) pipelines offer powerful end-to-end performance but are critically dependent on large-scale paired raw-to-sRGB datasets. This reliance on costly-to-acquire paired data remains a significant bottleneck. To address this challenge, we introduce a novel, unsupervised training framework based on Optimal Transport capable of training arbitrary ISP architectures in both unpaired and paired modes. We are the first to successfully apply Unbalanced Optimal Transport (UOT) for this complex, cross-domain translation task. Our UOT-based framework provides robustness to outliers in the target sRGB data, allowing it to discount atypical samples that would be prohibitively costly to map. A key component of our framework is a novel ``committee of expert discriminators,'' a hybrid adversarial regularizer. This committee guides the optimal transport mapping by providing specialized, targeted gradients to correct specific ISP failure modes, including color fidelity, structural artifacts, and frequency-domain realism. To demonstrate the superiority of our approach, we retrained existing state-of-the-art ISP architectures using our paired and unpaired setups. Our experiments show that while our framework, when trained in paired mode, exceeds the performance of the original paired methods across all metrics, our unpaired mode concurrently achieves quantitative and qualitative performance that rivals, and in some cases surpasses, the original paired-trained counterparts. The code and pre-trained models are available at: https://github.com/gosha20777/EGUOT-ISP.git.

</details>


### [58] [Self-Supervised AI-Generated Image Detection: A Camera Metadata Perspective](https://arxiv.org/abs/2512.05651)
*Nan Zhong,Mian Zou,Yiran Xu,Zhenxing Qian,Xinpeng Zhang,Baoyuan Wu,Kede Ma*

Main category: cs.CV

TL;DR: 利用相机元数据（EXIF）进行自监督学习，实现对AI生成图像的高效检测，显著提升跨模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法依赖特定生成模型的内部结构，泛化能力差，难以应对多样化的AI生成图像。

Method: 通过分类和排序EXIF标签（如相机型号、光圈值）自监督训练特征提取器，采用高斯混合模型进行单类检测，并结合高频残差与空间打乱块进行二分类检测。

Result: 在多种生成模型上实验表明，该方法在泛化性和抗干扰性上显著超越现有技术，对真实场景样本表现优异。

Conclusion: EXIF元数据是检测AI生成图像的强有力信号，自监督学习框架可实现高效、鲁棒的跨模型检测。

Abstract: The proliferation of AI-generated imagery poses escalating challenges for multimedia forensics, yet many existing detectors depend on assumptions about the internals of specific generative models, limiting their cross-model applicability. We introduce a self-supervised approach for detecting AI-generated images that leverages camera metadata -- specifically exchangeable image file format (EXIF) tags -- to learn features intrinsic to digital photography. Our pretext task trains a feature extractor solely on camera-captured photographs by classifying categorical EXIF tags (\eg, camera model and scene type) and pairwise-ranking ordinal and continuous EXIF tags (\eg, focal length and aperture value). Using these EXIF-induced features, we first perform one-class detection by modeling the distribution of photographic images with a Gaussian mixture model and flagging low-likelihood samples as AI-generated. We then extend to binary detection that treats the learned extractor as a strong regularizer for a classifier of the same architecture, operating on high-frequency residuals from spatially scrambled patches. Extensive experiments across various generative models demonstrate that our EXIF-induced detectors substantially advance the state of the art, delivering strong generalization to in-the-wild samples and robustness to common benign image perturbations.

</details>


### [59] [LeAD-M3D: Leveraging Asymmetric Distillation for Real-time Monocular 3D Detection](https://arxiv.org/abs/2512.05663)
*Johannes Meier,Jonathan Michel,Oussema Dhaouadi,Yung-Hsu Yang,Christoph Reich,Zuria Bauer,Stefan Roth,Marc Pollefeys,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: LeAD-M3D实现无LiDAR的实时高精度单目3D检测，显著提升速度与精度平衡


<details>
  <summary>Details</summary>
Motivation: 单目3D检测面临深度模糊、视角变化和计算开销大等问题，现有方法要么依赖LiDAR，要么牺牲效率

Method: 提出A2D2（非对称增强去噪知识蒸馏）、CM3D（3D感知一致匹配）和CGI3D（置信度门控3D推理）三项技术，分别增强深度推理、匹配精度和推理效率

Result: 在KITTI、Waymo和Rope3D上达到SOTA精度，速度比先前高精度方法快3.6倍

Conclusion: 无需LiDAR、立体或几何先验，单目3D检测可同时实现高保真与实时效率

Abstract: Real-time monocular 3D object detection remains challenging due to severe depth ambiguity, viewpoint shifts, and the high computational cost of 3D reasoning. Existing approaches either rely on LiDAR or geometric priors to compensate for missing depth, or sacrifice efficiency to achieve competitive accuracy. We introduce LeAD-M3D, a monocular 3D detector that achieves state-of-the-art accuracy and real-time inference without extra modalities. Our method is powered by three key components. Asymmetric Augmentation Denoising Distillation (A2D2) transfers geometric knowledge from a clean-image teacher to a mixup-noised student via a quality- and importance-weighted depth-feature loss, enabling stronger depth reasoning without LiDAR supervision. 3D-aware Consistent Matching (CM3D) improves prediction-to-ground truth assignment by integrating 3D MGIoU into the matching score, yielding more stable and precise supervision. Finally, Confidence-Gated 3D Inference (CGI3D) accelerates detection by restricting expensive 3D regression to top-confidence regions. Together, these components set a new Pareto frontier for monocular 3D detection: LeAD-M3D achieves state-of-the-art accuracy on KITTI and Waymo, and the best reported car AP on Rope3D, while running up to 3.6x faster than prior high-accuracy methods. Our results demonstrate that high fidelity and real-time efficiency in monocular 3D detection are simultaneously attainable - without LiDAR, stereo, or geometric assumptions.

</details>


### [60] [Deep Learning-Based Real-Time Sequential Facial Expression Analysis Using Geometric Features](https://arxiv.org/abs/2512.05669)
*Talha Enes Koksal,Abdurrahman Gumus*

Main category: cs.CV

TL;DR: 提出一种基于MediaPipe FaceMesh和ConvLSTM1D的实时面部表情识别方法，在多个数据集上达到高精度并实现165帧/秒的处理速度。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互与情感感知系统的实时性与准确性，满足个性化体验与智能监控等应用需求。

Method: 使用MediaPipe FaceMesh提取几何特征（欧氏距离与角度），通过帧间差异捕捉表情时序动态，采用ConvLSTM1D+MLP进行分类。

Result: 在CK+、Oulu-CASIA(VIS/NIR)、MMI数据集上分别达到93%、79%、77%、68%准确率，处理速度达165 FPS。

Conclusion: 该方法高效、准确且可扩展，推动情感计算与个性化人机交互发展，代码已开源。

Abstract: Facial expression recognition is a crucial component in enhancing human-computer interaction and developing emotion-aware systems. Real-time detection and interpretation of facial expressions have become increasingly important for various applications, from user experience personalization to intelligent surveillance systems. This study presents a novel approach to real-time sequential facial expression recognition using deep learning and geometric features. The proposed method utilizes MediaPipe FaceMesh for rapid and accurate facial landmark detection. Geometric features, including Euclidean distances and angles, are extracted from these landmarks. Temporal dynamics are incorporated by analyzing feature differences between consecutive frames, enabling the detection of onset, apex, and offset phases of expressions. For classification, a ConvLSTM1D network followed by multilayer perceptron blocks is employed. The method's performance was evaluated on multiple publicly available datasets, including CK+, Oulu-CASIA (VIS and NIR), and MMI. Accuracies of 93%, 79%, 77%, and 68% were achieved respectively. Experiments with composite datasets were also conducted to assess the model's generalization capabilities. The approach demonstrated real-time applicability, processing approximately 165 frames per second on consumer-grade hardware. This research contributes to the field of facial expression analysis by providing a fast, accurate, and adaptable solution. The findings highlight the potential for further advancements in emotion-aware technologies and personalized user experiences, paving the way for more sophisticated human-computer interaction systems. To facilitate further research in this field, the complete source code for this study has been made publicly available on GitHub: https://github.com/miralab-ai/facial-expression-analysis.

</details>


### [61] [InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem](https://arxiv.org/abs/2512.05672)
*Yeobin Hong,Suhyeon Lee,Hyungjin Chung,Jong Chul Ye*

Main category: cs.CV

TL;DR: InverseCrafter通过在潜空间中将4D视频生成转化为修复问题，实现高效无开销的可控视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖微调视频扩散模型，计算成本高且易导致原始生成先验的灾难性遗忘。

Method: 将4D生成任务重构为潜空间中的修复问题，通过连续多通道潜掩码编码像素退化算子，避免重复VAE运算与反向传播。

Result: 在相机控制任务中实现与现有方法相当的视图生成质量与更高测量一致性，且计算开销接近于零，同时擅长通用视频修复与编辑。

Conclusion: InverseCrafter提供了一种高效、无遗忘的4D视频生成新范式，显著降低计算负担并提升编辑灵活性。

Abstract: Recent approaches to controllable 4D video generation often rely on fine-tuning pre-trained Video Diffusion Models (VDMs). This dominant paradigm is computationally expensive, requiring large-scale datasets and architectural modifications, and frequently suffers from catastrophic forgetting of the model's original generative priors. Here, we propose InverseCrafter, an efficient inpainting inverse solver that reformulates the 4D generation task as an inpainting problem solved in the latent space. The core of our method is a principled mechanism to encode the pixel space degradation operator into a continuous, multi-channel latent mask, thereby bypassing the costly bottleneck of repeated VAE operations and backpropagation. InverseCrafter not only achieves comparable novel view generation and superior measurement consistency in camera control tasks with near-zero computational overhead, but also excels at general-purpose video inpainting with editing. Code is available at https://github.com/yeobinhong/InverseCrafter.

</details>


### [62] [Hyperspectral Unmixing with 3D Convolutional Sparse Coding and Projected Simplex Volume Maximization](https://arxiv.org/abs/2512.05674)
*Gargi Panda,Soumitra Kundu,Saumik Bhattacharya,Aurobinda Routray*

Main category: cs.CV

TL;DR: 提出一种基于3D稀疏编码和自编码器的超光谱解混网络3D-CSCNet，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有解混算法未能有效联合建模光谱与空间信息，且端元初始化不优。

Method: 设计3D-CSC块通过算法展开求解3D稀疏编码，嵌入自编码器框架，解码器权重作为端元矩阵，并引入PSVM算法初始化端元。

Result: 在三个真实数据集和一个模拟数据集上，3D-CSCNet在不同信噪比下均优于当前最优方法。

Conclusion: 3D-CSCNet通过联合光谱-空间建模与端元优化初始化，显著提升了超光谱解混精度。

Abstract: Hyperspectral unmixing (HSU) aims to separate each pixel into its constituent endmembers and estimate their corresponding abundance fractions. This work presents an algorithm-unrolling-based network for the HSU task, named the 3D Convolutional Sparse Coding Network (3D-CSCNet), built upon a 3D CSC model. Unlike existing unrolling-based networks, our 3D-CSCNet is designed within the powerful autoencoder (AE) framework. Specifically, to solve the 3D CSC problem, we propose a 3D CSC block (3D-CSCB) derived through deep algorithm unrolling. Given a hyperspectral image (HSI), 3D-CSCNet employs the 3D-CSCB to estimate the abundance matrix. The use of 3D CSC enables joint learning of spectral and spatial relationships in the 3D HSI data cube. The estimated abundance matrix is then passed to the AE decoder to reconstruct the HSI, and the decoder weights are extracted as the endmember matrix. Additionally, we propose a projected simplex volume maximization (PSVM) algorithm for endmember estimation, and the resulting endmembers are used to initialize the decoder weights of 3D-CSCNet. Extensive experiments on three real datasets and one simulated dataset with three different signal-to-noise ratio (SNR) levels demonstrate that our 3D-CSCNet outperforms state-of-the-art methods.

</details>


### [63] [Physics-Informed Graph Neural Network with Frequency-Aware Learning for Optical Aberration Correction](https://arxiv.org/abs/2512.05683)
*Yong En Kok,Bowen Deng,Alexander Bentley,Andrew J. Parkes,Michael G. Somekh,Amanda J. Wright,Michael P. Pound*

Main category: cs.CV

TL;DR: ZRNet是一种物理信息驱动的框架，联合预测Zernike系数并恢复显微图像，显著提升复杂像差下的图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为黑箱模型，未利用光学物理原理，难以处理深层样本中的强像差。

Method: 提出ZRNet，包含Zernike Graph模块建模Zernike多项式间的物理关系，并引入频率感知对齐（FAA）损失函数，在频域统一校正与预测。

Result: 在CytoImageNet上实现多模态显微图像恢复与Zernike系数预测的SOTA性能。

Conclusion: 物理信息引导的联合学习框架能更有效处理复杂像差，为显微成像提供新范式。

Abstract: Optical aberrations significantly degrade image quality in microscopy, particularly when imaging deeper into samples. These aberrations arise from distortions in the optical wavefront and can be mathematically represented using Zernike polynomials. Existing methods often address only mild aberrations on limited sample types and modalities, typically treating the problem as a black-box mapping without leveraging the underlying optical physics of wavefront distortions. We propose ZRNet, a physics-informed framework that jointly performs Zernike coefficient prediction and optical image Restoration. We contribute a Zernike Graph module that explicitly models physical relationships between Zernike polynomials based on their azimuthal degrees-ensuring that learned corrections align with fundamental optical principles. To further enforce physical consistency between image restoration and Zernike prediction, we introduce a Frequency-Aware Alignment (FAA) loss, which better aligns Zernike coefficient prediction and image features in the Fourier domain. Extensive experiments on CytoImageNet demonstrates that our approach achieves state-of-the-art performance in both image restoration and Zernike coefficient prediction across diverse microscopy modalities and biological samples with complex, large-amplitude aberrations. Code is available at https://github.com/janetkok/ZRNet.

</details>


### [64] [OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning](https://arxiv.org/abs/2512.05698)
*Xusheng Guo,Wanfa Zhang,Shijia Zhao,Qiming Xia,Xiaolong Xie,Mingming Wang,Hai Wu,Chenglu Wen*

Main category: cs.CV

TL;DR: OWL通过占用引导预热和大模型先验推理，显著提升无监督3D目标检测性能，超越现有方法15%以上mAP。


<details>
  <summary>Details</summary>
Motivation: 现有无监督3D检测方法依赖初始伪标签，但其错误率高，误导训练过程，且滤波与优化困难。

Method: 提出OWL框架，包含占用引导预热（OGW）、实例引导推理（ICR）和权重自适应自训练（WAS）三部分，利用空间感知初始化、大模型先验评估和动态加权提升伪标签质量。

Result: 在Waymo和KITTI数据集上，OWL比现有最优方法提升超15.0% mAP。

Conclusion: OWL有效缓解伪标签噪声影响，结合大模型先验与自适应机制，实现无监督3D检测性能的重大突破。

Abstract: Unsupervised 3D object detection leverages heuristic algorithms to discover potential objects, offering a promising route to reduce annotation costs in autonomous driving. Existing approaches mainly generate pseudo labels and refine them through self-training iterations. However, these pseudo-labels are often incorrect at the beginning of training, resulting in misleading the optimization process. Moreover, effectively filtering and refining them remains a critical challenge. In this paper, we propose OWL for unsupervised 3D object detection by occupancy guided warm-up and large-model priors reasoning. OWL first employs an Occupancy Guided Warm-up (OGW) strategy to initialize the backbone weight with spatial perception capabilities, mitigating the interference of incorrect pseudo-labels on network convergence. Furthermore, OWL introduces an Instance-Cued Reasoning (ICR) module that leverages the prior knowledge of large models to assess pseudo-label quality, enabling precise filtering and refinement. Finally, we design a Weight-adapted Self-training (WAS) strategy to dynamically re-weight pseudo-labels, improving the performance through self-training. Extensive experiments on Waymo Open Dataset (WOD) and KITTI demonstrate that OWL outperforms state-of-the-art unsupervised methods by over 15.0% mAP, revealing the effectiveness of our method.

</details>


### [65] [Manifold-Aware Point Cloud Completion via Geodesic-Attentive Hierarchical Feature Learning](https://arxiv.org/abs/2512.05710)
*Jianan Sun,Dongzhihan Wang,Mingyu Fan*

Main category: cs.CV

TL;DR: 提出一种流形感知的点云补全框架，通过测地距离建模提升几何一致性和语义协调性


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖欧几里得距离，忽视点云的内在非线性几何结构，导致重建结果几何不一致和语义模糊

Method: 引入测地距离近似器（GDA）和流形感知特征提取器（MAFE），利用测地k-NN分组和测地关系注意力机制进行层次化特征学习

Result: 在基准数据集上显著超越现有SOTA方法，重建质量更高

Conclusion: 融入测地信息能有效提升点云补全的几何一致性与语义完整性

Abstract: Point cloud completion seeks to recover geometrically consistent shapes from partial or sparse 3D observations. Although recent methods have achieved reasonable global shape reconstruction, they often rely on Euclidean proximity and overlook the intrinsic nonlinear geometric structure of point clouds, resulting in suboptimal geometric consistency and semantic ambiguity. In this paper, we present a manifold-aware point cloud completion framework that explicitly incorporates nonlinear geometry information throughout the feature learning pipeline. Our approach introduces two key modules: a Geodesic Distance Approximator (GDA), which estimates geodesic distances between points to capture the latent manifold topology, and a Manifold-Aware Feature Extractor (MAFE), which utilizes geodesic-based $k$-NN groupings and a geodesic-relational attention mechanism to guide the hierarchical feature extraction process. By integrating geodesic-aware relational attention, our method promotes semantic coherence and structural fidelity in the reconstructed point clouds. Extensive experiments on benchmark datasets demonstrate that our approach consistently outperforms state-of-the-art methods in reconstruction quality.

</details>


### [66] [Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision](https://arxiv.org/abs/2512.05740)
*Lennart Maack,Julia-Kristin Graß,Lisa-Marie Toscha,Nathaniel Melling,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出一种隐私保护的知识蒸馏框架，将大模型知识迁移到本地部署的视觉语言模型，提升手术场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在手术场景理解上表现不足，且依赖云端模型导致患者数据隐私风险。

Method: 通过仅使用文本描述和二值分割掩码生成专家监督数据集，对本地VLM进行监督微调（SFT）和直接偏好优化（DPO）。

Result: 所提方法显著提升VLM在结直肠手术领域的专业知识，且无需泄露敏感图像数据。

Conclusion: 该框架实现了高效、隐私合规的本地化手术视觉语言模型训练，具有临床应用潜力。

Abstract: Recently, Vision Large Language Models (VLMs) have demonstrated high potential in computer-aided diagnosis and decision-support. However, current VLMs show deficits in domain specific surgical scene understanding, such as identifying and explaining anatomical landmarks during Complete Mesocolic Excision. Additionally, there is a need for locally deployable models to avoid patient data leakage to large VLMs, hosted outside the clinic. We propose a privacy-preserving framework to distill knowledge from large, general-purpose LLMs into an efficient, local VLM. We generate an expert-supervised dataset by prompting a teacher LLM without sensitive images, using only textual context and binary segmentation masks for spatial information. This dataset is used for Supervised Fine-Tuning (SFT) and subsequent Direct Preference Optimization (DPO) of the locally deployable VLM. Our evaluation confirms that finetuning VLMs with our generated datasets increases surgical domain knowledge compared to its base VLM by a large margin. Overall, this work validates a data-efficient and privacy-conforming way to train a surgical domain optimized, locally deployable VLM for surgical scene understanding.

</details>


### [67] [HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models](https://arxiv.org/abs/2512.05746)
*Shizhuo Mao,Hongtao Zou,Qihu Xie,Song Chen,Yi Kang*

Main category: cs.CV

TL;DR: 提出HQ-DM框架，通过单Hadamard变换降低扩散模型激活异常值，实现低比特量化下性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算和内存开销大，传统量化方法在低比特下因激活异常值导致性能严重下降。

Method: 提出HQ-DM量化感知训练框架，采用单Hadamard变换处理激活矩阵，支持INT卷积并避免权重异常值放大。

Result: 在ImageNet 256x256上使用LDM-4模型，W4A4和W4A3量化方案分别使Inception Score提升12.8%和467.73%。

Conclusion: HQ-DM有效缓解激活异常值问题，在保持模型性能的同时显著降低量化开销。

Abstract: Diffusion models have demonstrated significant applications in the field of image generation. However, their high computational and memory costs pose challenges for deployment. Model quantization has emerged as a promising solution to reduce storage overhead and accelerate inference. Nevertheless, existing quantization methods for diffusion models struggle to mitigate outliers in activation matrices during inference, leading to substantial performance degradation under low-bit quantization scenarios. To address this, we propose HQ-DM, a novel Quantization-Aware Training framework that applies Single Hadamard Transformation to activation matrices. This approach effectively reduces activation outliers while preserving model performance under quantization. Compared to traditional Double Hadamard Transformation, our proposed scheme offers distinct advantages by seamlessly supporting INT convolution operations while preventing the amplification of weight outliers. For conditional generation on the ImageNet 256x256 dataset using the LDM-4 model, our W4A4 and W4A3 quantization schemes improve the Inception Score by 12.8% and 467.73%, respectively, over the existing state-of-the-art method.

</details>


### [68] [USV: Unified Sparsification for Accelerating Video Diffusion Models](https://arxiv.org/abs/2512.05754)
*Xinjian Wu,Hongmei Wang,Yuan Zhou,Qinglin Lu*

Main category: cs.CV

TL;DR: USV通过联合优化注意力稀疏化与采样步数减少，实现视频扩散模型的高效加速，兼顾速度与画质。


<details>
  <summary>Details</summary>
Motivation: 现有加速方法仅单独优化注意力或采样步数，面临边际效益递减，难以突破模型效率瓶颈。

Method: USV提出端到端可训练框架，动态联合稀疏化注意力连接、合并语义相似token并减少去噪步数，统一优化多维加速策略。

Result: 在大规模视频生成基准上，USV实现最高83.3%的去噪加速和22.7%的端到端加速，同时保持高视觉保真度。

Conclusion: 统一动态稀疏化是实现高效高质量视频生成的实用路径。

Abstract: The scalability of high-fidelity video diffusion models (VDMs) is constrained by two key sources of redundancy: the quadratic complexity of global spatio-temporal attention and the computational overhead of long iterative denoising trajectories. Existing accelerators -- such as sparse attention and step-distilled samplers -- typically target a single dimension in isolation and quickly encounter diminishing returns, as the remaining bottlenecks become dominant. In this work, we introduce USV (Unified Sparsification for Video diffusion models), an end-to-end trainable framework that overcomes this limitation by jointly orchestrating sparsification across both the model's internal computation and its sampling process. USV learns a dynamic, data- and timestep-dependent sparsification policy that prunes redundant attention connections, adaptively merges semantically similar tokens, and reduces denoising steps, treating them not as independent tricks but as coordinated actions within a single optimization objective. This multi-dimensional co-design enables strong mutual reinforcement among previously disjoint acceleration strategies. Extensive experiments on large-scale video generation benchmarks demonstrate that USV achieves up to 83.3% speedup in the denoising process and 22.7% end-to-end acceleration, while maintaining high visual fidelity. Our results highlight unified, dynamic sparsification as a practical path toward efficient, high-quality video generation.

</details>


### [69] [FNOPT: Resolution-Agnostic, Self-Supervised Cloth Simulation using Meta-Optimization with Fourier Neural Operators](https://arxiv.org/abs/2512.05762)
*Ruochen Chen,Thuy Tran,Shaifali Parashar*

Main category: cs.CV

TL;DR: FNOpt是一种自监督的布料模拟框架，通过傅里叶神经算子优化时间积分，实现跨分辨率的稳定高精度模拟。


<details>
  <summary>Details</summary>
Motivation: 现有神经模拟器依赖大量标注数据或牺牲细节，且在不同分辨率和运动模式下泛化能力差。

Method: 将时间积分建模为优化问题，使用傅里叶神经算子参数化神经优化器，仅在粗网格上用物理损失训练。

Result: FNOpt在未重新训练的情况下，可泛化到细网格，捕捉细微褶皱并保持稳定性，超越现有学习型模拟器的准确性和鲁棒性。

Conclusion: 基于FNO的元优化方法为布料模拟提供了无需人工标注数据、跨分辨率可靠的替代方案。

Abstract: We present FNOpt, a self-supervised cloth simulation framework that formulates time integration as an optimization problem and trains a resolution-agnostic neural optimizer parameterized by a Fourier neural operator (FNO). Prior neural simulators often rely on extensive ground truth data or sacrifice fine-scale detail, and generalize poorly across resolutions and motion patterns. In contrast, FNOpt learns to simulate physically plausible cloth dynamics and achieves stable and accurate rollouts across diverse mesh resolutions and motion patterns without retraining. Trained only on a coarse grid with physics-based losses, FNOpt generalizes to finer resolutions, capturing fine-scale wrinkles and preserving rollout stability. Extensive evaluations on a benchmark cloth simulation dataset demonstrate that FNOpt outperforms prior learning-based approaches in out-of-distribution settings in both accuracy and robustness. These results position FNO-based meta-optimization as a compelling alternative to previous neural simulators for cloth, thus reducing the need for curated data and improving cross-resolution reliability.

</details>


### [70] [Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding](https://arxiv.org/abs/2512.05774)
*Ziyang Wang,Honglu Zhou,Shijie Wang,Junnan Li,Caiming Xiong,Silvio Savarese,Mohit Bansal,Michael S. Ryoo,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: AVP通过主动感知机制，在长视频理解中仅提取与查询相关的证据，显著提升性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖查询无关的字幕生成，浪费算力并模糊细粒度时空信息，难以有效处理长视频中的稀疏关键线索。

Method: 提出Active Video Perception (AVP)，通过MLLM代理迭代执行计划-观察-反思过程，主动选择观察时间与空间位置，直接从像素中提取与查询相关的证据。

Result: 在五个LVU基准上达到最优性能，平均准确率比最佳代理方法高5.7%，推理时间减少81.6%，输入token减少87.6%。

Conclusion: 主动感知范式能高效应对长视频理解的稀疏性挑战，为未来视频智能系统提供新方向。

Abstract: Long video understanding (LVU) is challenging because answering real-world queries often depends on sparse, temporally dispersed cues buried in hours of mostly redundant and irrelevant content. While agentic pipelines improve video reasoning capabilities, prevailing frameworks rely on a query-agnostic captioner to perceive video information, which wastes computation on irrelevant content and blurs fine-grained temporal and spatial information. Motivated by active perception theory, we argue that LVU agents should actively decide what, when, and where to observe, and continuously assess whether the current observation is sufficient to answer the query. We present Active Video Perception (AVP), an evidence-seeking framework that treats the video as an interactive environment and acquires compact, queryrelevant evidence directly from pixels. Concretely, AVP runs an iterative plan-observe-reflect process with MLLM agents. In each round, a planner proposes targeted video interactions, an observer executes them to extract time-stamped evidence, and a reflector evaluates the sufficiency of the evidence for the query, either halting with an answer or triggering further observation. Across five LVU benchmarks, AVP achieves highest performance with significant improvements. Notably, AVP outperforms the best agentic method by 5.7% in average accuracy while only requires 18.4% inference time and 12.4% input tokens.

</details>


### [71] [Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth](https://arxiv.org/abs/2512.05783)
*Maryam Yousefi,Soodeh Bakhshandeh*

Main category: cs.CV

TL;DR: 使用离散拉普拉斯算子进行曲率正则化，在仅5%深度测量下实现更准确的3D重建，超越传统变分自编码器。


<details>
  <summary>Details</summary>
Motivation: 稀疏深度传感器导致3D重建误差，影响自动驾驶和机器人安全，需提升重建精度。

Method: 提出基于离散拉普拉斯算子的曲率正则化方法，仅用单一正则项替代复杂多约束组合。

Result: 重建精度比标准VAE提升18.1%，训练开销仅15%，推理无额外成本。

Conclusion: 单一精心设计的正则项可超越多约束方法，挑战几何深度学习的常见假设。

Abstract: When depth sensors provide only 5% of needed measurements, reconstructing complete 3D scenes becomes difficult. Autonomous vehicles and robots cannot tolerate the geometric errors that sparse reconstruction introduces. We propose curvature regularization through a discrete Laplacian operator, achieving 18.1% better reconstruction accuracy than standard variational autoencoders. Our contribution challenges an implicit assumption in geometric deep learning: that combining multiple geometric constraints improves performance. A single well-designed regularization term not only matches but exceeds the effectiveness of complex multi-term formulations. The discrete Laplacian offers stable gradients and noise suppression with just 15% training overhead and zero inference cost. Code and models are available at https://github.com/Maryousefi/GeoVAE-3D.

</details>


### [72] [Bring Your Dreams to Life: Continual Text-to-Video Customization](https://arxiv.org/abs/2512.05802)
*Jiahua Dong,Xudong Wang,Wenqi Liang,Zongyan Han,Meng Cao,Duzhen Zhang,Hanbin Zhao,Zhi Han,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 提出一种持续学习新概念的定制化文本到视频生成模型CCVD，解决遗忘和概念忽视问题。


<details>
  <summary>Details</summary>
Motivation: 现有定制化文本到视频生成方法无法持续学习新概念，存在灾难性遗忘和概念忽视问题。

Method: 引入概念特定属性保留模块与任务感知概念聚合策略应对遗忘，通过可控条件合成与层特异性区域注意力引导噪声估计缓解概念忽视。

Result: CCVD在持续学习任务中显著优于现有模型，能有效保留旧概念并合成新概念视频。

Conclusion: CCVD实现了高效、持续的定制化视频生成，为动态学习场景提供了新范式。

Abstract: Customized text-to-video generation (CTVG) has recently witnessed great progress in generating tailored videos from user-specific text. However, most CTVG methods assume that personalized concepts remain static and do not expand incrementally over time. Additionally, they struggle with forgetting and concept neglect when continuously learning new concepts, including subjects and motions. To resolve the above challenges, we develop a novel Continual Customized Video Diffusion (CCVD) model, which can continuously learn new concepts to generate videos across various text-to-video generation tasks by tackling forgetting and concept neglect. To address catastrophic forgetting, we introduce a concept-specific attribute retention module and a task-aware concept aggregation strategy. They can capture the unique characteristics and identities of old concepts during training, while combining all subject and motion adapters of old concepts based on their relevance during testing. Besides, to tackle concept neglect, we develop a controllable conditional synthesis to enhance regional features and align video contexts with user conditions, by incorporating layer-specific region attention-guided noise estimation. Extensive experimental comparisons demonstrate that our CCVD outperforms existing CTVG models. The code is available at https://github.com/JiahuaDong/CCVD.

</details>


### [73] [Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling](https://arxiv.org/abs/2512.05809)
*Saurav Jha,M. Jehanzeb Mirza,Wei Lin,Shiqi Yang,Sarath Chandar*

Main category: cs.CV

TL;DR: 本文揭示了MindJourney等测试时验证方法在空间推理中的局限性，并提出ViSA框架通过空间断言提升性能，但发现当前世界模型仍存在信息瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有测试时验证方法在多视角与具身视角转换任务中表现不佳，存在动作偏置和不可靠奖励信号问题。

Method: 提出ViSA框架，将测试时奖励锚定于可验证的、帧级的微断言，以改善轨迹选择的平衡性与可靠性。

Result: ViSA在SAT-Real基准上显著提升空间推理性能，缓解偏置，但在MMSI-Bench上仍无法实现一致扩展。

Conclusion: 测试时验证有潜力但存在严重缺陷，当前世界模型成为细粒度推理的信息瓶颈，未来需突破模型生成能力。

Abstract: Vision-Language Models (VLMs) remain limited in spatial reasoning tasks that require multi-view understanding and embodied perspective shifts. Recent approaches such as MindJourney attempt to mitigate this gap through test-time scaling where a world model imagines action-conditioned trajectories and a heuristic verifier selects helpful views from such trajectories. In this work, we systematically examine how such test-time verifiers behave across benchmarks, uncovering both their promise and their pitfalls. Our uncertainty-based analyses show that MindJourney's verifier provides little meaningful calibration, and that random scoring often reduces answer entropy equally well, thus exposing systematic action biases and unreliable reward signals. To mitigate these, we introduce a Verification through Spatial Assertions (ViSA) framework that grounds the test-time reward in verifiable, frame-anchored micro-claims. This principled verifier consistently improves spatial reasoning on the SAT-Real benchmark and corrects trajectory-selection biases through more balanced exploratory behavior. However, on the challenging MMSI-Bench, none of the verifiers, including ours, achieve consistent scaling, suggesting that the current world models form an information bottleneck where imagined views fail to enrich fine-grained reasoning. Together, these findings chart the bad, good, and ugly aspects of test-time verification for world-model-based reasoning. Our code is available at https://github.com/chandar-lab/visa-for-mindjourney.

</details>


### [74] [UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer's Disease Detection](https://arxiv.org/abs/2512.05814)
*Fubao Zhu,Zhanyuan Jia,Zhiguo Wang,Huan Huang,Danyang Sun,Chuang Han,Yanting Li,Jiaofen Nan,Chen Zhao,Weihua Zhou*

Main category: cs.CV

TL;DR: 提出一种不确定性引导的联邦域自适应框架UG-FedDA，用于多中心阿尔茨海默病分类，在保护隐私的同时提升跨站点诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有分类方法忽视多中心数据的站点异质性且缺乏不确定性量化机制，导致鲁棒性与临床适用性不足。

Method: 结合不确定性量化与联邦域自适应，使用自注意力Transformer提取多模板ROI特征，通过不确定性加权缓解分布偏移。

Result: 在ADNI、AIBL、OASIS三个数据集上，对ADvsNC、MCIvsAD、NCvsMCI三类任务均实现稳定提升，最高准确率达90.54%。

Conclusion: UG-FedDA有效应对多中心MRI异质性，兼顾隐私保护与高精度诊断，具有显著临床应用潜力。

Abstract: Alzheimer's disease (AD) is an irreversible neurodegenerative disorder, and early diagnosis is critical for timely intervention. However, most existing classification frameworks face challenges in multicenter studies, as they often neglect inter-site heterogeneity and lack mechanisms to quantify uncertainty, which limits their robustness and clinical applicability. To address these issues, we proposed Uncertainty-Guided Federated Domain Adaptation (UG-FedDA), a novel multicenter AD classification framework that integrates uncertainty quantification (UQ) with federated domain adaptation to handle cross-site structure magnetic resonance imaging (MRI) heterogeneity under privacy constraints. Our approach extracts multi-template region-of-interest (RoI) features using a self-attention transformer, capturing both regional representations and their interactions. UQ is integrated to guide feature alignment, mitigating source-target distribution shifts by down-weighting uncertain samples. Experiments are conducted on three public datasets: the Alzheimer's Disease Neuroimaging Initiative (ADNI), the Australian Imaging, Biomarkers and Lifestyle study (AIBL), and the Open Access Series of Imaging Studies (OASIS). UG-FedDA achieved consistent cross-domain improvements in accuracy, sensitivity, and area under the ROC curve across three classification tasks: AD vs. normal controls (NC), mild cognitive impairment (MCI) vs. AD, and NC vs. MCI. For NC vs. AD, UG-FedDA achieves accuracies of 90.54%, 89.04%, and 77.78% on ADNI, AIBL and OASIS datasets, respectively. For MCI vs. AD, accuracies are 80.20% (ADNI), 71.91% (AIBL), and 79.73% (OASIS). For NC vs. MCI, results are 76.87% (ADNI), 73.91% (AIBL), and 83.73% (OASIS). These results demonstrate that the proposed framework not only adapts efficiently across multiple sites but also preserves strict privacy.

</details>


### [75] [Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning](https://arxiv.org/abs/2512.05830)
*Muhammet Cagri Yeke,Samil Sirin,Kivilcim Yuksel,Abdurrahman Gumus*

Main category: cs.CV

TL;DR: 将一维Phase-OTDR数据转为图像，用深度学习模型实现高达98%以上的事件分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统一维数据分析在光纤事件检测中效率低、适应性差，亟需更鲁棒的分析方法。

Method: 通过Gramian Angular Field和Recurrence Plot将一维信号转为灰度图像，组合成RGB多通道图像，利用EfficientNetB0和DenseNet121进行迁移学习分类。

Result: 在公开数据集上，EfficientNetB0和DenseNet121分别达到98.84%和98.24%的分类准确率，5折交叉验证测试准确率分别为99.07%和98.68%。

Conclusion: 图像化分析显著提升光纤事件检测的精度与效率，为光纤传感系统提供新范式，代码与数据集已开源。

Abstract: This study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: https://github.com/miralab-ai/Phase-OTDR-event-detection.

</details>


### [76] [VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack](https://arxiv.org/abs/2512.05853)
*Shiji Zhao,Shukun Xiong,Yao Huang,Yan Jin,Zhenyu Wu,Jiyang Guan,Ranjie Duan,Jialing Tao,Hui Xue,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出视觉推理序列攻击（VRSA），通过分解有害文本为连续子图像，绕过多模态大模型的安全防护，显著提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有攻击主要关注文本模态的推理安全风险，忽视了视觉模态中潜在的有害推理漏洞，亟需系统评估视觉推理任务中的安全威胁。

Method: 提出VRSA框架，包含自适应场景优化、语义连贯补全和图文一致性对齐三个模块，将有害意图分解为一系列语义连贯的视觉子任务逐步诱导模型输出有害内容。

Result: 在GPT-4o、Claude-4.5-Sonnet等开源与闭源MLLM上，VRSA的攻击成功率显著优于现有先进方法。

Conclusion: 视觉模态是MLLM安全防护的薄弱环节，VRSA揭示了通过序列视觉推理实施隐蔽攻击的可行性，呼吁加强多模态安全机制设计。

Abstract: Multimodal Large Language Models (MLLMs) are widely used in various fields due to their powerful cross-modal comprehension and generation capabilities. However, more modalities bring more vulnerabilities to being utilized for jailbreak attacks, which induces MLLMs to output harmful content. Due to the strong reasoning ability of MLLMs, previous jailbreak attacks try to explore reasoning safety risk in text modal, while similar threats have been largely overlooked in the visual modal. To fully evaluate potential safety risks in the visual reasoning task, we propose Visual Reasoning Sequential Attack (VRSA), which induces MLLMs to gradually externalize and aggregate complete harmful intent by decomposing the original harmful text into several sequentially related sub-images. In particular, to enhance the rationality of the scene in the image sequence, we propose Adaptive Scene Refinement to optimize the scene most relevant to the original harmful query. To ensure the semantic continuity of the generated image, we propose Semantic Coherent Completion to iteratively rewrite each sub-text combined with contextual information in this scene. In addition, we propose Text-Image Consistency Alignment to keep the semantical consistency. A series of experiments demonstrates that the VRSA can achieve a higher attack success rate compared with the state-of-the-art jailbreak attack methods on both the open-source and closed-source MLLMs such as GPT-4o and Claude-4.5-Sonnet.

</details>


### [77] [Edit-aware RAW Reconstruction](https://arxiv.org/abs/2512.05859)
*Abhijith Punnappurath,Luxi Zhao,Ke Zhao,Hue Nguyen,Radek Grzeszczuk,Michael S. Brown*

Main category: cs.CV

TL;DR: 提出一种可插拔的、感知编辑的损失函数，提升从sRGB重建RAW数据的鲁棒性，显著改善编辑后的图像质量。


<details>
  <summary>Details</summary>
Motivation: 用户常在sRGB JPEG上编辑照片，但RAW重建多仅优化像素精度，难以应对多样化的后期处理风格。

Method: 设计一个可微分的图像信号处理器（ISP），在训练中随机采样其参数模拟真实相机处理流程，并在sRGB空间计算重建损失。

Result: 在多种编辑条件下，PSNR提升1.5-2 dB；结合元数据方法可进一步优化目标编辑效果。

Conclusion: 该损失函数简单有效，可通用增强现有RAW重建方法的编辑保真度与渲染灵活性。

Abstract: Users frequently edit camera images post-capture to achieve their preferred photofinishing style. While editing in the RAW domain provides greater accuracy and flexibility, most edits are performed on the camera's display-referred output (e.g., 8-bit sRGB JPEG) since RAW images are rarely stored. Existing RAW reconstruction methods can recover RAW data from sRGB images, but these approaches are typically optimized for pixel-wise RAW reconstruction fidelity and tend to degrade under diverse rendering styles and editing operations. We introduce a plug-and-play, edit-aware loss function that can be integrated into any existing RAW reconstruction framework to make the recovered RAWs more robust to different rendering styles and edits. Our loss formulation incorporates a modular, differentiable image signal processor (ISP) that simulates realistic photofinishing pipelines with tunable parameters. During training, parameters for each ISP module are randomly sampled from carefully designed distributions that model practical variations in real camera processing. The loss is then computed in sRGB space between ground-truth and reconstructed RAWs rendered through this differentiable ISP. Incorporating our loss improves sRGB reconstruction quality by up to 1.5-2 dB PSNR across various editing conditions. Moreover, when applied to metadata-assisted RAW reconstruction methods, our approach enables fine-tuning for target edits, yielding further gains. Since photographic editing is the primary motivation for RAW reconstruction in consumer imaging, our simple yet effective loss function provides a general mechanism for enhancing edit fidelity and rendering flexibility across existing methods.

</details>


### [78] [Underwater Image Reconstruction Using a Swin Transformer-Based Generator and PatchGAN Discriminator](https://arxiv.org/abs/2512.05866)
*Md. Mahbub Hasan Akash,Aria Tasnim Mridula,Sheekar Banerjee,Ishtiak Al Mamoon*

Main category: cs.CV

TL;DR: 提出了一种基于Swin Transformer与GAN结合的深度学习框架，显著提升了水下图像的重建质量。


<details>
  <summary>Details</summary>
Motivation: 水下成像受吸收和散射影响严重，传统方法和CNN难以处理全局依赖和长距离特征，亟需更有效的重建方法。

Method: 采用U-Net结构嵌入Swin Transformer块作为生成器，结合PatchGAN判别器，利用对抗训练保留高频细节，并在EUVP数据集上训练。

Result: 在EUVP数据集上达到PSNR 24.76 dB、SSIM 0.89，视觉效果显著改善颜色平衡、对比度和去雾效果，消融实验验证了Swin Transformer的优势。

Conclusion: 所提方法在水下图像重建中表现卓越，具备实际海洋应用价值。

Abstract: Underwater imaging is essential for marine exploration, environmental monitoring, and infrastructure inspection. However, water causes severe image degradation through wavelength-dependent absorption and scattering, resulting in color distortion, low contrast, and haze effects. Traditional reconstruction methods and convolutional neural network-based approaches often fail to adequately address these challenges due to limited receptive fields and inability to model global dependencies. This paper presented a novel deep learning framework that integrated a Swin Transformer architecture within a generative adversarial network (GAN) for underwater image reconstruction. Our generator employed a U-Net structure with Swin Transformer blocks to capture both local features and long-range dependencies crucial for color correction across entire images. A PatchGAN discriminator provided adversarial training to ensure high-frequency detail preservation. We trained and evaluated our model on the EUVP dataset, which contains paired underwater images of varying quality. Quantitative results demonstrate stateof-the-art performance with PSNR of 24.76 dB and SSIM of 0.89, representing significant improvements over existing methods. Visual results showed effective color balance restoration, contrast improvement, and haze reduction. An ablation study confirms the superiority of our Swin Transformer designed over convolutional alternatives. The proposed method offers robust underwater image reconstruction suitable for various marine applications.

</details>


### [79] [SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations](https://arxiv.org/abs/2512.05905)
*Wenhao Yan,Sheng Ye,Zhuoyi Yang,Jiayan Teng,ZhenHui Dong,Kairui Wen,Xiaotao Gu,Yong-Jin Liu,Jie Tang*

Main category: cs.CV

TL;DR: SCAIL通过创新的3D姿态表示和全上下文姿态注入机制，实现了接近工作室级别的角色动画效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂运动和跨身份动画中难以保持结构保真度和时间一致性，无法满足工作室生产标准。

Method: 提出新的3D姿态表示和扩散变换器架构中的全上下文姿态注入机制，并构建高质量数据管道与评估基准。

Result: SCAIL在角色动画中达到最先进水平，显著提升动画的可靠性与真实感。

Conclusion: SCAIL为实现工作室级角色动画提供了有效解决方案，推动了该领域的发展。

Abstract: Achieving character animation that meets studio-grade production standards remains challenging despite recent progress. Existing approaches can transfer motion from a driving video to a reference image, but often fail to preserve structural fidelity and temporal consistency in wild scenarios involving complex motion and cross-identity animations. In this work, we present \textbf{SCAIL} (\textbf{S}tudio-grade \textbf{C}haracter \textbf{A}nimation via \textbf{I}n-context \textbf{L}earning), a framework designed to address these challenges from two key innovations. First, we propose a novel 3D pose representation, providing a more robust and flexible motion signal. Second, we introduce a full-context pose injection mechanism within a diffusion-transformer architecture, enabling effective spatio-temporal reasoning over full motion sequences. To align with studio-level requirements, we develop a curated data pipeline ensuring both diversity and quality, and establish a comprehensive benchmark for systematic evaluation. Experiments show that \textbf{SCAIL} achieves state-of-the-art performance and advances character animation toward studio-grade reliability and realism.

</details>


### [80] [NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction](https://arxiv.org/abs/2512.05920)
*Jiawen Yang,Yihui Cao,Xuanyu Tian,Yuyao Zhang,Hongjiang Wei*

Main category: cs.CV

TL;DR: 提出NICE模型，利用隐式神经表示精确预测正颌手术后面部外观，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生物力学、参数化模型和深度学习方法在计算效率或捕捉骨骼与软组织非线性相互作用方面存在不足。

Method: NICE模型包含形状模块（区域特定SDF解码器）和手术模块（共享外科潜码驱动的变形解码器），输出逐点位移场以建模手术结果。

Result: 在关键区域如唇部和下巴的预测精度显著提升，同时保持解剖完整性，优于当前最先进方法。

Conclusion: NICE为正颌手术规划和患者咨询提供了临床可行的工具。

Abstract: Orthognathic surgery is a crucial intervention for correcting dentofacial skeletal deformities to enhance occlusal functionality and facial aesthetics. Accurate postoperative facial appearance prediction remains challenging due to the complex nonlinear interactions between skeletal movements and facial soft tissue. Existing biomechanical, parametric models and deep-learning approaches either lack computational efficiency or fail to fully capture these intricate interactions. To address these limitations, we propose Neural Implicit Craniofacial Model (NICE) which employs implicit neural representations for accurate anatomical reconstruction and surgical outcome prediction. NICE comprises a shape module, which employs region-specific implicit Signed Distance Function (SDF) decoders to reconstruct the facial surface, maxilla, and mandible, and a surgery module, which employs region-specific deformation decoders. These deformation decoders are driven by a shared surgical latent code to effectively model the complex, nonlinear biomechanical response of the facial surface to skeletal movements, incorporating anatomical prior knowledge. The deformation decoders output point-wise displacement fields, enabling precise modeling of surgical outcomes. Extensive experiments demonstrate that NICE outperforms current state-of-the-art methods, notably improving prediction accuracy in critical facial regions such as lips and chin, while robustly preserving anatomical integrity. This work provides a clinically viable tool for enhanced surgical planning and patient consultation in orthognathic procedures.

</details>


### [81] [LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation](https://arxiv.org/abs/2512.05922)
*Khang Le,Anh Mai Vu,Thi Kim Trang Vo,Ha Thach,Ngoc Bui Lam Quang,Thanh-Huy Nguyen,Minh H. N. Le,Zhu Han,Chandra Mohan,Hien Van Nguyen*

Main category: cs.CV

TL;DR: 提出一种无聚类、单阶段可学习原型框架，提升组织病理学弱监督语义分割性能，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖两阶段聚类原型构建，成本高、超参敏感且原型发现与分割学习脱节，导致效果受限。

Method: 引入无聚类的单阶段可学习原型框架，结合多样性正则化，增强类内异质性覆盖。

Result: 在BCSS-WSSS数据集上达到SOTA性能，mIoU和mDice均优于先前方法，分割边界更清晰，激活图覆盖更全面。

Conclusion: 可学习原型相比聚类原型能更有效捕捉类内多样区域，提升分割精度与鲁棒性。

Abstract: Weakly supervised semantic segmentation (WSSS) in histopathology reduces pixel-level labeling by learning from image-level labels, but it is hindered by inter-class homogeneity, intra-class heterogeneity, and CAM-induced region shrinkage (global pooling-based class activation maps whose activations highlight only the most distinctive areas and miss nearby class regions). Recent works address these challenges by constructing a clustering prototype bank and then refining masks in a separate stage; however, such two-stage pipelines are costly, sensitive to hyperparameters, and decouple prototype discovery from segmentation learning, limiting their effectiveness and efficiency. We propose a cluster-free, one-stage learnable-prototype framework with diversity regularization to enhance morphological intra-class heterogeneity coverage. Our approach achieves state-of-the-art (SOTA) performance on BCSS-WSSS, outperforming prior methods in mIoU and mDice. Qualitative segmentation maps show sharper boundaries and fewer mislabels, and activation heatmaps further reveal that, compared with clustering-based prototypes, our learnable prototypes cover more diverse and complementary regions within each class, providing consistent qualitative evidence for their effectiveness.

</details>


### [82] [A Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition](https://arxiv.org/abs/2512.05928)
*Pedro Vidal,Bernardo Biesseck,Luiz E. L. Coelho,Roger Granada,David Menotti*

Main category: cs.CV

TL;DR: 研究比较了不同生成技术合成的人脸数据在人脸识别任务中的效果，发现其能捕捉真实变化但仍落后于真实数据。


<details>
  <summary>Details</summary>
Motivation: 人脸识别面临可解释性、偏见、隐私和鲁棒性等问题，且真实数据集因隐私法规退化，合成数据被视为解决这些问题的有前景方案。

Method: 在八个主流数据集上评估了使用扩散模型、GANs和3D模型生成的合成数据的准确性、rank-1、rank-5和FPR=0.01%时的TPR。

Result: 合成数据在多种指标上表现良好，能有效模拟真实变化，但性能仍低于真实数据，不同生成技术均有显著进展。

Conclusion: 合成人脸数据是缓解隐私与偏见问题的有效途径，但需进一步研究以缩小其与真实数据的性能差距。

Abstract: Facial recognition has become a widely used method for authentication and identification, with applications for secure access and locating missing persons. Its success is largely attributed to deep learning, which leverages large datasets and effective loss functions to learn discriminative features. Despite these advances, facial recognition still faces challenges in explainability, demographic bias, privacy, and robustness to aging, pose variations, lighting changes, occlusions, and facial expressions. Privacy regulations have also led to the degradation of several datasets, raising legal, ethical, and privacy concerns. Synthetic facial data generation has been proposed as a promising solution. It mitigates privacy issues, enables experimentation with controlled facial attributes, alleviates demographic bias, and provides supplementary data to improve models trained on real data. This study compares the effectiveness of synthetic facial datasets generated using different techniques in facial recognition tasks. We evaluate accuracy, rank-1, rank-5, and the true positive rate at a false positive rate of 0.01% on eight leading datasets, offering a comparative analysis not extensively explored in the literature. Results demonstrate the ability of synthetic data to capture realistic variations while emphasizing the need for further research to close the performance gap with real data. Techniques such as diffusion models, GANs, and 3D models show substantial progress; however, challenges remain.

</details>


### [83] [Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding](https://arxiv.org/abs/2512.05941)
*Zhiyuan Jiang,Shenghao Xie,Wenyi Li,Wenqiang Zu,Peihang Li,Jiahao Qiu,Siqi Pei,Lei Ma,Tiejun Huang,Mengdi Wang,Shilong Liu*

Main category: cs.CV

TL;DR: 提出一种无需训练的ZoomClick方法，利用缩放作为GUI定位的先验，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位方法依赖大规模边界框标注，面临跨平台泛化、复杂布局分析和细粒度定位等挑战。

Method: 通过分析缩放的四个关键属性（预缩放、深度、收缩尺寸、最小裁剪尺寸），提出无需训练的ZoomClick方法，实现动态空间聚焦与自适应上下文切换。

Result: 在多个主流基准上达到SOTA效果，如UI-Venus-72B在ScreenSpot-Pro上达到73.1%成功率；并构建GUIZoom-Bench新基准。

Conclusion: 缩放是一种强大且被忽视的GUI定位先验，ZoomClick为未来研究提供了可扩展的训练与测试框架。

Abstract: Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.

</details>


### [84] [AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement](https://arxiv.org/abs/2512.05960)
*Munsif Ali,Najmul Hassan,Lucia Ventura,Davide Di Bari,Simonepietro Canese*

Main category: cs.CV

TL;DR: 提出AQUA-Net模型，结合频率与光照分支，在参数更少的情况下实现优于或等同于SOTA的水下图像增强效果。


<details>
  <summary>Details</summary>
Motivation: 水下图像存在严重色彩失真、低对比度和雾化问题，且现有深度学习模型计算复杂度高，难以实时部署。

Method: 设计AQUA-Net，采用残差编码器-解码器结构，融合傅里叶域频率信息与基于Retinex的光照感知解码器，实现空间、频率与光照联合优化。

Result: 在多个基准数据集上达到与SOTA相当的性能，参数更少；新发布的地中海真实水下视频数据集提升了评估可靠性。

Conclusion: AQUA-Net具有强泛化能力与鲁棒性，为真实水下成像应用提供了高效解决方案。

Abstract: Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.

</details>


### [85] [EditThinker: Unlocking Iterative Reasoning for Any Image Editor](https://arxiv.org/abs/2512.05965)
*Hongyu Li,Manyuan Zhang,Dian Zheng,Ziyu Guo,Yimeng Jia,Kaituo Feng,Hao Yu,Yexin Liu,Yan Feng,Peng Pei,Xunliang Cai,Linjiang Huang,Hongsheng Li,Si Liu*

Main category: cs.CV

TL;DR: 提出一种名为EditThinker的反思式图像编辑框架，通过迭代的“思考-编辑”循环显著提升指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法因随机性和缺乏深思熟虑，单次编辑指令遵循成功率有限。

Method: 构建Think-while-Edit循环，训练单个MLLM模型EditThinker协同生成批判评分、推理过程与优化指令，并使用强化学习对齐思考与编辑行为。

Result: 在四个基准上显著提升任意图像编辑模型的指令遵循能力，效果大幅提升。

Conclusion: 该框架通过模拟人类认知循环，有效解决指令编辑中的不确定性问题，将开源数据、数据构建框架与模型以促进社区发展。

Abstract: Instruction-based image editing has emerged as a prominent research area, which, benefiting from image generation foundation models, have achieved high aesthetic quality, making instruction-following capability the primary challenge. Existing approaches improve instruction adherence via supervised or reinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to 'think' while they edit, which simulates the human cognitive loop by iteratively executing a Think-while-Edit cycle: Critiquing results and Refining instructions , followed by Repeating the generation until satisfactory. Specifically, we train a single MLLM, EditThinker, to act as the reasoning engine of this framework, which jointly produce the critique score, reasoning process, and refined instructions. We employ reinforcement learning to align the EditThinker's thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves the instruction-following capability of any image editing model by a large margin. We will release our data construction framework, datasets, and models to benefit the community.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [86] [Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques](https://arxiv.org/abs/2512.05169)
*Abdelmalik Moujahid,Fadi Dornaika*

Main category: cs.LG

TL;DR: 本文系统综述了多视图聚类（MVC）方法，分类归纳了七类主流技术，分析了其优劣与挑战，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 单视图学习方法在计算限制、数据复杂性和异构性方面存在局限，多视图聚类能提供更丰富的数据表示，提升无监督学习性能。

Method: 系统分类MVC方法为协同训练、协同正则化、子空间、深度学习、核方法、锚点方法和图方法；分析集成策略（早融合、晚融合、联合学习）；综述140+文献并探讨医疗、多媒体、社交网络等应用场景。

Result: 构建了MVC领域的完整技术框架，揭示了 scalability、不完整数据等关键挑战，并提出未来跨学科应用与发展方向。

Conclusion: 本综述填补了MVC研究空白，为该领域提供了系统性指导与实践洞见，推动其在真实场景中的进一步发展。

Abstract: Machine learning techniques face numerous challenges to achieve optimal performance. These include computational constraints, the limitations of single-view learning algorithms and the complexity of processing large datasets from different domains, sources or views. In this context, multi-view clustering (MVC), a class of unsupervised multi-view learning, emerges as a powerful approach to overcome these challenges. MVC compensates for the shortcomings of single-view methods and provides a richer data representation and effective solutions for a variety of unsupervised learning tasks. In contrast to traditional single-view approaches, the semantically rich nature of multi-view data increases its practical utility despite its inherent complexity. This survey makes a threefold contribution: (1) a systematic categorization of multi-view clustering methods into well-defined groups, including co-training, co-regularization, subspace, deep learning, kernel-based, anchor-based, and graph-based strategies; (2) an in-depth analysis of their respective strengths, weaknesses, and practical challenges, such as scalability and incomplete data; and (3) a forward-looking discussion of emerging trends, interdisciplinary applications, and future directions in MVC research. This study represents an extensive workload, encompassing the review of over 140 foundational and recent publications, the development of comparative insights on integration strategies such as early fusion, late fusion, and joint learning, and the structured investigation of practical use cases in the areas of healthcare, multimedia, and social network analysis. By integrating these efforts, this work aims to fill existing gaps in MVC research and provide actionable insights for the advancement of the field.

</details>


### [87] [Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models](https://arxiv.org/abs/2512.05216)
*Rajna Fani,Rafi Al Attrach,David Restrepo,Yugang Jia,Leo Anthony Celi,Peter Schüffler*

Main category: cs.LG

TL;DR: 提出一种基于特征波动性的自适应掩码策略CV-Masking，提升电子健康记录预训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用均匀随机掩码，忽略实验室指标波动性差异，而高波动指标（如乳酸）更具临床意义但更难建模。

Method: 提出系数变异掩码（CV-Masking），根据每个特征的变异系数自适应调整掩码概率，并结合仅值掩码目标优化。

Result: 在大量实验室数据上验证，CV-Masking显著提升重建精度、下游预测性能和收敛速度，生成更稳健的临床表征。

Conclusion: CV-Masking通过引入临床相关的波动性感知机制，优于随机和方差基掩码策略，为EHR预训练提供更有效的方向。

Abstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly assuming all features are equally predictable. In reality, laboratory tests exhibit substantial heterogeneity in volatility: some biomarkers (e.g., sodium) remain stable, while others (e.g., lactate) fluctuate considerably and are more difficult to model. Clinically, volatile biomarkers often signal acute pathophysiology and require more sophisticated modeling to capture their complex temporal patterns. We propose a volatility-aware pretraining strategy, Coefficient of Variation Masking (CV-Masking), that adaptively adjusts masking probabilities according to the intrinsic variability of each feature. Combined with a value-only masking objective aligned with clinical workflows, CV-Masking yields systematic improvements over random and variance-based strategies. Experiments on a large panel of laboratory tests show that CV-Masking enhances reconstruction, improves downstream predictive performance, and accelerates convergence, producing more robust and clinically meaningful EHR representations.

</details>


### [88] [Rethinking Tokenization for Clinical Time Series: When Less is More](https://arxiv.org/abs/2512.05217)
*Rafi Al Attrach,Rajna Fani,David Restrepo,Yugang Jia,Peter Schüffler*

Main category: cs.LG

TL;DR: 简单高效的词元化策略在临床时间序列建模中表现优异，复杂时间编码未必有益，冻结预训练编码器更优。


<details>
  <summary>Details</summary>
Motivation: 现有词元化方法缺乏公平比较，亟需系统评估不同策略对临床预测任务的影响。

Method: 在MIMIC-IV数据集上，对四种临床预测任务进行受控消融实验，比较时间编码、值特征和预训练编码器的效用。

Result: 时间编码无显著收益；值特征任务相关；冻结预训练编码器性能远超可训练模型且参数更少；大模型持续提升性能。

Conclusion: 最优词元化策略依赖任务，简单、参数高效的方案常足以达成强性能。

Abstract: Tokenization strategies shape how models process electronic health records, yet fair comparisons of their effectiveness remain limited. We present a systematic evaluation of tokenization approaches for clinical time series modeling using transformer-based architectures, revealing task-dependent and sometimes counterintuitive findings about temporal and value feature importance. Through controlled ablations across four clinical prediction tasks on MIMIC-IV, we demonstrate that explicit time encodings provide no consistent statistically significant benefit for the evaluated downstream tasks. Value features show task-dependent importance, affecting mortality prediction but not readmission, suggesting code sequences alone can carry sufficient predictive signal. We further show that frozen pretrained code encoders dramatically outperform their trainable counterparts while requiring dramatically fewer parameters. Larger clinical encoders provide consistent improvements across tasks, benefiting from frozen embeddings that eliminate computational overhead. Our controlled evaluation enables fairer tokenization comparisons and demonstrates that simpler, parameter-efficient approaches can, in many cases, achieve strong performance, though the optimal tokenization strategy remains task-dependent.

</details>


### [89] [Mitigating the Antigenic Data Bottleneck: Semi-supervised Learning with Protein Language Models for Influenza A Surveillance](https://arxiv.org/abs/2512.05222)
*Yanhua Xu*

Main category: cs.LG

TL;DR: 结合预训练蛋白质语言模型与半监督学习，可在标注数据稀缺时准确预测流感病毒抗原性，提升疫苗株筛选效率。


<details>
  <summary>Details</summary>
Motivation: 传统HI检测耗时且难以扩展，导致基因组数据远多于表型标注，限制监督模型效果。

Method: 使用四种PLM嵌入（ESM-2, ProtVec, ProtT5, ProtBert）结合自训练和标签传播两种半监督策略，在四种流感亚型上进行嵌套交叉验证，模拟不同标注比例场景。

Result: 半监督学习在低标注率下显著提升性能，ProtVec+自训练增益最大，ESM-2在仅25%标注时F1超0.82，H3N2仍具挑战但有所改善。

Conclusion: PLM与SSL结合能有效缓解抗原性标注瓶颈，充分利用未标注序列，支持快速变异株优先级判断和疫苗株选择。

Abstract: Influenza A viruses (IAVs) evolve antigenically at a pace that requires frequent vaccine updates, yet the haemagglutination inhibition (HI) assays used to quantify antigenicity are labor-intensive and unscalable. As a result, genomic data vastly outpace available phenotypic labels, limiting the effectiveness of traditional supervised models. We hypothesize that combining pre-trained Protein Language Models (PLMs) with Semi-Supervised Learning (SSL) can retain high predictive accuracy even when labeled data are scarce. We evaluated two SSL strategies, Self-training and Label Spreading, against fully supervised baselines using four PLM-derived embeddings (ESM-2, ProtVec, ProtT5, ProtBert) applied to haemagglutinin (HA) sequences. A nested cross-validation framework simulated low-label regimes (25%, 50%, 75%, and 100% label availability) across four IAV subtypes (H1N1, H3N2, H5N1, H9N2). SSL consistently improved performance under label scarcity. Self-training with ProtVec produced the largest relative gains, showing that SSL can compensate for lower-resolution representations. ESM-2 remained highly robust, achieving F1 scores above 0.82 with only 25% labeled data, indicating that its embeddings capture key antigenic determinants. While H1N1 and H9N2 were predicted with high accuracy, the hypervariable H3N2 subtype remained challenging, although SSL mitigated the performance decline. These findings demonstrate that integrating PLMs with SSL can address the antigenicity labeling bottleneck and enable more effective use of unlabeled surveillance sequences, supporting rapid variant prioritization and timely vaccine strain selection.

</details>


### [90] [Variance Matters: Improving Domain Adaptation via Stratified Sampling](https://arxiv.org/abs/2512.05226)
*Andrea Napoli,Paul White*

Main category: cs.LG

TL;DR: 提出VaRDASS，首个用于无监督域自适应的随机方差缩减方法，通过分层采样提升域差异估计精度，理论最优且实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 域移位是机器学习部署的关键挑战，现有UDA方法在随机设置中域差异估计方差高，限制了理论优势。

Method: 提出VaRDASS，针对相关性对齐和MMD设计分层目标，推导误差界，证明MMD目标在假设下方差最小，并提出k-means风格优化算法。

Result: 在三个域移位数据集上，VaRDASS显著提升域差异估计准确性和目标域性能。

Conclusion: VaRDASS是首个专为UDA设计的方差缩减方法，理论严谨且实验有效，为域自适应提供了新方向。

Abstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high variance in stochastic settings, which can stifle the theoretical benefits of the method. This paper proposes Variance-Reduced Domain Adaptation via Stratified Sampling (VaRDASS), the first specialised stochastic variance reduction technique for UDA. We consider two specific discrepancy measures -- correlation alignment and the maximum mean discrepancy (MMD) -- and derive ad hoc stratification objectives for these terms. We then present expected and worst-case error bounds, and prove that our proposed objective for the MMD is theoretically optimal (i.e., minimises the variance) under certain assumptions. Finally, a practical k-means style optimisation algorithm is introduced and analysed. Experiments on three domain shift datasets demonstrate improved discrepancy estimation accuracy and target domain performance.

</details>


### [91] [MAR-FL: A Communication Efficient Peer-to-Peer Federated Learning System](https://arxiv.org/abs/2512.05234)
*Felix Mulitze,Herbert Woisetschläger,Hans Arno Jacobsen*

Main category: cs.LG

TL;DR: MAR-FL提出一种新的P2P联邦学习系统，通过分组聚合显著降低通信开销，实现O(N log N)复杂度，提升可扩展性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有P2P联邦学习方法通信复杂度高（O(N^2)），难以在动态无线网络中扩展。

Method: 引入迭代分组聚合机制，减少通信开销，支持网络抖动下的鲁棒性和隐私计算集成。

Result: 通信复杂度从O(N^2)降至O(N log N)，在大规模对等网络中保持高效与稳定。

Conclusion: MAR-FL为无线环境下的分布式学习提供了可扩展、鲁棒且高效的P2P联邦学习解决方案。

Abstract: The convergence of next-generation wireless systems and distributed Machine Learning (ML) demands Federated Learning (FL) methods that remain efficient and robust with wireless connected peers and under network churn. Peer-to-peer (P2P) FL removes the bottleneck of a central coordinator, but existing approaches suffer from excessive communication complexity, limiting their scalability in practice. We introduce MAR-FL, a novel P2P FL system that leverages iterative group-based aggregation to substantially reduce communication overhead while retaining resilience to churn. MAR-FL achieves communication costs that scale as O(N log N), contrasting with the O(N^2) complexity of previously existing baselines, and thereby maintains effectiveness especially as the number of peers in an aggregation round grows. The system is robust towards unreliable FL clients and can integrate private computing.

</details>


### [92] [Edged Weisfeiler-Lehman Algorithm](https://arxiv.org/abs/2512.05238)
*Xiao Yue,Bo Liu,Feng Zhang,Guangzhi Qu*

Main category: cs.LG

TL;DR: 提出E-WL算法和EGIN模型，利用边特征提升图学习性能，实验表明在12个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统1-WL算法和多数GNN未利用边特征，限制了图学习效果，亟需一种能有效融合边特征的方法。

Method: 提出Edged-WL（E-WL）算法扩展1-WL以包含边特征，并基于此构建Edged Graph Isomorphism Network（EGIN）模型。

Result: 在12个含边特征的图数据集上，EGIN模型在图分类任务中普遍优于现有SOTA方法。

Conclusion: E-WL和EGIN有效利用边特征，显著提升图学习性能，为GNN设计提供了新方向。

Abstract: As a classical approach on graph learning, the propagation-aggregation methodology is widely exploited by many of Graph Neural Networks (GNNs), wherein the representation of a node is updated by aggregating representations from itself and neighbor nodes recursively. Similar to the propagation-aggregation methodology, the Weisfeiler-Lehman (1-WL) algorithm tests isomorphism through color refinement according to color representations of a node and its neighbor nodes. However, 1-WL does not leverage any edge features (labels), presenting a potential improvement on exploiting edge features in some fields. To address this limitation, we proposed a novel Edged-WL algorithm (E-WL) which extends the original 1-WL algorithm to incorporate edge features. Building upon the E-WL algorithm, we also introduce an Edged Graph Isomorphism Network (EGIN) model for further exploiting edge features, which addresses one key drawback in many GNNs that do not utilize any edge features of graph data. We evaluated the performance of proposed models using 12 edge-featured benchmark graph datasets and compared them with some state-of-the-art baseline models. Experimental results indicate that our proposed EGIN models, in general, demonstrate superior performance in graph learning on graph classification tasks.

</details>


### [93] [Bridging quantum and classical computing for partial differential equations through multifidelity machine learning](https://arxiv.org/abs/2512.05241)
*Bruno Jacob,Amanda A. Howard,Panos Stinis*

Main category: cs.LG

TL;DR: 提出一种多保真度学习框架，利用少量经典数据校正量子求解器的粗分辨率PDE解，实现高精度预测与时间外推，推动近期内量子计算在科学计算中的实用化。


<details>
  <summary>Details</summary>
Motivation: 当前量子硬件受限于有限量子比特和电路深度，导致PDE求解精度低，难以满足实际需求。

Method: 构建多保真度神经架构，用量子求解器生成的大量低精度数据训练代理模型，并通过线性与非线性变换学习校正映射，结合稀疏经典高精度数据优化。

Result: 在粘性Burgers方程和不可压Navier-Stokes方程上验证，该方法显著提升量子解精度，实现超越训练时间窗的外推，精度接近经典模拟。

Conclusion: 该框架有效弥合量子硬件限制与应用需求间的差距，为近期内量子计算在计算物理中的实际应用提供可行路径。

Abstract: Quantum algorithms for partial differential equations (PDEs) face severe practical constraints on near-term hardware: limited qubit counts restrict spatial resolution to coarse grids, while circuit depth limitations prevent accurate long-time integration. These hardware bottlenecks confine quantum PDE solvers to low-fidelity regimes despite their theoretical potential for computational speedup. We introduce a multifidelity learning framework that corrects coarse quantum solutions to high-fidelity accuracy using sparse classical training data, facilitating the path toward practical quantum utility for scientific computing. The approach trains a low-fidelity surrogate on abundant quantum solver outputs, then learns correction mappings through a multifidelity neural architecture that balances linear and nonlinear transformations. Demonstrated on benchmark nonlinear PDEs including viscous Burgers equation and incompressible Navier-Stokes flows via quantum lattice Boltzmann methods, the framework successfully corrects coarse quantum predictions and achieves temporal extrapolation well beyond the classical training window. This strategy illustrates how one can reduce expensive high-fidelity simulation requirements while producing predictions that are competitive with classical accuracy. By bridging the gap between hardware-limited quantum simulations and application requirements, this work establishes a pathway for extracting computational value from current quantum devices in real-world scientific applications, advancing both algorithm development and practical deployment of near-term quantum computing for computational physics.

</details>


### [94] [When unlearning is free: leveraging low influence points to reduce computational costs](https://arxiv.org/abs/2512.05254)
*Anat Kleiman,Robert Fisher,Ben Deaner,Udi Wieder*

Main category: cs.LG

TL;DR: 提出一种高效遗忘框架，通过识别对模型影响可忽略的数据点，减少遗忘所需数据量，节省高达50%计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法对所有需遗忘数据点一视同仁，未考虑部分数据对模型影响微弱，导致计算资源浪费。

Method: 通过语言与视觉任务中的影响函数分析，识别出对模型输出影响可忽略的训练数据子集，并在遗忘前对数据集进行精简。

Result: 在真实场景中实现高达约50%的计算开销节省。

Conclusion: 忽略对模型影响微小的数据点可显著提升遗忘效率，为隐私保护提供更优解。

Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically treat all points in the forget set equally. In this work, we challenge this approach by asking whether points that have a negligible impact on the model's learning need to be removed. Through a comparative analysis of influence functions across language and vision tasks, we identify subsets of training data with negligible impact on model outputs. Leveraging this insight, we propose an efficient unlearning framework that reduces the size of datasets before unlearning leading to significant computational savings (up to approximately 50 percent) on real world empirical examples.

</details>


### [95] [DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models](https://arxiv.org/abs/2512.05287)
*Ziqi Zhang*

Main category: cs.LG

TL;DR: 提出一种基于图神经网络的机器学习模型DMAGT，用于高效预测药物与miRNA的关联，显著提升药物开发效率。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验方法效率低、成本高，难以大规模探索药物与miRNA的潜在关联，亟需计算模型加速miRNA靶向药物研发。

Method: 构建多层Transformer图神经网络DMAGT，将药物-miRNA关联建模为图结构，结合Word2Vec嵌入药物分子与miRNA碱基特征，利用图变换器学习结构与特征关系进行预测。

Result: 在ncDR、RNAInter和SM2miR三个数据集上达到AUC 95.24±0.05，显著优于现有方法；对5-氟尿嘧啶和奥沙利铂预测的20个关联中14个被实验验证。

Conclusion: DMAGT在预测药物-miRNA关联上表现优异且稳定，为miRNA靶向药物开发提供了高效的计算工具。

Abstract: MiRNAs, due to their role in gene regulation, have paved a new pathway for pharmacology, focusing on drug development that targets miRNAs. However, traditional wet lab experiments are limited by efficiency and cost constraints, making it difficult to extensively explore potential associations between developed drugs and target miRNAs. Therefore, we have designed a novel machine learning model based on a multi-layer transformer-based graph neural network, DMAGT, specifically for predicting associations between drugs and miRNAs. This model transforms drug-miRNA associations into graphs, employs Word2Vec for embedding features of drug molecular structures and miRNA base structures, and leverages a graph transformer model to learn from embedded features and relational structures, ultimately predicting associations between drugs and miRNAs. To evaluate DMAGT, we tested its performance on three datasets composed of drug-miRNA associations: ncDR, RNAInter, and SM2miR, achieving up to AUC of $95.24\pm0.05$. DMAGT demonstrated superior performance in comparative experiments tackling similar challenges. To validate its practical efficacy, we specifically focused on two drugs, namely 5-Fluorouracil and Oxaliplatin. Of the 20 potential drug-miRNA associations identified as the most likely, 14 were successfully validated. The above experiments demonstrate that DMAGT has an excellent performance and stability in predicting drug-miRNA associations, providing a new shortcut for miRNA drug development.

</details>


### [96] [Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2512.05291)
*Na Li,Hangguan Shan,Wei Ni,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 提出一种基于RKHS-SHAP的可解释强化学习算法RSA2C，通过状态归因指导演员-评论家训练，提升效率、稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释强化学习方法忽视状态特征对奖励的异质影响，缺乏利用状态归因指导训练的机制。

Method: 提出RSA2C算法，结合RKHS与SHAP，使用Mahalanobis加权核函数，通过状态归因生成门控权重调制演员梯度与优势评论家目标，采用稀疏词典结构。

Result: 理论上证明了在状态扰动下的全局非渐近收敛性，实验在三个连续控制环境中验证了效率、稳定性和可解释性的提升。

Conclusion: RSA2C通过归因感知机制有效融合可解释性与性能，为高维连续控制任务提供了新的可解释RL框架。

Abstract: Actor-critic (AC) methods are a cornerstone of reinforcement learning (RL) but offer limited interpretability. Current explainable RL methods seldom use state attributions to assist training. Rather, they treat all state features equally, thereby neglecting the heterogeneous impacts of individual state dimensions on the reward. We propose RKHS--SHAP-based Advanced Actor--Critic (RSA2C), an attribution-aware, kernelized, two-timescale AC algorithm, including Actor, Value Critic, and Advantage Critic. The Actor is instantiated in a vector-valued reproducing kernel Hilbert space (RKHS) with a Mahalanobis-weighted operator-valued kernel, while the Value Critic and Advantage Critic reside in scalar RKHSs. These RKHS-enhanced components use sparsified dictionaries: the Value Critic maintains its own dictionary, while the Actor and Advantage Critic share one. State attributions, computed from the Value Critic via RKHS--SHAP (kernel mean embedding for on-manifold expectations and conditional mean embedding for off-manifold expectations), are converted into Mahalanobis-gated weights that modulate Actor gradients and Advantage Critic targets. Theoretically, we derive a global, non-asymptotic convergence bound under state perturbations, showing stability through the perturbation-error term and efficiency through the convergence-error term. Empirical results on three standard continuous-control environments show that our algorithm achieves efficiency, stability, and interpretability.

</details>


### [97] [CFO: Learning Continuous-Time PDE Dynamics via Flow-Matched Neural Operators](https://arxiv.org/abs/2512.05297)
*Xianglong Hou,Xinquan Huang,Paris Perdikaris*

Main category: cs.LG

TL;DR: CFO是一种无需反向传播ODE求解器的连续时间PDE学习框架，通过流匹配直接学习PDE右端项，实现时间分辨率无关、高精度与数据高效性。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子采用自回归预测，存在误差累积和固定时间离散化问题，而现有连续方法如神经ODE计算负担重。

Method: CFO利用流匹配技术，对轨迹数据拟合时间样条，通过有限差分估计节点处的时间导数，构建概率路径，训练神经算子预测解析速度场，无需反向传播ODE求解器。

Result: 在四个基准测试中，CFO在仅使用25%不规则采样数据时，比自回归基线误差降低达87%，且推理时仅需50%的函数评估次数，支持反向时间和任意时间分辨率查询。

Conclusion: CFO实现了高精度、高数据效率和计算效率的平衡，突破了传统方法的时间离散化限制，为PDE学习提供了新范式。

Abstract: Neural operator surrogates for time-dependent partial differential equations (PDEs) conventionally employ autoregressive prediction schemes, which accumulate error over long rollouts and require uniform temporal discretization. We introduce the Continuous Flow Operator (CFO), a framework that learns continuous-time PDE dynamics without the computational burden of standard continuous approaches, e.g., neural ODE. The key insight is repurposing flow matching to directly learn the right-hand side of PDEs without backpropagating through ODE solvers. CFO fits temporal splines to trajectory data, using finite-difference estimates of time derivatives at knots to construct probability paths whose velocities closely approximate the true PDE dynamics. A neural operator is then trained via flow matching to predict these analytic velocity fields. This approach is inherently time-resolution invariant: training accepts trajectories sampled on arbitrary, non-uniform time grids while inference queries solutions at any temporal resolution through ODE integration. Across four benchmarks (Lorenz, 1D Burgers, 2D diffusion-reaction, 2D shallow water), CFO demonstrates superior long-horizon stability and remarkable data efficiency. CFO trained on only 25% of irregularly subsampled time points outperforms autoregressive baselines trained on complete data, with relative error reductions up to 87%. Despite requiring numerical integration at inference, CFO achieves competitive efficiency, outperforming autoregressive baselines using only 50% of their function evaluations, while uniquely enabling reverse-time inference and arbitrary temporal querying.

</details>


### [98] [Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)](https://arxiv.org/abs/2512.05306)
*Y. Sungtaek Ju*

Main category: cs.LG

TL;DR: 提出了一种结合稀疏变分高斯过程的Kolmogorov-Arnold网络，实现可扩展的贝叶斯不确定性量化，适用于科学机器学习。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov-Arnold网络缺乏系统性的不确定性量化能力，限制了其在科学应用中的使用。

Method: 将稀疏变分高斯过程推理与Kolmogorov-Arnold结构结合，利用解析矩匹配传播不确定性，保持可解释性且计算复杂度近线性。

Result: 在流体流动重建、多步预报和异常检测三个案例中成功区分了偶然性和认知不确定性。

Conclusion: SVGP KAN是一种有前景的科学机器学习架构，能实现可解释且不确定性感知的学习。

Abstract: Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Gaussian process inference with the Kolmogorov-Arnold topology, enabling scalable Bayesian inference with computational complexity quasi-linear in sample size. Through analytic moment matching, we propagate uncertainty through deep additive structures while maintaining interpretability. We use three example studies to demonstrate the framework's ability to distinguish aleatoric from epistemic uncertainty: calibration of heteroscedastic measurement noise in fluid flow reconstruction, quantification of prediction confidence degradation in multi-step forecasting of advection-diffusion dynamics, and out-of-distribution detection in convolutional autoencoders. These results suggest Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KANs) is a promising architecture for uncertainty-aware learning in scientific machine learning.

</details>


### [99] [The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?](https://arxiv.org/abs/2512.05311)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee*

Main category: cs.LG

TL;DR: 研究首次系统评估了SOTA模型区分人类与LLM生成科研想法的能力，发现 paraphrasing 显著降低检测准确率，但加入研究问题上下文可提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为研究代理的广泛应用，亟需区分人类与LLM生成的科研想法，但该领域尚未被探索。

Method: 系统评估SOTA机器学习模型在多轮改写下区分人类与LLM生成科研想法的能力，并测试加入研究问题上下文的影响。

Result: 检测性能在五轮改写后平均下降25.4%；加入研究问题上下文可提升最多2.97%；非专家风格简化改写对检测性能冲击最大。

Conclusion: 当前检测模型难以应对LLM生成想法的语义模糊化，需结合领域上下文并重视语言风格变化以提升区分能力。

Abstract: With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs' research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.

</details>


### [100] [Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay](https://arxiv.org/abs/2512.05320)
*Mehmet Efe Lorasdagi,Dogan Can Cicek,Furkan Burak Mutlu,Suleyman Serdar Kozat*

Main category: cs.LG

TL;DR: 提出解耦优先经验回放（DPER），分别优化Actor和Critic的样本采样，提升DDPG类算法性能。


<details>
  <summary>Details</summary>
Motivation: Actor和Critic学习目标不同，使用相同样本批次可能非最优，需解耦采样以提供更合适的训练信号。

Method: 引入DPER，独立采样Actor和Critic的过渡批次，并与TD3结合，在MuJoCo任务中验证。

Result: DPER在多个MuJoCo任务上超越传统经验回放方法（如vanilla和PER）。

Conclusion: 解耦经验回放能改善训练动态与策略质量，DPER是一种可泛化、提升Actor-Critic算法性能的通用机制。

Abstract: Background: Deep Deterministic Policy Gradient-based reinforcement learning algorithms utilize Actor-Critic architectures, where both networks are typically trained using identical batches of replayed transitions. However, the learning objectives and update dynamics of the Actor and Critic differ, raising concerns about whether uniform transition usage is optimal.
  Objectives: We aim to improve the performance of deep deterministic policy gradient algorithms by decoupling the transition batches used to train the Actor and the Critic. Our goal is to design an experience replay mechanism that provides appropriate learning signals to each component by using separate, tailored batches.
  Methods: We introduce Decoupled Prioritized Experience Replay (DPER), a novel approach that allows independent sampling of transition batches for the Actor and the Critic. DPER can be integrated into any off-policy deep reinforcement learning algorithm that operates in continuous control domains. We combine DPER with the state-of-the-art Twin Delayed DDPG algorithm and evaluate its performance across standard continuous control benchmarks.
  Results: DPER outperforms conventional experience replay strategies such as vanilla experience replay and prioritized experience replay in multiple MuJoCo tasks from the OpenAI Gym suite.
  Conclusions: Our findings show that decoupling experience replay for Actor and Critic networks can enhance training dynamics and final policy quality. DPER offers a generalizable mechanism that enhances performance for a wide class of actor-critic off-policy reinforcement learning algorithms.

</details>


### [101] [Robustness Test for AI Forecasting of Hurricane Florence Using FourCastNetv2 and Random Perturbations of the Initial Condition](https://arxiv.org/abs/2512.05323)
*Adam Lizerbram,Shane Stevenson,Iman Khadir,Matthew Tu,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 研究FCNv2模型在初始条件加入噪声下的鲁棒性，发现其能保持风暴轨迹但低估强度，且对随机输入也能生成平滑输出。


<details>
  <summary>Details</summary>
Motivation: 评估AI天气模型在输入噪声和不确定性下的输出可靠性，尤其针对飓风等极端天气事件。

Method: 对ERA5数据集中的飓风Florence初始条件注入不同水平高斯噪声，并测试完全随机初始条件下的模型响应。

Result: 低至中等噪声下模型保持风暴特征；高噪声下轨迹仍保留但位置精度下降；模型始终低估风暴强度和持续性；随机输入后迅速生成平滑预测。

Conclusion: FCNv2具有较强鲁棒性，但存在系统性低估强度问题，该方法可推广至其他AI天气模型。

Abstract: Understanding the robustness of a weather forecasting model with respect to input noise or different uncertainties is important in assessing its output reliability, particularly for extreme weather events like hurricanes. In this paper, we test sensitivity and robustness of an artificial intelligence (AI) weather forecasting model: NVIDIAs FourCastNetv2 (FCNv2). We conduct two experiments designed to assess model output under different levels of injected noise in the models initial condition. First, we perturb the initial condition of Hurricane Florence from the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset (September 13-16, 2018) with varying amounts of Gaussian noise and examine the impact on predicted trajectories and forecasted storm intensity. Second, we start FCNv2 with fully random initial conditions and observe how the model responds to nonsensical inputs. Our results indicate that FCNv2 accurately preserves hurricane features under low to moderate noise injection. Even under high levels of noise, the model maintains the general storm trajectory and structure, although positional accuracy begins to degrade. FCNv2 consistently underestimates storm intensity and persistence across all levels of injected noise. With full random initial conditions, the model generates smooth and cohesive forecasts after a few timesteps, implying the models tendency towards stable, smoothed outputs. Our approach is simple and portable to other data-driven AI weather forecasting models.

</details>


### [102] [Non-Convex Federated Optimization under Cost-Aware Client Selection](https://arxiv.org/abs/2512.05327)
*Xiaowen Jiang,Anton Rodomanov,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出一种新的联邦优化模型，量化通信与本地计算成本，并基于SAGA改进的RG-SAGA梯度估计器，实现了非凸优化下最优的通信与本地复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有联邦优化算法的客户端选择策略在通信成本上差异大，但评估指标未区分这些差异，导致公平比较困难。

Method: 构建新联邦优化模型，引入RG-SAGA梯度估计器，结合SAGA方差缩减与Recursive-Gradient技术，提升估计精度。

Result: 所提算法在非凸优化中达到当前最优的通信与本地计算复杂度，且能利用函数相似性降低方差。

Conclusion: 该模型与算法为联邦优化提供了更精确的评估框架，并推动了高效梯度估计器的设计。

Abstract: Different federated optimization algorithms typically employ distinct client-selection strategies: some methods communicate only with a randomly sampled subset of clients at each round, while others need to periodically communicate with all clients or use a hybrid scheme that combines both strategies. However, existing metrics for comparing optimization methods typically do not distinguish between these strategies, which often incur different communication costs in practice. To address this disparity, we introduce a simple and natural model of federated optimization that quantifies communication and local computation complexities. This new model allows for several commonly used client-selection strategies and explicitly associates each with a distinct cost. Within this setting, we propose a new algorithm that achieves the best-known communication and local complexities among existing federated optimization methods for non-convex optimization. This algorithm is based on the inexact composite gradient method with a carefully constructed gradient estimator and a special procedure for solving the auxiliary subproblem at each iteration. The gradient estimator is based on SAGA, a popular variance-reduced gradient estimator. We first derive a new variance bound for it, showing that SAGA can exploit functional similarity. We then introduce the Recursive-Gradient technique as a general way to potentially improve the error bound of a given conditionally unbiased gradient estimator, including both SAGA and SVRG. By applying this technique to SAGA, we obtain a new estimator, RG-SAGA, which has an improved error bound compared to the original one.

</details>


### [103] [PathFinder: MCTS and LLM Feedback-based Path Selection for Multi-Hop Question Answering](https://arxiv.org/abs/2512.05336)
*Durga Prasad Maram,Kalpa Gunaratna,Vijay Srinivasan,Haris Jeelani,Srinivas Chappidi*

Main category: cs.LG

TL;DR: PATHFINDER使用蒙特卡洛树搜索和过滤机制提升多跳问答性能，减少大模型幻觉和错误推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于训练的多跳问答方法受大语言模型幻觉和错误推理路径影响，性能受限。

Method: 采用蒙特卡洛树搜索生成训练路径，通过子答案召回率和LLM作为裁判过滤错误长路径，并重写失败的子查询。

Result: PATHFINDER在多个公开基准数据集上显著提升了多跳问答性能。

Conclusion: 通过优化训练数据质量与推理路径，PATHFINDER有效缓解了大模型在多跳推理中的幻觉问题。

Abstract: Multi-hop question answering is a challenging task in which language models must reason over multiple steps to reach the correct answer. With the help of Large Language Models and their reasoning capabilities, existing systems are able to think and decompose an input question over multiple steps to analyze, retrieve, and reason. However, training-based approaches for this problem still suffer from LLM hallucinations and incorrect reasoning paths that hinder performance. Hence, we propose PATHFINDER, an approach that: (i) uses Monte Carlo Tree Search to generate training path traces, (ii) improves training data quality by filtering erroneous and lengthy traces using sub-answer recall and LLM-as-a-judge verification, and (iii) reformulates sub-queries to handle failed retrieval cases. By following these steps, we demonstrate that PATHFINDER improves the performance of multi-hop QA over public benchmark datasets.

</details>


### [104] [Interaction Tensor Shap](https://arxiv.org/abs/2512.05338)
*Hiroki Hasegawa,Yukihiko Okada*

Main category: cs.LG

TL;DR: 提出IT SHAP方法，将高阶Shapley交互表示为张量网络收缩，实现多项式时间计算，解决高维模型交互分析的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有Shapley值方法无法高效计算高阶特征交互，STII计算复杂度指数级增长，而MST仅限一阶效应，缺乏同时满足公理精确性和计算可扩展性的框架。

Method: 将STII重构为价值张量与权重张量的张量网络收缩，采用张量列车（TT）结构对权重张量进行多项式秩近似，实现并行多项式时间计算。

Result: IT SHAP将STII的指数复杂度Θ(4^n)降低至NC2并行时间，首次实现高阶交互的精确、高效、可扩展计算。

Conclusion: IT SHAP为高维黑箱模型提供统一、公理化、可扩展的交互解释框架，推动可解释AI在复杂模型中的应用。

Abstract: Machine learning models have grown increasingly deep and high dimensional, making it difficult to understand how individual and combined features influence their predictions. While Shapley value based methods provide principled feature attributions, existing formulations cannot tractably evaluate higher order interactions: the Shapley Taylor Interaction Index (STII) requires exponential scale enumeration of subsets, and current tensor based approaches such as the Marginal SHAP Tensor (MST) are restricted to first order effects. The central problem is that no existing framework simultaneously preserves the axiomatic exactness of STII and avoids the exponential computational blow up inherent to high order discrete derivatives. Here we show that high order Shapley interactions can be represented exactly as tensor network contractions, enabling polynomial time and polylog depth computation under Tensor Train (TT) structure. We introduce Interaction Tensor SHAP (IT SHAP), which reformulates STII as the contraction of a Value Tensor and a Weight Tensor, and assume a finite state TT representation of the Weight Tensor with polynomial TT ranks. Under TT structured model and distribution tensors, we show that IT SHAP reduces the exponential complex Theta(4^n) of STII to NC2 parallel time. These results demonstrate that IT SHAP provides a unified, axiomatic, and computationally tractable formulation of main effects and higher order interactions in high dimensional models. This framework establishes a foundation for scalable interaction aware explainable AI, with implications for large black box models whose combinatorial structure has previously rendered interaction analysis infeasible.

</details>


### [105] [Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models](https://arxiv.org/abs/2512.05339)
*Mahesh Kumar Nandwana,Youngwan Lim,Joseph Liu,Alex Yang,Varun Notibala,Nishchaie Khanna*

Main category: cs.LG

TL;DR: 提出Roblox Guard 1.0，一种基于Llama-3.1-8B-Instruct的指令微调模型，通过输入输出联合审查提升LLM安全性，并发布新评估基准RobloxGuard-Eval。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在后训练阶段对齐安全性仍不足，易生成有害输出，需更强大的输入输出双重防护机制。

Method: 基于Llama-3.1-8B-Instruct进行指令微调，融合合成与开源安全数据集，引入思维链（CoT）和输入逆向技术增强上下文理解，构建多LLM协同的审查流水线。

Result: 模型在未见过的安全分类和跨领域安全基准上表现优异，显著提升泛化能力。

Conclusion: Roblox Guard 1.0为LLM安全提供了高效、可扩展的解决方案，配套的评估基准推动了安全机制的系统化评测。

Abstract: Large Language Models (LLMs) are typically aligned for safety during the post-training phase; however, they may still generate inappropriate outputs that could potentially pose risks to users. This challenge underscores the need for robust safeguards that operate across both model inputs and outputs. In this work, we introduce Roblox Guard 1.0, a state-of-the-art instruction fine-tuned LLM designed to enhance the safety of LLM systems through comprehensive input-output moderation, using a pipeline of LLMs to enhance moderation capability. Built on the Llama-3.1-8B-Instruct backbone, our model is instruction fine-tuned to generalize across previously unseen safety taxonomies and demonstrates strong performance on out-of-domain safety benchmarks. The instruction fine-tuning process uses a mix of synthetic and open-source safety datasets, augmented with chain-of-thought (CoT) rationales and input inversion to enhance contextual understanding and decision making. To support systematic evaluation, we also release RobloxGuard-Eval, a new benchmark featuring an extensible safety taxonomy to assess the effectiveness of LLM guardrails and moderation frameworks.

</details>


### [106] [When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation](https://arxiv.org/abs/2512.05341)
*Yiwen Liang,Qiufeng Li,Shikai Wang,Weidong Cao*

Main category: cs.LG

TL;DR: 提出一种面向硬件代码生成的LLM遗忘框架，在不损害生成能力的前提下有效去除有害知识。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在硬件代码生成中存在记忆专有IP、污染基准和不安全编码模式的风险，亟需可靠的知识遗忘机制。

Method: 结合语法保留遗忘策略与细粒度floor感知选择性损失，实现高效精准的知识遗忘。

Result: 支持3倍更大的遗忘集，单轮训练即可完成，同时保持RTL代码的语法正确性与功能完整性。

Conclusion: 该框架为可靠的大语言模型辅助硬件设计开辟了新途径。

Abstract: Large Language Models (LLMs) have shown strong potential in accelerating digital hardware design through automated code generation. Yet, ensuring their reliability remains a critical challenge, as existing LLMs trained on massive heterogeneous datasets often exhibit problematic memorization of proprietary intellectual property (IP), contaminated benchmarks, and unsafe coding patterns. To mitigate these risks, we propose a novel unlearning framework tailored for LLM-based hardware code generation. Our method combines (i) a syntax-preserving unlearning strategy that safeguards the structural integrity of hardware code during forgetting, and (ii) a fine-grained floor-aware selective loss that enables precise and efficient removal of problematic knowledge. This integration achieves effective unlearning without degrading LLM code generation capabilities. Extensive experiments show that our framework supports forget sets up to 3x larger, typically requiring only a single training epoch, while preserving both syntactic correctness and functional integrity of register-transfer level (RTL) codes. Our work paves an avenue towards reliable LLM-assisted hardware design.

</details>


### [107] [Enhancing Dimensionality Prediction in Hybrid Metal Halides via Feature Engineering and Class-Imbalance Mitigation](https://arxiv.org/abs/2512.05367)
*Mariia Karabin,Isaac Armstrong,Leo Beck,Paulina Apanel,Markus Eisenbach,David B. Mitzi,Hanna Terletska,Hendrik Heinz*

Main category: cs.LG

TL;DR: 使用化学信息特征工程和类不平衡处理技术，构建机器学习框架以预测杂化金属卤化物的结构维度，通过SMOTE扩增数据并结合多阶段模型提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 杂化金属卤化物的结构维度预测面临类不平衡问题，传统方法对低频维度（如0D、1D）预测效果差，亟需更稳健的机器学习方法。

Method: 采用化学信息特征工程，结合SMOTE过采样、特征选择、模型堆叠与性能优化，构建多阶段预测框架。

Result: 显著提升低频维度类的F1分数，实现所有维度的稳健交叉验证性能。

Conclusion: 该框架有效解决类不平衡问题，为杂化金属卤化物维度预测提供了高精度、可推广的机器学习解决方案。

Abstract: We present a machine learning framework for predicting the structural dimensionality of hybrid metal halides (HMHs), including organic-inorganic perovskites, using a combination of chemically-informed feature engineering and advanced class-imbalance handling techniques. The dataset, consisting of 494 HMH structures, is highly imbalanced across dimensionality classes (0D, 1D, 2D, 3D), posing significant challenges to predictive modeling. This dataset was later augmented to 1336 via the Synthetic Minority Oversampling Technique (SMOTE) to mitigate the effects of the class imbalance. We developed interaction-based descriptors and integrated them into a multi-stage workflow that combines feature selection, model stacking, and performance optimization to improve dimensionality prediction accuracy. Our approach significantly improves F1-scores for underrepresented classes, achieving robust cross-validation performance across all dimensionalities.

</details>


### [108] [Text Rationalization for Robust Causal Effect Estimation](https://arxiv.org/abs/2512.05373)
*Lijinghua Zhang,Hengrui Cai*

Main category: cs.LG

TL;DR: CATR通过选择性保留文本中与混杂因素相关的稀疏词元，缓解高维文本导致的正性假设 violation，提升因果效应估计的准确性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 高维文本特征导致冗余和虚假信息，引发正性假设 violations、倾向得分极端化和估计方差增大，现有方法难以有效处理。

Method: 提出Confounding-Aware Token Rationalization (CATR)，基于残差独立性诊断筛选保留对无混杂性充分的稀疏词元，剔除无关文本。

Result: 在合成数据和MIMIC-III真实数据上，CATR相比基线方法产生更准确、稳定且可解释的因果效应估计。

Conclusion: CATR通过词元层面的混杂感知稀疏化，有效解决文本因果推断中的正性假设问题，提升因果估计性能。

Abstract: Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.

</details>


### [109] [China Regional 3km Downscaling Based on Residual Corrective Diffusion Model](https://arxiv.org/abs/2512.05377)
*Honglu Sun,Hao Jing,Zhixiang Dai,Sa Xiao,Wei Xue,Jian Sun,Qifeng Lu*

Main category: cs.LG

TL;DR: 使用改进的CorrDiff扩散模型对全球模型输出进行统计降尺度，在中国区域实现3km高分辨率预报，性能优于传统区域模型。


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报难以高效生成高分辨率结果，统计降尺度方法特别是深度学习模型（如扩散模型）为解决此问题提供了新途径。

Method: 基于CorrDiff扩散框架，扩展至20倍更大区域并引入六层高空变量，新增全局残差连接，对CMA-GFS和SFF的25km输出进行降尺度，以CMA-MESO为基准。

Result: 降尺度结果在MAE指标上优于CMA-MESO，且能生成更真实的雷达复合反射率细节，优于确定性回归模型。

Conclusion: 改进的CorrDiff模型在大范围、多变量统计降尺度任务中表现优越，具备生成高分辨率细致结构的能力，具有实际业务应用潜力。

Abstract: A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep learning has emerged as a powerful tool for this task, giving rise to various high-performance super-resolution models, which can be directly applied for downscaling, such as diffusion models and Generative Adversarial Networks. This work relies on a diffusion-based downscaling framework named CorrDiff. In contrast to the original work of CorrDiff, the region considered in this work is nearly 20 times larger, and we not only consider surface variables as in the original work, but also encounter high-level variables (six pressure levels) as target downscaling variables. In addition, a global residual connection is added to improve accuracy. In order to generate the 3km forecasts for the China region, we apply our trained models to the 25km global grid forecasts of CMA-GFS, an operational global model of the China Meteorological Administration (CMA), and SFF, a data-driven deep learning-based weather model developed from Spherical Fourier Neural Operators (SFNO). CMA-MESO, a high-resolution regional model, is chosen as the baseline model. The experimental results demonstrate that the forecasts downscaled by our method generally outperform the direct forecasts of CMA-MESO in terms of MAE for the target variables. Our forecasts of radar composite reflectivity show that CorrDiff, as a generative model, can generate fine-scale details that lead to more realistic predictions compared to the corresponding deterministic regression models.

</details>


### [110] [Generalization Beyond Benchmarks: Evaluating Learnable Protein-Ligand Scoring Functions on Unseen Targets](https://arxiv.org/abs/2512.05386)
*Jakub Kopko,David Graber,Saltuk Mustafa Eyrilmez,Stanislav Mazurenko,David Bednar,Jiri Sedlar,Josef Sivic*

Main category: cs.LG

TL;DR: 现有蛋白-配体打分函数在新靶点上泛化能力差，需更严谨的评估方法；自监督预训练和少量测试数据微调有望提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前打分函数在标准基准上表现良好，但难以泛化到仅有少量已知结构和亲和力数据的新靶点，真实应用场景面临重大挑战。

Method: 在模拟新靶点（少量数据）的数据划分下评估前沿打分函数的泛化能力，并检验自监督预训练和简单微调方法的效果。

Result: 标准基准无法反映真实泛化难度；自监督预训练初步显示提升潜力，利用少量测试数据的简单方法可有效改善性能。

Conclusion: 需建立更真实的评估协议，未来打分函数设计应注重泛化能力，结合预训练与小样本适应策略。

Abstract: As machine learning becomes increasingly central to molecular design, it is vital to ensure the reliability of learnable protein-ligand scoring functions on novel protein targets. While many scoring functions perform well on standard benchmarks, their ability to generalize beyond training data remains a significant challenge. In this work, we evaluate the generalization capability of state-of-the-art scoring functions on dataset splits that simulate evaluation on targets with a limited number of known structures and experimental affinity measurements. Our analysis reveals that the commonly used benchmarks do not reflect the true challenge of generalizing to novel targets. We also investigate whether large-scale self-supervised pretraining can bridge this generalization gap and we provide preliminary evidence of its potential. Furthermore, we probe the efficacy of simple methods that leverage limited test-target data to improve scoring function performance. Our findings underscore the need for more rigorous evaluation protocols and offer practical guidance for designing scoring functions with predictive power extending to novel protein targets.

</details>


### [111] [Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction](https://arxiv.org/abs/2512.05402)
*Sithumi Wickramasinghe,Bikramjit Das,Dorien Herremans*

Main category: cs.LG

TL;DR: 提出MineROI-Net模型，基于Transformer预测比特币矿机采购的ROI，准确率达83.7%，显著降低投资风险。


<details>
  <summary>Details</summary>
Motivation: 比特币挖矿硬件采购缺乏科学决策框架，市场波动大、技术迭代快，现有方法无法有效预测投资回报。

Method: 将硬件采购决策建模为时间序列分类任务，提出MineROI-Net，一种基于Transformer的多尺度时序模型，预测一年内ROI类别（盈利/边缘/亏损）。

Result: 在2015-2024年20款ASIC矿机数据上，MineROI-Net达到83.7%准确率和83.1%宏F1分数，盈利与亏损预测精度分别达98.5%和93.6%。

Conclusion: MineROI-Net为比特币矿机采购提供了首个数据驱动的决策工具，有效避免错误分类，显著降低资本密集型挖矿的财务风险。

Abstract: Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net.

</details>


### [112] [RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design](https://arxiv.org/abs/2512.05403)
*Gyusam Chang,Jeongyoon Yoon,Shin han yi,JaeHyeok Lee,Sujin Jang,Sangpil Kim*

Main category: cs.LG

TL;DR: RevoNAD通过反思式进化框架结合LLM与反馈驱动搜索，实现高效可靠的神经架构设计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的架构生成方法因离散非可微设计循环导致反馈难以优化，易陷入冗余或不可行设计。

Method: 提出RevoNAD，包含多轮多专家共识、自适应反思探索和帕累托引导进化选择三部分，融合LLM推理与多目标反馈优化。

Result: 在CIFAR10、CIFAR100、ImageNet16-120、COCO-5K和Cityscapes上达到SOTA性能，验证了可靠性与可部署性。

Conclusion: RevoNAD有效解决了LLM架构生成中的反馈断裂问题，实现了准确率、效率与多样性的协同优化。

Abstract: Recent progress in leveraging large language models (LLMs) has enabled Neural Architecture Design (NAD) systems to generate new architecture not limited from manually predefined search space. Nevertheless, LLM-driven generation remains challenging: the token-level design loop is discrete and non-differentiable, preventing feedback from smoothly guiding architectural improvement. These methods, in turn, commonly suffer from mode collapse into redundant structures or drift toward infeasible designs when constructive reasoning is not well grounded. We introduce RevoNAD, a reflective evolutionary orchestrator that effectively bridges LLM-based reasoning with feedback-aligned architectural search. First, RevoNAD presents a Multi-round Multi-expert Consensus to transfer isolated design rules into meaningful architectural clues. Then, Adaptive Reflective Exploration adjusts the degree of exploration leveraging reward variance; it explores when feedback is uncertain and refines when stability is reached. Finally, Pareto-guided Evolutionary Selection effectively promotes architectures that jointly optimize accuracy, efficiency, latency, confidence, and structural diversity. Across CIFAR10, CIFAR100, ImageNet16-120, COCO-5K, and Cityscape, RevoNAD achieves state-of-the-art performance. Ablation and transfer studies further validate the effectiveness of RevoNAD in allowing practically reliable, and deployable neural architecture design.

</details>


### [113] [Sepsis Prediction Using Graph Convolutional Networks over Patient-Feature-Value Triplets](https://arxiv.org/abs/2512.05416)
*Bozhi Dan,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi*

Main category: cs.LG

TL;DR: Triplet-GCN通过将EHR数据建模为患者-特征-值三元组并构建二部图，显著提升了脓毒症早期预警的性能。


<details>
  <summary>Details</summary>
Motivation: 脓毒症在重症监护中死亡率高，但EHR数据的复杂性、稀疏性和异质性阻碍了其及时检测。

Method: 提出Triplet-GCN模型，使用图卷积网络（GCN）处理患者-特征-值三元组构建的二部图，结合轻量MLP，并采用类型特定预处理方法保留测量值信息。

Result: 在648例中国多中心回顾性队列中，Triplet-GCN优于KNN、SVM、XGBoost、Random Forest等基线模型，在判别力和平衡误差指标上表现更优。

Conclusion: 将EHR编码为三元组并通过患者-特征图传播信息，能生成更有效的患者表征，为可部署的脓毒症风险分层提供简洁端到端方案。

Abstract: In the intensive care setting, sepsis continues to be a major contributor to patient illness and death; however, its timely detection is hindered by the complex, sparse, and heterogeneous nature of electronic health record (EHR) data. We propose Triplet-GCN, a single-branch graph convolutional model that represents each encounter as patient--feature--value triplets, constructs a bipartite EHR graph, and learns patient embeddings via a Graph Convolutional Network (GCN) followed by a lightweight multilayer perceptron (MLP). The pipeline applies type-specific preprocessing -- median imputation and standardization for numeric variables, effect coding for binary features, and mode imputation with low-dimensional embeddings for rare categorical attributes -- and initializes patient nodes with summary statistics, while retaining measurement values on edges to preserve "who measured what and by how much". In a retrospective, multi-center Chinese cohort (N = 648; 70/30 train--test split) drawn from three tertiary hospitals, Triplet-GCN consistently outperforms strong tabular baselines (KNN, SVM, XGBoost, Random Forest) across discrimination and balanced error metrics, yielding a more favorable sensitivity--specificity trade-off and improved overall utility for early warning. These findings indicate that encoding EHR as triplets and propagating information over a patient--feature graph produce more informative patient representations than feature-independent models, offering a simple, end-to-end blueprint for deployable sepsis risk stratification.

</details>


### [114] [TS-HINT: Enhancing Semiconductor Time Series Regression Using Attention Hints From Large Language Model Reasoning](https://arxiv.org/abs/2512.05419)
*Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu*

Main category: cs.LG

TL;DR: 提出TS-Hint框架，利用时序基础模型与思维链推理，在少量数据下有效预测半导体抛光过程的材料去除率


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法依赖静态特征提取，丢失时序动态信息且依赖大量训练数据

Method: 提出TS-Hint，一种融合思维链推理的时序基础模型，利用注意力机制和显著性数据提供训练提示

Result: 在少量数据场景下通过少样本学习有效建模多元时序特征，优于传统方法

Conclusion: TS-Hint能直接从时序数据中学习，显著提升数据效率与建模精度，适用于数据稀缺的半导体制造场景

Abstract: Existing data-driven methods rely on the extraction of static features from time series to approximate the material removal rate (MRR) of semiconductor manufacturing processes such as chemical mechanical polishing (CMP). However, this leads to a loss of temporal dynamics. Moreover, these methods require a large amount of data for effective training. In this paper, we propose TS-Hint, a Time Series Foundation Model (TSFM) framework, integrated with chain-of-thought reasoning which provides attention hints during training based on attention mechanism data and saliency data. Experimental results demonstrate the effectiveness of our model in limited data settings via few-shot learning and can learn directly from multivariate time series features.

</details>


### [115] [IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?](https://arxiv.org/abs/2512.05442)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: 提出IdealTSF框架，利用非理想负样本提升时间序列预测性能，适用于噪声数据场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽视缺失值和异常值等负样本的潜力，本研究旨在利用这些非理想样本增强预测能力。

Method: IdealTSF包含预训练、训练和优化三阶段：先从负样本中提取知识，再将序列转化为理想正样本，并引入对抗扰动的负优化机制。

Result: 实验表明，负样本能显著提升基础注意力架构的预测性能，尤其在噪声或低质量数据中表现优异。

Conclusion: 非理想负样本具有重要价值，IdealTSF为低质量时间序列预测提供了新范式。

Abstract: Deep learning has shown strong performance in time series forecasting tasks. However, issues such as missing values and anomalies in sequential data hinder its further development in prediction tasks. Previous research has primarily focused on extracting feature information from sequence data or addressing these suboptimal data as positive samples for knowledge transfer. A more effective approach would be to leverage these non-ideal negative samples to enhance event prediction. In response, this study highlights the advantages of non-ideal negative samples and proposes the IdealTSF framework, which integrates both ideal positive and negative samples for time series forecasting. IdealTSF consists of three progressive steps: pretraining, training, and optimization. It first pretrains the model by extracting knowledge from negative sample data, then transforms the sequence data into ideal positive samples during training. Additionally, a negative optimization mechanism with adversarial disturbances is applied. Extensive experiments demonstrate that negative sample data unlocks significant potential within the basic attention architecture for time series forecasting. Therefore, IdealTSF is particularly well-suited for applications with noisy samples or low-quality data.

</details>


### [116] [How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data](https://arxiv.org/abs/2512.05469)
*Zubair Ahmed Mohammad*

Main category: cs.LG

TL;DR: 研究发现集成模型在保持低泛化差距的同时提升准确率，尤其在非线性数据上效果显著，但在噪声或不平衡数据中需正则化。


<details>
  <summary>Details</summary>
Motivation: 尽管集成模型通常更准确，但其如何平衡准确率与过拟合尚不清晰，本研究旨在揭示其在不同数据特征下的泛化行为。

Method: 使用重复分层交叉验证和统计显著性检验，对比线性模型、单决策树和九种集成方法在四个表格分类任务上的表现，并计算数据复杂性指标。

Result: 在近线性干净数据中，线性模型已表现良好；在非线性数据中，树集成提升准确率5-7%，泛化差距低于3%；在噪声或不平衡数据中，集成需正则化才能避免过拟合。

Conclusion: 集成模型在非线性结构数据中能有效控制方差、提升准确率且保持低过拟合，数据复杂性指标可指导实际场景中的模型选择。

Abstract: Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.

</details>


### [117] [PERM EQ x GRAPH EQ: Equivariant Neural Networks for Quantum Molecular Learning](https://arxiv.org/abs/2512.05475)
*Saumya Biswas,Jiten Oswal*

Main category: cs.LG

TL;DR: 研究几何量子机器学习模型在LiH和NH3分子数据集上的性能，发现图嵌入和置换对称性提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索不同对称性约束的量子机器学习模型在分子几何结构中的表现，以确定最优模型选择标准。

Method: 比较无对称性、旋转/置换对称性及图嵌入置换对称性的量子模型，并以经典等变模型为基线。

Result: 图嵌入显著提升可训练性，置换对称嵌入模型在几何学习中泛化能力最强。

Conclusion: 分子几何结构决定模型选择，置换对称性结合图嵌入是量子机器学习的最佳路径。

Abstract: In hierarchal order of molecular geometry, we compare the performances of Geometric Quantum Machine Learning models. Two molecular datasets are considered: the simplistic linear shaped LiH-molecule and the trigonal pyramidal molecule NH3. Both accuracy and generalizability metrics are considered. A classical equivariant model is used as a baseline for the performance comparison. The comparative performance of Quantum Machine Learning models with no symmetry equivariance, rotational and permutational equivariance, and graph embedded permutational equivariance is investigated. The performance differentials and the molecular geometry in question reveals the criteria for choice of models for generalizability. Graph embedding of features is shown to be an effective pathway to greater trainability for geometric datasets. Permutational symmetric embedding is found to be the most generalizable quantum Machine Learning model for geometric learning.

</details>


### [118] [Turbulence Regression](https://arxiv.org/abs/2512.05483)
*Yingang Fan,Binjie Ding,Baiyi Chen*

Main category: cs.LG

TL;DR: 本文提出一种基于NeuTucker分解的离散化模型，用于从风廓线雷达数据中更准确地预测低空湍流状态。


<details>
  <summary>Details</summary>
Motivation: 传统方法在仅使用风廓线雷达数据时难以准确预测复杂的低空湍流状态，亟需更有效的建模方法。

Method: 采用离散化处理连续风场数据，并构建四维Tucker交互张量，基于Tucker神经网络捕捉三维风场中的潜在时空交互。

Result: 该离散化NeuTucker模型在真实数据缺失观测估计中，性能优于多种常规回归模型。

Conclusion: 离散化与四维Tucker张量建模有效提升了低空湍流预测的准确性，为风场数据建模提供了新思路。

Abstract: Air turbulence refers to the disordered and irregular motion state generated by drastic changes in velocity, pressure, or direction during airflow. Various complex factors lead to intricate low-altitude turbulence outcomes. Under current observational conditions, especially when using only wind profile radar data, traditional methods struggle to accurately predict turbulence states. Therefore, this paper introduces a NeuTucker decomposition model utilizing discretized data. Designed for continuous yet sparse three-dimensional wind field data, it constructs a low-rank Tucker decomposition model based on a Tucker neural network to capture the latent interactions within the three-dimensional wind field data. Therefore, two core ideas are proposed here: 1) Discretizing continuous input data to adapt to models like NeuTucF that require discrete data inputs. 2) Constructing a four-dimensional Tucker interaction tensor to represent all possible spatio-temporal interactions among different elevations and three-dimensional wind speeds. In estimating missing observations in real datasets, this discretized NeuTucF model demonstrates superior performance compared to various common regression models.

</details>


### [119] [GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop](https://arxiv.org/abs/2512.05502)
*Omid Bazgir,Vineeth Manthapuri,Ilia Rattsev,Mohammad Jafarnejad*

Main category: cs.LG

TL;DR: GRASP 是一个基于图推理的多智能体框架，通过自然语言将QSP模型转化为可执行代码，大幅提升建模效率与生物合理性。


<details>
  <summary>Details</summary>
Motivation: 传统QSP建模耗时长，限制专家效率，亟需自动化且保持生物严谨性的新方法。

Method: 采用图结构知识图谱编码QSP模型，结合两阶段工作流（理解与行动）和状态机控制，通过BFS参数对齐与自动诊断生成MATLAB/SimBiology代码。

Result: GRASP在生物合理性、数学正确性、结构保真度和代码质量上显著优于专家引导的CoT和ToT方法（9-10/10 vs 5-7/10），BFS对齐F1达0.95。

Conclusion: 图结构智能体工作流使非编程专家能用自然语言高效构建高保真QSP模型，兼顾易用性与科学严谨性。

Abstract: Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that encodes QSP models as typed biological knowledge graphs and compiles them to executable MATLAB/SimBiology code while preserving units, mass balance, and physiological constraints. A two-phase workflow -- \textsc{Understanding} (graph reconstruction of legacy code) and \textsc{Action} (constraint-checked, language-driven modification) -- is orchestrated by a state machine with iterative validation. GRASP performs breadth-first parameter-alignment around new entities to surface dependent quantities and propose biologically plausible defaults, and it runs automatic execution/diagnostics until convergence. In head-to-head evaluations using LLM-as-judge, GRASP outperforms SME-guided CoT and ToT baselines across biological plausibility, mathematical correctness, structural fidelity, and code quality (\(\approx\)9--10/10 vs.\ 5--7/10). BFS alignment achieves F1 = 0.95 for dependency discovery, units, and range. These results demonstrate that graph-structured, agentic workflows can make QSP model development both accessible and rigorous, enabling domain experts to specify mechanisms in natural language without sacrificing biomedical fidelity.

</details>


### [120] [Credal and Interval Deep Evidential Classifications](https://arxiv.org/abs/2512.05526)
*Michele Caprio,Shireen K. Manchingal,Fabio Cuzzolin*

Main category: cs.LG

TL;DR: 提出CDEC和IDEC两种新方法，通过认知集和区间证据分布量化分类任务中的不确定性，实现可靠预测与异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在不确定性量化上存在过拟合、无法区分认知与偶然不确定性等问题，影响决策可靠性。

Method: 利用认知集（CDEC）和区间证据分布（IDEC），结合证据理论损失函数，通过标准反向传播训练，支持在不确定性超限时拒绝分类。

Result: 在MNIST、CIFAR-10/100及OOD数据上表现优异，实现高精度预测、先进OOD检测和校准良好的预测区间，且CDEC仅需小集成即可稳定估计不确定性。

Conclusion: CDEC和IDEC显著改进了证据深度学习框架，在不确定性量化与模型可靠性方面达到新水平。

Abstract: Uncertainty Quantification (UQ) presents a pivotal challenge in the field of Artificial Intelligence (AI), profoundly impacting decision-making, risk assessment and model reliability. In this paper, we introduce Credal and Interval Deep Evidential Classifications (CDEC and IDEC, respectively) as novel approaches to address UQ in classification tasks. CDEC and IDEC leverage a credal set (closed and convex set of probabilities) and an interval of evidential predictive distributions, respectively, allowing us to avoid overfitting to the training data and to systematically assess both epistemic (reducible) and aleatoric (irreducible) uncertainties. When those surpass acceptable thresholds, CDEC and IDEC have the capability to abstain from classification and flag an excess of epistemic or aleatoric uncertainty, as relevant. Conversely, within acceptable uncertainty bounds, CDEC and IDEC provide a collection of labels with robust probabilistic guarantees. CDEC and IDEC are trained using standard backpropagation and a loss function that draws from the theory of evidence. They overcome the shortcomings of previous efforts, and extend the current evidential deep learning literature. Through extensive experiments on MNIST, CIFAR-10 and CIFAR-100, together with their natural OoD shifts (F-MNIST/K-MNIST, SVHN/Intel, TinyImageNet), we show that CDEC and IDEC achieve competitive predictive accuracy, state-of-the-art OoD detection under epistemic and total uncertainty, and tight, well-calibrated prediction regions that expand reliably under distribution shift. An ablation over ensemble size further demonstrates that CDEC attains stable uncertainty estimates with only a small ensemble.

</details>


### [121] [IDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection](https://arxiv.org/abs/2512.05531)
*Yang Xu,Yixiao Ma,Kaifeng Zhang,Zuliang Yang,Kai Ming Ting*

Main category: cs.LG

TL;DR: 提出一种新颖的增量分布核方法IDK-S，用于流式异常检测，在保持高精度的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 流式数据分布动态变化，现有方法难以兼顾检测精度与实时效率。

Method: 基于核均值嵌入框架，继承Isolation Distributional Kernel的优点，并引入轻量级增量更新机制，避免全模型重训。

Result: 在13个基准上实验表明，IDK-S比现有SOTA方法精度更高、速度快一个数量级。

Conclusion: IDK-S实现了精度与效率的协同优化，且在统计上等价于全重训模型。

Abstract: Anomaly detection on data streams presents significant challenges, requiring methods to maintain high detection accuracy among evolving distributions while ensuring real-time efficiency. Here we introduce $\mathcal{IDK}$-$\mathcal{S}$, a novel $\mathbf{I}$ncremental $\mathbf{D}$istributional $\mathbf{K}$ernel for $\mathbf{S}$treaming anomaly detection that effectively addresses these challenges by creating a new dynamic representation in the kernel mean embedding framework. The superiority of $\mathcal{IDK}$-$\mathcal{S}$ is attributed to two key innovations. First, it inherits the strengths of the Isolation Distributional Kernel, an offline detector that has demonstrated significant performance advantages over foundational methods like Isolation Forest and Local Outlier Factor due to the use of a data-dependent kernel. Second, it adopts a lightweight incremental update mechanism that significantly reduces computational overhead compared to the naive baseline strategy of performing a full model retraining. This is achieved without compromising detection accuracy, a claim supported by its statistical equivalence to the full retrained model. Our extensive experiments on thirteen benchmarks demonstrate that $\mathcal{IDK}$-$\mathcal{S}$ achieves superior detection accuracy while operating substantially faster, in many cases by an order of magnitude, than existing state-of-the-art methods.

</details>


### [122] [On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability](https://arxiv.org/abs/2512.05534)
*Yiming Tang,Harshvardhan Saini,Yizhen Liao,Dianbo Liu*

Main category: cs.LG

TL;DR: 本文首次为稀疏字典学习方法提供统一理论框架，解释其在神经网络可解释性中的作用，并验证观测现象。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性研究依赖经验成功的稀疏字典学习方法，但缺乏理论基础，尤其对非绑定权重方法无正式解释。

Method: 构建统一的优化理论框架，将稀疏自编码器、transcoders和crosscoders纳入同一模型，并分析其优化景观。

Result: 首次理论解释了特征吸收、死神经元和神经元重采样等经验现象，并通过控制实验验证。

Conclusion: 该框架为稀疏字典学习方法提供了坚实的理论基础，推动可解释性研究从经验走向理论。

Abstract: As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode many concepts in superposition. Various sparse dictionary learning (SDL) methods, including sparse autoencoders, transcoders, and crosscoders, address this by training auxiliary models with sparsity constraints to disentangle these superposed concepts into interpretable features. These methods have demonstrated remarkable empirical success but have limited theoretical understanding. Existing theoretical work is limited to sparse autoencoders with tied-weight constraints, leaving the broader family of SDL methods without formal grounding. In this work, we develop the first unified theoretical framework considering SDL as one unified optimization problem. We demonstrate how diverse methods instantiate the theoretical framwork and provide rigorous analysis on the optimization landscape. We provide the first theoretical explanations for some empirically observed phenomena, including feature absorption, dead neurons, and the neuron resampling technique. We further design controlled experiments to validate our theoretical results.

</details>


### [123] [SCoNE: Spherical Consistent Neighborhoods Ensemble for Effective and Efficient Multi-View Anomaly Detection](https://arxiv.org/abs/2512.05540)
*Yang Xu,Hang Zhang,Yixiao Ma,Ye Zhu,Kai Ming Ting*

Main category: cs.LG

TL;DR: 提出SCoNE方法，通过球面一致邻域直接建模多视图正常实例的邻域，无需学习，实现高效高精度异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视图异常检测中无法保证跨视图一致邻域的准确捕捉，且计算复杂度高（O(N²)），影响大样本适用性。

Method: SCoNE直接使用多视图实例表示一致邻域，引入数据依赖的邻域大小（稀疏区大、密集区小），避免中间表示与学习过程。

Result: SCoNE在检测精度上显著优于现有方法，时间复杂度降至O(N)，在大数据集上速度提升数个数量级。

Conclusion: SCoNE通过无学习的球面一致邻域建模，解决了准确性和效率的双重瓶颈，适合大规模多视图异常检测。

Abstract: The core problem in multi-view anomaly detection is to represent local neighborhoods of normal instances consistently across all views. Recent approaches consider a representation of local neighborhood in each view independently, and then capture the consistent neighbors across all views via a learning process. They suffer from two key issues. First, there is no guarantee that they can capture consistent neighbors well, especially when the same neighbors are in regions of varied densities in different views, resulting in inferior detection accuracy. Second, the learning process has a high computational cost of $\mathcal{O}(N^2)$, rendering them inapplicable for large datasets. To address these issues, we propose a novel method termed \textbf{S}pherical \textbf{C}onsistent \textbf{N}eighborhoods \textbf{E}nsemble (SCoNE). It has two unique features: (a) the consistent neighborhoods are represented with multi-view instances directly, requiring no intermediate representations as used in existing approaches; and (b) the neighborhoods have data-dependent properties, which lead to large neighborhoods in sparse regions and small neighborhoods in dense regions. The data-dependent properties enable local neighborhoods in different views to be represented well as consistent neighborhoods, without learning. This leads to $\mathcal{O}(N)$ time complexity. Empirical evaluations show that SCoNE has superior detection accuracy and runs orders-of-magnitude faster in large datasets than existing approaches.

</details>


### [124] [RoBoN: Routed Online Best-of-n for Test-Time Scaling with Multiple LLMs](https://arxiv.org/abs/2512.05542)
*Jonathan Geuter,Gregor Kornhardt*

Main category: cs.LG

TL;DR: RoBoN通过顺序路由多个LLM提升best-of-n性能，无需额外训练，显著提高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统best-of-n仅使用单模型生成，未能利用多模型间的互补优势。

Method: RoBoN基于奖励模型和响应一致性信号，顺序路由生成到不同模型，无需训练。

Result: 在多个推理基准上比单模型best-of-n和均匀多模型基线提升最高3.4%准确率。

Conclusion: 多模型多样性可在推理阶段有效利用，提供一种无需训练的测试时扩展方法。

Abstract: Best-of-$n$ is a widely used test-time scaling approach for LLM inference. Yet despite evidence that LLMs exhibit complementary strengths across tasks, traditionally best-of-$n$ relies on a single model to generate responses. We propose RoBoN (Routed Online Best-of-$n$), a sequential multi-LLM alternative to the prevailing single-model best-of-$n$. Given a suite of models $\{m_i\}_{i=1}^M$, RoBoN sequentially routes generations one-by-one across models, based on scores computed using a reward model and an agreement signal on the predicted responses. This online routing requires no additional training, keeps compute parity, and works with any plug-in reward model. Across reasoning benchmarks (MATH500, OlympiadBench, MinervaMath, GSM8K, MMLU), RoBoN consistently outperforms standard best-of-$n$ applied to each individual model for larger $n$, with gains of up to 3.4\% in absolute accuracy, and also improves over a uniform multi-model portfolio baseline. Our results indicate that diversity across models can be exploited at inference to improve best-of-$n$ performance over any constituent model alone, providing a simple, training-free path to test-time scaling with multiple LLMs.

</details>


### [125] [Improving Local Fidelity Through Sampling and Modeling Nonlinearity](https://arxiv.org/abs/2512.05556)
*Sanjeev Shrestha,Rahul Dubey,Hui Liu*

Main category: cs.LG

TL;DR: 提出一种基于MARS和N-ball采样的新方法，提升黑箱模型局部解释的保真度，显著降低误差37%


<details>
  <summary>Details</summary>
Motivation: LIME假设局部决策边界为线性，无法捕捉非线性关系，导致解释不准确

Method: 采用MARS建模非线性局部边界，结合N-ball采样直接从目标分布采样，替代LIME的重加权策略

Result: 在三个UCI数据集上实验显示，相比基线方法，平均RMSE降低37%，局部保真度显著提升

Conclusion: 所提方法有效提升了黑箱模型局部解释的准确性和可靠性，优于现有LIME方法

Abstract: With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.

</details>


### [126] [Wasserstein distance based semi-supervised manifold learning and application to GNSS multi-path detection](https://arxiv.org/abs/2512.05567)
*Antoine Blais,Nicolas Couëllan*

Main category: cs.LG

TL;DR: 提出基于最优传输的半监督方法，利用Wasserstein距离提升少量标注图像数据的分类精度，应用于GNSS多径干扰检测。


<details>
  <summary>Details</summary>
Motivation: 解决标注数据稀缺条件下深度网络的性能瓶颈，提升半监督学习在真实场景中的有效性。

Method: 采用基于Wasserstein距离的隐式图传递学习机制，结合深度卷积网络进行标签传播。

Result: 在不同信号条件下，优化超参数后，分类准确率显著优于全监督方法。

Conclusion: 该方法在标注数据有限时能有效提升模型性能，尤其适用于GNSS多径干扰检测等实际应用。

Abstract: The main objective of this study is to propose an optimal transport based semi-supervised approach to learn from scarce labelled image data using deep convolutional networks. The principle lies in implicit graph-based transductive semi-supervised learning where the similarity metric between image samples is the Wasserstein distance. This metric is used in the label propagation mechanism during learning. We apply and demonstrate the effectiveness of the method on a GNSS real life application. More specifically, we address the problem of multi-path interference detection. Experiments are conducted under various signal conditions. The results show that for specific choices of hyperparameters controlling the amount of semi-supervision and the level of sensitivity to the metric, the classification accuracy can be significantly improved over the fully supervised training method.

</details>


### [127] [Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning](https://arxiv.org/abs/2512.05591)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Tiehua Mei,Zijia Lin,Yuntao Li,Wenping Hu,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 提出熵率裁剪（ERC）机制，通过全局熵比约束稳定大语言模型强化学习训练，提升PPO-Clip性能。


<details>
  <summary>Details</summary>
Motivation: PPO-Clip虽能缓解策略偏移，但忽视动作分布的全局偏移，导致训练不稳定。

Method: 引入熵率（当前与上一策略熵之比）作为全局度量，设计双向熵率裁剪（ERC）机制，约束策略探索变化。

Result: ERC集成到DAPO和GPPO中，在多个基准上一致提升性能。

Conclusion: ERC有效缓解分布偏移，增强策略更新稳定性，弥补PPO-Clip对未采样动作概率变化的调控不足。

Abstract: Large language model post-training relies on reinforcement learning to improve model capability and alignment quality. However, the off-policy training paradigm introduces distribution shift, which often pushes the policy beyond the trust region, leading to training instabilities manifested as fluctuations in policy entropy and unstable gradients. Although PPO-Clip mitigates this issue through importance clipping, it still overlooks the global distributional shift of actions. To address these challenges, we propose using the entropy ratio between the current and previous policies as a new global metric that effectively quantifies the relative change in policy exploration throughout updates. Building on this metric, we introduce an \textbf{Entropy Ratio Clipping} (ERC) mechanism that imposes bidirectional constraints on the entropy ratio. This stabilizes policy updates at the global distribution level and compensates for the inability of PPO-clip to regulate probability shifts of un-sampled actions. We integrate ERC into both DAPO and GPPO reinforcement learning algorithms. Experiments across multiple benchmarks show that ERC consistently improves performance.

</details>


### [128] [Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales](https://arxiv.org/abs/2512.05620)
*Shikai Qiu,Zixi Chen,Hoang Phan,Qi Lei,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 通过超参数迁移缩放规则，证明Muon和Shampoo在大模型训练中比AdamW快1.3–1.4倍，但需正确缩放学习率与权重衰减。


<details>
  <summary>Details</summary>
Motivation: 现有预条件优化器在小规模实验中表现良好，但在大规模验证中结果不一致，亟需系统研究其可扩展性。

Method: 基于μP理论，系统分析学习率与权重衰减随模型宽度和深度的缩放规律，验证Shampoo、SOAP、Muon等优化器，并结合阻塞与谱归一化缓解有限宽度偏差。

Result: 采用正确缩放规则后，Muon和Shampoo在Llama模型（190M–1.4B）上分别实现1.4×和1.3×的训练加速，错误缩放则加速效果消失。

Conclusion: 在现实调参预算下，研究超参数迁移是可靠比较大规模优化器性能的关键。

Abstract: Several recently introduced deep learning optimizers utilizing matrix-level preconditioning have shown promising speedups relative to the current dominant optimizer AdamW, particularly in relatively small-scale experiments. However, efforts to validate and replicate their successes have reported mixed results. To better understand the effectiveness of these optimizers at scale, in this work we investigate how to scale preconditioned optimizers via hyperparameter transfer, building on prior works such as $μ$P. We study how the optimal learning rate and weight decay should scale with model width and depth for a wide range of optimizers, including Shampoo, SOAP, and Muon, accounting for the impact of commonly used techniques such as blocking and grafting. We find that scaling the learning rate according to $μ$P improves transfer, but can still suffer from significant finite-width deviations that cause drifting optimal learning rates, which we show can be mitigated by blocking and explicit spectral normalization. For compute-optimal scaling, we find scaling independent weight decay as $1/\mathrm{width}$ is nearly optimal across optimizers. Applying these scaling rules, we show Muon and Shampoo consistently achieve $1.4\times$ and $1.3\times$ speedup over AdamW for training Llama-architecture language models of sizes ranging from $190$M to $1.4$B, whereas the speedup vanishes rapidly with scale under incorrect scaling. Based on these results and further ablations, we argue that studying optimal hyperparameter transfer is essential for reliably comparing optimizers at scale given a realistic tuning budget.

</details>


### [129] [Bounded Graph Clustering with Graph Neural Networks](https://arxiv.org/abs/2512.05623)
*Kibidi Neocosmos,Diego Baptista,Nicole Ludwig*

Main category: cs.LG

TL;DR: 提出一种灵活的GNN框架，允许用户指定社区数量的范围或精确值，并在训练中强制约束以可靠地返回目标社区数。


<details>
  <summary>Details</summary>
Motivation: 传统GNN方法无法可靠地返回指定的社区数量，且多数方法需预先已知聚类数，而 exhaustive search 计算不可行。

Method: 引入一种可灵活控制社区数量的框架，支持用户指定范围或精确值，并在训练过程中施加约束。

Result: 该框架能可靠地返回用户指定的精确社区数，或在指定范围内自适应发现社区数量。

Conclusion: 该方法解决了GNN在社区检测中对聚类数控制不足的问题，提升了模型的实用性和灵活性。

Abstract: In community detection, many methods require the user to specify the number of clusters in advance since an exhaustive search over all possible values is computationally infeasible. While some classical algorithms can infer this number directly from the data, this is typically not the case for graph neural networks (GNNs): even when a desired number of clusters is specified, standard GNN-based methods often fail to return the exact number due to the way they are designed. In this work, we address this limitation by introducing a flexible and principled way to control the number of communities discovered by GNNs. Rather than assuming the true number of clusters is known, we propose a framework that allows the user to specify a plausible range and enforce these bounds during training. However, if the user wants an exact number of clusters, it may also be specified and reliably returned.

</details>


### [130] [Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability](https://arxiv.org/abs/2512.05638)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 本文提出模块化喷射（Modular Jets）方法，通过局部线性响应分析模型内部结构，区分观测上等价但结构不同的分解，超越传统损失评估的局限。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习仅通过预测风险评估模型，无法识别模型内部结构的唯一性，存在多个不同分解产生相同输入输出映射的“幻影”问题。

Method: 引入模块化喷射，利用输入微扰下模块级表示的局部线性响应，构建经验喷射，并提出“幻影”与“可识别”区域的概念，结合算法MoJet进行估计与诊断。

Result: 在两模块线性回归中证明了喷射可识别定理，表明在适当条件下模块分解可唯一确定，而仅靠风险评估存在大量幻影分解。

Conclusion: 模块化喷射提供了一种超越预测性能、识别模型内部结构的新范式，有助于理解模型的可解释性与结构唯一性。

Abstract: Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.

</details>


### [131] [Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs](https://arxiv.org/abs/2512.05648)
*Igor Shilov,Alex Cloud,Aryo Pradipta Gema,Jacob Goldman-Wetzler,Nina Panickssery,Henry Sleight,Erik Jones,Cem Anil*

Main category: cs.LG

TL;DR: SGTM是一种改进的梯度路由方法，能在标签噪声下更鲁棒地删除模型中的有害知识，相比数据过滤和传统梯度路由表现更优。


<details>
  <summary>Details</summary>
Motivation: 数据过滤在预训练阶段用于缓解大语言模型的双重用途风险，但标签成本高且易受噪声影响，导致误标数据可能引发危险能力。

Method: 提出Selective Gradient Masking (SGTM)，通过零掩码特定梯度，使目标领域样本仅更新专用参数，实现知识的精准删除。

Result: 在删除语言知识和生物学知识的实验中，SGTM在标签噪声下实现更优的保留/遗忘权衡，且对对抗微调具有强鲁棒性，需7倍微调步数才能恢复性能。

Conclusion: SGTM是一种有前景的预训练期安全增强方法，尤其适用于标签噪声不可避免的场景。

Abstract: Large Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) -- a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM's effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.

</details>


### [132] [Feasibility of AI-Assisted Programming for End-User Development](https://arxiv.org/abs/2512.05666)
*Irene Weber*

Main category: cs.LG

TL;DR: AI辅助端用户编程在非编程人员开发Web应用中表现出可行性，可能成为低代码/无代码平台的有力补充或替代。


<details>
  <summary>Details</summary>
Motivation: 传统低代码/无代码平台受限于可视化编程，而生成式AI允许通过自然语言直接构建应用，有望提升灵活性、效率与通用性。

Method: 通过案例研究，让非程序员用户与AI助手交互开发基础Web应用，观察其完成情况与反馈。

Result: 多数参与者在合理时间内成功完成任务，并支持AI辅助编程作为可行的端用户开发方式。

Conclusion: AI辅助端用户编程具有前景，值得在实践、研究与教学中进一步探索和推广。

Abstract: End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and "copilots", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.

</details>


### [133] [Meta-Learning Multi-armed Bandits for Beam Tracking in 5G and 6G Networks](https://arxiv.org/abs/2512.05680)
*Alexander Mattick,George Yammine,Georgios Kontes,Setareh Maghsudi,Christopher Mutschler*

Main category: cs.LG

TL;DR: 将波束选择问题建模为POMDP，通过在线搜索动态定位最优波束，显著超越传统监督学习方法


<details>
  <summary>Details</summary>
Motivation: 传统基于码本的模拟波束赋形在用户移动、反射和遮挡下难以高效选择最优波束，监督学习方法无法应对新环境和未知轨迹

Method: 将波束选择建模为部分可观测马尔可夫决策过程（POMDP），以码本为环境，基于信念状态和历史探测波束进行在线搜索

Result: 方法能适应新轨迹与环境变化，性能比现有方法高出数个数量级

Conclusion: POMDP框架优于传统监督学习，为5G/6G动态波束管理提供了更鲁棒且高效的解决方案

Abstract: Beamforming-capable antenna arrays with many elements enable higher data rates in next generation 5G and 6G networks. In current practice, analog beamforming uses a codebook of pre-configured beams with each of them radiating towards a specific direction, and a beam management function continuously selects \textit{optimal} beams for moving user equipments (UEs). However, large codebooks and effects caused by reflections or blockages of beams make an optimal beam selection challenging. In contrast to previous work and standardization efforts that opt for supervised learning to train classifiers to predict the next best beam based on previously selected beams we formulate the problem as a partially observable Markov decision process (POMDP) and model the environment as the codebook itself. At each time step, we select a candidate beam conditioned on the belief state of the unobservable optimal beam and previously probed beams. This frames the beam selection problem as an online search procedure that locates the moving optimal beam. In contrast to previous work, our method handles new or unforeseen trajectories and changes in the physical environment, and outperforms previous work by orders of magnitude.

</details>


### [134] [BERTO: an Adaptive BERT-based Network Time Series Predictor with Operator Preferences in Natural Language](https://arxiv.org/abs/2512.05721)
*Nitin Priyadarshini Shankar,Vaibhav Singh,Sheetal Kalyani,Christian Maciocco*

Main category: cs.LG

TL;DR: BERTO是一个基于BERT的框架，用于蜂窝网络中的交通预测与能耗优化，通过自然语言提示平衡节能与性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以在节能与服务质量之间灵活权衡，缺乏直观的调控方式。

Method: 采用BERT架构，结合平衡损失函数和基于提示的定制方法，通过自然语言指令控制预测偏差。

Result: 在真实数据集上，BERTO将MSE降低4.13%，支持1.4 kW功率调节范围和9倍服务质量变化。

Conclusion: BERTO为智能RAN部署提供了高效、可解释且灵活的能耗优化解决方案。

Abstract: We introduce BERTO, a BERT-based framework for traffic prediction and energy optimization in cellular networks. Built on transformer architectures, BERTO delivers high prediction accuracy, while its Balancing Loss Function and prompt-based customization allow operators to adjust the trade-off between power savings and performance. Natural language prompts guide the model to manage underprediction and overprediction in accordance with the operator's intent. Experiments on real-world datasets show that BERTO improves upon existing models with a $4.13$\% reduction in MSE while introducing the feature of balancing competing objectives of power saving and performance through simple natural language inputs, operating over a flexible range of $1.4$ kW in power and up to $9\times$ variation in service quality, making it well suited for intelligent RAN deployments.

</details>


### [135] [Teaching Language Models Mechanistic Explainability Through Arrow-Pushing](https://arxiv.org/abs/2512.05722)
*Théo A. Neukomm,Zlatko Jončev,Philippe Schwaller*

Main category: cs.LG

TL;DR: 提出MechSMILES格式与语言模型，实现基于电子流动的化学反应机理预测，显著提升合成规划的化学合理性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有计算机辅助合成规划（CASP）系统缺乏对反应机理的物理基础支持，导致预测结果化学上不可靠。

Method: 设计MechSMILES文本编码格式，基于电子推动规则训练语言模型，在多个机理预测任务上进行训练与验证。

Result: 在 Elementary Step 预测中 top-3 准确率超 95%，在 mech-USPTO-31k 和 FlowER 数据集上机制检索准确率分别超 73% 和 93%。

Conclusion: 该框架为CASP提供了可解释、化学合理的机理验证工具，并支持原子映射与催化剂识别，具有架构无关的基准价值。

Abstract: Chemical reaction mechanisms provide crucial insight into synthesizability, yet current Computer-Assisted Synthesis Planning (CASP) systems lack mechanistic grounding. We introduce a computational framework for teaching language models to predict chemical reaction mechanisms through arrow pushing formalism, a century-old notation that tracks electron flow while respecting conservation laws. We developed MechSMILES, a compact textual format encoding molecular structure and electron flow, and trained language models on four mechanism prediction tasks of increasing complexity using mechanistic reaction datasets, such as mech-USPTO-31k and FlowER. Our models achieve more than 95\% top-3 accuracy on elementary step prediction and scores that surpass 73\% on mech-USPTO-31k, and 93\% on FlowER dataset for the retrieval of complete reaction mechanisms on our hardest task. This mechanistic understanding enables three key applications. First, our models serve as post-hoc validators for CASP systems, filtering chemically implausible transformations. Second, they enable holistic atom-to-atom mapping that tracks all atoms, including hydrogens. Third, they extract catalyst-aware reaction templates that distinguish recycled catalysts from spectator species. By grounding predictions in physically meaningful electron moves that ensure conservation of mass and charge, this work provides a pathway toward more explainable and chemically valid computational synthesis planning, while providing an architecture-agnostic framework for the benchmarking of mechanism prediction.

</details>


### [136] [Towards agent-based-model informed neural networks](https://arxiv.org/abs/2512.05764)
*Nino Antulov-Fantulin*

Main category: cs.LG

TL;DR: 提出ABM-NNs框架，结合图神经网络与层次分解，实现符合代理模型约束的可解释神经网络动力学建模。


<details>
  <summary>Details</summary>
Motivation: 标准神经微分方程难以保留复杂系统中的非物理约束（如质量守恒、网络局部性、有界理性），亟需结构化建模方法。

Method: 引入ABM-NNs，通过受限图神经网络与层次分解，学习符合代理模型结构的动力学系统。

Result: 在三类复杂系统中验证：恢复Lotka-Volterra参数、SIR模型预测优于GCN等基线、真实宏观经济数据中实现政策反事实分析。

Conclusion: ABM-NNs能有效融合领域知识与数据驱动建模，提升模型可解释性、泛化性与政策分析能力。

Abstract: In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka--Volterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.

</details>


### [137] [Learnability Window in Gated Recurrent Neural Networks](https://arxiv.org/abs/2512.05790)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 本文提出一个理论框架，揭示门控机制通过有效学习率决定RNN可学习时间窗口，指出梯度噪声与门控谱结构共同影响长期依赖学习能力。


<details>
  <summary>Details</summary>
Motivation: 经典分析仅关注雅可比乘积的数值稳定性，但无法解释为何门控RNN能学习长程依赖，亟需从梯度传输机制出发建立新理论。

Method: 引入每延迟步和每神经元的有效学习率 $μ_{t,	au}$，通过一阶展开分析门控引起的雅可比乘积，在α-稳定梯度噪声下推导样本复杂度与学习率包络 $f(ℓ)$ 的幂律关系。

Result: 证明可学习窗口 $\mathcal{H}_N \propto f(ℓ)^{-α}$，并给出对数、多项式和指数衰减下 $\mathcal{H}_N$ 的闭式表达，发现门控谱越宽或异质性越高，$\mathcal{H}_N$ 越大；噪声越重尾，$\mathcal{H}_N$ 越小。

Conclusion: 有效学习率是决定门控RNN能否学习长程依赖的核心量，连接了门控结构、梯度噪声与样本复杂度，为设计长时依赖模型提供理论指导。

Abstract: We develop a theoretical framework that explains how gating mechanisms determine the learnability window $\mathcal{H}_N$ of recurrent neural networks, defined as the largest temporal horizon over which gradient information remains statistically recoverable. While classical analyses emphasize numerical stability of Jacobian products, we show that stability alone is insufficient: learnability is governed instead by the \emph{effective learning rates} $μ_{t,\ell}$, per-lag and per-neuron quantities obtained from first-order expansions of gate-induced Jacobian products in Backpropagation Through Time. These effective learning rates act as multiplicative filters that control both the magnitude and anisotropy of gradient transport. Under heavy-tailed ($α$-stable) gradient noise, we prove that the minimal sample size required to detect a dependency at lag~$\ell$ satisfies $N(\ell)\propto f(\ell)^{-α}$, where $f(\ell)=\|μ_{t,\ell}\|_1$ is the effective learning rate envelope. This leads to an explicit formula for $\mathcal{H}_N$ and closed-form scaling laws for logarithmic, polynomial, and exponential decay of $f(\ell)$. The theory predicts that broader or more heterogeneous gate spectra produce slower decay of $f(\ell)$ and hence larger learnability windows, whereas heavier-tailed noise compresses $\mathcal{H}_N$ by slowing statistical concentration. By linking gate-induced time-scale structure, gradient noise, and sample complexity, the framework identifies the effective learning rates as the fundamental quantities that govern when -- and for how long -- gated recurrent networks can learn long-range temporal dependencies.

</details>


### [138] [Mechanistic Interpretability of Antibody Language Models Using SAEs](https://arxiv.org/abs/2512.05794)
*Rebonto Haque,Oliver M. Turnbull,Anisha Parsan,Nithin Parsan,John J. Yang,Charlotte M. Deane*

Main category: cs.LG

TL;DR: TopK和Ordered SAEs用于分析抗体语言模型p-IgGen，发现TopK适合概念映射，Ordered更适合精准生成控制。


<details>
  <summary>Details</summary>
Motivation: 提升领域特异性蛋白语言模型的机制可解释性，并实现对生成过程的精准控制。

Method: 采用TopK和Ordered稀疏自编码器分析p-IgGen模型的潜在特征，比较其在概念识别与生成引导上的表现。

Result: TopK SAE能揭示生物学意义的特征但无法保证因果控制；Ordered SAE能可靠识别可引导特征，但激活模式更复杂、可解释性更低。

Conclusion: TopK SAE适用于特征-概念映射，Ordered SAE更适合需要精确生成引导的场景。

Abstract: Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.

</details>


### [139] [Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws](https://arxiv.org/abs/2512.05817)
*Zhengquan Luo,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 提出统一理论框架解释数据集蒸馏的通用原理，揭示样本规模与配置多样性间的线性关系，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法缺乏统一理论基础，不同方法基于异构目标和假设，难以分析共性或提供泛化保证，且不清楚在训练配置变化时蒸馏数据是否仍有效。

Method: 提出配置-动力学-误差分析框架，将主流方法统一到泛化误差视角，推导出缩放定律和覆盖定律。

Result: （i）缩放定律：蒸馏样本量增加时误差下降并饱和；（ii）覆盖定律：所需样本量与配置多样性呈线性关系，上下界匹配。

Conclusion: 统一框架解释了不同匹配方法的等价性，为设计高效、鲁棒的数据集蒸馏提供了理论指导。

Abstract: Dataset distillation (DD) aims to construct compact synthetic datasets that allow models to achieve comparable performance to full-data training while substantially reducing storage and computation. Despite rapid empirical progress, its theoretical foundations remain limited: existing methods (gradient, distribution, trajectory matching) are built on heterogeneous surrogate objectives and optimization assumptions, which makes it difficult to analyze their common principles or provide general guarantees. Moreover, it is still unclear under what conditions distilled data can retain the effectiveness of full datasets when the training configuration, such as optimizer, architecture, or augmentation, changes. To answer these questions, we propose a unified theoretical framework, termed configuration--dynamics--error analysis, which reformulates major DD approaches under a common generalization-error perspective and provides two main results: (i) a scaling law that provides a single-configuration upper bound, characterizing how the error decreases as the distilled sample size increases and explaining the commonly observed performance saturation effect; and (ii) a coverage law showing that the required distilled sample size scales linearly with configuration diversity, with provably matching upper and lower bounds. In addition, our unified analysis reveals that various matching methods are interchangeable surrogates, reducing the same generalization error, clarifying why they can all achieve dataset distillation and providing guidance on how surrogate choices affect sample efficiency and robustness. Experiments across diverse methods and configurations empirically confirm the derived laws, advancing a theoretical foundation for DD and enabling theory-driven design of compact, configuration-robust dataset distillation.

</details>


### [140] [Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization](https://arxiv.org/abs/2512.05825)
*Shuhei Watanabe*

Main category: cs.LG

TL;DR: 本文填补了超体积近似算法在贝叶斯优化中的算法描述空白，提供了完整的数学与算法细节。


<details>
  <summary>Details</summary>
Motivation: 超体积改进计算的高计算成本是多目标贝叶斯优化的瓶颈，现有精确方法内存复杂度过高，而近似方法缺乏严谨描述。

Method: 提出并详细阐述了一种超体积近似算法，补全了文献中缺失的算法描述与数学推导。

Result: 首次系统化提供了该近似算法的完整数学与算法细节。

Conclusion: 该工作为高效多目标贝叶斯优化提供了可实现的近似方法基础。

Abstract: Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\lfloor \frac{M + 1}{2} \rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.

</details>


### [141] [NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation](https://arxiv.org/abs/2512.05844)
*Daniel Rose,Roxane Axel Jacob,Johannes Kirchmair,Thierry Langer*

Main category: cs.LG

TL;DR: NEAT是一种高效、自回归的集变换器，无需依赖原子顺序假设即可生成3D分子结构，性能接近最优且具有原子置换不变性。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型依赖原子顺序假设，与分子图的置换不变性不匹配，需借助规范顺序或焦点原子规避问题。

Method: NEAT将分子图视为原子集合，通过自回归流模型学习边界可接受令牌的顺序无关分布。

Result: NEAT在3D分子生成任务中达到近似最优性能，兼具高计算效率和原子置换不变性。

Conclusion: NEAT为可扩展的分子设计提供了实用基础，摆脱了对人为顺序的依赖。

Abstract: Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.

</details>


### [142] [Sparse Attention Post-Training for Mechanistic Interpretability](https://arxiv.org/abs/2512.05865)
*Florent Draye,Anson Lei,Ingmar Posner,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 一种后训练方法使Transformer注意力稀疏化，不牺牲性能，稀疏度达0.3%，并提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 减少Transformer注意力计算冗余，提升模型结构的可解释性与组织性。

Method: 在约束损失目标下应用灵活的稀疏正则化，对高达10亿参数的模型进行后训练稀疏化。

Result: 在保持原预训练损失的前提下，注意力连接减少至约0.3%，任务相关电路组件减少达100倍，全局电路简化。

Conclusion: Transformer注意力可大幅稀疏化，表明大量计算冗余，稀疏性可作为构建更结构化、可解释模型的指导原则。

Abstract: We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\approx 0.3 \%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.

</details>


### [143] [Predicting Price Movements in High-Frequency Financial Data with Spiking Neural Networks](https://arxiv.org/abs/2512.05868)
*Brian Ezinwoke,Oliver Rhodes*

Main category: cs.LG

TL;DR: 使用脉冲神经网络（SNN）结合贝叶斯优化提升高频交易中价格脉冲预测性能，提出PSA目标函数，显著超越传统模型。


<details>
  <summary>Details</summary>
Motivation: 传统金融模型难以捕捉高频交易中的毫秒级价格脉冲，SNN因天然处理离散事件和时序信息而具优势。

Method: 将高频股价数据转换为脉冲序列，比较三种SNN架构，并引入PSA（惩罚性脉冲精度）作为贝叶斯优化的目标函数。

Result: 基于PSA优化的扩展SNN模型在回测中实现76.8%的累积收益，远超监督模型（42.54%）和SA优化模型。

Conclusion: SNN结合任务特定目标函数（如PSA）在高频价格脉冲预测中具有显著潜力。

Abstract: Modern high-frequency trading (HFT) environments are characterized by sudden price spikes that present both risk and opportunity, but conventional financial models often fail to capture the required fine temporal structure. Spiking Neural Networks (SNNs) offer a biologically inspired framework well-suited to these challenges due to their natural ability to process discrete events and preserve millisecond-scale timing. This work investigates the application of SNNs to high-frequency price-spike forecasting, enhancing performance via robust hyperparameter tuning with Bayesian Optimization (BO). This work converts high-frequency stock data into spike trains and evaluates three architectures: an established unsupervised STDP-trained SNN, a novel SNN with explicit inhibitory competition, and a supervised backpropagation network. BO was driven by a novel objective, Penalized Spike Accuracy (PSA), designed to ensure a network's predicted price spike rate aligns with the empirical rate of price events. Simulated trading demonstrated that models optimized with PSA consistently outperformed their Spike Accuracy (SA)-tuned counterparts and baselines. Specifically, the extended SNN model with PSA achieved the highest cumulative return (76.8%) in simple backtesting, significantly surpassing the supervised alternative (42.54% return). These results validate the potential of spiking networks, when robustly tuned with task-specific objectives, for effective price spike forecasting in HFT.

</details>


### [144] [Computational Design of Low-Volatility Lubricants for Space Using Interpretable Machine Learning](https://arxiv.org/abs/2512.05870)
*Daniel Miliate,Ashlie Martini*

Main category: cs.LG

TL;DR: 使用机器学习预测适合太空环境的液体润滑剂蒸气压，加速新型润滑剂筛选


<details>
  <summary>Details</summary>
Motivation: 太空机械组件需要低蒸气压液体润滑剂，但现有选项有限且存在设计约束

Method: 基于高通量分子动力学和实验数据训练可解释性机器学习模型

Result: 识别出化学结构与蒸气压的关系，提出若干潜在候选分子

Conclusion: 数据驱动方法可有效助力太空润滑剂的虚拟筛选与设计

Abstract: The function and lifetime of moving mechanical assemblies (MMAs) in space depend on the properties of lubricants. MMAs that experience high speeds or high cycles require liquid based lubricants due to their ability to reflow to the point of contact. However, only a few liquid-based lubricants have vapor pressures low enough for the vacuum conditions of space, each of which has limitations that add constraints to MMA designs. This work introduces a data-driven machine learning (ML) approach to predicting vapor pressure, enabling virtual screening and discovery of new space-suitable liquid lubricants. The ML models are trained with data from both high-throughput molecular dynamics simulations and experimental databases. The models are designed to prioritize interpretability, enabling the relationships between chemical structure and vapor pressure to be identified. Based on these insights, several candidate molecules are proposed that may have promise for future space lubricant applications in MMAs.

</details>


### [145] [Neural Coherence : Find higher performance to out-of-distribution tasks from few samples](https://arxiv.org/abs/2512.05880)
*Simon Guiroy,Mats Richter,Sarath Chandar,Christopher Pal*

Main category: cs.LG

TL;DR: 提出一种名为神经一致性（Neural Coherence）的新方法，仅用少量无标签目标数据即可高效选择预训练模型检查点，显著提升跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 在目标数据稀缺、无标签且分布外时，传统基于内分布验证的模型选择方法不可靠，亟需高效、无监督的模型选择策略。

Method: 引入神经一致性概念，通过分析源域与目标域的激活统计特性，构建仅需少量无标签目标样本的模型选择准则，并将其扩展至训练数据选择。

Result: 在ImageNet预训练基础上，于Food-101、PlantNet-300K、iNaturalist等任务及元学习设置中，显著优于现有基线方法。

Conclusion: 神经一致性是一种高效、通用的模型选择与数据选择原则，适用于低资源、分布外场景，具有广泛适用性。

Abstract: To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.

</details>


### [146] [DAE-HardNet: A Physics Constrained Neural Network Enforcing Differential-Algebraic Hard Constraints](https://arxiv.org/abs/2512.05881)
*Rahul Golder,Bimol Nath Roy,M. M. Faruque Hasan*

Main category: cs.LG

TL;DR: DAE-HardNet通过可微投影层同时学习函数及其导数，严格满足微分代数方程约束，显著降低物理损失并提升建模精度。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs仅软性最小化物理约束违反，难以严格满足微分算子约束，而数据驱动模型难以直接获取导数。

Method: 提出DAE-HardNet，引入可微投影层，同步学习函数与导数，并强制投影至约束流形，联合优化代数与微分约束。

Result: 在Lotka-Volterra系统和瞬态热传导等DAE问题中，DAE-HardNet物理损失降低数个数量级，保持预测精度，并能估计未知参数。

Conclusion: DAE-HardNet实现严格物理约束嵌入，优于MLP和PINN，且可选省略投影层加速推理，代码已开源。

Abstract: Traditional physics-informed neural networks (PINNs) do not always satisfy physics based constraints, especially when the constraints include differential operators. Rather, they minimize the constraint violations in a soft way. Strict satisfaction of differential-algebraic equations (DAEs) to embed domain knowledge and first-principles in data-driven models is generally challenging. This is because data-driven models consider the original functions to be black-box whose derivatives can only be obtained after evaluating the functions. We introduce DAE-HardNet, a physics-constrained (rather than simply physics-informed) neural network that learns both the functions and their derivatives simultaneously, while enforcing algebraic as well as differential constraints. This is done by projecting model predictions onto the constraint manifold using a differentiable projection layer. We apply DAE-HardNet to several systems and test problems governed by DAEs, including the dynamic Lotka-Volterra predator-prey system and transient heat conduction. We also show the ability of DAE-HardNet to estimate unknown parameters through a parameter estimation problem. Compared to multilayer perceptrons (MLPs) and PINNs, DAE-HardNet achieves orders of magnitude reduction in the physics loss while maintaining the prediction accuracy. It has the added benefits of learning the derivatives which improves the constrained learning of the backbone neural network prior to the projection layer. For specific problems, this suggests that the projection layer can be bypassed for faster inference. The current implementation and codes are available at https://github.com/SOULS-TAMU/DAE-HardNet.

</details>


### [147] [NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process](https://arxiv.org/abs/2512.05893)
*Neha Gupta,Aditya Maheshwari*

Main category: cs.LG

TL;DR: 使用LSTM模型估算分数泊松过程的参数，显著优于传统矩估计方法，并在真实数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统矩估计方法在处理具有记忆性和长程依赖的事件到达过程时精度有限，需更强大的时序建模方法。

Method: 采用长短期记忆网络（LSTM）从到达间隔时间序列中直接估计分数泊松过程的参数μ和β。

Result: 在合成数据上MSE降低55.3%，在真实数据（紧急呼叫和股票交易）中能有效捕捉日间模式与参数变化。

Conclusion: LSTM框架在建模具有长程依赖的事件过程方面优于传统方法，具有良好的实际应用潜力。

Abstract: In this paper, we propose a recurrent neural network (RNN)-based framework for estimating the parameters of the fractional Poisson process (FPP), which models event arrivals with memory and long-range dependence. The Long Short-Term Memory (LSTM) network estimates the key parameters $μ>0$ and $β\in(0,1)$ from sequences of inter-arrival times, effectively modeling their temporal dependencies. Our experiments on synthetic data show that the proposed approach reduces the mean squared error (MSE) by about 55.3\% compared to the traditional method of moments (MOM) and performs reliably across different training conditions. We tested the method on two real-world high-frequency datasets: emergency call records from Montgomery County, PA, and AAPL stock trading data. The results show that the LSTM can effectively track daily patterns and parameter changes, indicating its effectiveness on real-world data with complex time dependencies.

</details>


### [148] [LDLT $\mathcal{L}$-Lipschitz Network: Generalized Deep End-To-End Lipschitz Network Construction](https://arxiv.org/abs/2512.05915)
*Marius F. R. Juston,Ramavarapu S. Sreenivas,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.LG

TL;DR: 本文提出一种基于LMI和LDL^分解的框架，可构造满足Lipschitz约束的深度残差网络及其他层次架构，提升对抗鲁棒性与认证性，并在121个UCI数据集上实现3%-13%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 为增强神经网络的对抗鲁棒性和可认证性，需控制其Lipschitz常数，但现有方法在保持表达能力与效率之间存在权衡。

Method: 将ResNet重构为循环三对角LMI，推导参数约束；引入LDL^分解认证LMI可行性，扩展至任意非线性架构，并结合Cholesky分解实现高效参数化。

Result: 所提方法在保持网络表达力的同时，实现3%-13%的准确率提升，优于SLL层，并适用于对抗鲁棒训练与控制系统。

Conclusion: 该框架提供了一种通用、高效且紧致的Lipschitz约束网络设计方法，兼具理论保证与实际性能优势。

Abstract: Deep residual networks (ResNets) have demonstrated outstanding success in computer vision tasks, attributed to their ability to maintain gradient flow through deep architectures. Simultaneously, controlling the Lipschitz constant in neural networks has emerged as an essential area of research to enhance adversarial robustness and network certifiability. This paper presents a rigorous approach to the general design of $\mathcal{L}$-Lipschitz deep residual networks using a Linear Matrix Inequality (LMI) framework. Initially, the ResNet architecture was reformulated as a cyclic tridiagonal LMI, and closed-form constraints on network parameters were derived to ensure $\mathcal{L}$-Lipschitz continuity; however, using a new $LDL^\top$ decomposition approach for certifying LMI feasibility, we extend the construction of $\mathcal{L}$-Lipchitz networks to any other nonlinear architecture. Our contributions include a provable parameterization methodology for constructing Lipschitz-constrained residual networks and other hierarchical architectures. Cholesky decomposition is also used for efficient parameterization. These findings enable robust network designs applicable to adversarial robustness, certified training, and control systems. The $LDL^\top$ formulation is shown to be a tight relaxation of the SDP-based network, maintaining full expressiveness and achieving 3\%-13\% accuracy gains over SLL Layers on 121 UCI data sets.

</details>


### [149] [KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity](https://arxiv.org/abs/2512.05916)
*Damien Lesens,Beheshteh T. Rakhshan,Guillaume Rabusseau*

Main category: cs.LG

TL;DR: KQ-SVD通过直接对注意力矩阵进行最优低秩分解，显著提升KV缓存压缩效率与精度。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法仅对键（keys）或联合嵌入查询与键，未考虑注意力机制依赖于键值内积的本质，导致近似效果次优。

Method: 提出KQ-SVD，利用闭式解对注意力矩阵进行最优低秩分解，直接针对注意力计算的冗余源进行压缩。

Result: 在LLaMA和Mistral模型上的实验表明，KQ-SVD在压缩后保持了更高的注意力输出保真度，投影质量优于现有方法。

Conclusion: KQ-SVD通过聚焦注意力矩阵的内在结构，实现了更高效且精准的KV缓存压缩，为大规模语言模型推理提供新思路。

Abstract: The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.

</details>


### [150] [On the Bayes Inconsistency of Disagreement Discrepancy Surrogates](https://arxiv.org/abs/2512.05931)
*Neil G. Marchant,Andrew C. Cullen,Feng Liu,Sarah M. Erfani*

Main category: cs.LG

TL;DR: 提出一种新的不一致差异损失函数，解决现有代理损失不一致的问题，提升模型在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在真实场景中因分布偏移而失效，不一致差异是应对该问题的关键指标，但现有代理损失不具贝叶斯一致性。

Method: 理论分析现有代理损失的最优性缺口，提出一种与交叉熵结合的新型一致代理损失。

Result: 新损失函数在多种基准上更准确鲁棒地估计不一致差异，尤其在对抗条件下表现优越。

Conclusion: 所提方法为不一致差异优化提供了理论保障与实用工具，显著提升模型分布偏移鲁棒性。

Abstract: Deep neural networks often fail when deployed in real-world contexts due to distribution shift, a critical barrier to building safe and reliable systems. An emerging approach to address this problem relies on \emph{disagreement discrepancy} -- a measure of how the disagreement between two models changes under a shifting distribution. The process of maximizing this measure has seen applications in bounding error under shifts, testing for harmful shifts, and training more robust models. However, this optimization involves the non-differentiable zero-one loss, necessitating the use of practical surrogate losses. We prove that existing surrogates for disagreement discrepancy are not Bayes consistent, revealing a fundamental flaw: maximizing these surrogates can fail to maximize the true disagreement discrepancy. To address this, we introduce new theoretical results providing both upper and lower bounds on the optimality gap for such surrogates. Guided by this theory, we propose a novel disagreement loss that, when paired with cross-entropy, yields a provably consistent surrogate for disagreement discrepancy. Empirical evaluations across diverse benchmarks demonstrate that our method provides more accurate and robust estimates of disagreement discrepancy than existing approaches, particularly under challenging adversarial conditions.

</details>


### [151] [Developing synthetic microdata through machine learning for firm-level business surveys](https://arxiv.org/abs/2512.05948)
*Jorge Cisneros Paz,Timothy Wojan,Matthew Williams,Jennifer Ozawa,Robert Chew,Kimberly Janda,Timothy Navarro,Michael Floyd,Christine Task,Damon Streat*

Main category: cs.LG

TL;DR: 本文利用机器学习生成符合美国商业调查（ABS）特征的合成微观数据，解决匿名化与数据可用性之间的矛盾，并通过经济计量验证其真实性。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力提升和大数据普及，传统匿名化数据易被重新识别，威胁受访者隐私；同时，企业数据因行业集中性更难匿名，亟需安全可用的替代数据。

Method: 采用机器学习模型构建合成PUMS，基于2007年企业主调查数据生成两组合成数据集，并通过经济计量复现已有高影响力研究来评估质量。

Result: 合成数据成功复现了发表于《Small Business Economics》的实证结果，表明其在统计特征与经济行为上高度接近真实数据。

Conclusion: 合成数据为敏感企业调查数据提供了可行的公共使用方案，未来可推广至ABS等更大规模数据集，促进研究与政策分析。

Abstract: Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.

</details>


### [152] [Impugan: Learning Conditional Generative Models for Robust Data Imputation](https://arxiv.org/abs/2512.05950)
*Zalish Mahmud,Anantaa Kotal,Aritran Piplai*

Main category: cs.LG

TL;DR: 提出Impugan，一种基于条件生成对抗网络的缺失值填补方法，在异构数据整合中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据常缺失且异构，传统插补方法假设线性与独立性，难以应对复杂数据分布，导致偏差或过度平滑。

Method: 采用条件生成对抗网络（cGAN），通过生成器重构缺失值，判别器区分真实与插补数据，学习观测变量与缺失变量间的非线性、多模态关系。

Result: 在基准数据集和多源整合任务中，Impugan相比基线方法降低最多82%的地球移动距离（EMD）和70%的互信息偏差（MI）。

Conclusion: 对抗训练的生成模型为缺失值填补和异构数据融合提供了可扩展且稳健的解决方案。

Abstract: Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\% lower Earth Mover's Distance (EMD) and 70\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025

</details>


### [153] [MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution](https://arxiv.org/abs/2512.05958)
*Sara Patel,Mingxun Zhou,Giulia Fanti*

Main category: cs.LG

TL;DR: 提出MaxShapley算法，高效公平地分配生成式搜索引擎中内容提供者的贡献补偿。


<details>
  <summary>Details</summary>
Motivation: 传统搜索被LLM生成式搜索取代，亟需公平的机制来评估和补偿内容提供者的贡献。

Method: 引入MaxShapley算法，基于可分解的max-sum效用函数，将Shapley值计算复杂度从指数级降低至线性。

Result: 在HotPotQA、MuSiQUE、MS MARCO三个多跳问答数据集上，MaxShapley与精确Shapley值效果相当，资源消耗最多降低8倍。

Conclusion: MaxShapley实现了高效且公平的贡献 Attribution，为生成式搜索生态的可持续发展提供可行方案。

Abstract: Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.

</details>


### [154] [Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity](https://arxiv.org/abs/2512.05962)
*Germán Kruszewski,Pierre Erbacher,Jos Rozen,Marc Dymetman*

Main category: cs.LG

TL;DR: 通过α-散度家族优化LLM的推理任务，平衡精度与多样性，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统RL训练导致模型多样性丧失，因其隐式优化逆KL散度，过度集中于高概率区域。

Method: 从过滤后的正确答案分布出发，使用α-散度家族近似目标分布，通过α参数调控精度-多样性权衡。

Result: 在Lean定理证明基准上，该方法在覆盖度指标上达到SOTA，优于所有先前方法。

Conclusion: α-散度提供灵活框架，有效解决RL训练中的多样性损失问题。

Abstract: Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the "mode-seeking" or "zero-forcing" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [155] [Wake Vectoring for Efficient Morphing Flight](https://arxiv.org/abs/2512.05211)
*Ioannis Mandralis,Severin Schumacher,Morteza Gharib*

Main category: cs.RO

TL;DR: 提出一种被动尾流偏转机制，在飞行形态变化时恢复高达40%的垂直推力，提升空中机器人的稳定性和机动性。


<details>
  <summary>Details</summary>
Motivation: 飞行中形态变化会导致推力损失，影响稳定与控制，需解决无额外机械复杂度下的推力恢复问题。

Method: 在ATMO机器人中集成被动定子偏转器，拦截并向下引导旋翼尾流，利用气流动量实现推力恢复。

Result: 在无有效推力的形态下，垂直推力恢复率达40%，显著延长悬停与机动能力。

Conclusion: 被动气动结构可高效实现形态变化飞行，为下一代可变形空中机器人提供新设计方向。

Abstract: Morphing aerial robots have the potential to transform autonomous flight, enabling navigation through cluttered environments, perching, and seamless transitions between aerial and terrestrial locomotion. Yet mid-flight reconfiguration presents a critical aerodynamic challenge: tilting propulsors to achieve shape change reduces vertical thrust, undermining stability and control authority. Here, we introduce a passive wake vectoring mechanism that recovers lost thrust during morphing. Integrated into a novel robotic system, Aerially Transforming Morphobot (ATMO), internal deflectors intercept and redirect rotor wake downward, passively steering airflow momentum that would otherwise be wasted. This electronics-free solution achieves up to a 40% recovery of vertical thrust in configurations where no useful thrust would otherwise be produced, substantially extending hover and maneuvering capabilities during transformation. Our findings highlight a new direction for morphing aerial robot design, where passive aerodynamic structures, inspired by thrust vectoring in rockets and aircraft, enable efficient, agile flight without added mechanical complexity.

</details>


### [156] [Search at Scale: Improving Numerical Conditioning of Ergodic Coverage Optimization for Multi-Scale Domains](https://arxiv.org/abs/2512.05229)
*Yanis Lahrach,Christian Hughes,Ian Abraham*

Main category: cs.RO

TL;DR: 提出一种基于MMD的尺度无关自适应遍历覆盖优化方法，提升数值稳定性并保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有遍历覆盖方法对问题空间数值尺度敏感，优化 formulation 易受非线性约束影响而数值不稳定。

Method: 基于最大均值差异（MMD）构建尺度无关优化框架，结合对数空间变体与超参数退火机制，自适应调整微分约束尺度。

Result: 在多种覆盖问题中验证了方法的数值稳定性和性能优势，优于现有方法。

Conclusion: 所提方法有效解决尺度敏感问题，提升遍历覆盖的鲁棒性与适用性。

Abstract: Recent methods in ergodic coverage planning have shown promise as tools that can adapt to a wide range of geometric coverage problems with general constraints, but are highly sensitive to the numerical scaling of the problem space. The underlying challenge is that the optimization formulation becomes brittle and numerically unstable with changing scales, especially under potentially nonlinear constraints that impose dynamic restrictions, due to the kernel-based formulation. This paper proposes to address this problem via the development of a scale-agnostic and adaptive ergodic coverage optimization method based on the maximum mean discrepancy metric (MMD). Our approach allows the optimizer to solve for the scale of differential constraints while annealing the hyperparameters to best suit the problem domain and ensure physical consistency. We also derive a variation of the ergodic metric in the log space, providing additional numerical conditioning without loss of performance. We compare our approach with existing coverage planning methods and demonstrate the utility of our approach on a wide range of coverage problems.

</details>


### [157] [Invariance Co-training for Robot Visual Generalization](https://arxiv.org/abs/2512.05230)
*Jonathan Yang,Chelsea Finn,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 通过引入状态相似性和观测不变性辅助任务，结合机器人演示数据与合成视觉数据，显著提升机器人在多变观测条件下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人策略对摄像头视角、光照和干扰物等观测变化敏感，因缺乏覆盖这些变化的大规模数据。

Method: 提出两个辅助任务：状态相似性和观测扰动不变性，联合训练机器人演示数据与非物理仿真生成的视觉数据。

Result: 在未见过的视角、光照和干扰条件下，性能比现有生成增强方法提升18%。

Conclusion: 结合低成本合成数据与高成本演示数据，能有效提升机器人泛化能力，突破数据稀缺瓶颈。

Abstract: Reasoning from diverse observations is a fundamental capability for generalist robot policies to operate in a wide range of environments. Despite recent advancements, many large-scale robotic policies still remain sensitive to key sources of observational variation such as changes in camera perspective, lighting, and the presence of distractor objects. We posit that the limited generalizability of these models arises from the substantial diversity required to robustly cover these quasistatic axes, coupled with the current scarcity of large-scale robotic datasets that exhibit rich variation across them. In this work, we propose to systematically examine what robots need to generalize across these challenging axes by introducing two key auxiliary tasks, state similarity and invariance to observational perturbations, applied to both demonstration data and static visual data. We then show that via these auxiliary tasks, leveraging both more-expensive robotic demonstration data and less-expensive, visually rich synthetic images generated from non-physics-based simulation (for example, Unreal Engine) can lead to substantial increases in generalization to unseen camera viewpoints, lighting configurations, and distractor conditions. Our results demonstrate that co-training on this diverse data improves performance by 18 percent over existing generative augmentation methods. For more information and videos, please visit https://invariance-cotraining.github.io

</details>


### [158] [XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots](https://arxiv.org/abs/2512.05270)
*Tianyi Wang,Jiseop Byeon,Ahmad Yehia,Huihai Wang,Yiming Xu,Tianyi Zeng,Ziran Wang,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 提出XR-DT框架，结合扩展现实与数字孪生，提升人机交互的可解释性与信任度。


<details>
  <summary>Details</summary>
Motivation: 现有研究侧重于人类行为预测，忽视人类对机器人推理的感知与信任，制约其在安全关键环境中的部署。

Method: 构建分层XR-DT架构，融合虚拟/增强/混合现实，结合Unity仿真、实时传感数据、AR穿戴设备反馈，并设计扩散策略与Chain-of-Thought提示机制，辅以AutoGen多智能体协同。

Result: 实验验证了人与机器人轨迹预测的准确性，证明XR-DT在HRI任务中有效提升交互的可解释性、可信度与适应性。

Conclusion: XR-DT通过整合人类意图、环境动态与机器人认知，实现可解释、可信且自适应的人机协同。

Abstract: As mobile robots increasingly operate alongside humans in shared workspaces, ensuring safe, efficient, and interpretable Human-Robot Interaction (HRI) has become a pressing challenge. While substantial progress has been devoted to human behavior prediction, limited attention has been paid to how humans perceive, interpret, and trust robots' inferences, impeding deployment in safety-critical and socially embedded environments. This paper presents XR-DT, an eXtended Reality-enhanced Digital Twin framework for agentic mobile robots, that bridges physical and virtual spaces to enable bi-directional understanding between humans and robots. Our hierarchical XR-DT architecture integrates virtual-, augmented-, and mixed-reality layers, fusing real-time sensor data, simulated environments in the Unity game engine, and human feedback captured through wearable AR devices. Within this framework, we design an agentic mobile robot system with a unified diffusion policy for context-aware task adaptation. We further propose a chain-of-thought prompting mechanism that allows multimodal large language models to reason over human instructions and environmental context, while leveraging an AutoGen-based multi-agent coordination layer to enhance robustness and collaboration in dynamic tasks. Initial experimental results demonstrate accurate human and robot trajectory prediction, validating the XR-DT framework's effectiveness in HRI tasks. By embedding human intention, environmental dynamics, and robot cognition into the XR-DT framework, our system enables interpretable, trustworthy, and adaptive HRI.

</details>


### [159] [Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture](https://arxiv.org/abs/2512.05292)
*Fan Zhang,Jinfeng Chen,Joseph J. B. Mvogo Ahanda,Hanz Richter,Ge Lv,Bin Hu,Qin Lin*

Main category: cs.RO

TL;DR: 提出一种可轻松集成的外环控制器，结合扰动抑制与鲁棒控制屏障函数，实现工业机械臂的高精度跟踪与安全控制，适用于不可修改的内环控制器和不确定动力学模型。


<details>
  <summary>Details</summary>
Motivation: 工业机器人内环力矩控制器通常不可修改且存在不确定性，外环控制器需在保证安全的前提下提升跟踪性能。

Method: 在外部环路层结合扰动拒绝控制与鲁棒控制屏障函数，实现动态系统高精度跟踪与安全约束保障。

Result: 在PUMA机械臂上实验证明，该方法在实现简单性、鲁棒性、跟踪精度和安全性上优于现有方法。

Conclusion: 所提方法为不可修改内环控制器的工业机器人提供了一种高效、安全、易部署的外环控制解决方案。

Abstract: In commercial robotic systems, it is common to encounter a closed inner-loop torque controller that is not user-modifiable. However, the outer-loop controller, which sends kinematic commands such as position or velocity for the inner-loop controller to track, is typically exposed to users. In this work, we focus on the development of an easily integrated add-on at the outer-loop layer by combining disturbance rejection control and robust control barrier function for high-performance tracking and safe control of the whole dynamic system of an industrial manipulator. This is particularly beneficial when 1) the inner-loop controller is imperfect, unmodifiable, and uncertain; and 2) the dynamic model exhibits significant uncertainty. Stability analysis, formal safety guarantee proof, and hardware experiments with a PUMA robotic manipulator are presented. Our solution demonstrates superior performance in terms of simplicity of implementation, robustness, tracking precision, and safety compared to the state of the art. Video: https://youtu.be/zw1tanvrV8Q

</details>


### [160] [Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite](https://arxiv.org/abs/2512.05303)
*Christian Westerdahl,Jonas Poulsen,Daniel Holmelund,Peter Nicholas Hansen,Fletcher Thompson,Roberto Galeazzi*

Main category: cs.RO

TL;DR: 提出一种无需GNSS的统一海底到天空测绘系统，融合LiDAR-IMU与双正交前视声呐，实现实时三维映射。


<details>
  <summary>Details</summary>
Motivation: 现有海底到天空测绘依赖GNSS或昂贵声呐，易受遮挡和欺骗，亟需鲁棒、低成本的替代方案。

Method: 融合LiDAR-IMU与双正交前视声呐（FLS），扩展正交宽孔径融合算法处理非共置声呐，提取声呐前沿形成线扫描，并改进LIO-SAM以融合声呐点云与线扫描数据，构建单一因子图地图。

Result: 在哥本哈根Belvederekanalen实测数据中实现2.65 Hz地图更新与2.85 Hz里程计，生成跨空气-水介质的统一三维模型。

Conclusion: 该系统实现了GNSS独立、实时、高精度的跨介质测绘，为自主水面航行器提供了鲁棒的环境感知能力。

Abstract: Critical maritime infrastructure increasingly demands situational awareness both above and below the surface, yet existing ''seabed-to-sky'' mapping pipelines either rely on GNSS (vulnerable to shadowing/spoofing) or expensive bathymetric sonars. We present a unified, GNSS-independent mapping system that fuses LiDAR-IMU with a dual, orthogonally mounted Forward Looking Sonars (FLS) to generate consistent seabed-to-sky maps from an Autonomous Surface Vehicle. On the acoustic side, we extend orthogonal wide-aperture fusion to handle arbitrary inter-sonar translations (enabling heterogeneous, non-co-located models) and extract a leading edge from each FLS to form line-scans. On the mapping side, we modify LIO-SAM to ingest both stereo-derived 3D sonar points and leading-edge line-scans at and between keyframes via motion-interpolated poses, allowing sparse acoustic updates to contribute continuously to a single factor-graph map. We validate the system on real-world data from Belvederekanalen (Copenhagen), demonstrating real-time operation with approx. 2.65 Hz map updates and approx. 2.85 Hz odometry while producing a unified 3D model that spans air-water domains.

</details>


### [161] [State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning](https://arxiv.org/abs/2512.05335)
*Yuxiang Liu,Shengfan Cao*

Main category: cs.RO

TL;DR: 提出一种无需专家数据的视觉域迁移方法SCAL，实现高效模仿学习


<details>
  <summary>Details</summary>
Motivation: 在目标域数据稀缺、无专家示范且为离策略的情况下，实现视觉域间的端到端模仿学习

Method: 提出状态条件对抗学习（SCAL），通过判别器估计源域与目标域观测模型的条件KL散度，对齐潜在分布

Result: 在BARC-CARLA模拟器上的视觉多样驾驶环境中，SCAL展现出鲁棒的迁移能力和高样本效率

Conclusion: 理论分析指导的条件KL对齐方法能有效解决离策略视觉域迁移问题

Abstract: We study visual domain transfer for end-to-end imitation learning in a realistic and challenging setting where target-domain data are strictly off-policy, expert-free, and scarce. We first provide a theoretical analysis showing that the target-domain imitation loss can be upper bounded by the source-domain loss plus a state-conditional latent KL divergence between source and target observation models. Guided by this result, we propose State- Conditional Adversarial Learning, an off-policy adversarial framework that aligns latent distributions conditioned on system state using a discriminator-based estimator of the conditional KL term. Experiments on visually diverse autonomous driving environments built on the BARC-CARLA simulator demonstrate that SCAL achieves robust transfer and strong sample efficiency.

</details>


### [162] [Spatiotemporal Tubes for Differential Drive Robots with Model Uncertainty](https://arxiv.org/abs/2512.05495)
*Ratnangshu Das,Ahan Basu,Christos Verginis,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出基于时空管的控制框架，实现动态不确定环境下差动轮机器人满足时序可达-避障-停留规范的高效鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖模型近似或在线优化，难以同时保证鲁棒性、计算效率与形式化安全约束满足。

Method: 采用时变圆形时空管定义安全走廊，结合采样综合算法生成可行管路，并设计解析闭合形式控制律实现无近似、无在线优化的实时控制。

Result: 仿真验证表明，该方法在鲁棒性、精度和计算效率上优于现有方法，且无需模型近似或在线优化。

Conclusion: 所提框架为动态不确定环境下时序安全控制提供了高效、可靠且形式化保证的解决方案。

Abstract: This paper presents a Spatiotemporal Tube (STT)-based control framework for differential-drive mobile robots with dynamic uncertainties and external disturbances, guaranteeing the satisfaction of Temporal Reach-Avoid-Stay (T-RAS) specifications. The approach employs circular STT, characterized by smoothly time-varying center and radius, to define dynamic safe corridors that guide the robot from the start region to the goal while avoiding obstacles. In particular, we first develop a sampling-based synthesis algorithm to construct a feasible STT that satisfies the prescribed timing and safety constraints with formal guarantees. To ensure that the robot remains confined within this tube, we then design analytically a closed-form, approximation-free control law. The resulting controller is computationally efficient, robust to disturbances and {model uncertainties}, and requires no model approximations or online optimization. The proposed framework is validated through simulation studies on a differential-drive robot and benchmarked against state-of-the-art methods, demonstrating superior robustness, accuracy, and computational efficiency.

</details>


### [163] [A Hyperspectral Imaging Guided Robotic Grasping System](https://arxiv.org/abs/2512.05578)
*Zheng Sun,Zhipeng Dong,Shixiong Wang,Zhongyi Chu,Fei Chen*

Main category: cs.RO

TL;DR: 提出一种基于高光谱成像的机器人抓取系统PRISM+SpectralGrasp，显著提升纺织品识别与分拣成功率。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在机器人抓取中应用受限于部署复杂性和高成本，亟需低成本高效集成方案。

Method: 设计PRISM光学机制实现无畸变高光谱成像，结合SpectralGrasp框架融合空间与光谱信息生成抓取策略。

Result: 在纺织品识别上超越人类表现，分拣成功率显著优于RGB方法，实验验证了系统有效性。

Conclusion: 高光谱成像与机器人抓取融合可大幅提升复杂环境下的识别与抓取能力，具有广阔应用前景。

Abstract: Hyperspectral imaging is an advanced technique for precisely identifying and analyzing materials or objects. However, its integration with robotic grasping systems has so far been explored due to the deployment complexities and prohibitive costs. Within this paper, we introduce a novel hyperspectral imaging-guided robotic grasping system. The system consists of PRISM (Polyhedral Reflective Imaging Scanning Mechanism) and the SpectralGrasp framework. PRISM is designed to enable high-precision, distortion-free hyperspectral imaging while simplifying system integration and costs. SpectralGrasp generates robotic grasping strategies by effectively leveraging both the spatial and spectral information from hyperspectral images. The proposed system demonstrates substantial improvements in both textile recognition compared to human performance and sorting success rate compared to RGB-based methods. Additionally, a series of comparative experiments further validates the effectiveness of our system. The study highlights the potential benefits of integrating hyperspectral imaging with robotic grasping systems, showcasing enhanced recognition and grasping capabilities in complex and dynamic environments. The project is available at: https://zainzh.github.io/PRISM.

</details>


### [164] [A Comprehensive Framework for Automated Quality Control in the Automotive Industry](https://arxiv.org/abs/2512.05579)
*Panagiota Moraiti,Panagiotis Giannikos,Athanasios Mastrogeorgiou,Panagiotis Mavridis,Linghao Zhou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 本文提出一种基于协作机器人与YOLO11n深度学习模型的自动化汽车零部件缺陷检测系统，实现高精度、实时的表面与螺纹缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 传统人工质检效率低、易出错，汽车制造中对铝合金高压压铸件的缺陷检测需求日益增长，亟需自动化解决方案。

Method: 采用双协作机器人搭载高分辨率视觉系统，结合优化照明与镜头，使用增强型YOLO11n模型（含图像切片、集成学习和边界框合并），并运用图像处理技术估算缺陷程度。

Result: 系统在多种缺陷类型上实现高精度与实时检测，显著降低误检率，具备良好的泛化能力和稳定性。

Conclusion: 该方案高效、可扩展，可灵活适配不同产线，满足汽车行业对质量控制的持续升级需求。

Abstract: This paper presents a cutting-edge robotic inspection solution designed to automate quality control in automotive manufacturing. The system integrates a pair of collaborative robots, each equipped with a high-resolution camera-based vision system to accurately detect and localize surface and thread defects in aluminum high-pressure die casting (HPDC) automotive components. In addition, specialized lenses and optimized lighting configurations are employed to ensure consistent and high-quality image acquisition. The YOLO11n deep learning model is utilized, incorporating additional enhancements such as image slicing, ensemble learning, and bounding-box merging to significantly improve performance and minimize false detections. Furthermore, image processing techniques are applied to estimate the extent of the detected defects. Experimental results demonstrate real-time performance with high accuracy across a wide variety of defects, while minimizing false detections. The proposed solution is promising and highly scalable, providing the flexibility to adapt to various production environments and meet the evolving demands of the automotive industry.

</details>


### [165] [An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation](https://arxiv.org/abs/2512.05599)
*Panagiotis Giannikos,Lampis Papakostas,Evangelos Katralis,Panagiotis Mavridis,George Chryssinas,Myrto Inglezou,Nikolaos Panagopoulos,Antonis Porichis,Athanasios Mastrogeorgiou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 提出一种结合双能X射线成像与YOLO/U-Net模型的自动化电池检测与分拣系统，在仿真和真实环境中验证。


<details>
  <summary>Details</summary>
Motivation: 电池用量激增与资源有限促使回收需求上升，但现有检测方法在复杂WEEE中准确率不足，且存在安全风险。

Method: 采用双能X射线成像提升材料对比度，结合YOLO检测与U-Net分割，通过智能追踪算法控制Delta机器人精准抓取电池设备。

Result: 在NVIDIA Isaac Sim仿真及真实系统中均实现高精度电池识别与分拣，显著优于传统视觉方法。

Conclusion: 该系统为复杂WEEE中电池自动化回收提供了高效、安全的全新解决方案。

Abstract: Battery recycling is becoming increasingly critical due to the rapid growth in battery usage and the limited availability of natural resources. Moreover, as battery energy densities continue to rise, improper handling during recycling poses significant safety hazards, including potential fires at recycling facilities. Numerous systems have been proposed for battery detection and removal from WEEE recycling lines, including X-ray and RGB-based visual inspection methods, typically driven by AI-powered object detection models (e.g., Mask R-CNN, YOLO, ResNets). Despite advances in optimizing detection techniques and model modifications, a fully autonomous solution capable of accurately identifying and sorting batteries across diverse WEEEs types has yet to be realized. In response to these challenges, we present our novel approach which integrates a specialized X-ray transmission dual energy imaging subsystem with advanced pre-processing algorithms, enabling high-contrast image reconstruction for effective differentiation of dense and thin materials in WEEE. Devices move along a conveyor belt through a high-resolution X-ray imaging system, where YOLO and U-Net models precisely detect and segment battery-containing items. An intelligent tracking and position estimation algorithm then guides a Delta robot equipped with a suction gripper to selectively extract and properly discard the targeted devices. The approach is validated in a photorealistic simulation environment developed in NVIDIA Isaac Sim and on the real setup.

</details>


### [166] [Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees](https://arxiv.org/abs/2512.05682)
*Yiming Shu,Jiahui Xu,Linghuan Kong,Fangni Zhang,Guodong Yin,Chen Sun*

Main category: cs.RO

TL;DR: 提出一种场景感知的轨迹预测不确定性量化框架，结合CopulaCPTS校准与轨迹可靠性判别器，实现安全驾驶中的可靠风险评估。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习预测方法缺乏适应异构真实场景的不确定性感知框架，影响自动驾驶系统的安全性。

Method: 将预测轨迹与真实轨迹投影到Frenet坐标系下的参考路径，使用CopulaCPTS生成场景相关的时序预测区间，并通过轨迹可靠性判别器（TRD）结合均值误差与校准置信区间建立场景化可靠性模型，再利用风险感知判别器融合纵向与横向区间识别关键点，分割可靠/不可靠轨迹段。

Result: 在nuPlan真实数据集上验证了框架在多样驾驶场景中有效实现场景感知的不确定性量化与可靠性评估。

Conclusion: 该框架为下游规划模块提供了可操作的轨迹可靠性信息，显著提升自动驾驶系统在复杂场景中的安全决策能力。

Abstract: Reliable uncertainty quantification in trajectory prediction is crucial for safety-critical autonomous driving systems, yet existing deep learning predictors lack uncertainty-aware frameworks adaptable to heterogeneous real-world scenarios. To bridge this gap, we propose a novel scenario-aware uncertainty quantification framework to provide the predicted trajectories with prediction intervals and reliability assessment. To begin with, predicted trajectories from the trained predictor and their ground truth are projected onto the map-derived reference routes within the Frenet coordinate system. We then employ CopulaCPTS as the conformal calibration method to generate temporal prediction intervals for distinct scenarios as the uncertainty measure. Building upon this, within the proposed trajectory reliability discriminator (TRD), mean error and calibrated confidence intervals are synergistically analyzed to establish reliability models for different scenarios. Subsequently, the risk-aware discriminator leverages a joint risk model that integrates longitudinal and lateral prediction intervals within the Frenet coordinate to identify critical points. This enables segmentation of trajectories into reliable and unreliable segments, holding the advantage of informing downstream planning modules with actionable reliability results. We evaluated our framework using the real-world nuPlan dataset, demonstrating its effectiveness in scenario-aware uncertainty quantification and reliability assessment across diverse driving contexts.

</details>


### [167] [HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies](https://arxiv.org/abs/2512.05693)
*Zhiying Du,Bei Liu,Yaobo Liang,Yichao Shen,Haidong Cao,Xiangyu Zheng,Zhiyuan Feng,Zuxuan Wu,Jiaolong Yang,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: 提出HiMoE-VLA框架，通过分层混合专家架构有效处理机器人数据异构性，显著提升跨机器人与动作空间的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型难以处理机器人数据中因体形态、动作空间、传感器配置和控制频率等带来的显著异构性，导致泛化能力受限。

Method: 设计分层混合专家（HiMoE）架构，在动作模块中自适应处理多源异构性，并逐层抽象为共享知识表示。

Result: 在仿真与真实机器人平台上，HiMoE-VLA相比现有VLA基线模型在准确率和泛化性上均取得一致提升。

Conclusion: HiMoE-VLA为异构机器人数据的统一建模提供了有效解决方案，推动了具身智能基础模型的发展。

Abstract: The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.

</details>


### [168] [Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning](https://arxiv.org/abs/2512.05711)
*Ali Krayani,Seyedeh Fatemeh Sadati,Lucio Marcenaro,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 提出一种基于贝叶斯主动推断的无人机分层轨迹规划框架，以应对对抗性干扰。


<details>
  <summary>Details</summary>
Motivation: 传统无模型强化学习方法在对抗性干扰环境下泛化能力差，且需大量训练数据，亟需一种能结合专家演示与概率建模的鲁棒规划方法。

Method: 采用贝叶斯主动推断，融合专家演示、概率生成模型与无线信号反馈，实现高层符号规划、底层运动策略与干扰感知的联合建模，并在线推理以动态调整轨迹。

Result: 仿真表明，该方法接近专家性能，显著降低通信干扰与任务成本，优于无模型强化学习基线，且在动态环境中保持强泛化能力。

Conclusion: 该框架有效提升了无人机在未知干扰环境中的自主规划与适应能力，为抗干扰无人机系统提供了新范式。

Abstract: This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.

</details>


### [169] [3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering](https://arxiv.org/abs/2512.05803)
*Blanca Inigo,Benjamin D. Killeen,Rebecca Choi,Michelle Song,Ali Uneri,Majid Khan,Christopher Bailey,Axel Krieger,Mathias Unberath*

Main category: cs.RO

TL;DR: 提出一种基于可微渲染的CT-free 3D经椎弓根路径规划框架，仅用双平面X射线即可实现高精度椎体重建与机器人辅助椎体成形术路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖术前CT与术中2D图像配准，但在椎体成形术中常无术前CT，增加负担与成本，亟需无需CT的解决方案。

Method: 结合可微渲染、统计形状模型（SSM）和学习的相似性损失，动态优化椎体形状与位姿，仅使用任意视角的双平面X射线进行3D重建与路径规划。

Result: 重建DICE达0.75，优于基线（0.65），接近SOTA模型ReVerteR（0.77）；双侧路径规划成功率：合成数据82%、尸检数据75%，显著高于2D-3D基线（66%和31%）。

Conclusion: 该框架实现无需术前CT的灵活、通用3D路径规划，适应真实世界成像多样性，推动机器人辅助椎体成形术的临床应用。

Abstract: Robotic systems are transforming image-guided interventions by enhancing accuracy and minimizing radiation exposure. A significant challenge in robotic assistance lies in surgical path planning, which often relies on the registration of intraoperative 2D images with preoperative 3D CT scans. This requirement can be burdensome and costly, particularly in procedures like vertebroplasty, where preoperative CT scans are not routinely performed. To address this issue, we introduce a differentiable rendering-based framework for 3D transpedicular path planning utilizing bi-planar 2D X-rays. Our method integrates differentiable rendering with a vertebral atlas generated through a Statistical Shape Model (SSM) and employs a learned similarity loss to refine the SSM shape and pose dynamically, independent of fixed imaging geometries. We evaluated our framework in two stages: first, through vertebral reconstruction from orthogonal X-rays for benchmarking, and second, via clinician-in-the-loop path planning using arbitrary-view X-rays. Our results indicate that our method outperformed a normalized cross-correlation baseline in reconstruction metrics (DICE: 0.75 vs. 0.65) and achieved comparable performance to the state-of-the-art model ReVerteR (DICE: 0.77), while maintaining generalization to arbitrary views. Success rates for bipedicular planning reached 82% with synthetic data and 75% with cadaver data, exceeding the 66% and 31% rates of a 2D-to-3D baseline, respectively. In conclusion, our framework facilitates versatile, CT-free 3D path planning for robot-assisted vertebroplasty, effectively accommodating real-world imaging diversity without the need for preoperative CT scans.

</details>


### [170] [Global stability of vehicle-with-driver dynamics via Sum-of-Squares programming](https://arxiv.org/abs/2512.05806)
*Martino Gulisano,Marco Gabiccini*

Main category: cs.RO

TL;DR: 使用SOS方法估计车辆-驾驶员系统的安全不变集，支持实时安全评估


<details>
  <summary>Details</summary>
Motivation: 需要在考虑状态安全约束的前提下，准确估计车辆-驾驶员系统的区域吸引子中的安全子集，以支持实时安全控制

Method: 通过原创的迭代平方和（SOS）优化方法，构建多项式李亚普诺夫函数，结合非线性车辆模型的多项式近似及其操作包络约束

Result: 在二维基准和车辆-驾驶员系统中成功恢复安全区域，SOS方法产生的安全集与仿真边界高度一致，验证了其有效性

Conclusion: SOS技术能高效生成李亚普诺夫定义的安全区域，具备作为主动车辆控制监督层的潜力

Abstract: This work estimates safe invariant subsets of the Region of Attraction (ROA) for a seven-state vehicle-with-driver system, capturing both asymptotic stability and the influence of state-safety bounds along the system trajectory. Safe sets are computed by optimizing Lyapunov functions through an original iterative Sum-of-Squares (SOS) procedure. The method is first demonstrated on a two-state benchmark, where it accurately recovers a prescribed safe region as the 1-level set of a polynomial Lyapunov function. We then describe the distinguishing characteristics of the studied vehicle-with-driver system: the control dynamics mimic human driver behavior through a delayed preview-tracking model that, with suitable parameter choices, can also emulate digital controllers. To enable SOS optimization, a polynomial approximation of the nonlinear vehicle model is derived, together with its operating-envelope constraints. The framework is then applied to understeering and oversteering scenarios, and the estimated safe sets are compared with reference boundaries obtained from exhaustive simulations. The results show that SOS techniques can efficiently deliver Lyapunov-defined safe regions, supporting their potential use for real-time safety assessment, for example as a supervisory layer for active vehicle control.

</details>


### [171] [Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots](https://arxiv.org/abs/2512.05808)
*Sushmita Bhattacharya,Ninad Jadhav,Hammad Izhar,Karen Li,Kevin George,Robert Wood,Stephanie Gil*

Main category: cs.RO

TL;DR: 使用自主无人机结合模型强化学习实现实时抹香鲸海上会合


<details>
  <summary>Details</summary>
Motivation: 实现对抹香鲸的实时追踪与会合，克服多鲸声学追踪、分布式决策和机载信号处理等挑战

Method: 采用基于模型的强化学习，融合现场传感器数据与经验性鲸鱼潜水模型进行导航决策

Result: 在多米尼克海域成功完成抹香鲸会合实验，并通过陆地硬件实验和模拟验证了系统有效性

Conclusion: 该系统为海洋哺乳动物的非侵入式实时追踪提供了可行的技术方案

Abstract: We introduce a system for real-time sperm whale rendezvous at sea using an autonomous uncrewed aerial vehicle. Our system employs model-based reinforcement learning that combines in situ sensor data with an empirical whale dive model to guide navigation decisions. Key challenges include (i) real-time acoustic tracking in the presence of multiple whales, (ii) distributed communication and decision-making for robot deployments, and (iii) on-board signal processing and long-range detection from fish-trackers. We evaluate our system by conducting rendezvous with sperm whales at sea in Dominica, performing hardware experiments on land, and running simulations using whale trajectories interpolated from marine biologists' surface observations.

</details>


### [172] [Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation](https://arxiv.org/abs/2512.05812)
*Fabian Konstantinidis,Moritz Sackmann,Ulrich Hofmann,Christoph Stiller*

Main category: cs.RO

TL;DR: 通过实例中心表示和对抗逆强化学习，实现高效且真实的多智能体驾驶模拟。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体驾驶模拟面临真实性和计算效率难以兼顾的问题。

Method: 采用实例中心场景表示，结合对称上下文编码器与相对位置编码，并使用对抗逆强化学习与自适应奖励变换训练行为模型。

Result: 显著降低训练与推理时间，超越多个智能体中心基线，在位置精度和鲁棒性上表现更优。

Conclusion: 该方法有效平衡了效率与真实性，为大规模多智能体驾驶模拟提供了可行方案。

Abstract: Scalable multi-agent driving simulation requires behavior models that are both realistic and computationally efficient. We address this by optimizing the behavior model that controls individual traffic participants. To improve efficiency, we adopt an instance-centric scene representation, where each traffic participant and map element is modeled in its own local coordinate frame. This design enables efficient, viewpoint-invariant scene encoding and allows static map tokens to be reused across simulation steps. To model interactions, we employ a query-centric symmetric context encoder with relative positional encodings between local frames. We use Adversarial Inverse Reinforcement Learning to learn the behavior model and propose an adaptive reward transformation that automatically balances robustness and realism during training. Experiments demonstrate that our approach scales efficiently with the number of tokens, significantly reducing training and inference times, while outperforming several agent-centric baselines in terms of positional accuracy and robustness.

</details>


### [173] [Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints](https://arxiv.org/abs/2512.05815)
*Marios-Nektarios Stamatopoulos,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出一种多无人机协同3D打印的优化调度框架，实现无冲突并行作业并动态优化无人机数量。


<details>
  <summary>Details</summary>
Motivation: 解决多无人机在3D打印中因任务依赖、安全约束和资源限制导致的协同冲突与效率低下问题。

Method: 构建基于任务分解与资源约束的优化模型，动态分配任务时空起点，引入重要性优先级加速求解，并通过效用最大化确定最优无人机数量。

Result: 在Gazebo仿真中验证了框架的有效性，实现了材料与电池约束下的无冲突协同打印。

Conclusion: 该框架显著提升多无人机3D打印的协同效率与资源利用率，支持动态扩展无人机队列以平衡时间与成本。

Abstract: This article presents a novel coordination and task-planning framework to enable the simultaneous conflict-free collaboration of multiple unmanned aerial vehicles (UAVs) for aerial 3D printing. The proposed framework formulates an optimization problem that takes a construction mission divided into sub-tasks and a team of autonomous UAVs, along with limited volume and battery. It generates an optimal mission plan comprising task assignments and scheduling while accounting for task dependencies arising from the geometric and structural requirements of the 3D design, inter-UAV safety constraints, material usage, and total flight time of each UAV. The potential conflicts occurring during the simultaneous operation of the UAVs are addressed at a segment level by dynamically selecting the starting time and location of each task to guarantee collision-free parallel execution. An importance prioritization is proposed to accelerate the computation by guiding the solution toward more important tasks. Additionally, a utility maximization formulation is proposed to dynamically determine the optimal number of UAVs required for a given mission, balancing the trade-off between minimizing makespan and the deployment of excess agents. The proposed framework's effectiveness is evaluated through a Gazebo-based simulation setup, where agents are coordinated by a mission control module allocating the printing tasks based on the generated optimal scheduling plan while remaining within the material and battery constraints of each UAV.

</details>


### [174] [Physically-Based Simulation of Automotive LiDAR](https://arxiv.org/abs/2512.05932)
*L. Dudzik,M. Roschani,A. Sielemann,K. Trampert,J. Ziehn,J. Beyerer,C. Neumann*

Main category: cs.RO

TL;DR: 提出一种基于物理渲染的汽车ToF LiDAR仿真模型，包含 blooms、回波脉宽和环境光，通过实验室测量标定参数，并在Valeo Scala Gen.2和Blickfeld Cube 1上验证。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR仿真模型缺乏对真实物理效应（如blooming、环境光、非零光束直径）的精确建模，限制了仿真可靠性。

Method: 采用近红外域的物理渲染（PBR）方法，模拟单次反射与后向反射，结合实验室高分辨率光度测量（0.01°）获取系统参数，涵盖光束特性、接收灵敏度、发射强度与环境光照等。

Result: 成功为Valeo Scala Gen.2和Blickfeld Cube 1两个不同结构的车规LiDAR系统提取关键模型参数，并实现高保真仿真。

Conclusion: 该模型具备系统通用性与参数可测量性，为汽车LiDAR系统设计与测试提供高精度仿真工具。

Abstract: We present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter.
  Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties.
  Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01° resolution, which marks the best available resolution for measuring the beam pattern.
  The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.

</details>


### [175] [Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning](https://arxiv.org/abs/2512.05953)
*Yunhao Cao,Zubin Bhaumik,Jessie Jia,Xingyi He,Kuan Fang*

Main category: cs.RO

TL;DR: COIL是一种基于关键点对应关系的模仿学习框架，用于3D视觉运动控制，支持灵活的空间和时间粒度任务表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于固定关键点数量和均匀时间间隔，难以适应多样化的用户意图和任务需求。

Method: 提出COIL框架，通过时空注意力机制融合多模态信息，利用仿真中自监督生成的对应标签进行训练。

Result: COIL在真实世界操作任务中优于现有方法，能泛化至不同任务、物体和运动模式，适用于稀疏和密集任务规格。

Conclusion: COIL通过灵活的对应导向表示和自监督学习，实现了高效、通用的视觉运动控制。

Abstract: We introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.

</details>


### [176] [SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models](https://arxiv.org/abs/2512.05955)
*Haowen Liu,Shaoxiong Yao,Haonan Chen,Jiawei Gao,Jiayuan Mao,Jia-Bin Huang,Yilun Du*

Main category: cs.RO

TL;DR: SIMPACT通过测试时仿真增强视觉语言模型的物理推理能力，无需重新训练即可实现精细机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型缺乏对物理动态的地面理解，难以用于需物理推理的机器人操作任务。

Method: SIMPACT在测试时通过RGB-D观测构建物理仿真，让VLM迭代提出动作并观察仿真结果，结合语言与物理预测进行推理。

Result: 在五个真实世界的刚体和柔性操作任务中，SIMPACT性能超越现有通用机器人模型。

Conclusion: 通过测试时仿真嵌入物理理解，为通用具身智能提供了有前景的新路径。

Abstract: Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

</details>


### [177] [Training-Time Action Conditioning for Efficient Real-Time Chunking](https://arxiv.org/abs/2512.05964)
*Kevin Black,Allen Z. Ren,Michael Equi,Sergey Levine*

Main category: cs.RO

TL;DR: 训练时模拟推理延迟以替代推理时的修复操作，实现更高效的实时动作预测，无需修改模型架构。


<details>
  <summary>Details</summary>
Motivation: 推理时的修复方法引入计算开销，增加推理延迟，影响实时机器人控制效率。

Method: 在训练时模拟推理延迟，直接以动作前缀为条件，避免推理时的计算负担。

Result: 在仿真和真实机器人任务中，训练时RTC在保持性能和速度的同时，计算开销更低，优于推理时RTC。

Conclusion: 训练时动作条件化是推理时修复的实用替代方案，适用于实时机器人控制。

Abstract: Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.

</details>
